2021-08-13 11:08:13,269 - mmseg - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.7.6 (default, Jan  8 2020, 19:59:22) [GCC 7.3.0]
CUDA available: True
GPU 0,1,2,3,4,5,6,7: TITAN Xp
CUDA_HOME: /mnt/lustre/share/polaris/dep/cuda-9.0-cudnn7.6.5
NVCC: Cuda compilation tools, release 9.0, V9.0.176
GCC: gcc (GCC) 5.4.0
PyTorch: 1.5.0
PyTorch compiling details: PyTorch built with:
  - GCC 5.4
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.1 Product Build 20200208 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v0.21.1 (Git Hash 912ce228837d1ce28e1a61806118835de03f5751)
  - OpenMP 201307 (a.k.a. OpenMP 4.0)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 9.0
  - NVCC architecture flags: -gencode;arch=compute_52,code=sm_52;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_70,code=compute_70
  - CuDNN 7.6.5
  - Magma 2.5.0
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_INTERNAL_THREADPOOL_IMPL -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=ON, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

TorchVision: 0.6.0
OpenCV: 4.2.0
MMCV: 1.3.11
MMCV Compiler: n/a
MMCV CUDA Compiler: n/a
MMSegmentation: 0.16.0+2bb6f37
------------------------------------------------------------

2021-08-13 11:08:13,270 - mmseg - INFO - Distributed training: True
2021-08-13 11:08:13,667 - mmseg - INFO - Config:
norm_cfg = dict(type='SyncBN', requires_grad=True)
model = dict(
    type='EncoderDecoder',
    backbone=dict(
        type='LiteHRNet',
        norm_cfg=dict(type='SyncBN', requires_grad=True),
        norm_eval=False,
        extra=dict(
            stem=dict(stem_channels=32, out_channels=32, expand_ratio=1),
            num_stages=3,
            stages_spec=dict(
                num_modules=(2, 4, 2),
                num_branches=(2, 3, 4),
                num_blocks=(2, 2, 2),
                module_type=('LITE', 'LITE', 'LITE'),
                with_fuse=(True, True, True),
                reduce_ratios=(8, 8, 8),
                num_channels=((40, 80), (40, 80, 160), (40, 80, 160, 320))),
            with_head=False)),
    decode_head=dict(
        type='FCNHead',
        in_channels=40,
        in_index=0,
        channels=40,
        input_transform=None,
        kernel_size=3,
        num_convs=2,
        concat_input=True,
        dropout_ratio=0.1,
        num_classes=150,
        norm_cfg=dict(type='SyncBN', requires_grad=True),
        align_corners=False,
        loss_decode=dict(
            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0)),
    train_cfg=dict(),
    test_cfg=dict(mode='whole'))
dataset_type = 'ADE20KDataset'
data_root = 'data/ade/ADEChallengeData2016'
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
crop_size = (512, 512)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations', reduce_zero_label=True),
    dict(type='Resize', img_scale=(2048, 512), ratio_range=(0.5, 2.0)),
    dict(type='RandomCrop', crop_size=(512, 512), cat_max_ratio=0.75),
    dict(type='RandomFlip', prob=0.5),
    dict(type='PhotoMetricDistortion'),
    dict(
        type='Normalize',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='Pad', size=(512, 512), pad_val=0, seg_pad_val=255),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_semantic_seg'])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(2048, 512),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
data = dict(
    samples_per_gpu=4,
    workers_per_gpu=4,
    train=dict(
        type='ADE20KDataset',
        data_root='data/ade/ADEChallengeData2016',
        img_dir='images/training',
        ann_dir='annotations/training',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations', reduce_zero_label=True),
            dict(type='Resize', img_scale=(2048, 512), ratio_range=(0.5, 2.0)),
            dict(type='RandomCrop', crop_size=(512, 512), cat_max_ratio=0.75),
            dict(type='RandomFlip', prob=0.5),
            dict(type='PhotoMetricDistortion'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='Pad', size=(512, 512), pad_val=0, seg_pad_val=255),
            dict(type='DefaultFormatBundle'),
            dict(type='Collect', keys=['img', 'gt_semantic_seg'])
        ]),
    val=dict(
        type='ADE20KDataset',
        data_root='data/ade/ADEChallengeData2016',
        img_dir='images/validation',
        ann_dir='annotations/validation',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(2048, 512),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]),
    test=dict(
        type='ADE20KDataset',
        data_root='data/ade/ADEChallengeData2016',
        img_dir='images/validation',
        ann_dir='annotations/validation',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(2048, 512),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]))
log_config = dict(
    interval=50, hooks=[dict(type='TextLoggerHook', by_epoch=False)])
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]
cudnn_benchmark = True
optimizer = dict(type='SGD', lr=0.01, momentum=0.9, weight_decay=0.0005)
optimizer_config = dict()
lr_config = dict(policy='poly', power=0.9, min_lr=0.0001, by_epoch=False)
runner = dict(type='IterBasedRunner', max_iters=160000)
checkpoint_config = dict(by_epoch=False, interval=16000)
evaluation = dict(interval=16000, metric='mIoU')
find_unused_parameters = True
work_dir = './work_dirs/fcn_litehr18-without-head_512x512_160k_ade20k'
gpu_ids = range(0, 1)

2021-08-13 11:08:13,667 - mmseg - INFO - Set random seed to 0, deterministic: False
2021-08-13 11:08:14,003 - mmseg - INFO - initialize LiteHRNet with init_cfg [{'type': 'Normal', 'std': 0.001, 'layer': 'Conv2d'}, {'type': 'Constant', 'val': 1, 'layer': ['_BatchNorm', 'GroupNorm']}]
2021-08-13 11:08:14,281 - mmseg - INFO - initialize FCNHead with init_cfg {'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
Name of parameter - Initialization information

backbone.stem.conv1.conv.weight - torch.Size([32, 3, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.stem.conv1.bn.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stem.conv1.bn.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stem.branch1.0.conv.weight - torch.Size([16, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stem.branch1.0.bn.weight - torch.Size([16]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stem.branch1.0.bn.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stem.branch1.1.conv.weight - torch.Size([16, 16, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stem.branch1.1.bn.weight - torch.Size([16]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stem.branch1.1.bn.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stem.expand_conv.conv.weight - torch.Size([32, 16, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.stem.expand_conv.bn.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stem.expand_conv.bn.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stem.depthwise_conv.conv.weight - torch.Size([32, 1, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.stem.depthwise_conv.bn.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stem.depthwise_conv.bn.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stem.linear_conv.conv.weight - torch.Size([16, 32, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.stem.linear_conv.bn.weight - torch.Size([16]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stem.linear_conv.bn.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.transition0.0.0.weight - torch.Size([32, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.transition0.0.1.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.transition0.0.1.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.transition0.0.2.weight - torch.Size([40, 32, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.transition0.0.3.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.transition0.0.3.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.transition0.1.0.0.weight - torch.Size([32, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.transition0.1.0.1.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.transition0.1.0.1.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.transition0.1.0.2.weight - torch.Size([80, 32, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.transition0.1.0.3.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.transition0.1.0.3.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.0.cross_resolution_weighting.conv1.conv.weight - torch.Size([7, 60, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.layers.0.cross_resolution_weighting.conv1.bn.weight - torch.Size([7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.0.cross_resolution_weighting.conv1.bn.bias - torch.Size([7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.0.cross_resolution_weighting.conv2.conv.weight - torch.Size([60, 7, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.layers.0.cross_resolution_weighting.conv2.bn.weight - torch.Size([60]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.0.cross_resolution_weighting.conv2.bn.bias - torch.Size([60]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.0.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.layers.0.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.0.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.0.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.layers.0.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.0.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.0.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.layers.0.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.0.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.layers.0.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.0.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.layers.0.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.0.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.layers.0.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.1.cross_resolution_weighting.conv1.conv.weight - torch.Size([7, 60, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.layers.1.cross_resolution_weighting.conv1.bn.weight - torch.Size([7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.1.cross_resolution_weighting.conv1.bn.bias - torch.Size([7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.1.cross_resolution_weighting.conv2.conv.weight - torch.Size([60, 7, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.layers.1.cross_resolution_weighting.conv2.bn.weight - torch.Size([60]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.1.cross_resolution_weighting.conv2.bn.bias - torch.Size([60]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.1.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.layers.1.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.1.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.1.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.layers.1.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.1.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.1.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.layers.1.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.1.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.layers.1.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.1.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.layers.1.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.1.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.layers.1.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.fuse_layers.0.1.0.weight - torch.Size([40, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.fuse_layers.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.fuse_layers.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.fuse_layers.1.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.fuse_layers.1.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.fuse_layers.1.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.fuse_layers.1.0.0.2.weight - torch.Size([80, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.fuse_layers.1.0.0.3.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.fuse_layers.1.0.0.3.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.0.cross_resolution_weighting.conv1.conv.weight - torch.Size([7, 60, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.layers.0.cross_resolution_weighting.conv1.bn.weight - torch.Size([7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.0.cross_resolution_weighting.conv1.bn.bias - torch.Size([7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.0.cross_resolution_weighting.conv2.conv.weight - torch.Size([60, 7, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.layers.0.cross_resolution_weighting.conv2.bn.weight - torch.Size([60]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.0.cross_resolution_weighting.conv2.bn.bias - torch.Size([60]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.0.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.layers.0.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.0.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.0.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.layers.0.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.0.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.0.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.layers.0.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.0.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.layers.0.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.0.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.layers.0.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.0.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.layers.0.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.1.cross_resolution_weighting.conv1.conv.weight - torch.Size([7, 60, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.layers.1.cross_resolution_weighting.conv1.bn.weight - torch.Size([7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.1.cross_resolution_weighting.conv1.bn.bias - torch.Size([7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.1.cross_resolution_weighting.conv2.conv.weight - torch.Size([60, 7, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.layers.1.cross_resolution_weighting.conv2.bn.weight - torch.Size([60]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.1.cross_resolution_weighting.conv2.bn.bias - torch.Size([60]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.1.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.layers.1.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.1.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.1.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.layers.1.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.1.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.1.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.layers.1.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.1.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.layers.1.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.1.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.layers.1.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.1.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.layers.1.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.fuse_layers.0.1.0.weight - torch.Size([40, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.fuse_layers.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.fuse_layers.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.fuse_layers.1.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.fuse_layers.1.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.fuse_layers.1.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.fuse_layers.1.0.0.2.weight - torch.Size([80, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.fuse_layers.1.0.0.3.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.fuse_layers.1.0.0.3.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.transition1.2.0.0.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.transition1.2.0.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.transition1.2.0.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.transition1.2.0.2.weight - torch.Size([160, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.transition1.2.0.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.transition1.2.0.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.0.cross_resolution_weighting.conv1.conv.weight - torch.Size([17, 140, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.0.cross_resolution_weighting.conv1.bn.weight - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.0.cross_resolution_weighting.conv1.bn.bias - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.0.cross_resolution_weighting.conv2.conv.weight - torch.Size([140, 17, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.0.cross_resolution_weighting.conv2.bn.weight - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.0.cross_resolution_weighting.conv2.bn.bias - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.0.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.0.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.0.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.0.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.0.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.0.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.0.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.0.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.0.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.0.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.0.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.0.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.0.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.0.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.0.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.0.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.0.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.0.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.0.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.0.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.0.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.1.cross_resolution_weighting.conv1.conv.weight - torch.Size([17, 140, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.1.cross_resolution_weighting.conv1.bn.weight - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.1.cross_resolution_weighting.conv1.bn.bias - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.1.cross_resolution_weighting.conv2.conv.weight - torch.Size([140, 17, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.1.cross_resolution_weighting.conv2.bn.weight - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.1.cross_resolution_weighting.conv2.bn.bias - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.1.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.1.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.1.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.1.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.1.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.1.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.1.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.1.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.1.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.1.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.1.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.1.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.1.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.1.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.1.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.1.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.1.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.1.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.1.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.1.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.1.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.0.1.0.weight - torch.Size([40, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.fuse_layers.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.0.2.0.weight - torch.Size([40, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.fuse_layers.0.2.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.0.2.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.1.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.fuse_layers.1.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.1.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.1.0.0.2.weight - torch.Size([80, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.fuse_layers.1.0.0.3.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.1.0.0.3.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.1.2.0.weight - torch.Size([80, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.fuse_layers.1.2.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.1.2.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.2.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.fuse_layers.2.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.2.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.2.0.0.2.weight - torch.Size([40, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.fuse_layers.2.0.0.3.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.2.0.0.3.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.2.0.1.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.fuse_layers.2.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.2.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.2.0.1.2.weight - torch.Size([160, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.fuse_layers.2.0.1.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.2.0.1.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.2.1.0.0.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.fuse_layers.2.1.0.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.2.1.0.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.2.1.0.2.weight - torch.Size([160, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.fuse_layers.2.1.0.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.2.1.0.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.0.cross_resolution_weighting.conv1.conv.weight - torch.Size([17, 140, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.0.cross_resolution_weighting.conv1.bn.weight - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.0.cross_resolution_weighting.conv1.bn.bias - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.0.cross_resolution_weighting.conv2.conv.weight - torch.Size([140, 17, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.0.cross_resolution_weighting.conv2.bn.weight - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.0.cross_resolution_weighting.conv2.bn.bias - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.0.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.0.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.0.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.0.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.0.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.0.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.0.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.0.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.0.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.0.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.0.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.0.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.0.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.0.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.0.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.0.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.0.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.0.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.0.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.0.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.0.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.1.cross_resolution_weighting.conv1.conv.weight - torch.Size([17, 140, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.1.cross_resolution_weighting.conv1.bn.weight - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.1.cross_resolution_weighting.conv1.bn.bias - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.1.cross_resolution_weighting.conv2.conv.weight - torch.Size([140, 17, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.1.cross_resolution_weighting.conv2.bn.weight - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.1.cross_resolution_weighting.conv2.bn.bias - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.1.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.1.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.1.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.1.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.1.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.1.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.1.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.1.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.1.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.1.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.1.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.1.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.1.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.1.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.1.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.1.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.1.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.1.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.1.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.1.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.1.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.0.1.0.weight - torch.Size([40, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.fuse_layers.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.0.2.0.weight - torch.Size([40, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.fuse_layers.0.2.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.0.2.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.1.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.fuse_layers.1.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.1.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.1.0.0.2.weight - torch.Size([80, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.fuse_layers.1.0.0.3.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.1.0.0.3.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.1.2.0.weight - torch.Size([80, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.fuse_layers.1.2.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.1.2.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.2.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.fuse_layers.2.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.2.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.2.0.0.2.weight - torch.Size([40, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.fuse_layers.2.0.0.3.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.2.0.0.3.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.2.0.1.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.fuse_layers.2.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.2.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.2.0.1.2.weight - torch.Size([160, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.fuse_layers.2.0.1.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.2.0.1.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.2.1.0.0.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.fuse_layers.2.1.0.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.2.1.0.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.2.1.0.2.weight - torch.Size([160, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.fuse_layers.2.1.0.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.2.1.0.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.0.cross_resolution_weighting.conv1.conv.weight - torch.Size([17, 140, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.0.cross_resolution_weighting.conv1.bn.weight - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.0.cross_resolution_weighting.conv1.bn.bias - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.0.cross_resolution_weighting.conv2.conv.weight - torch.Size([140, 17, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.0.cross_resolution_weighting.conv2.bn.weight - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.0.cross_resolution_weighting.conv2.bn.bias - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.0.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.0.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.0.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.0.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.0.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.0.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.0.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.0.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.0.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.0.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.0.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.0.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.0.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.0.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.0.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.0.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.0.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.0.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.0.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.0.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.0.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.1.cross_resolution_weighting.conv1.conv.weight - torch.Size([17, 140, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.1.cross_resolution_weighting.conv1.bn.weight - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.1.cross_resolution_weighting.conv1.bn.bias - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.1.cross_resolution_weighting.conv2.conv.weight - torch.Size([140, 17, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.1.cross_resolution_weighting.conv2.bn.weight - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.1.cross_resolution_weighting.conv2.bn.bias - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.1.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.1.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.1.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.1.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.1.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.1.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.1.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.1.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.1.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.1.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.1.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.1.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.1.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.1.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.1.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.1.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.1.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.1.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.1.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.1.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.1.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.0.1.0.weight - torch.Size([40, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.fuse_layers.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.0.2.0.weight - torch.Size([40, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.fuse_layers.0.2.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.0.2.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.1.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.fuse_layers.1.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.1.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.1.0.0.2.weight - torch.Size([80, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.fuse_layers.1.0.0.3.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.1.0.0.3.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.1.2.0.weight - torch.Size([80, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.fuse_layers.1.2.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.1.2.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.2.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.fuse_layers.2.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.2.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.2.0.0.2.weight - torch.Size([40, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.fuse_layers.2.0.0.3.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.2.0.0.3.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.2.0.1.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.fuse_layers.2.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.2.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.2.0.1.2.weight - torch.Size([160, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.fuse_layers.2.0.1.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.2.0.1.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.2.1.0.0.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.fuse_layers.2.1.0.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.2.1.0.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.2.1.0.2.weight - torch.Size([160, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.fuse_layers.2.1.0.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.2.1.0.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.0.cross_resolution_weighting.conv1.conv.weight - torch.Size([17, 140, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.0.cross_resolution_weighting.conv1.bn.weight - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.0.cross_resolution_weighting.conv1.bn.bias - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.0.cross_resolution_weighting.conv2.conv.weight - torch.Size([140, 17, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.0.cross_resolution_weighting.conv2.bn.weight - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.0.cross_resolution_weighting.conv2.bn.bias - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.0.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.0.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.0.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.0.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.0.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.0.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.0.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.0.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.0.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.0.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.0.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.0.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.0.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.0.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.0.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.0.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.0.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.0.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.0.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.0.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.0.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.1.cross_resolution_weighting.conv1.conv.weight - torch.Size([17, 140, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.1.cross_resolution_weighting.conv1.bn.weight - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.1.cross_resolution_weighting.conv1.bn.bias - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.1.cross_resolution_weighting.conv2.conv.weight - torch.Size([140, 17, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.1.cross_resolution_weighting.conv2.bn.weight - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.1.cross_resolution_weighting.conv2.bn.bias - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.1.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.1.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.1.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.1.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.1.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.1.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.1.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.1.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.1.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.1.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.1.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.1.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.1.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.1.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.1.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.1.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.1.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.1.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.1.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.1.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.1.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.0.1.0.weight - torch.Size([40, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.fuse_layers.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.0.2.0.weight - torch.Size([40, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.fuse_layers.0.2.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.0.2.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.1.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.fuse_layers.1.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.1.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.1.0.0.2.weight - torch.Size([80, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.fuse_layers.1.0.0.3.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.1.0.0.3.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.1.2.0.weight - torch.Size([80, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.fuse_layers.1.2.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.1.2.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.2.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.fuse_layers.2.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.2.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.2.0.0.2.weight - torch.Size([40, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.fuse_layers.2.0.0.3.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.2.0.0.3.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.2.0.1.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.fuse_layers.2.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.2.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.2.0.1.2.weight - torch.Size([160, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.fuse_layers.2.0.1.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.2.0.1.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.2.1.0.0.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.fuse_layers.2.1.0.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.2.1.0.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.2.1.0.2.weight - torch.Size([160, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.fuse_layers.2.1.0.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.2.1.0.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.transition2.3.0.0.weight - torch.Size([160, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.transition2.3.0.1.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.transition2.3.0.1.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.transition2.3.0.2.weight - torch.Size([320, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.transition2.3.0.3.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.transition2.3.0.3.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.cross_resolution_weighting.conv1.conv.weight - torch.Size([37, 300, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.0.cross_resolution_weighting.conv1.bn.weight - torch.Size([37]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.cross_resolution_weighting.conv1.bn.bias - torch.Size([37]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.cross_resolution_weighting.conv2.conv.weight - torch.Size([300, 37, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.0.cross_resolution_weighting.conv2.bn.weight - torch.Size([300]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.cross_resolution_weighting.conv2.bn.bias - torch.Size([300]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.0.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.0.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.0.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.depthwise_convs.3.conv.weight - torch.Size([160, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.0.depthwise_convs.3.bn.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.depthwise_convs.3.bn.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.0.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.0.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.0.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.0.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.0.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.0.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.spatial_weighting.3.conv1.conv.weight - torch.Size([40, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.0.spatial_weighting.3.conv1.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.spatial_weighting.3.conv2.conv.weight - torch.Size([160, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.0.spatial_weighting.3.conv2.conv.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.cross_resolution_weighting.conv1.conv.weight - torch.Size([37, 300, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.1.cross_resolution_weighting.conv1.bn.weight - torch.Size([37]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.cross_resolution_weighting.conv1.bn.bias - torch.Size([37]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.cross_resolution_weighting.conv2.conv.weight - torch.Size([300, 37, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.1.cross_resolution_weighting.conv2.bn.weight - torch.Size([300]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.cross_resolution_weighting.conv2.bn.bias - torch.Size([300]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.1.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.1.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.1.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.depthwise_convs.3.conv.weight - torch.Size([160, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.1.depthwise_convs.3.bn.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.depthwise_convs.3.bn.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.1.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.1.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.1.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.1.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.1.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.1.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.spatial_weighting.3.conv1.conv.weight - torch.Size([40, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.1.spatial_weighting.3.conv1.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.spatial_weighting.3.conv2.conv.weight - torch.Size([160, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.1.spatial_weighting.3.conv2.conv.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.0.1.0.weight - torch.Size([40, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.0.2.0.weight - torch.Size([40, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.0.2.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.0.2.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.0.3.0.weight - torch.Size([40, 320, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.0.3.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.0.3.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.1.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.1.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.1.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.1.0.0.2.weight - torch.Size([80, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.1.0.0.3.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.1.0.0.3.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.1.2.0.weight - torch.Size([80, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.1.2.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.1.2.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.1.3.0.weight - torch.Size([80, 320, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.1.3.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.1.3.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.2.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.2.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.2.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.2.0.0.2.weight - torch.Size([40, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.2.0.0.3.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.2.0.0.3.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.2.0.1.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.2.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.2.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.2.0.1.2.weight - torch.Size([160, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.2.0.1.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.2.0.1.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.2.1.0.0.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.2.1.0.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.2.1.0.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.2.1.0.2.weight - torch.Size([160, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.2.1.0.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.2.1.0.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.2.3.0.weight - torch.Size([160, 320, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.2.3.1.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.2.3.1.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.3.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.0.0.2.weight - torch.Size([40, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.3.0.0.3.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.0.0.3.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.0.1.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.3.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.0.1.2.weight - torch.Size([40, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.3.0.1.3.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.0.1.3.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.0.2.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.3.0.2.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.0.2.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.0.2.2.weight - torch.Size([320, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.3.0.2.3.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.0.2.3.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.1.0.0.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.3.1.0.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.1.0.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.1.0.2.weight - torch.Size([80, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.3.1.0.3.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.1.0.3.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.1.1.0.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.3.1.1.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.1.1.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.1.1.2.weight - torch.Size([320, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.3.1.1.3.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.1.1.3.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.2.0.0.weight - torch.Size([160, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.3.2.0.1.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.2.0.1.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.2.0.2.weight - torch.Size([320, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.3.2.0.3.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.2.0.3.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.cross_resolution_weighting.conv1.conv.weight - torch.Size([37, 300, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.0.cross_resolution_weighting.conv1.bn.weight - torch.Size([37]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.cross_resolution_weighting.conv1.bn.bias - torch.Size([37]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.cross_resolution_weighting.conv2.conv.weight - torch.Size([300, 37, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.0.cross_resolution_weighting.conv2.bn.weight - torch.Size([300]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.cross_resolution_weighting.conv2.bn.bias - torch.Size([300]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.0.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.0.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.0.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.depthwise_convs.3.conv.weight - torch.Size([160, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.0.depthwise_convs.3.bn.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.depthwise_convs.3.bn.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.0.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.0.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.0.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.0.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.0.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.0.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.spatial_weighting.3.conv1.conv.weight - torch.Size([40, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.0.spatial_weighting.3.conv1.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.spatial_weighting.3.conv2.conv.weight - torch.Size([160, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.0.spatial_weighting.3.conv2.conv.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.cross_resolution_weighting.conv1.conv.weight - torch.Size([37, 300, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.1.cross_resolution_weighting.conv1.bn.weight - torch.Size([37]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.cross_resolution_weighting.conv1.bn.bias - torch.Size([37]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.cross_resolution_weighting.conv2.conv.weight - torch.Size([300, 37, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.1.cross_resolution_weighting.conv2.bn.weight - torch.Size([300]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.cross_resolution_weighting.conv2.bn.bias - torch.Size([300]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.1.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.1.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.1.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.depthwise_convs.3.conv.weight - torch.Size([160, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.1.depthwise_convs.3.bn.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.depthwise_convs.3.bn.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.1.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.1.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.1.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.1.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.1.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.1.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.spatial_weighting.3.conv1.conv.weight - torch.Size([40, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.1.spatial_weighting.3.conv1.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.spatial_weighting.3.conv2.conv.weight - torch.Size([160, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.1.spatial_weighting.3.conv2.conv.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.0.1.0.weight - torch.Size([40, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.0.2.0.weight - torch.Size([40, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.0.2.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.0.2.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.0.3.0.weight - torch.Size([40, 320, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.0.3.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.0.3.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.1.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.1.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.1.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.1.0.0.2.weight - torch.Size([80, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.1.0.0.3.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.1.0.0.3.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.1.2.0.weight - torch.Size([80, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.1.2.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.1.2.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.1.3.0.weight - torch.Size([80, 320, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.1.3.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.1.3.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.2.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.2.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.2.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.2.0.0.2.weight - torch.Size([40, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.2.0.0.3.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.2.0.0.3.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.2.0.1.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.2.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.2.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.2.0.1.2.weight - torch.Size([160, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.2.0.1.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.2.0.1.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.2.1.0.0.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.2.1.0.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.2.1.0.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.2.1.0.2.weight - torch.Size([160, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.2.1.0.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.2.1.0.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.2.3.0.weight - torch.Size([160, 320, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.2.3.1.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.2.3.1.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.3.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.0.0.2.weight - torch.Size([40, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.3.0.0.3.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.0.0.3.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.0.1.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.3.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.0.1.2.weight - torch.Size([40, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.3.0.1.3.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.0.1.3.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.0.2.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.3.0.2.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.0.2.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.0.2.2.weight - torch.Size([320, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.3.0.2.3.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.0.2.3.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.1.0.0.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.3.1.0.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.1.0.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.1.0.2.weight - torch.Size([80, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.3.1.0.3.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.1.0.3.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.1.1.0.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.3.1.1.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.1.1.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.1.1.2.weight - torch.Size([320, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.3.1.1.3.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.1.1.3.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.2.0.0.weight - torch.Size([160, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.3.2.0.1.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.2.0.1.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.2.0.2.weight - torch.Size([320, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.3.2.0.3.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.2.0.3.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.conv_seg.weight - torch.Size([150, 40, 1, 1]): 
NormalInit: mean=0, std=0.01, bias=0 

decode_head.conv_seg.bias - torch.Size([150]): 
NormalInit: mean=0, std=0.01, bias=0 

decode_head.convs.0.conv.weight - torch.Size([40, 40, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.convs.0.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.convs.0.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.convs.1.conv.weight - torch.Size([40, 40, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.conv_cat.conv.weight - torch.Size([40, 80, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

decode_head.conv_cat.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.conv_cat.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  
2021-08-13 11:08:14,307 - mmseg - INFO - EncoderDecoder(
  (backbone): LiteHRNet(
    (stem): Stem(
      (conv1): ConvModule(
        (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (branch1): Sequential(
        (0): ConvModule(
          (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)
          (bn): SyncBatchNorm(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): ConvModule(
          (conv): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): SyncBatchNorm(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (expand_conv): ConvModule(
        (conv): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (depthwise_conv): ConvModule(
        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)
        (bn): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (linear_conv): ConvModule(
        (conv): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): SyncBatchNorm(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (transition0): ModuleList(
      (0): Sequential(
        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
        (1): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Conv2d(32, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (3): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (4): ReLU()
      )
      (1): Sequential(
        (0): Sequential(
          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)
          (1): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Conv2d(32, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU()
        )
      )
    )
    (stage0): Sequential(
      (0): LiteHRModule(
        (layers): Sequential(
          (0): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(60, 7, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(7, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
          (1): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(60, 7, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(7, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
        )
        (fuse_layers): ModuleList(
          (0): ModuleList(
            (0): None
            (1): Sequential(
              (0): Conv2d(80, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
          )
          (1): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): None
          )
        )
        (relu): ReLU()
      )
      (1): LiteHRModule(
        (layers): Sequential(
          (0): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(60, 7, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(7, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
          (1): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(60, 7, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(7, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
        )
        (fuse_layers): ModuleList(
          (0): ModuleList(
            (0): None
            (1): Sequential(
              (0): Conv2d(80, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
          )
          (1): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): None
          )
        )
        (relu): ReLU()
      )
    )
    (transition1): ModuleList(
      (0): None
      (1): None
      (2): Sequential(
        (0): Sequential(
          (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=80, bias=False)
          (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Conv2d(80, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU()
        )
      )
    )
    (stage1): Sequential(
      (0): LiteHRModule(
        (layers): Sequential(
          (0): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(140, 17, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(17, 140, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
          (1): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(140, 17, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(17, 140, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
        )
        (fuse_layers): ModuleList(
          (0): ModuleList(
            (0): None
            (1): Sequential(
              (0): Conv2d(80, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
            (2): Sequential(
              (0): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=4.0, mode=nearest)
            )
          )
          (1): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): None
            (2): Sequential(
              (0): Conv2d(160, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
          )
          (2): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (1): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=80, bias=False)
                (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(80, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): None
          )
        )
        (relu): ReLU()
      )
      (1): LiteHRModule(
        (layers): Sequential(
          (0): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(140, 17, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(17, 140, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
          (1): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(140, 17, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(17, 140, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
        )
        (fuse_layers): ModuleList(
          (0): ModuleList(
            (0): None
            (1): Sequential(
              (0): Conv2d(80, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
            (2): Sequential(
              (0): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=4.0, mode=nearest)
            )
          )
          (1): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): None
            (2): Sequential(
              (0): Conv2d(160, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
          )
          (2): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (1): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=80, bias=False)
                (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(80, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): None
          )
        )
        (relu): ReLU()
      )
      (2): LiteHRModule(
        (layers): Sequential(
          (0): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(140, 17, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(17, 140, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
          (1): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(140, 17, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(17, 140, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
        )
        (fuse_layers): ModuleList(
          (0): ModuleList(
            (0): None
            (1): Sequential(
              (0): Conv2d(80, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
            (2): Sequential(
              (0): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=4.0, mode=nearest)
            )
          )
          (1): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): None
            (2): Sequential(
              (0): Conv2d(160, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
          )
          (2): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (1): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=80, bias=False)
                (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(80, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): None
          )
        )
        (relu): ReLU()
      )
      (3): LiteHRModule(
        (layers): Sequential(
          (0): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(140, 17, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(17, 140, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
          (1): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(140, 17, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(17, 140, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
        )
        (fuse_layers): ModuleList(
          (0): ModuleList(
            (0): None
            (1): Sequential(
              (0): Conv2d(80, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
            (2): Sequential(
              (0): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=4.0, mode=nearest)
            )
          )
          (1): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): None
            (2): Sequential(
              (0): Conv2d(160, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
          )
          (2): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (1): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=80, bias=False)
                (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(80, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): None
          )
        )
        (relu): ReLU()
      )
    )
    (transition2): ModuleList(
      (0): None
      (1): None
      (2): None
      (3): Sequential(
        (0): Sequential(
          (0): Conv2d(160, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=160, bias=False)
          (1): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Conv2d(160, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): SyncBatchNorm(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU()
        )
      )
    )
    (stage2): Sequential(
      (0): LiteHRModule(
        (layers): Sequential(
          (0): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(300, 37, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(37, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(37, 300, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): ConvModule(
                (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (3): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
          (1): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(300, 37, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(37, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(37, 300, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): ConvModule(
                (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (3): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
        )
        (fuse_layers): ModuleList(
          (0): ModuleList(
            (0): None
            (1): Sequential(
              (0): Conv2d(80, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
            (2): Sequential(
              (0): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=4.0, mode=nearest)
            )
            (3): Sequential(
              (0): Conv2d(320, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=8.0, mode=nearest)
            )
          )
          (1): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): None
            (2): Sequential(
              (0): Conv2d(160, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
            (3): Sequential(
              (0): Conv2d(320, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=4.0, mode=nearest)
            )
          )
          (2): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (1): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=80, bias=False)
                (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(80, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): None
            (3): Sequential(
              (0): Conv2d(320, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
          )
          (3): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (1): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (2): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=80, bias=False)
                (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (1): Sequential(
                (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=80, bias=False)
                (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(80, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): Sequential(
              (0): Sequential(
                (0): Conv2d(160, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=160, bias=False)
                (1): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(160, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): None
          )
        )
        (relu): ReLU()
      )
      (1): LiteHRModule(
        (layers): Sequential(
          (0): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(300, 37, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(37, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(37, 300, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): ConvModule(
                (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (3): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
          (1): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(300, 37, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(37, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(37, 300, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): ConvModule(
                (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (3): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
        )
        (fuse_layers): ModuleList(
          (0): ModuleList(
            (0): None
            (1): Sequential(
              (0): Conv2d(80, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
            (2): Sequential(
              (0): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=4.0, mode=nearest)
            )
            (3): Sequential(
              (0): Conv2d(320, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=8.0, mode=nearest)
            )
          )
          (1): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): None
            (2): Sequential(
              (0): Conv2d(160, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
            (3): Sequential(
              (0): Conv2d(320, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=4.0, mode=nearest)
            )
          )
          (2): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (1): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=80, bias=False)
                (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(80, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): None
            (3): Sequential(
              (0): Conv2d(320, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
          )
          (3): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (1): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (2): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=80, bias=False)
                (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (1): Sequential(
                (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=80, bias=False)
                (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(80, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): Sequential(
              (0): Sequential(
                (0): Conv2d(160, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=160, bias=False)
                (1): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(160, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): None
          )
        )
        (relu): ReLU()
      )
    )
  )
  init_cfg=[{'type': 'Normal', 'std': 0.001, 'layer': 'Conv2d'}, {'type': 'Constant', 'val': 1, 'layer': ['_BatchNorm', 'GroupNorm']}]
  (decode_head): FCNHead(
    input_transform=None, ignore_index=255, align_corners=False
    (loss_decode): CrossEntropyLoss()
    (conv_seg): Conv2d(40, 150, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (convs): Sequential(
      (0): ConvModule(
        (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (conv_cat): ConvModule(
      (conv): Conv2d(80, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
)
2021-08-13 11:08:14,938 - mmseg - INFO - Loaded 20210 images
2021-08-13 11:08:21,726 - mmseg - INFO - Loaded 2000 images
2021-08-13 11:08:21,727 - mmseg - INFO - Start running, host: hejunjun@SH-IDC2-172-20-20-68, work_dir: /mnt/lustrenew/hejunjun/mmseg_dev/lite_hrnet/mmsegmentation/work_dirs/fcn_litehr18-without-head_512x512_160k_ade20k
2021-08-13 11:08:21,727 - mmseg - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(NORMAL      ) CheckpointHook                     
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
2021-08-13 11:08:21,727 - mmseg - INFO - workflow: [('train', 1)], max: 160000 iters
2021-08-13 11:09:43,166 - mmseg - INFO - Iter [50/160000]	lr: 9.997e-03, eta: 1 day, 18:38:10, time: 0.960, data_time: 0.018, memory: 4317, decode.loss_seg: 3.4769, decode.acc_seg: 14.5902, loss: 3.4769
2021-08-13 11:10:25,441 - mmseg - INFO - Iter [100/160000]	lr: 9.994e-03, eta: 1 day, 16:05:48, time: 0.846, data_time: 0.010, memory: 4317, decode.loss_seg: 2.9644, decode.acc_seg: 15.9940, loss: 2.9644
2021-08-13 11:11:08,503 - mmseg - INFO - Iter [150/160000]	lr: 9.992e-03, eta: 1 day, 15:28:37, time: 0.862, data_time: 0.009, memory: 4317, decode.loss_seg: 2.8720, decode.acc_seg: 16.9513, loss: 2.8720
2021-08-13 11:11:50,660 - mmseg - INFO - Iter [200/160000]	lr: 9.989e-03, eta: 1 day, 14:57:04, time: 0.843, data_time: 0.009, memory: 4317, decode.loss_seg: 2.7697, decode.acc_seg: 17.6866, loss: 2.7697
2021-08-13 11:12:33,207 - mmseg - INFO - Iter [250/160000]	lr: 9.986e-03, eta: 1 day, 14:42:16, time: 0.851, data_time: 0.009, memory: 4317, decode.loss_seg: 2.7010, decode.acc_seg: 18.3366, loss: 2.7010
2021-08-13 11:13:15,684 - mmseg - INFO - Iter [300/160000]	lr: 9.983e-03, eta: 1 day, 14:31:27, time: 0.849, data_time: 0.009, memory: 4317, decode.loss_seg: 2.6331, decode.acc_seg: 19.7767, loss: 2.6331
2021-08-13 11:13:58,414 - mmseg - INFO - Iter [350/160000]	lr: 9.981e-03, eta: 1 day, 14:25:26, time: 0.855, data_time: 0.009, memory: 4317, decode.loss_seg: 2.5891, decode.acc_seg: 21.9026, loss: 2.5891
2021-08-13 11:14:40,583 - mmseg - INFO - Iter [400/160000]	lr: 9.978e-03, eta: 1 day, 14:17:10, time: 0.844, data_time: 0.009, memory: 4317, decode.loss_seg: 2.5356, decode.acc_seg: 24.2964, loss: 2.5356
2021-08-13 11:15:23,242 - mmseg - INFO - Iter [450/160000]	lr: 9.975e-03, eta: 1 day, 14:13:14, time: 0.853, data_time: 0.009, memory: 4317, decode.loss_seg: 2.4656, decode.acc_seg: 24.3816, loss: 2.4656
2021-08-13 11:16:05,193 - mmseg - INFO - Iter [500/160000]	lr: 9.972e-03, eta: 1 day, 14:06:24, time: 0.839, data_time: 0.010, memory: 4317, decode.loss_seg: 2.4498, decode.acc_seg: 26.2810, loss: 2.4498
2021-08-13 11:16:47,841 - mmseg - INFO - Iter [550/160000]	lr: 9.969e-03, eta: 1 day, 14:03:52, time: 0.853, data_time: 0.009, memory: 4317, decode.loss_seg: 2.3802, decode.acc_seg: 27.3477, loss: 2.3802
2021-08-13 11:17:30,619 - mmseg - INFO - Iter [600/160000]	lr: 9.967e-03, eta: 1 day, 14:02:19, time: 0.856, data_time: 0.009, memory: 4317, decode.loss_seg: 2.4117, decode.acc_seg: 28.1913, loss: 2.4117
2021-08-13 11:18:48,833 - mmseg - INFO - Iter [650/160000]	lr: 9.964e-03, eta: 1 day, 16:25:38, time: 1.564, data_time: 0.762, memory: 4317, decode.loss_seg: 2.3662, decode.acc_seg: 27.9979, loss: 2.3662
2021-08-13 11:19:31,954 - mmseg - INFO - Iter [700/160000]	lr: 9.961e-03, eta: 1 day, 16:15:14, time: 0.863, data_time: 0.011, memory: 4317, decode.loss_seg: 2.3261, decode.acc_seg: 28.3040, loss: 2.3261
2021-08-13 11:20:14,592 - mmseg - INFO - Iter [750/160000]	lr: 9.958e-03, eta: 1 day, 16:04:22, time: 0.853, data_time: 0.010, memory: 4317, decode.loss_seg: 2.3276, decode.acc_seg: 29.2002, loss: 2.3276
2021-08-13 11:20:57,875 - mmseg - INFO - Iter [800/160000]	lr: 9.955e-03, eta: 1 day, 15:56:59, time: 0.866, data_time: 0.010, memory: 4317, decode.loss_seg: 2.2099, decode.acc_seg: 31.7424, loss: 2.2099
2021-08-13 11:21:40,487 - mmseg - INFO - Iter [850/160000]	lr: 9.953e-03, eta: 1 day, 15:48:08, time: 0.851, data_time: 0.010, memory: 4317, decode.loss_seg: 2.2010, decode.acc_seg: 30.2974, loss: 2.2010
2021-08-13 11:22:24,067 - mmseg - INFO - Iter [900/160000]	lr: 9.950e-03, eta: 1 day, 15:43:15, time: 0.872, data_time: 0.011, memory: 4317, decode.loss_seg: 2.1927, decode.acc_seg: 30.9447, loss: 2.1927
2021-08-13 11:23:07,862 - mmseg - INFO - Iter [950/160000]	lr: 9.947e-03, eta: 1 day, 15:39:15, time: 0.876, data_time: 0.011, memory: 4317, decode.loss_seg: 2.1507, decode.acc_seg: 30.9209, loss: 2.1507
2021-08-13 11:23:49,378 - mmseg - INFO - Exp name: fcn_litehr18-without-head_512x512_160k_ade20k.py
2021-08-13 11:23:49,378 - mmseg - INFO - Iter [1000/160000]	lr: 9.944e-03, eta: 1 day, 15:29:38, time: 0.831, data_time: 0.010, memory: 4317, decode.loss_seg: 2.1749, decode.acc_seg: 32.2914, loss: 2.1749
2021-08-13 11:24:29,843 - mmseg - INFO - Iter [1050/160000]	lr: 9.942e-03, eta: 1 day, 15:18:12, time: 0.809, data_time: 0.010, memory: 4317, decode.loss_seg: 2.1487, decode.acc_seg: 31.0143, loss: 2.1487
2021-08-13 11:25:11,106 - mmseg - INFO - Iter [1100/160000]	lr: 9.939e-03, eta: 1 day, 15:09:39, time: 0.825, data_time: 0.010, memory: 4317, decode.loss_seg: 2.1097, decode.acc_seg: 32.6403, loss: 2.1097
2021-08-13 11:25:53,397 - mmseg - INFO - Iter [1150/160000]	lr: 9.936e-03, eta: 1 day, 15:04:11, time: 0.846, data_time: 0.010, memory: 4317, decode.loss_seg: 2.1278, decode.acc_seg: 32.2782, loss: 2.1278
2021-08-13 11:26:34,165 - mmseg - INFO - Iter [1200/160000]	lr: 9.933e-03, eta: 1 day, 14:55:43, time: 0.815, data_time: 0.010, memory: 4317, decode.loss_seg: 2.0783, decode.acc_seg: 33.4291, loss: 2.0783
2021-08-13 11:27:15,194 - mmseg - INFO - Iter [1250/160000]	lr: 9.930e-03, eta: 1 day, 14:48:23, time: 0.820, data_time: 0.010, memory: 4317, decode.loss_seg: 2.0383, decode.acc_seg: 34.1737, loss: 2.0383
2021-08-13 11:28:32,851 - mmseg - INFO - Iter [1300/160000]	lr: 9.928e-03, eta: 1 day, 15:56:08, time: 1.553, data_time: 0.667, memory: 4317, decode.loss_seg: 2.1084, decode.acc_seg: 32.6977, loss: 2.1084
2021-08-13 11:29:13,766 - mmseg - INFO - Iter [1350/160000]	lr: 9.925e-03, eta: 1 day, 15:46:47, time: 0.818, data_time: 0.011, memory: 4317, decode.loss_seg: 2.0159, decode.acc_seg: 34.8275, loss: 2.0159
2021-08-13 11:29:55,171 - mmseg - INFO - Iter [1400/160000]	lr: 9.922e-03, eta: 1 day, 15:39:00, time: 0.828, data_time: 0.010, memory: 4317, decode.loss_seg: 2.0638, decode.acc_seg: 32.8038, loss: 2.0638
2021-08-13 11:30:36,340 - mmseg - INFO - Iter [1450/160000]	lr: 9.919e-03, eta: 1 day, 15:31:16, time: 0.823, data_time: 0.011, memory: 4317, decode.loss_seg: 2.0021, decode.acc_seg: 34.0582, loss: 2.0021
2021-08-13 11:31:17,593 - mmseg - INFO - Iter [1500/160000]	lr: 9.916e-03, eta: 1 day, 15:24:11, time: 0.825, data_time: 0.010, memory: 4317, decode.loss_seg: 2.0073, decode.acc_seg: 33.9912, loss: 2.0073
2021-08-13 11:31:58,962 - mmseg - INFO - Iter [1550/160000]	lr: 9.914e-03, eta: 1 day, 15:17:37, time: 0.827, data_time: 0.010, memory: 4317, decode.loss_seg: 1.9360, decode.acc_seg: 35.4096, loss: 1.9360
2021-08-13 11:32:42,102 - mmseg - INFO - Iter [1600/160000]	lr: 9.911e-03, eta: 1 day, 15:14:26, time: 0.863, data_time: 0.010, memory: 4317, decode.loss_seg: 2.0170, decode.acc_seg: 33.7229, loss: 2.0170
2021-08-13 11:33:25,132 - mmseg - INFO - Iter [1650/160000]	lr: 9.908e-03, eta: 1 day, 15:11:11, time: 0.861, data_time: 0.010, memory: 4317, decode.loss_seg: 1.9252, decode.acc_seg: 35.4354, loss: 1.9252
2021-08-13 11:34:06,320 - mmseg - INFO - Iter [1700/160000]	lr: 9.905e-03, eta: 1 day, 15:05:14, time: 0.824, data_time: 0.010, memory: 4317, decode.loss_seg: 1.9751, decode.acc_seg: 35.2364, loss: 1.9751
2021-08-13 11:34:47,360 - mmseg - INFO - Iter [1750/160000]	lr: 9.903e-03, eta: 1 day, 14:59:22, time: 0.821, data_time: 0.010, memory: 4317, decode.loss_seg: 1.9603, decode.acc_seg: 35.7209, loss: 1.9603
2021-08-13 11:35:29,038 - mmseg - INFO - Iter [1800/160000]	lr: 9.900e-03, eta: 1 day, 14:54:44, time: 0.834, data_time: 0.010, memory: 4317, decode.loss_seg: 1.9369, decode.acc_seg: 36.0589, loss: 1.9369
2021-08-13 11:36:11,788 - mmseg - INFO - Iter [1850/160000]	lr: 9.897e-03, eta: 1 day, 14:51:48, time: 0.855, data_time: 0.010, memory: 4317, decode.loss_seg: 1.9417, decode.acc_seg: 35.2137, loss: 1.9417
2021-08-13 11:37:28,383 - mmseg - INFO - Iter [1900/160000]	lr: 9.894e-03, eta: 1 day, 15:35:58, time: 1.532, data_time: 0.695, memory: 4317, decode.loss_seg: 1.9528, decode.acc_seg: 36.0014, loss: 1.9528
2021-08-13 11:38:10,246 - mmseg - INFO - Iter [1950/160000]	lr: 9.891e-03, eta: 1 day, 15:30:50, time: 0.837, data_time: 0.009, memory: 4317, decode.loss_seg: 1.9009, decode.acc_seg: 34.5410, loss: 1.9009
2021-08-13 11:38:51,786 - mmseg - INFO - Exp name: fcn_litehr18-without-head_512x512_160k_ade20k.py
2021-08-13 11:38:51,786 - mmseg - INFO - Iter [2000/160000]	lr: 9.889e-03, eta: 1 day, 15:25:32, time: 0.831, data_time: 0.010, memory: 4317, decode.loss_seg: 1.9482, decode.acc_seg: 35.6147, loss: 1.9482
2021-08-13 11:39:33,797 - mmseg - INFO - Iter [2050/160000]	lr: 9.886e-03, eta: 1 day, 15:21:02, time: 0.840, data_time: 0.010, memory: 4317, decode.loss_seg: 1.8448, decode.acc_seg: 37.7701, loss: 1.8448
2021-08-13 11:40:15,134 - mmseg - INFO - Iter [2100/160000]	lr: 9.883e-03, eta: 1 day, 15:15:56, time: 0.827, data_time: 0.010, memory: 4317, decode.loss_seg: 1.9300, decode.acc_seg: 36.2871, loss: 1.9300
2021-08-13 11:40:56,912 - mmseg - INFO - Iter [2150/160000]	lr: 9.880e-03, eta: 1 day, 15:11:30, time: 0.835, data_time: 0.010, memory: 4317, decode.loss_seg: 1.9171, decode.acc_seg: 35.3187, loss: 1.9171
2021-08-13 11:41:40,306 - mmseg - INFO - Iter [2200/160000]	lr: 9.877e-03, eta: 1 day, 15:09:13, time: 0.868, data_time: 0.010, memory: 4317, decode.loss_seg: 1.8501, decode.acc_seg: 36.2954, loss: 1.8501
2021-08-13 11:42:21,322 - mmseg - INFO - Iter [2250/160000]	lr: 9.875e-03, eta: 1 day, 15:04:14, time: 0.821, data_time: 0.010, memory: 4317, decode.loss_seg: 1.8784, decode.acc_seg: 36.8875, loss: 1.8784
2021-08-13 11:43:03,930 - mmseg - INFO - Iter [2300/160000]	lr: 9.872e-03, eta: 1 day, 15:01:12, time: 0.852, data_time: 0.009, memory: 4317, decode.loss_seg: 1.8879, decode.acc_seg: 36.3970, loss: 1.8879
2021-08-13 11:43:45,844 - mmseg - INFO - Iter [2350/160000]	lr: 9.869e-03, eta: 1 day, 14:57:32, time: 0.838, data_time: 0.010, memory: 4317, decode.loss_seg: 1.8765, decode.acc_seg: 36.8796, loss: 1.8765
2021-08-13 11:44:28,876 - mmseg - INFO - Iter [2400/160000]	lr: 9.866e-03, eta: 1 day, 14:55:12, time: 0.861, data_time: 0.010, memory: 4317, decode.loss_seg: 1.8135, decode.acc_seg: 38.8811, loss: 1.8135
2021-08-13 11:45:12,422 - mmseg - INFO - Iter [2450/160000]	lr: 9.864e-03, eta: 1 day, 14:53:29, time: 0.871, data_time: 0.010, memory: 4317, decode.loss_seg: 1.8169, decode.acc_seg: 37.9081, loss: 1.8169
2021-08-13 11:45:54,930 - mmseg - INFO - Iter [2500/160000]	lr: 9.861e-03, eta: 1 day, 14:50:44, time: 0.850, data_time: 0.010, memory: 4317, decode.loss_seg: 1.8709, decode.acc_seg: 37.7044, loss: 1.8709
2021-08-13 11:47:11,295 - mmseg - INFO - Iter [2550/160000]	lr: 9.858e-03, eta: 1 day, 15:22:55, time: 1.528, data_time: 0.664, memory: 4317, decode.loss_seg: 1.8099, decode.acc_seg: 37.9315, loss: 1.8099
2021-08-13 11:47:53,929 - mmseg - INFO - Iter [2600/160000]	lr: 9.855e-03, eta: 1 day, 15:19:45, time: 0.853, data_time: 0.009, memory: 4317, decode.loss_seg: 1.7778, decode.acc_seg: 37.9145, loss: 1.7778
2021-08-13 11:48:35,647 - mmseg - INFO - Iter [2650/160000]	lr: 9.852e-03, eta: 1 day, 15:15:45, time: 0.834, data_time: 0.009, memory: 4317, decode.loss_seg: 1.8555, decode.acc_seg: 37.8856, loss: 1.8555
2021-08-13 11:49:17,288 - mmseg - INFO - Iter [2700/160000]	lr: 9.850e-03, eta: 1 day, 15:11:51, time: 0.833, data_time: 0.010, memory: 4317, decode.loss_seg: 1.8503, decode.acc_seg: 37.6889, loss: 1.8503
2021-08-13 11:49:58,822 - mmseg - INFO - Iter [2750/160000]	lr: 9.847e-03, eta: 1 day, 15:07:55, time: 0.830, data_time: 0.009, memory: 4317, decode.loss_seg: 1.8263, decode.acc_seg: 37.5596, loss: 1.8263
2021-08-13 11:50:41,364 - mmseg - INFO - Iter [2800/160000]	lr: 9.844e-03, eta: 1 day, 15:05:03, time: 0.851, data_time: 0.010, memory: 4317, decode.loss_seg: 1.7306, decode.acc_seg: 38.7679, loss: 1.7306
2021-08-13 11:51:22,255 - mmseg - INFO - Iter [2850/160000]	lr: 9.841e-03, eta: 1 day, 15:00:47, time: 0.818, data_time: 0.009, memory: 4317, decode.loss_seg: 1.7929, decode.acc_seg: 38.0823, loss: 1.7929
2021-08-13 11:52:04,503 - mmseg - INFO - Iter [2900/160000]	lr: 9.838e-03, eta: 1 day, 14:57:49, time: 0.845, data_time: 0.009, memory: 4317, decode.loss_seg: 1.7559, decode.acc_seg: 39.0209, loss: 1.7559
2021-08-13 11:52:45,926 - mmseg - INFO - Iter [2950/160000]	lr: 9.836e-03, eta: 1 day, 14:54:13, time: 0.829, data_time: 0.010, memory: 4317, decode.loss_seg: 1.7554, decode.acc_seg: 39.2662, loss: 1.7554
2021-08-13 11:53:26,897 - mmseg - INFO - Exp name: fcn_litehr18-without-head_512x512_160k_ade20k.py
2021-08-13 11:53:26,898 - mmseg - INFO - Iter [3000/160000]	lr: 9.833e-03, eta: 1 day, 14:50:20, time: 0.820, data_time: 0.010, memory: 4317, decode.loss_seg: 1.8028, decode.acc_seg: 38.3907, loss: 1.8028
2021-08-13 11:54:07,126 - mmseg - INFO - Iter [3050/160000]	lr: 9.830e-03, eta: 1 day, 14:45:54, time: 0.805, data_time: 0.009, memory: 4317, decode.loss_seg: 1.8227, decode.acc_seg: 38.2037, loss: 1.8227
2021-08-13 11:54:49,022 - mmseg - INFO - Iter [3100/160000]	lr: 9.827e-03, eta: 1 day, 14:43:00, time: 0.838, data_time: 0.009, memory: 4317, decode.loss_seg: 1.7778, decode.acc_seg: 39.1261, loss: 1.7778
2021-08-13 11:55:30,408 - mmseg - INFO - Iter [3150/160000]	lr: 9.824e-03, eta: 1 day, 14:39:45, time: 0.828, data_time: 0.009, memory: 4317, decode.loss_seg: 1.7708, decode.acc_seg: 39.5103, loss: 1.7708
2021-08-13 11:56:46,994 - mmseg - INFO - Iter [3200/160000]	lr: 9.822e-03, eta: 1 day, 15:05:18, time: 1.531, data_time: 0.683, memory: 4317, decode.loss_seg: 1.7830, decode.acc_seg: 38.1529, loss: 1.7830
2021-08-13 11:57:30,079 - mmseg - INFO - Iter [3250/160000]	lr: 9.819e-03, eta: 1 day, 15:03:08, time: 0.862, data_time: 0.010, memory: 4317, decode.loss_seg: 1.8038, decode.acc_seg: 39.5256, loss: 1.8038
2021-08-13 11:58:11,687 - mmseg - INFO - Iter [3300/160000]	lr: 9.816e-03, eta: 1 day, 14:59:48, time: 0.832, data_time: 0.009, memory: 4317, decode.loss_seg: 1.7691, decode.acc_seg: 39.6519, loss: 1.7691
2021-08-13 11:58:53,070 - mmseg - INFO - Iter [3350/160000]	lr: 9.813e-03, eta: 1 day, 14:56:24, time: 0.828, data_time: 0.010, memory: 4317, decode.loss_seg: 1.7553, decode.acc_seg: 39.4913, loss: 1.7553
2021-08-13 11:59:33,592 - mmseg - INFO - Iter [3400/160000]	lr: 9.811e-03, eta: 1 day, 14:52:26, time: 0.811, data_time: 0.010, memory: 4317, decode.loss_seg: 1.7421, decode.acc_seg: 40.0421, loss: 1.7421
2021-08-13 12:00:15,081 - mmseg - INFO - Iter [3450/160000]	lr: 9.808e-03, eta: 1 day, 14:49:16, time: 0.830, data_time: 0.010, memory: 4317, decode.loss_seg: 1.7607, decode.acc_seg: 39.2864, loss: 1.7607
2021-08-13 12:00:57,365 - mmseg - INFO - Iter [3500/160000]	lr: 9.805e-03, eta: 1 day, 14:46:46, time: 0.846, data_time: 0.010, memory: 4317, decode.loss_seg: 1.7564, decode.acc_seg: 39.0528, loss: 1.7564
2021-08-13 12:01:38,976 - mmseg - INFO - Iter [3550/160000]	lr: 9.802e-03, eta: 1 day, 14:43:49, time: 0.832, data_time: 0.010, memory: 4317, decode.loss_seg: 1.7186, decode.acc_seg: 38.9928, loss: 1.7186
2021-08-13 12:02:19,772 - mmseg - INFO - Iter [3600/160000]	lr: 9.799e-03, eta: 1 day, 14:40:22, time: 0.816, data_time: 0.011, memory: 4317, decode.loss_seg: 1.7280, decode.acc_seg: 40.3727, loss: 1.7280
2021-08-13 12:03:01,867 - mmseg - INFO - Iter [3650/160000]	lr: 9.797e-03, eta: 1 day, 14:37:53, time: 0.841, data_time: 0.010, memory: 4317, decode.loss_seg: 1.7358, decode.acc_seg: 39.7618, loss: 1.7358
2021-08-13 12:03:42,305 - mmseg - INFO - Iter [3700/160000]	lr: 9.794e-03, eta: 1 day, 14:34:19, time: 0.809, data_time: 0.011, memory: 4317, decode.loss_seg: 1.7036, decode.acc_seg: 40.4828, loss: 1.7036
2021-08-13 12:04:22,867 - mmseg - INFO - Iter [3750/160000]	lr: 9.791e-03, eta: 1 day, 14:30:53, time: 0.811, data_time: 0.010, memory: 4317, decode.loss_seg: 1.6948, decode.acc_seg: 40.2624, loss: 1.6948
2021-08-13 12:05:48,793 - mmseg - INFO - Iter [3800/160000]	lr: 9.788e-03, eta: 1 day, 14:58:36, time: 1.718, data_time: 0.911, memory: 4317, decode.loss_seg: 1.7505, decode.acc_seg: 39.7792, loss: 1.7505
2021-08-13 12:06:31,079 - mmseg - INFO - Iter [3850/160000]	lr: 9.785e-03, eta: 1 day, 14:56:05, time: 0.846, data_time: 0.011, memory: 4317, decode.loss_seg: 1.7006, decode.acc_seg: 40.1939, loss: 1.7006
2021-08-13 12:07:12,638 - mmseg - INFO - Iter [3900/160000]	lr: 9.783e-03, eta: 1 day, 14:53:07, time: 0.831, data_time: 0.010, memory: 4317, decode.loss_seg: 1.6592, decode.acc_seg: 40.7893, loss: 1.6592
2021-08-13 12:07:53,558 - mmseg - INFO - Iter [3950/160000]	lr: 9.780e-03, eta: 1 day, 14:49:48, time: 0.819, data_time: 0.010, memory: 4317, decode.loss_seg: 1.7243, decode.acc_seg: 40.5000, loss: 1.7243
2021-08-13 12:08:35,044 - mmseg - INFO - Exp name: fcn_litehr18-without-head_512x512_160k_ade20k.py
2021-08-13 12:08:35,045 - mmseg - INFO - Iter [4000/160000]	lr: 9.777e-03, eta: 1 day, 14:46:54, time: 0.829, data_time: 0.010, memory: 4317, decode.loss_seg: 1.6840, decode.acc_seg: 40.6519, loss: 1.6840
2021-08-13 12:09:16,682 - mmseg - INFO - Iter [4050/160000]	lr: 9.774e-03, eta: 1 day, 14:44:09, time: 0.833, data_time: 0.010, memory: 4317, decode.loss_seg: 1.7030, decode.acc_seg: 40.3149, loss: 1.7030
2021-08-13 12:09:57,282 - mmseg - INFO - Iter [4100/160000]	lr: 9.771e-03, eta: 1 day, 14:40:49, time: 0.812, data_time: 0.010, memory: 4317, decode.loss_seg: 1.7064, decode.acc_seg: 40.1760, loss: 1.7064
2021-08-13 12:10:37,996 - mmseg - INFO - Iter [4150/160000]	lr: 9.769e-03, eta: 1 day, 14:37:36, time: 0.814, data_time: 0.010, memory: 4317, decode.loss_seg: 1.7079, decode.acc_seg: 39.6647, loss: 1.7079
2021-08-13 12:11:19,803 - mmseg - INFO - Iter [4200/160000]	lr: 9.766e-03, eta: 1 day, 14:35:07, time: 0.836, data_time: 0.010, memory: 4317, decode.loss_seg: 1.6998, decode.acc_seg: 39.5844, loss: 1.6998
2021-08-13 12:12:00,379 - mmseg - INFO - Iter [4250/160000]	lr: 9.763e-03, eta: 1 day, 14:31:56, time: 0.811, data_time: 0.010, memory: 4317, decode.loss_seg: 1.6623, decode.acc_seg: 41.1967, loss: 1.6623
2021-08-13 12:12:41,630 - mmseg - INFO - Iter [4300/160000]	lr: 9.760e-03, eta: 1 day, 14:29:12, time: 0.825, data_time: 0.010, memory: 4317, decode.loss_seg: 1.6746, decode.acc_seg: 40.6958, loss: 1.6746
2021-08-13 12:13:22,496 - mmseg - INFO - Iter [4350/160000]	lr: 9.757e-03, eta: 1 day, 14:26:18, time: 0.817, data_time: 0.011, memory: 4317, decode.loss_seg: 1.7006, decode.acc_seg: 40.2924, loss: 1.7006
2021-08-13 12:14:03,575 - mmseg - INFO - Iter [4400/160000]	lr: 9.755e-03, eta: 1 day, 14:23:34, time: 0.822, data_time: 0.011, memory: 4317, decode.loss_seg: 1.6741, decode.acc_seg: 40.6780, loss: 1.6741
2021-08-13 12:15:20,097 - mmseg - INFO - Iter [4450/160000]	lr: 9.752e-03, eta: 1 day, 14:41:33, time: 1.531, data_time: 0.692, memory: 4317, decode.loss_seg: 1.6483, decode.acc_seg: 41.4861, loss: 1.6483
2021-08-13 12:16:01,549 - mmseg - INFO - Iter [4500/160000]	lr: 9.749e-03, eta: 1 day, 14:38:52, time: 0.828, data_time: 0.010, memory: 4317, decode.loss_seg: 1.6624, decode.acc_seg: 40.0455, loss: 1.6624
2021-08-13 12:16:42,382 - mmseg - INFO - Iter [4550/160000]	lr: 9.746e-03, eta: 1 day, 14:35:54, time: 0.817, data_time: 0.010, memory: 4317, decode.loss_seg: 1.7108, decode.acc_seg: 40.1109, loss: 1.7108
2021-08-13 12:17:23,502 - mmseg - INFO - Iter [4600/160000]	lr: 9.744e-03, eta: 1 day, 14:33:09, time: 0.822, data_time: 0.010, memory: 4317, decode.loss_seg: 1.6856, decode.acc_seg: 41.3041, loss: 1.6856
2021-08-13 12:18:05,964 - mmseg - INFO - Iter [4650/160000]	lr: 9.741e-03, eta: 1 day, 14:31:11, time: 0.849, data_time: 0.010, memory: 4317, decode.loss_seg: 1.5915, decode.acc_seg: 41.9051, loss: 1.5915
2021-08-13 12:18:47,791 - mmseg - INFO - Iter [4700/160000]	lr: 9.738e-03, eta: 1 day, 14:28:53, time: 0.837, data_time: 0.010, memory: 4317, decode.loss_seg: 1.6171, decode.acc_seg: 41.5395, loss: 1.6171
2021-08-13 12:19:29,323 - mmseg - INFO - Iter [4750/160000]	lr: 9.735e-03, eta: 1 day, 14:26:28, time: 0.831, data_time: 0.010, memory: 4317, decode.loss_seg: 1.6422, decode.acc_seg: 40.7190, loss: 1.6422
2021-08-13 12:20:11,589 - mmseg - INFO - Iter [4800/160000]	lr: 9.732e-03, eta: 1 day, 14:24:30, time: 0.845, data_time: 0.010, memory: 4317, decode.loss_seg: 1.6236, decode.acc_seg: 41.9709, loss: 1.6236
2021-08-13 12:20:53,832 - mmseg - INFO - Iter [4850/160000]	lr: 9.730e-03, eta: 1 day, 14:22:31, time: 0.845, data_time: 0.009, memory: 4317, decode.loss_seg: 1.6569, decode.acc_seg: 41.5653, loss: 1.6569
2021-08-13 12:21:36,388 - mmseg - INFO - Iter [4900/160000]	lr: 9.727e-03, eta: 1 day, 14:20:44, time: 0.851, data_time: 0.010, memory: 4317, decode.loss_seg: 1.6121, decode.acc_seg: 43.1613, loss: 1.6121
2021-08-13 12:22:18,515 - mmseg - INFO - Iter [4950/160000]	lr: 9.724e-03, eta: 1 day, 14:18:45, time: 0.842, data_time: 0.010, memory: 4317, decode.loss_seg: 1.6871, decode.acc_seg: 40.3732, loss: 1.6871
2021-08-13 12:23:00,964 - mmseg - INFO - Exp name: fcn_litehr18-without-head_512x512_160k_ade20k.py
2021-08-13 12:23:00,965 - mmseg - INFO - Iter [5000/160000]	lr: 9.721e-03, eta: 1 day, 14:16:58, time: 0.849, data_time: 0.010, memory: 4317, decode.loss_seg: 1.6566, decode.acc_seg: 41.4396, loss: 1.6566
2021-08-13 12:24:19,298 - mmseg - INFO - Iter [5050/160000]	lr: 9.718e-03, eta: 1 day, 14:33:33, time: 1.567, data_time: 0.706, memory: 4317, decode.loss_seg: 1.6476, decode.acc_seg: 41.3187, loss: 1.6476
2021-08-13 12:24:59,638 - mmseg - INFO - Iter [5100/160000]	lr: 9.716e-03, eta: 1 day, 14:30:34, time: 0.807, data_time: 0.010, memory: 4317, decode.loss_seg: 1.5391, decode.acc_seg: 42.2013, loss: 1.5391
2021-08-13 12:25:42,343 - mmseg - INFO - Iter [5150/160000]	lr: 9.713e-03, eta: 1 day, 14:28:47, time: 0.854, data_time: 0.009, memory: 4317, decode.loss_seg: 1.6467, decode.acc_seg: 40.8068, loss: 1.6467
2021-08-13 12:26:24,979 - mmseg - INFO - Iter [5200/160000]	lr: 9.710e-03, eta: 1 day, 14:26:59, time: 0.852, data_time: 0.010, memory: 4317, decode.loss_seg: 1.6413, decode.acc_seg: 41.7863, loss: 1.6413
2021-08-13 12:27:07,144 - mmseg - INFO - Iter [5250/160000]	lr: 9.707e-03, eta: 1 day, 14:25:00, time: 0.844, data_time: 0.010, memory: 4317, decode.loss_seg: 1.5967, decode.acc_seg: 42.7061, loss: 1.5967
2021-08-13 12:27:49,095 - mmseg - INFO - Iter [5300/160000]	lr: 9.704e-03, eta: 1 day, 14:22:56, time: 0.839, data_time: 0.010, memory: 4317, decode.loss_seg: 1.6372, decode.acc_seg: 41.8668, loss: 1.6372
2021-08-13 12:28:30,563 - mmseg - INFO - Iter [5350/160000]	lr: 9.702e-03, eta: 1 day, 14:20:39, time: 0.829, data_time: 0.010, memory: 4317, decode.loss_seg: 1.6783, decode.acc_seg: 41.2509, loss: 1.6783
2021-08-13 12:29:12,138 - mmseg - INFO - Iter [5400/160000]	lr: 9.699e-03, eta: 1 day, 14:18:26, time: 0.831, data_time: 0.010, memory: 4317, decode.loss_seg: 1.6400, decode.acc_seg: 43.0516, loss: 1.6400
2021-08-13 12:29:54,847 - mmseg - INFO - Iter [5450/160000]	lr: 9.696e-03, eta: 1 day, 14:16:48, time: 0.854, data_time: 0.010, memory: 4317, decode.loss_seg: 1.5795, decode.acc_seg: 42.3968, loss: 1.5795
2021-08-13 12:30:36,289 - mmseg - INFO - Iter [5500/160000]	lr: 9.693e-03, eta: 1 day, 14:14:35, time: 0.829, data_time: 0.010, memory: 4317, decode.loss_seg: 1.5526, decode.acc_seg: 42.3747, loss: 1.5526
2021-08-13 12:31:17,413 - mmseg - INFO - Iter [5550/160000]	lr: 9.690e-03, eta: 1 day, 14:12:16, time: 0.823, data_time: 0.010, memory: 4317, decode.loss_seg: 1.6297, decode.acc_seg: 42.4169, loss: 1.6297
2021-08-13 12:31:58,132 - mmseg - INFO - Iter [5600/160000]	lr: 9.688e-03, eta: 1 day, 14:09:46, time: 0.814, data_time: 0.010, memory: 4317, decode.loss_seg: 1.5436, decode.acc_seg: 41.9697, loss: 1.5436
2021-08-13 12:32:38,408 - mmseg - INFO - Iter [5650/160000]	lr: 9.685e-03, eta: 1 day, 14:07:06, time: 0.805, data_time: 0.009, memory: 4317, decode.loss_seg: 1.5791, decode.acc_seg: 41.8601, loss: 1.5791
2021-08-13 12:33:55,523 - mmseg - INFO - Iter [5700/160000]	lr: 9.682e-03, eta: 1 day, 14:21:07, time: 1.543, data_time: 0.662, memory: 4317, decode.loss_seg: 1.6227, decode.acc_seg: 41.3692, loss: 1.6227
2021-08-13 12:34:36,875 - mmseg - INFO - Iter [5750/160000]	lr: 9.679e-03, eta: 1 day, 14:18:50, time: 0.827, data_time: 0.010, memory: 4317, decode.loss_seg: 1.5891, decode.acc_seg: 41.2903, loss: 1.5891
2021-08-13 12:35:18,409 - mmseg - INFO - Iter [5800/160000]	lr: 9.676e-03, eta: 1 day, 14:16:41, time: 0.831, data_time: 0.010, memory: 4317, decode.loss_seg: 1.6151, decode.acc_seg: 42.3848, loss: 1.6151
2021-08-13 12:35:59,986 - mmseg - INFO - Iter [5850/160000]	lr: 9.674e-03, eta: 1 day, 14:14:35, time: 0.832, data_time: 0.010, memory: 4317, decode.loss_seg: 1.5862, decode.acc_seg: 42.1602, loss: 1.5862
2021-08-13 12:36:39,626 - mmseg - INFO - Iter [5900/160000]	lr: 9.671e-03, eta: 1 day, 14:11:39, time: 0.793, data_time: 0.010, memory: 4317, decode.loss_seg: 1.5986, decode.acc_seg: 42.5256, loss: 1.5986
2021-08-13 12:37:20,978 - mmseg - INFO - Iter [5950/160000]	lr: 9.668e-03, eta: 1 day, 14:09:30, time: 0.828, data_time: 0.010, memory: 4317, decode.loss_seg: 1.6065, decode.acc_seg: 41.1982, loss: 1.6065
2021-08-13 12:38:01,794 - mmseg - INFO - Exp name: fcn_litehr18-without-head_512x512_160k_ade20k.py
2021-08-13 12:38:01,795 - mmseg - INFO - Iter [6000/160000]	lr: 9.665e-03, eta: 1 day, 14:07:09, time: 0.816, data_time: 0.009, memory: 4317, decode.loss_seg: 1.5406, decode.acc_seg: 42.5236, loss: 1.5406
2021-08-13 12:38:44,328 - mmseg - INFO - Iter [6050/160000]	lr: 9.663e-03, eta: 1 day, 14:05:32, time: 0.851, data_time: 0.010, memory: 4317, decode.loss_seg: 1.5784, decode.acc_seg: 43.0946, loss: 1.5784
2021-08-13 12:39:26,282 - mmseg - INFO - Iter [6100/160000]	lr: 9.660e-03, eta: 1 day, 14:03:43, time: 0.839, data_time: 0.009, memory: 4317, decode.loss_seg: 1.5942, decode.acc_seg: 42.3334, loss: 1.5942
2021-08-13 12:40:07,093 - mmseg - INFO - Iter [6150/160000]	lr: 9.657e-03, eta: 1 day, 14:01:26, time: 0.816, data_time: 0.010, memory: 4317, decode.loss_seg: 1.5827, decode.acc_seg: 44.2029, loss: 1.5827
2021-08-13 12:40:47,610 - mmseg - INFO - Iter [6200/160000]	lr: 9.654e-03, eta: 1 day, 13:59:03, time: 0.810, data_time: 0.009, memory: 4317, decode.loss_seg: 1.5615, decode.acc_seg: 43.7304, loss: 1.5615
2021-08-13 12:41:28,483 - mmseg - INFO - Iter [6250/160000]	lr: 9.651e-03, eta: 1 day, 13:56:50, time: 0.817, data_time: 0.010, memory: 4317, decode.loss_seg: 1.5759, decode.acc_seg: 42.3555, loss: 1.5759
2021-08-13 12:42:09,685 - mmseg - INFO - Iter [6300/160000]	lr: 9.649e-03, eta: 1 day, 13:54:47, time: 0.824, data_time: 0.010, memory: 4317, decode.loss_seg: 1.6364, decode.acc_seg: 42.3191, loss: 1.6364
2021-08-13 12:43:25,717 - mmseg - INFO - Iter [6350/160000]	lr: 9.646e-03, eta: 1 day, 14:06:48, time: 1.521, data_time: 0.695, memory: 4317, decode.loss_seg: 1.6070, decode.acc_seg: 43.2290, loss: 1.6070
2021-08-13 12:44:07,421 - mmseg - INFO - Iter [6400/160000]	lr: 9.643e-03, eta: 1 day, 14:04:53, time: 0.834, data_time: 0.010, memory: 4317, decode.loss_seg: 1.5364, decode.acc_seg: 43.4580, loss: 1.5364
2021-08-13 12:44:49,290 - mmseg - INFO - Iter [6450/160000]	lr: 9.640e-03, eta: 1 day, 14:03:02, time: 0.837, data_time: 0.009, memory: 4317, decode.loss_seg: 1.5566, decode.acc_seg: 42.4353, loss: 1.5566
2021-08-13 12:45:29,953 - mmseg - INFO - Iter [6500/160000]	lr: 9.637e-03, eta: 1 day, 14:00:45, time: 0.814, data_time: 0.010, memory: 4317, decode.loss_seg: 1.6070, decode.acc_seg: 41.9193, loss: 1.6070
2021-08-13 12:46:10,573 - mmseg - INFO - Iter [6550/160000]	lr: 9.635e-03, eta: 1 day, 13:58:27, time: 0.812, data_time: 0.009, memory: 4317, decode.loss_seg: 1.5659, decode.acc_seg: 42.0664, loss: 1.5659
2021-08-13 12:46:52,284 - mmseg - INFO - Iter [6600/160000]	lr: 9.632e-03, eta: 1 day, 13:56:37, time: 0.834, data_time: 0.010, memory: 4317, decode.loss_seg: 1.5483, decode.acc_seg: 42.7794, loss: 1.5483
2021-08-13 12:47:33,948 - mmseg - INFO - Iter [6650/160000]	lr: 9.629e-03, eta: 1 day, 13:54:46, time: 0.833, data_time: 0.010, memory: 4317, decode.loss_seg: 1.5695, decode.acc_seg: 42.8423, loss: 1.5695
2021-08-13 12:48:13,943 - mmseg - INFO - Iter [6700/160000]	lr: 9.626e-03, eta: 1 day, 13:52:19, time: 0.800, data_time: 0.010, memory: 4317, decode.loss_seg: 1.5488, decode.acc_seg: 43.8901, loss: 1.5488
2021-08-13 12:48:55,135 - mmseg - INFO - Iter [6750/160000]	lr: 9.623e-03, eta: 1 day, 13:50:20, time: 0.824, data_time: 0.010, memory: 4317, decode.loss_seg: 1.5519, decode.acc_seg: 42.8233, loss: 1.5519
2021-08-13 12:49:35,824 - mmseg - INFO - Iter [6800/160000]	lr: 9.621e-03, eta: 1 day, 13:48:11, time: 0.813, data_time: 0.010, memory: 4317, decode.loss_seg: 1.5870, decode.acc_seg: 43.2058, loss: 1.5870
2021-08-13 12:50:16,971 - mmseg - INFO - Iter [6850/160000]	lr: 9.618e-03, eta: 1 day, 13:46:13, time: 0.823, data_time: 0.010, memory: 4317, decode.loss_seg: 1.5798, decode.acc_seg: 42.9611, loss: 1.5798
2021-08-13 12:50:58,494 - mmseg - INFO - Iter [6900/160000]	lr: 9.615e-03, eta: 1 day, 13:44:25, time: 0.830, data_time: 0.010, memory: 4317, decode.loss_seg: 1.5709, decode.acc_seg: 43.8530, loss: 1.5709
2021-08-13 12:52:16,282 - mmseg - INFO - Iter [6950/160000]	lr: 9.612e-03, eta: 1 day, 13:55:57, time: 1.556, data_time: 0.733, memory: 4317, decode.loss_seg: 1.4990, decode.acc_seg: 43.4924, loss: 1.4990
2021-08-13 12:52:56,536 - mmseg - INFO - Exp name: fcn_litehr18-without-head_512x512_160k_ade20k.py
2021-08-13 12:52:56,537 - mmseg - INFO - Iter [7000/160000]	lr: 9.609e-03, eta: 1 day, 13:53:37, time: 0.805, data_time: 0.010, memory: 4317, decode.loss_seg: 1.5519, decode.acc_seg: 43.0577, loss: 1.5519
2021-08-13 12:53:38,150 - mmseg - INFO - Iter [7050/160000]	lr: 9.607e-03, eta: 1 day, 13:51:48, time: 0.832, data_time: 0.010, memory: 4317, decode.loss_seg: 1.5479, decode.acc_seg: 43.6911, loss: 1.5479
2021-08-13 12:54:19,663 - mmseg - INFO - Iter [7100/160000]	lr: 9.604e-03, eta: 1 day, 13:49:58, time: 0.830, data_time: 0.010, memory: 4317, decode.loss_seg: 1.5518, decode.acc_seg: 42.5550, loss: 1.5518
2021-08-13 12:55:00,885 - mmseg - INFO - Iter [7150/160000]	lr: 9.601e-03, eta: 1 day, 13:48:02, time: 0.824, data_time: 0.010, memory: 4317, decode.loss_seg: 1.5507, decode.acc_seg: 43.4197, loss: 1.5507
2021-08-13 12:55:43,140 - mmseg - INFO - Iter [7200/160000]	lr: 9.598e-03, eta: 1 day, 13:46:30, time: 0.846, data_time: 0.011, memory: 4317, decode.loss_seg: 1.4829, decode.acc_seg: 43.8958, loss: 1.4829
2021-08-13 12:56:25,569 - mmseg - INFO - Iter [7250/160000]	lr: 9.595e-03, eta: 1 day, 13:45:02, time: 0.848, data_time: 0.009, memory: 4317, decode.loss_seg: 1.5270, decode.acc_seg: 44.1326, loss: 1.5270
2021-08-13 12:57:07,659 - mmseg - INFO - Iter [7300/160000]	lr: 9.593e-03, eta: 1 day, 13:43:27, time: 0.842, data_time: 0.010, memory: 4317, decode.loss_seg: 1.5508, decode.acc_seg: 43.5703, loss: 1.5508
2021-08-13 12:57:49,671 - mmseg - INFO - Iter [7350/160000]	lr: 9.590e-03, eta: 1 day, 13:41:51, time: 0.840, data_time: 0.010, memory: 4317, decode.loss_seg: 1.5370, decode.acc_seg: 43.6255, loss: 1.5370
2021-08-13 12:58:31,839 - mmseg - INFO - Iter [7400/160000]	lr: 9.587e-03, eta: 1 day, 13:40:20, time: 0.843, data_time: 0.010, memory: 4317, decode.loss_seg: 1.4927, decode.acc_seg: 44.0361, loss: 1.4927
2021-08-13 12:59:14,718 - mmseg - INFO - Iter [7450/160000]	lr: 9.584e-03, eta: 1 day, 13:39:04, time: 0.857, data_time: 0.010, memory: 4317, decode.loss_seg: 1.5563, decode.acc_seg: 44.1982, loss: 1.5563
2021-08-13 12:59:55,614 - mmseg - INFO - Iter [7500/160000]	lr: 9.581e-03, eta: 1 day, 13:37:08, time: 0.818, data_time: 0.010, memory: 4317, decode.loss_seg: 1.5853, decode.acc_seg: 43.3148, loss: 1.5853
2021-08-13 13:00:36,595 - mmseg - INFO - Iter [7550/160000]	lr: 9.579e-03, eta: 1 day, 13:35:14, time: 0.819, data_time: 0.009, memory: 4317, decode.loss_seg: 1.5340, decode.acc_seg: 43.7948, loss: 1.5340
2021-08-13 13:01:52,327 - mmseg - INFO - Iter [7600/160000]	lr: 9.576e-03, eta: 1 day, 13:44:59, time: 1.515, data_time: 0.732, memory: 4317, decode.loss_seg: 1.4815, decode.acc_seg: 44.0798, loss: 1.4815
2021-08-13 13:02:34,136 - mmseg - INFO - Iter [7650/160000]	lr: 9.573e-03, eta: 1 day, 13:43:18, time: 0.836, data_time: 0.010, memory: 4317, decode.loss_seg: 1.5271, decode.acc_seg: 43.6138, loss: 1.5271
2021-08-13 13:03:16,243 - mmseg - INFO - Iter [7700/160000]	lr: 9.570e-03, eta: 1 day, 13:41:45, time: 0.843, data_time: 0.010, memory: 4317, decode.loss_seg: 1.4974, decode.acc_seg: 44.9541, loss: 1.4974
2021-08-13 13:03:56,688 - mmseg - INFO - Iter [7750/160000]	lr: 9.567e-03, eta: 1 day, 13:39:40, time: 0.809, data_time: 0.010, memory: 4317, decode.loss_seg: 1.5261, decode.acc_seg: 43.2355, loss: 1.5261
2021-08-13 13:04:38,340 - mmseg - INFO - Iter [7800/160000]	lr: 9.565e-03, eta: 1 day, 13:38:00, time: 0.833, data_time: 0.010, memory: 4317, decode.loss_seg: 1.5419, decode.acc_seg: 42.9334, loss: 1.5419
2021-08-13 13:05:18,477 - mmseg - INFO - Iter [7850/160000]	lr: 9.562e-03, eta: 1 day, 13:35:50, time: 0.803, data_time: 0.010, memory: 4317, decode.loss_seg: 1.4962, decode.acc_seg: 43.8745, loss: 1.4962
2021-08-13 13:05:59,507 - mmseg - INFO - Iter [7900/160000]	lr: 9.559e-03, eta: 1 day, 13:33:59, time: 0.820, data_time: 0.010, memory: 4317, decode.loss_seg: 1.5348, decode.acc_seg: 43.2962, loss: 1.5348
2021-08-13 13:06:39,502 - mmseg - INFO - Iter [7950/160000]	lr: 9.556e-03, eta: 1 day, 13:31:49, time: 0.800, data_time: 0.011, memory: 4317, decode.loss_seg: 1.5087, decode.acc_seg: 44.0673, loss: 1.5087
2021-08-13 13:07:21,606 - mmseg - INFO - Exp name: fcn_litehr18-without-head_512x512_160k_ade20k.py
2021-08-13 13:07:21,606 - mmseg - INFO - Iter [8000/160000]	lr: 9.553e-03, eta: 1 day, 13:30:21, time: 0.842, data_time: 0.010, memory: 4317, decode.loss_seg: 1.5206, decode.acc_seg: 43.7763, loss: 1.5206
2021-08-13 13:08:02,987 - mmseg - INFO - Iter [8050/160000]	lr: 9.551e-03, eta: 1 day, 13:28:39, time: 0.828, data_time: 0.010, memory: 4317, decode.loss_seg: 1.4817, decode.acc_seg: 44.2465, loss: 1.4817
2021-08-13 13:08:42,600 - mmseg - INFO - Iter [8100/160000]	lr: 9.548e-03, eta: 1 day, 13:26:25, time: 0.792, data_time: 0.010, memory: 4317, decode.loss_seg: 1.5281, decode.acc_seg: 44.2358, loss: 1.5281
2021-08-13 13:09:23,354 - mmseg - INFO - Iter [8150/160000]	lr: 9.545e-03, eta: 1 day, 13:24:34, time: 0.815, data_time: 0.010, memory: 4317, decode.loss_seg: 1.5315, decode.acc_seg: 44.1555, loss: 1.5315
2021-08-13 13:10:03,520 - mmseg - INFO - Iter [8200/160000]	lr: 9.542e-03, eta: 1 day, 13:22:32, time: 0.803, data_time: 0.010, memory: 4317, decode.loss_seg: 1.5035, decode.acc_seg: 43.5329, loss: 1.5035
2021-08-13 13:11:19,752 - mmseg - INFO - Iter [8250/160000]	lr: 9.539e-03, eta: 1 day, 13:31:35, time: 1.525, data_time: 0.715, memory: 4317, decode.loss_seg: 1.4758, decode.acc_seg: 44.4383, loss: 1.4758
2021-08-13 13:12:00,185 - mmseg - INFO - Iter [8300/160000]	lr: 9.537e-03, eta: 1 day, 13:29:35, time: 0.809, data_time: 0.010, memory: 4317, decode.loss_seg: 1.5215, decode.acc_seg: 43.9085, loss: 1.5215
2021-08-13 13:12:41,318 - mmseg - INFO - Iter [8350/160000]	lr: 9.534e-03, eta: 1 day, 13:27:50, time: 0.823, data_time: 0.010, memory: 4317, decode.loss_seg: 1.5232, decode.acc_seg: 44.2485, loss: 1.5232
2021-08-13 13:13:22,278 - mmseg - INFO - Iter [8400/160000]	lr: 9.531e-03, eta: 1 day, 13:26:02, time: 0.819, data_time: 0.010, memory: 4317, decode.loss_seg: 1.4843, decode.acc_seg: 44.0599, loss: 1.4843
2021-08-13 13:14:03,106 - mmseg - INFO - Iter [8450/160000]	lr: 9.528e-03, eta: 1 day, 13:24:12, time: 0.816, data_time: 0.010, memory: 4317, decode.loss_seg: 1.4866, decode.acc_seg: 43.9431, loss: 1.4866
2021-08-13 13:14:43,794 - mmseg - INFO - Iter [8500/160000]	lr: 9.525e-03, eta: 1 day, 13:22:22, time: 0.815, data_time: 0.011, memory: 4317, decode.loss_seg: 1.4957, decode.acc_seg: 43.8930, loss: 1.4957
2021-08-13 13:15:24,455 - mmseg - INFO - Iter [8550/160000]	lr: 9.523e-03, eta: 1 day, 13:20:31, time: 0.813, data_time: 0.009, memory: 4317, decode.loss_seg: 1.5229, decode.acc_seg: 43.5506, loss: 1.5229
2021-08-13 13:16:05,597 - mmseg - INFO - Iter [8600/160000]	lr: 9.520e-03, eta: 1 day, 13:18:50, time: 0.823, data_time: 0.010, memory: 4317, decode.loss_seg: 1.4787, decode.acc_seg: 44.5992, loss: 1.4787
2021-08-13 13:16:45,744 - mmseg - INFO - Iter [8650/160000]	lr: 9.517e-03, eta: 1 day, 13:16:52, time: 0.803, data_time: 0.009, memory: 4317, decode.loss_seg: 1.5000, decode.acc_seg: 44.6155, loss: 1.5000
2021-08-13 13:17:27,056 - mmseg - INFO - Iter [8700/160000]	lr: 9.514e-03, eta: 1 day, 13:15:14, time: 0.826, data_time: 0.010, memory: 4317, decode.loss_seg: 1.4847, decode.acc_seg: 44.7296, loss: 1.4847
2021-08-13 13:18:08,146 - mmseg - INFO - Iter [8750/160000]	lr: 9.511e-03, eta: 1 day, 13:13:34, time: 0.822, data_time: 0.010, memory: 4317, decode.loss_seg: 1.4804, decode.acc_seg: 44.2794, loss: 1.4804
2021-08-13 13:18:48,171 - mmseg - INFO - Iter [8800/160000]	lr: 9.509e-03, eta: 1 day, 13:11:36, time: 0.801, data_time: 0.010, memory: 4317, decode.loss_seg: 1.4840, decode.acc_seg: 43.8929, loss: 1.4840
2021-08-13 13:20:06,082 - mmseg - INFO - Iter [8850/160000]	lr: 9.506e-03, eta: 1 day, 13:20:26, time: 1.558, data_time: 0.735, memory: 4317, decode.loss_seg: 1.5084, decode.acc_seg: 43.9934, loss: 1.5084
2021-08-13 13:20:47,891 - mmseg - INFO - Iter [8900/160000]	lr: 9.503e-03, eta: 1 day, 13:18:57, time: 0.836, data_time: 0.011, memory: 4317, decode.loss_seg: 1.4645, decode.acc_seg: 44.4380, loss: 1.4645
2021-08-13 13:21:29,627 - mmseg - INFO - Iter [8950/160000]	lr: 9.500e-03, eta: 1 day, 13:17:27, time: 0.835, data_time: 0.010, memory: 4317, decode.loss_seg: 1.4836, decode.acc_seg: 44.3454, loss: 1.4836
2021-08-13 13:22:09,908 - mmseg - INFO - Exp name: fcn_litehr18-without-head_512x512_160k_ade20k.py
2021-08-13 13:22:09,908 - mmseg - INFO - Iter [9000/160000]	lr: 9.497e-03, eta: 1 day, 13:15:32, time: 0.805, data_time: 0.010, memory: 4317, decode.loss_seg: 1.5017, decode.acc_seg: 44.1307, loss: 1.5017
2021-08-13 13:22:52,203 - mmseg - INFO - Iter [9050/160000]	lr: 9.495e-03, eta: 1 day, 13:14:13, time: 0.846, data_time: 0.010, memory: 4317, decode.loss_seg: 1.4724, decode.acc_seg: 44.8392, loss: 1.4724
2021-08-13 13:23:35,167 - mmseg - INFO - Iter [9100/160000]	lr: 9.492e-03, eta: 1 day, 13:13:04, time: 0.859, data_time: 0.010, memory: 4317, decode.loss_seg: 1.4659, decode.acc_seg: 44.7137, loss: 1.4659
2021-08-13 13:24:18,142 - mmseg - INFO - Iter [9150/160000]	lr: 9.489e-03, eta: 1 day, 13:11:56, time: 0.859, data_time: 0.010, memory: 4317, decode.loss_seg: 1.4947, decode.acc_seg: 44.7246, loss: 1.4947
2021-08-13 13:25:01,051 - mmseg - INFO - Iter [9200/160000]	lr: 9.486e-03, eta: 1 day, 13:10:48, time: 0.858, data_time: 0.010, memory: 4317, decode.loss_seg: 1.4964, decode.acc_seg: 43.7920, loss: 1.4964
2021-08-13 13:25:43,823 - mmseg - INFO - Iter [9250/160000]	lr: 9.483e-03, eta: 1 day, 13:09:37, time: 0.855, data_time: 0.010, memory: 4317, decode.loss_seg: 1.4107, decode.acc_seg: 44.8875, loss: 1.4107
2021-08-13 13:26:26,878 - mmseg - INFO - Iter [9300/160000]	lr: 9.481e-03, eta: 1 day, 13:08:31, time: 0.861, data_time: 0.010, memory: 4317, decode.loss_seg: 1.4777, decode.acc_seg: 44.1156, loss: 1.4777
2021-08-13 13:27:09,707 - mmseg - INFO - Iter [9350/160000]	lr: 9.478e-03, eta: 1 day, 13:07:22, time: 0.857, data_time: 0.010, memory: 4317, decode.loss_seg: 1.5249, decode.acc_seg: 44.4684, loss: 1.5249
2021-08-13 13:27:52,316 - mmseg - INFO - Iter [9400/160000]	lr: 9.475e-03, eta: 1 day, 13:06:10, time: 0.852, data_time: 0.010, memory: 4317, decode.loss_seg: 1.4597, decode.acc_seg: 44.6406, loss: 1.4597
2021-08-13 13:28:34,754 - mmseg - INFO - Iter [9450/160000]	lr: 9.472e-03, eta: 1 day, 13:04:55, time: 0.849, data_time: 0.010, memory: 4317, decode.loss_seg: 1.5017, decode.acc_seg: 43.3006, loss: 1.5017
2021-08-13 13:29:51,221 - mmseg - INFO - Iter [9500/160000]	lr: 9.469e-03, eta: 1 day, 13:12:40, time: 1.530, data_time: 0.723, memory: 4317, decode.loss_seg: 1.4192, decode.acc_seg: 46.2210, loss: 1.4192
2021-08-13 13:30:32,933 - mmseg - INFO - Iter [9550/160000]	lr: 9.467e-03, eta: 1 day, 13:11:12, time: 0.834, data_time: 0.011, memory: 4317, decode.loss_seg: 1.4759, decode.acc_seg: 44.1005, loss: 1.4759
2021-08-13 13:31:15,870 - mmseg - INFO - Iter [9600/160000]	lr: 9.464e-03, eta: 1 day, 13:10:03, time: 0.859, data_time: 0.010, memory: 4317, decode.loss_seg: 1.4883, decode.acc_seg: 44.7193, loss: 1.4883
2021-08-13 13:31:58,480 - mmseg - INFO - Iter [9650/160000]	lr: 9.461e-03, eta: 1 day, 13:08:49, time: 0.852, data_time: 0.010, memory: 4317, decode.loss_seg: 1.5061, decode.acc_seg: 44.4556, loss: 1.5061
2021-08-13 13:32:39,271 - mmseg - INFO - Iter [9700/160000]	lr: 9.458e-03, eta: 1 day, 13:07:08, time: 0.816, data_time: 0.010, memory: 4317, decode.loss_seg: 1.4649, decode.acc_seg: 44.2504, loss: 1.4649
2021-08-13 13:33:21,673 - mmseg - INFO - Iter [9750/160000]	lr: 9.455e-03, eta: 1 day, 13:05:51, time: 0.848, data_time: 0.010, memory: 4317, decode.loss_seg: 1.4045, decode.acc_seg: 46.9940, loss: 1.4045
2021-08-13 13:34:02,943 - mmseg - INFO - Iter [9800/160000]	lr: 9.453e-03, eta: 1 day, 13:04:18, time: 0.825, data_time: 0.010, memory: 4317, decode.loss_seg: 1.4538, decode.acc_seg: 44.8126, loss: 1.4538
2021-08-13 13:34:44,797 - mmseg - INFO - Iter [9850/160000]	lr: 9.450e-03, eta: 1 day, 13:02:55, time: 0.837, data_time: 0.010, memory: 4317, decode.loss_seg: 1.4418, decode.acc_seg: 45.4881, loss: 1.4418
2021-08-13 13:35:26,402 - mmseg - INFO - Iter [9900/160000]	lr: 9.447e-03, eta: 1 day, 13:01:28, time: 0.832, data_time: 0.010, memory: 4317, decode.loss_seg: 1.4609, decode.acc_seg: 46.3433, loss: 1.4609
2021-08-13 13:36:08,235 - mmseg - INFO - Iter [9950/160000]	lr: 9.444e-03, eta: 1 day, 13:00:05, time: 0.836, data_time: 0.010, memory: 4317, decode.loss_seg: 1.4439, decode.acc_seg: 44.0969, loss: 1.4439
2021-08-13 13:36:48,722 - mmseg - INFO - Exp name: fcn_litehr18-without-head_512x512_160k_ade20k.py
2021-08-13 13:36:48,723 - mmseg - INFO - Iter [10000/160000]	lr: 9.441e-03, eta: 1 day, 12:58:22, time: 0.810, data_time: 0.010, memory: 4317, decode.loss_seg: 1.4705, decode.acc_seg: 45.3152, loss: 1.4705
2021-08-13 13:37:29,448 - mmseg - INFO - Iter [10050/160000]	lr: 9.439e-03, eta: 1 day, 12:56:43, time: 0.814, data_time: 0.010, memory: 4317, decode.loss_seg: 1.4431, decode.acc_seg: 45.5564, loss: 1.4431
2021-08-13 13:38:44,386 - mmseg - INFO - Iter [10100/160000]	lr: 9.436e-03, eta: 1 day, 13:03:33, time: 1.499, data_time: 0.700, memory: 4317, decode.loss_seg: 1.4678, decode.acc_seg: 44.6118, loss: 1.4678
2021-08-13 13:39:25,448 - mmseg - INFO - Iter [10150/160000]	lr: 9.433e-03, eta: 1 day, 13:01:57, time: 0.821, data_time: 0.010, memory: 4317, decode.loss_seg: 1.4084, decode.acc_seg: 45.8229, loss: 1.4084
2021-08-13 13:40:07,684 - mmseg - INFO - Iter [10200/160000]	lr: 9.430e-03, eta: 1 day, 13:00:40, time: 0.845, data_time: 0.010, memory: 4317, decode.loss_seg: 1.4133, decode.acc_seg: 46.6848, loss: 1.4133
2021-08-13 13:40:49,349 - mmseg - INFO - Iter [10250/160000]	lr: 9.427e-03, eta: 1 day, 12:59:14, time: 0.833, data_time: 0.010, memory: 4317, decode.loss_seg: 1.4525, decode.acc_seg: 45.3872, loss: 1.4525
2021-08-13 13:41:31,303 - mmseg - INFO - Iter [10300/160000]	lr: 9.425e-03, eta: 1 day, 12:57:53, time: 0.839, data_time: 0.010, memory: 4317, decode.loss_seg: 1.4423, decode.acc_seg: 45.1988, loss: 1.4423
2021-08-13 13:42:12,536 - mmseg - INFO - Iter [10350/160000]	lr: 9.422e-03, eta: 1 day, 12:56:23, time: 0.825, data_time: 0.010, memory: 4317, decode.loss_seg: 1.4688, decode.acc_seg: 45.1554, loss: 1.4688
2021-08-13 13:42:53,302 - mmseg - INFO - Iter [10400/160000]	lr: 9.419e-03, eta: 1 day, 12:54:46, time: 0.815, data_time: 0.010, memory: 4317, decode.loss_seg: 1.4455, decode.acc_seg: 45.3212, loss: 1.4455
2021-08-13 13:43:33,842 - mmseg - INFO - Iter [10450/160000]	lr: 9.416e-03, eta: 1 day, 12:53:06, time: 0.811, data_time: 0.010, memory: 4317, decode.loss_seg: 1.4715, decode.acc_seg: 44.6860, loss: 1.4715
2021-08-13 13:44:14,172 - mmseg - INFO - Iter [10500/160000]	lr: 9.413e-03, eta: 1 day, 12:51:23, time: 0.807, data_time: 0.010, memory: 4317, decode.loss_seg: 1.4394, decode.acc_seg: 44.8614, loss: 1.4394
2021-08-13 13:44:54,414 - mmseg - INFO - Iter [10550/160000]	lr: 9.411e-03, eta: 1 day, 12:49:41, time: 0.805, data_time: 0.010, memory: 4317, decode.loss_seg: 1.4468, decode.acc_seg: 44.7392, loss: 1.4468
2021-08-13 13:45:34,545 - mmseg - INFO - Iter [10600/160000]	lr: 9.408e-03, eta: 1 day, 12:47:57, time: 0.803, data_time: 0.010, memory: 4317, decode.loss_seg: 1.4249, decode.acc_seg: 46.5625, loss: 1.4249
2021-08-13 13:46:15,110 - mmseg - INFO - Iter [10650/160000]	lr: 9.405e-03, eta: 1 day, 12:46:19, time: 0.811, data_time: 0.010, memory: 4317, decode.loss_seg: 1.4089, decode.acc_seg: 45.2968, loss: 1.4089
2021-08-13 13:46:55,587 - mmseg - INFO - Iter [10700/160000]	lr: 9.402e-03, eta: 1 day, 12:44:41, time: 0.810, data_time: 0.009, memory: 4317, decode.loss_seg: 1.4861, decode.acc_seg: 44.7201, loss: 1.4861
2021-08-13 13:48:10,351 - mmseg - INFO - Iter [10750/160000]	lr: 9.399e-03, eta: 1 day, 12:51:00, time: 1.495, data_time: 0.663, memory: 4317, decode.loss_seg: 1.4260, decode.acc_seg: 44.9593, loss: 1.4260
2021-08-13 13:48:51,638 - mmseg - INFO - Iter [10800/160000]	lr: 9.397e-03, eta: 1 day, 12:49:32, time: 0.826, data_time: 0.010, memory: 4317, decode.loss_seg: 1.4063, decode.acc_seg: 45.4154, loss: 1.4063
2021-08-13 13:49:32,615 - mmseg - INFO - Iter [10850/160000]	lr: 9.394e-03, eta: 1 day, 12:48:00, time: 0.819, data_time: 0.009, memory: 4317, decode.loss_seg: 1.4631, decode.acc_seg: 45.0438, loss: 1.4631
2021-08-13 13:50:15,014 - mmseg - INFO - Iter [10900/160000]	lr: 9.391e-03, eta: 1 day, 12:46:48, time: 0.848, data_time: 0.010, memory: 4317, decode.loss_seg: 1.4402, decode.acc_seg: 45.7628, loss: 1.4402
2021-08-13 13:50:57,013 - mmseg - INFO - Iter [10950/160000]	lr: 9.388e-03, eta: 1 day, 12:45:31, time: 0.841, data_time: 0.010, memory: 4317, decode.loss_seg: 1.4140, decode.acc_seg: 44.5198, loss: 1.4140
2021-08-13 13:51:39,461 - mmseg - INFO - Exp name: fcn_litehr18-without-head_512x512_160k_ade20k.py
2021-08-13 13:51:39,462 - mmseg - INFO - Iter [11000/160000]	lr: 9.385e-03, eta: 1 day, 12:44:20, time: 0.849, data_time: 0.010, memory: 4317, decode.loss_seg: 1.4451, decode.acc_seg: 45.8794, loss: 1.4451
2021-08-13 13:52:20,814 - mmseg - INFO - Iter [11050/160000]	lr: 9.383e-03, eta: 1 day, 12:42:55, time: 0.827, data_time: 0.009, memory: 4317, decode.loss_seg: 1.4442, decode.acc_seg: 45.3563, loss: 1.4442
2021-08-13 13:53:02,839 - mmseg - INFO - Iter [11100/160000]	lr: 9.380e-03, eta: 1 day, 12:41:39, time: 0.841, data_time: 0.010, memory: 4317, decode.loss_seg: 1.4389, decode.acc_seg: 44.9283, loss: 1.4389
2021-08-13 13:53:44,274 - mmseg - INFO - Iter [11150/160000]	lr: 9.377e-03, eta: 1 day, 12:40:16, time: 0.828, data_time: 0.010, memory: 4317, decode.loss_seg: 1.4570, decode.acc_seg: 44.4763, loss: 1.4570
2021-08-13 13:54:26,356 - mmseg - INFO - Iter [11200/160000]	lr: 9.374e-03, eta: 1 day, 12:39:01, time: 0.842, data_time: 0.010, memory: 4317, decode.loss_seg: 1.4149, decode.acc_seg: 45.8222, loss: 1.4149
2021-08-13 13:55:08,758 - mmseg - INFO - Iter [11250/160000]	lr: 9.371e-03, eta: 1 day, 12:37:51, time: 0.848, data_time: 0.010, memory: 4317, decode.loss_seg: 1.4433, decode.acc_seg: 44.6458, loss: 1.4433
2021-08-13 13:55:50,949 - mmseg - INFO - Iter [11300/160000]	lr: 9.369e-03, eta: 1 day, 12:36:39, time: 0.844, data_time: 0.010, memory: 4317, decode.loss_seg: 1.4643, decode.acc_seg: 45.1830, loss: 1.4643
2021-08-13 13:56:33,149 - mmseg - INFO - Iter [11350/160000]	lr: 9.366e-03, eta: 1 day, 12:35:27, time: 0.844, data_time: 0.010, memory: 4317, decode.loss_seg: 1.4071, decode.acc_seg: 46.3394, loss: 1.4071
2021-08-13 13:57:49,080 - mmseg - INFO - Iter [11400/160000]	lr: 9.363e-03, eta: 1 day, 12:41:35, time: 1.519, data_time: 0.670, memory: 4317, decode.loss_seg: 1.4056, decode.acc_seg: 45.3802, loss: 1.4056
2021-08-13 13:58:29,532 - mmseg - INFO - Iter [11450/160000]	lr: 9.360e-03, eta: 1 day, 12:39:58, time: 0.808, data_time: 0.010, memory: 4317, decode.loss_seg: 1.4604, decode.acc_seg: 45.6410, loss: 1.4604
2021-08-13 13:59:10,163 - mmseg - INFO - Iter [11500/160000]	lr: 9.357e-03, eta: 1 day, 12:38:25, time: 0.813, data_time: 0.010, memory: 4317, decode.loss_seg: 1.4427, decode.acc_seg: 45.0705, loss: 1.4427
2021-08-13 13:59:51,303 - mmseg - INFO - Iter [11550/160000]	lr: 9.354e-03, eta: 1 day, 12:36:59, time: 0.823, data_time: 0.010, memory: 4317, decode.loss_seg: 1.4368, decode.acc_seg: 46.0868, loss: 1.4368
2021-08-13 14:00:33,045 - mmseg - INFO - Iter [11600/160000]	lr: 9.352e-03, eta: 1 day, 12:35:40, time: 0.835, data_time: 0.010, memory: 4317, decode.loss_seg: 1.4155, decode.acc_seg: 45.5209, loss: 1.4155
2021-08-13 14:01:14,114 - mmseg - INFO - Iter [11650/160000]	lr: 9.349e-03, eta: 1 day, 12:34:14, time: 0.821, data_time: 0.010, memory: 4317, decode.loss_seg: 1.4331, decode.acc_seg: 45.7774, loss: 1.4331
2021-08-13 14:01:55,743 - mmseg - INFO - Iter [11700/160000]	lr: 9.346e-03, eta: 1 day, 12:32:54, time: 0.832, data_time: 0.010, memory: 4317, decode.loss_seg: 1.3913, decode.acc_seg: 46.6794, loss: 1.3913
2021-08-13 14:02:37,254 - mmseg - INFO - Iter [11750/160000]	lr: 9.343e-03, eta: 1 day, 12:31:34, time: 0.830, data_time: 0.010, memory: 4317, decode.loss_seg: 1.3944, decode.acc_seg: 46.4493, loss: 1.3944
2021-08-13 14:03:17,523 - mmseg - INFO - Iter [11800/160000]	lr: 9.340e-03, eta: 1 day, 12:29:59, time: 0.806, data_time: 0.010, memory: 4317, decode.loss_seg: 1.4312, decode.acc_seg: 45.7621, loss: 1.4312
2021-08-13 14:03:58,537 - mmseg - INFO - Iter [11850/160000]	lr: 9.338e-03, eta: 1 day, 12:28:33, time: 0.820, data_time: 0.010, memory: 4317, decode.loss_seg: 1.4689, decode.acc_seg: 44.4794, loss: 1.4689
2021-08-13 14:04:39,021 - mmseg - INFO - Iter [11900/160000]	lr: 9.335e-03, eta: 1 day, 12:27:01, time: 0.809, data_time: 0.009, memory: 4317, decode.loss_seg: 1.3966, decode.acc_seg: 45.2651, loss: 1.3966
2021-08-13 14:05:20,768 - mmseg - INFO - Iter [11950/160000]	lr: 9.332e-03, eta: 1 day, 12:25:45, time: 0.835, data_time: 0.010, memory: 4317, decode.loss_seg: 1.4171, decode.acc_seg: 46.6520, loss: 1.4171
2021-08-13 14:06:38,437 - mmseg - INFO - Exp name: fcn_litehr18-without-head_512x512_160k_ade20k.py
2021-08-13 14:06:38,441 - mmseg - INFO - Iter [12000/160000]	lr: 9.329e-03, eta: 1 day, 12:31:52, time: 1.553, data_time: 0.720, memory: 4317, decode.loss_seg: 1.4348, decode.acc_seg: 45.2666, loss: 1.4348
2021-08-13 14:07:20,685 - mmseg - INFO - Iter [12050/160000]	lr: 9.326e-03, eta: 1 day, 12:30:41, time: 0.845, data_time: 0.010, memory: 4317, decode.loss_seg: 1.4234, decode.acc_seg: 45.3621, loss: 1.4234
2021-08-13 14:08:01,472 - mmseg - INFO - Iter [12100/160000]	lr: 9.324e-03, eta: 1 day, 12:29:12, time: 0.816, data_time: 0.010, memory: 4317, decode.loss_seg: 1.4080, decode.acc_seg: 46.0946, loss: 1.4080
2021-08-13 14:08:42,686 - mmseg - INFO - Iter [12150/160000]	lr: 9.321e-03, eta: 1 day, 12:27:49, time: 0.824, data_time: 0.010, memory: 4317, decode.loss_seg: 1.4135, decode.acc_seg: 46.3112, loss: 1.4135
2021-08-13 14:09:23,488 - mmseg - INFO - Iter [12200/160000]	lr: 9.318e-03, eta: 1 day, 12:26:21, time: 0.816, data_time: 0.010, memory: 4317, decode.loss_seg: 1.4311, decode.acc_seg: 45.2873, loss: 1.4311
2021-08-13 14:10:04,758 - mmseg - INFO - Iter [12250/160000]	lr: 9.315e-03, eta: 1 day, 12:24:59, time: 0.826, data_time: 0.010, memory: 4317, decode.loss_seg: 1.4068, decode.acc_seg: 46.9224, loss: 1.4068
2021-08-13 14:10:45,130 - mmseg - INFO - Iter [12300/160000]	lr: 9.312e-03, eta: 1 day, 12:23:27, time: 0.807, data_time: 0.010, memory: 4317, decode.loss_seg: 1.4091, decode.acc_seg: 45.7435, loss: 1.4091
2021-08-13 14:11:25,808 - mmseg - INFO - Iter [12350/160000]	lr: 9.310e-03, eta: 1 day, 12:21:58, time: 0.813, data_time: 0.010, memory: 4317, decode.loss_seg: 1.4010, decode.acc_seg: 46.2129, loss: 1.4010
2021-08-13 14:12:05,789 - mmseg - INFO - Iter [12400/160000]	lr: 9.307e-03, eta: 1 day, 12:20:22, time: 0.800, data_time: 0.010, memory: 4317, decode.loss_seg: 1.3770, decode.acc_seg: 45.6273, loss: 1.3770
2021-08-13 14:12:47,021 - mmseg - INFO - Iter [12450/160000]	lr: 9.304e-03, eta: 1 day, 12:19:01, time: 0.824, data_time: 0.009, memory: 4317, decode.loss_seg: 1.4233, decode.acc_seg: 45.6316, loss: 1.4233
2021-08-13 14:13:27,800 - mmseg - INFO - Iter [12500/160000]	lr: 9.301e-03, eta: 1 day, 12:17:36, time: 0.816, data_time: 0.010, memory: 4317, decode.loss_seg: 1.4131, decode.acc_seg: 46.8007, loss: 1.4131
2021-08-13 14:14:08,832 - mmseg - INFO - Iter [12550/160000]	lr: 9.298e-03, eta: 1 day, 12:16:13, time: 0.820, data_time: 0.009, memory: 4317, decode.loss_seg: 1.4036, decode.acc_seg: 45.3533, loss: 1.4036
2021-08-13 14:14:49,757 - mmseg - INFO - Iter [12600/160000]	lr: 9.296e-03, eta: 1 day, 12:14:49, time: 0.818, data_time: 0.010, memory: 4317, decode.loss_seg: 1.3840, decode.acc_seg: 46.4933, loss: 1.3840
2021-08-13 14:16:07,594 - mmseg - INFO - Iter [12650/160000]	lr: 9.293e-03, eta: 1 day, 12:20:36, time: 1.557, data_time: 0.689, memory: 4317, decode.loss_seg: 1.3698, decode.acc_seg: 46.4569, loss: 1.3698
2021-08-13 14:16:48,292 - mmseg - INFO - Iter [12700/160000]	lr: 9.290e-03, eta: 1 day, 12:19:09, time: 0.814, data_time: 0.010, memory: 4317, decode.loss_seg: 1.3813, decode.acc_seg: 46.3637, loss: 1.3813
2021-08-13 14:17:29,255 - mmseg - INFO - Iter [12750/160000]	lr: 9.287e-03, eta: 1 day, 12:17:45, time: 0.819, data_time: 0.010, memory: 4317, decode.loss_seg: 1.3703, decode.acc_seg: 46.8552, loss: 1.3703
2021-08-13 14:18:09,477 - mmseg - INFO - Iter [12800/160000]	lr: 9.284e-03, eta: 1 day, 12:16:13, time: 0.804, data_time: 0.010, memory: 4317, decode.loss_seg: 1.3941, decode.acc_seg: 46.2612, loss: 1.3941
2021-08-13 14:18:50,449 - mmseg - INFO - Iter [12850/160000]	lr: 9.282e-03, eta: 1 day, 12:14:50, time: 0.819, data_time: 0.010, memory: 4317, decode.loss_seg: 1.3853, decode.acc_seg: 46.1048, loss: 1.3853
2021-08-13 14:19:31,345 - mmseg - INFO - Iter [12900/160000]	lr: 9.279e-03, eta: 1 day, 12:13:26, time: 0.818, data_time: 0.010, memory: 4317, decode.loss_seg: 1.3903, decode.acc_seg: 45.4708, loss: 1.3903
2021-08-13 14:20:12,760 - mmseg - INFO - Iter [12950/160000]	lr: 9.276e-03, eta: 1 day, 12:12:09, time: 0.827, data_time: 0.010, memory: 4317, decode.loss_seg: 1.4004, decode.acc_seg: 46.7282, loss: 1.4004
2021-08-13 14:20:54,230 - mmseg - INFO - Exp name: fcn_litehr18-without-head_512x512_160k_ade20k.py
2021-08-13 14:20:54,230 - mmseg - INFO - Iter [13000/160000]	lr: 9.273e-03, eta: 1 day, 12:10:53, time: 0.830, data_time: 0.010, memory: 4317, decode.loss_seg: 1.4062, decode.acc_seg: 46.7698, loss: 1.4062
2021-08-13 14:21:34,626 - mmseg - INFO - Iter [13050/160000]	lr: 9.270e-03, eta: 1 day, 12:09:24, time: 0.807, data_time: 0.010, memory: 4317, decode.loss_seg: 1.3895, decode.acc_seg: 46.6019, loss: 1.3895
2021-08-13 14:22:16,017 - mmseg - INFO - Iter [13100/160000]	lr: 9.267e-03, eta: 1 day, 12:08:07, time: 0.828, data_time: 0.010, memory: 4317, decode.loss_seg: 1.3454, decode.acc_seg: 45.4736, loss: 1.3454
2021-08-13 14:22:56,033 - mmseg - INFO - Iter [13150/160000]	lr: 9.265e-03, eta: 1 day, 12:06:36, time: 0.801, data_time: 0.011, memory: 4317, decode.loss_seg: 1.4227, decode.acc_seg: 44.9924, loss: 1.4227
2021-08-13 14:23:37,742 - mmseg - INFO - Iter [13200/160000]	lr: 9.262e-03, eta: 1 day, 12:05:23, time: 0.834, data_time: 0.010, memory: 4317, decode.loss_seg: 1.3924, decode.acc_seg: 46.2181, loss: 1.3924
2021-08-13 14:24:17,678 - mmseg - INFO - Iter [13250/160000]	lr: 9.259e-03, eta: 1 day, 12:03:51, time: 0.799, data_time: 0.010, memory: 4317, decode.loss_seg: 1.3936, decode.acc_seg: 45.7708, loss: 1.3936
2021-08-13 14:25:33,841 - mmseg - INFO - Iter [13300/160000]	lr: 9.256e-03, eta: 1 day, 12:08:59, time: 1.523, data_time: 0.675, memory: 4317, decode.loss_seg: 1.3915, decode.acc_seg: 45.8557, loss: 1.3915
2021-08-13 14:26:15,601 - mmseg - INFO - Iter [13350/160000]	lr: 9.253e-03, eta: 1 day, 12:07:46, time: 0.835, data_time: 0.011, memory: 4317, decode.loss_seg: 1.3784, decode.acc_seg: 46.0959, loss: 1.3784
2021-08-13 14:26:56,507 - mmseg - INFO - Iter [13400/160000]	lr: 9.251e-03, eta: 1 day, 12:06:24, time: 0.818, data_time: 0.010, memory: 4317, decode.loss_seg: 1.3603, decode.acc_seg: 47.2531, loss: 1.3603
2021-08-13 14:27:39,065 - mmseg - INFO - Iter [13450/160000]	lr: 9.248e-03, eta: 1 day, 12:05:20, time: 0.851, data_time: 0.011, memory: 4317, decode.loss_seg: 1.4085, decode.acc_seg: 46.2138, loss: 1.4085
2021-08-13 14:28:19,740 - mmseg - INFO - Iter [13500/160000]	lr: 9.245e-03, eta: 1 day, 12:03:56, time: 0.813, data_time: 0.010, memory: 4317, decode.loss_seg: 1.3892, decode.acc_seg: 46.1332, loss: 1.3892
2021-08-13 14:29:01,141 - mmseg - INFO - Iter [13550/160000]	lr: 9.242e-03, eta: 1 day, 12:02:40, time: 0.828, data_time: 0.010, memory: 4317, decode.loss_seg: 1.3385, decode.acc_seg: 46.6670, loss: 1.3385
2021-08-13 14:29:42,300 - mmseg - INFO - Iter [13600/160000]	lr: 9.239e-03, eta: 1 day, 12:01:22, time: 0.824, data_time: 0.010, memory: 4317, decode.loss_seg: 1.4071, decode.acc_seg: 46.9007, loss: 1.4071
2021-08-13 14:30:22,919 - mmseg - INFO - Iter [13650/160000]	lr: 9.237e-03, eta: 1 day, 11:59:59, time: 0.812, data_time: 0.010, memory: 4317, decode.loss_seg: 1.3656, decode.acc_seg: 46.9746, loss: 1.3656
2021-08-13 14:31:03,678 - mmseg - INFO - Iter [13700/160000]	lr: 9.234e-03, eta: 1 day, 11:58:37, time: 0.815, data_time: 0.009, memory: 4317, decode.loss_seg: 1.4058, decode.acc_seg: 46.4353, loss: 1.4058
2021-08-13 14:31:45,292 - mmseg - INFO - Iter [13750/160000]	lr: 9.231e-03, eta: 1 day, 11:57:24, time: 0.832, data_time: 0.010, memory: 4317, decode.loss_seg: 1.3957, decode.acc_seg: 46.2717, loss: 1.3957
2021-08-13 14:32:26,444 - mmseg - INFO - Iter [13800/160000]	lr: 9.228e-03, eta: 1 day, 11:56:07, time: 0.823, data_time: 0.010, memory: 4317, decode.loss_seg: 1.3638, decode.acc_seg: 46.6796, loss: 1.3638
2021-08-13 14:33:07,756 - mmseg - INFO - Iter [13850/160000]	lr: 9.225e-03, eta: 1 day, 11:54:52, time: 0.827, data_time: 0.010, memory: 4317, decode.loss_seg: 1.4153, decode.acc_seg: 45.9336, loss: 1.4153
2021-08-13 14:34:23,641 - mmseg - INFO - Iter [13900/160000]	lr: 9.223e-03, eta: 1 day, 11:59:40, time: 1.517, data_time: 0.665, memory: 4317, decode.loss_seg: 1.4081, decode.acc_seg: 45.5459, loss: 1.4081
2021-08-13 14:35:05,711 - mmseg - INFO - Iter [13950/160000]	lr: 9.220e-03, eta: 1 day, 11:58:32, time: 0.842, data_time: 0.011, memory: 4317, decode.loss_seg: 1.3718, decode.acc_seg: 45.8462, loss: 1.3718
2021-08-13 14:35:46,892 - mmseg - INFO - Exp name: fcn_litehr18-without-head_512x512_160k_ade20k.py
2021-08-13 14:35:46,893 - mmseg - INFO - Iter [14000/160000]	lr: 9.217e-03, eta: 1 day, 11:57:15, time: 0.824, data_time: 0.010, memory: 4317, decode.loss_seg: 1.4046, decode.acc_seg: 46.5823, loss: 1.4046
2021-08-13 14:36:27,003 - mmseg - INFO - Iter [14050/160000]	lr: 9.214e-03, eta: 1 day, 11:55:47, time: 0.802, data_time: 0.010, memory: 4317, decode.loss_seg: 1.3284, decode.acc_seg: 47.0336, loss: 1.3284
2021-08-13 14:37:07,487 - mmseg - INFO - Iter [14100/160000]	lr: 9.211e-03, eta: 1 day, 11:54:23, time: 0.810, data_time: 0.009, memory: 4317, decode.loss_seg: 1.4039, decode.acc_seg: 45.5394, loss: 1.4039
2021-08-13 14:37:49,019 - mmseg - INFO - Iter [14150/160000]	lr: 9.208e-03, eta: 1 day, 11:53:10, time: 0.830, data_time: 0.009, memory: 4317, decode.loss_seg: 1.3762, decode.acc_seg: 46.1282, loss: 1.3762
2021-08-13 14:38:29,314 - mmseg - INFO - Iter [14200/160000]	lr: 9.206e-03, eta: 1 day, 11:51:45, time: 0.806, data_time: 0.010, memory: 4317, decode.loss_seg: 1.3695, decode.acc_seg: 47.1667, loss: 1.3695
2021-08-13 14:39:10,373 - mmseg - INFO - Iter [14250/160000]	lr: 9.203e-03, eta: 1 day, 11:50:28, time: 0.821, data_time: 0.010, memory: 4317, decode.loss_seg: 1.3741, decode.acc_seg: 46.6862, loss: 1.3741
2021-08-13 14:39:50,866 - mmseg - INFO - Iter [14300/160000]	lr: 9.200e-03, eta: 1 day, 11:49:05, time: 0.809, data_time: 0.010, memory: 4317, decode.loss_seg: 1.3693, decode.acc_seg: 45.7875, loss: 1.3693
2021-08-13 14:40:31,720 - mmseg - INFO - Iter [14350/160000]	lr: 9.197e-03, eta: 1 day, 11:47:46, time: 0.817, data_time: 0.010, memory: 4317, decode.loss_seg: 1.3471, decode.acc_seg: 47.6121, loss: 1.3471
2021-08-13 14:41:12,168 - mmseg - INFO - Iter [14400/160000]	lr: 9.194e-03, eta: 1 day, 11:46:24, time: 0.809, data_time: 0.010, memory: 4317, decode.loss_seg: 1.3924, decode.acc_seg: 46.9006, loss: 1.3924
2021-08-13 14:41:52,416 - mmseg - INFO - Iter [14450/160000]	lr: 9.192e-03, eta: 1 day, 11:44:59, time: 0.805, data_time: 0.010, memory: 4317, decode.loss_seg: 1.3549, decode.acc_seg: 47.0249, loss: 1.3549
2021-08-13 14:42:33,974 - mmseg - INFO - Iter [14500/160000]	lr: 9.189e-03, eta: 1 day, 11:43:48, time: 0.831, data_time: 0.010, memory: 4317, decode.loss_seg: 1.3353, decode.acc_seg: 48.2576, loss: 1.3353
2021-08-13 14:43:50,116 - mmseg - INFO - Iter [14550/160000]	lr: 9.186e-03, eta: 1 day, 11:48:24, time: 1.523, data_time: 0.695, memory: 4317, decode.loss_seg: 1.3790, decode.acc_seg: 45.7580, loss: 1.3790
2021-08-13 14:44:32,086 - mmseg - INFO - Iter [14600/160000]	lr: 9.183e-03, eta: 1 day, 11:47:16, time: 0.840, data_time: 0.011, memory: 4317, decode.loss_seg: 1.3713, decode.acc_seg: 46.3705, loss: 1.3713
2021-08-13 14:45:13,942 - mmseg - INFO - Iter [14650/160000]	lr: 9.180e-03, eta: 1 day, 11:46:07, time: 0.837, data_time: 0.009, memory: 4317, decode.loss_seg: 1.3670, decode.acc_seg: 46.5385, loss: 1.3670
2021-08-13 14:45:55,522 - mmseg - INFO - Iter [14700/160000]	lr: 9.178e-03, eta: 1 day, 11:44:56, time: 0.832, data_time: 0.009, memory: 4317, decode.loss_seg: 1.3436, decode.acc_seg: 46.5911, loss: 1.3436
2021-08-13 14:46:36,768 - mmseg - INFO - Iter [14750/160000]	lr: 9.175e-03, eta: 1 day, 11:43:42, time: 0.825, data_time: 0.009, memory: 4317, decode.loss_seg: 1.3518, decode.acc_seg: 46.7054, loss: 1.3518
2021-08-13 14:47:18,772 - mmseg - INFO - Iter [14800/160000]	lr: 9.172e-03, eta: 1 day, 11:42:35, time: 0.840, data_time: 0.010, memory: 4317, decode.loss_seg: 1.3892, decode.acc_seg: 47.1379, loss: 1.3892
2021-08-13 14:47:59,717 - mmseg - INFO - Iter [14850/160000]	lr: 9.169e-03, eta: 1 day, 11:41:19, time: 0.819, data_time: 0.010, memory: 4317, decode.loss_seg: 1.3610, decode.acc_seg: 46.9877, loss: 1.3610
2021-08-13 14:48:40,121 - mmseg - INFO - Iter [14900/160000]	lr: 9.166e-03, eta: 1 day, 11:39:57, time: 0.808, data_time: 0.009, memory: 4317, decode.loss_seg: 1.3636, decode.acc_seg: 47.0828, loss: 1.3636
2021-08-13 14:49:21,405 - mmseg - INFO - Iter [14950/160000]	lr: 9.163e-03, eta: 1 day, 11:38:44, time: 0.825, data_time: 0.009, memory: 4317, decode.loss_seg: 1.3466, decode.acc_seg: 47.1437, loss: 1.3466
2021-08-13 14:50:03,279 - mmseg - INFO - Exp name: fcn_litehr18-without-head_512x512_160k_ade20k.py
2021-08-13 14:50:03,279 - mmseg - INFO - Iter [15000/160000]	lr: 9.161e-03, eta: 1 day, 11:37:37, time: 0.838, data_time: 0.010, memory: 4317, decode.loss_seg: 1.3803, decode.acc_seg: 46.3440, loss: 1.3803
2021-08-13 14:50:44,018 - mmseg - INFO - Iter [15050/160000]	lr: 9.158e-03, eta: 1 day, 11:36:19, time: 0.815, data_time: 0.009, memory: 4317, decode.loss_seg: 1.3170, decode.acc_seg: 47.4207, loss: 1.3170
2021-08-13 14:51:24,625 - mmseg - INFO - Iter [15100/160000]	lr: 9.155e-03, eta: 1 day, 11:35:00, time: 0.812, data_time: 0.010, memory: 4317, decode.loss_seg: 1.3343, decode.acc_seg: 47.0595, loss: 1.3343
2021-08-13 14:52:40,511 - mmseg - INFO - Iter [15150/160000]	lr: 9.152e-03, eta: 1 day, 11:39:19, time: 1.518, data_time: 0.677, memory: 4317, decode.loss_seg: 1.3260, decode.acc_seg: 47.6564, loss: 1.3260
2021-08-13 14:53:22,160 - mmseg - INFO - Iter [15200/160000]	lr: 9.149e-03, eta: 1 day, 11:38:09, time: 0.833, data_time: 0.010, memory: 4317, decode.loss_seg: 1.3398, decode.acc_seg: 46.2571, loss: 1.3398
2021-08-13 14:54:02,872 - mmseg - INFO - Iter [15250/160000]	lr: 9.147e-03, eta: 1 day, 11:36:51, time: 0.814, data_time: 0.010, memory: 4317, decode.loss_seg: 1.3676, decode.acc_seg: 46.5745, loss: 1.3676
2021-08-13 14:54:45,066 - mmseg - INFO - Iter [15300/160000]	lr: 9.144e-03, eta: 1 day, 11:35:47, time: 0.843, data_time: 0.010, memory: 4317, decode.loss_seg: 1.3869, decode.acc_seg: 47.8108, loss: 1.3869
2021-08-13 14:55:26,727 - mmseg - INFO - Iter [15350/160000]	lr: 9.141e-03, eta: 1 day, 11:34:38, time: 0.833, data_time: 0.010, memory: 4317, decode.loss_seg: 1.3436, decode.acc_seg: 46.7532, loss: 1.3436
2021-08-13 14:56:07,510 - mmseg - INFO - Iter [15400/160000]	lr: 9.138e-03, eta: 1 day, 11:33:21, time: 0.816, data_time: 0.010, memory: 4317, decode.loss_seg: 1.3807, decode.acc_seg: 47.2207, loss: 1.3807
2021-08-13 14:56:47,458 - mmseg - INFO - Iter [15450/160000]	lr: 9.135e-03, eta: 1 day, 11:31:56, time: 0.799, data_time: 0.009, memory: 4317, decode.loss_seg: 1.3579, decode.acc_seg: 48.0298, loss: 1.3579
2021-08-13 14:57:27,684 - mmseg - INFO - Iter [15500/160000]	lr: 9.133e-03, eta: 1 day, 11:30:34, time: 0.804, data_time: 0.010, memory: 4317, decode.loss_seg: 1.3513, decode.acc_seg: 46.2356, loss: 1.3513
2021-08-13 14:58:08,256 - mmseg - INFO - Iter [15550/160000]	lr: 9.130e-03, eta: 1 day, 11:29:16, time: 0.812, data_time: 0.010, memory: 4317, decode.loss_seg: 1.3540, decode.acc_seg: 46.2707, loss: 1.3540
2021-08-13 14:58:50,444 - mmseg - INFO - Iter [15600/160000]	lr: 9.127e-03, eta: 1 day, 11:28:13, time: 0.844, data_time: 0.010, memory: 4317, decode.loss_seg: 1.3514, decode.acc_seg: 46.2716, loss: 1.3514
2021-08-13 14:59:32,446 - mmseg - INFO - Iter [15650/160000]	lr: 9.124e-03, eta: 1 day, 11:27:08, time: 0.840, data_time: 0.010, memory: 4317, decode.loss_seg: 1.3513, decode.acc_seg: 47.0859, loss: 1.3513
2021-08-13 15:00:14,292 - mmseg - INFO - Iter [15700/160000]	lr: 9.121e-03, eta: 1 day, 11:26:03, time: 0.837, data_time: 0.010, memory: 4317, decode.loss_seg: 1.3584, decode.acc_seg: 47.3791, loss: 1.3584
2021-08-13 15:00:55,922 - mmseg - INFO - Iter [15750/160000]	lr: 9.118e-03, eta: 1 day, 11:24:55, time: 0.833, data_time: 0.010, memory: 4317, decode.loss_seg: 1.3157, decode.acc_seg: 46.5214, loss: 1.3157
2021-08-13 15:02:11,775 - mmseg - INFO - Iter [15800/160000]	lr: 9.116e-03, eta: 1 day, 11:29:00, time: 1.517, data_time: 0.701, memory: 4317, decode.loss_seg: 1.3464, decode.acc_seg: 47.5861, loss: 1.3464
2021-08-13 15:02:52,623 - mmseg - INFO - Iter [15850/160000]	lr: 9.113e-03, eta: 1 day, 11:27:44, time: 0.817, data_time: 0.010, memory: 4317, decode.loss_seg: 1.3241, decode.acc_seg: 46.5126, loss: 1.3241
2021-08-13 15:03:33,060 - mmseg - INFO - Iter [15900/160000]	lr: 9.110e-03, eta: 1 day, 11:26:25, time: 0.809, data_time: 0.010, memory: 4317, decode.loss_seg: 1.3243, decode.acc_seg: 48.5326, loss: 1.3243
2021-08-13 15:04:12,990 - mmseg - INFO - Iter [15950/160000]	lr: 9.107e-03, eta: 1 day, 11:25:01, time: 0.799, data_time: 0.010, memory: 4317, decode.loss_seg: 1.3288, decode.acc_seg: 46.7340, loss: 1.3288
2021-08-13 15:04:53,550 - mmseg - INFO - Saving checkpoint at 16000 iterations
2021-08-13 15:04:53,843 - mmseg - INFO - Exp name: fcn_litehr18-without-head_512x512_160k_ade20k.py
2021-08-13 15:04:53,846 - mmseg - INFO - Iter [16000/160000]	lr: 9.104e-03, eta: 1 day, 11:23:47, time: 0.818, data_time: 0.010, memory: 4317, decode.loss_seg: 1.3914, decode.acc_seg: 46.5758, loss: 1.3914
2021-08-13 15:07:30,540 - mmseg - INFO - per class results:
2021-08-13 15:07:30,557 - mmseg - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        | 47.28 | 82.14 |
|       building      | 60.91 | 85.59 |
|         sky         | 86.46 | 95.06 |
|        floor        | 51.94 | 74.07 |
|         tree        | 55.65 | 79.46 |
|       ceiling       | 62.45 | 86.84 |
|         road        | 60.27 | 83.92 |
|         bed         | 53.34 | 68.25 |
|      windowpane     | 38.53 | 53.79 |
|        grass        | 52.38 | 83.49 |
|       cabinet       | 28.33 | 34.73 |
|       sidewalk      | 26.21 | 33.97 |
|        person       | 36.24 | 51.27 |
|        earth        | 16.15 | 24.94 |
|         door        |  5.77 |  6.38 |
|        table        | 16.07 | 20.92 |
|       mountain      | 29.66 | 43.75 |
|        plant        | 15.37 | 16.81 |
|       curtain       | 24.78 | 27.98 |
|        chair        | 18.98 | 28.72 |
|         car         | 47.62 | 64.84 |
|        water        | 10.26 | 12.43 |
|       painting      | 42.45 | 54.47 |
|         sofa        | 22.51 | 34.39 |
|        shelf        |  7.95 |  9.36 |
|        house        | 22.23 |  30.0 |
|         sea         | 25.01 | 78.59 |
|        mirror       |  2.27 |  2.35 |
|         rug         |  9.05 |  9.28 |
|        field        | 13.12 | 31.94 |
|       armchair      |  0.76 |  0.77 |
|         seat        | 13.58 | 17.68 |
|        fence        |  7.82 | 12.19 |
|         desk        |  0.31 |  0.32 |
|         rock        |  3.95 |  4.7  |
|       wardrobe      |  0.0  |  0.0  |
|         lamp        |  9.8  | 10.42 |
|       bathtub       |  2.87 |  3.02 |
|       railing       |  2.51 |  2.82 |
|       cushion       |  8.97 | 10.42 |
|         base        |  0.0  |  0.0  |
|         box         |  0.0  |  0.0  |
|        column       |  0.0  |  0.0  |
|      signboard      |  0.62 |  0.63 |
|   chest of drawers  |  1.61 |  1.69 |
|       counter       |  0.0  |  0.0  |
|         sand        |  7.6  | 10.07 |
|         sink        | 13.53 | 16.96 |
|      skyscraper     |  29.4 | 38.74 |
|      fireplace      | 13.63 | 15.22 |
|     refrigerator    |  0.0  |  0.0  |
|      grandstand     |  2.91 |  3.65 |
|         path        |  0.0  |  0.0  |
|        stairs       |  0.37 |  0.38 |
|        runway       | 34.65 | 44.71 |
|         case        |  0.29 |  0.3  |
|      pool table     | 35.81 | 68.61 |
|        pillow       |  13.9 | 15.41 |
|     screen door     |  0.0  |  0.0  |
|       stairway      |  1.64 |  1.96 |
|        river        |  4.71 |  9.02 |
|        bridge       |  0.0  |  0.0  |
|       bookcase      |  0.82 |  0.83 |
|        blind        |  0.0  |  0.0  |
|     coffee table    |  0.41 |  0.41 |
|        toilet       | 23.93 | 32.19 |
|        flower       |  2.42 |  2.52 |
|         book        |  5.95 |  6.09 |
|         hill        |  0.46 |  0.49 |
|        bench        |  0.05 |  0.05 |
|      countertop     |  0.0  |  0.0  |
|        stove        |  8.38 |  9.35 |
|         palm        |  0.0  |  0.0  |
|    kitchen island   |  0.0  |  0.0  |
|       computer      |  0.35 |  0.37 |
|     swivel chair    |  0.0  |  0.0  |
|         boat        |  0.0  |  0.0  |
|         bar         |  0.0  |  0.0  |
|    arcade machine   |  0.0  |  0.0  |
|        hovel        |  0.0  |  0.0  |
|         bus         |  0.12 |  0.12 |
|        towel        |  0.0  |  0.0  |
|        light        |  0.31 |  0.31 |
|        truck        |  0.0  |  0.0  |
|        tower        |  0.0  |  0.0  |
|      chandelier     | 11.41 | 12.29 |
|        awning       |  0.0  |  0.0  |
|     streetlight     |  0.0  |  0.0  |
|        booth        |  0.0  |  0.0  |
| television receiver |  4.56 |  4.61 |
|       airplane      |  2.15 |  2.47 |
|      dirt track     |  0.0  |  0.0  |
|       apparel       |  0.0  |  0.0  |
|         pole        |  0.0  |  0.0  |
|         land        |  0.0  |  0.0  |
|      bannister      |  0.0  |  0.0  |
|      escalator      |  0.0  |  0.0  |
|       ottoman       |  0.0  |  0.0  |
|        bottle       |  0.0  |  0.0  |
|        buffet       |  0.0  |  0.0  |
|        poster       |  0.0  |  0.0  |
|        stage        |  0.0  |  0.0  |
|         van         |  0.0  |  0.0  |
|         ship        |  0.0  |  0.0  |
|       fountain      |  0.0  |  0.0  |
|    conveyer belt    |  0.0  |  0.0  |
|        canopy       |  0.0  |  0.0  |
|        washer       |  0.0  |  0.0  |
|      plaything      |  0.0  |  0.0  |
|    swimming pool    |  4.49 |  4.85 |
|        stool        |  0.0  |  0.0  |
|        barrel       |  0.0  |  0.0  |
|        basket       |  0.0  |  0.0  |
|      waterfall      | 24.92 | 39.79 |
|         tent        |  0.0  |  0.0  |
|         bag         |  0.0  |  0.0  |
|       minibike      |  0.0  |  0.0  |
|        cradle       |  4.53 |  4.58 |
|         oven        |  0.0  |  0.0  |
|         ball        |  0.0  |  0.0  |
|         food        |  0.0  |  0.0  |
|         step        |  0.0  |  0.0  |
|         tank        |  0.0  |  0.0  |
|      trade name     |  0.0  |  0.0  |
|      microwave      |  0.0  |  0.0  |
|         pot         |  0.0  |  0.0  |
|        animal       |  0.0  |  0.0  |
|       bicycle       |  0.0  |  0.0  |
|         lake        |  0.0  |  0.0  |
|      dishwasher     |  0.0  |  0.0  |
|        screen       |  0.0  |  0.0  |
|       blanket       |  0.0  |  0.0  |
|      sculpture      |  0.0  |  0.0  |
|         hood        |  0.0  |  0.0  |
|        sconce       |  0.0  |  0.0  |
|         vase        |  0.0  |  0.0  |
|    traffic light    |  0.0  |  0.0  |
|         tray        |  0.0  |  0.0  |
|        ashcan       |  0.0  |  0.0  |
|         fan         |  0.0  |  0.0  |
|         pier        |  0.0  |  0.0  |
|      crt screen     |  0.0  |  0.0  |
|        plate        |  0.0  |  0.0  |
|       monitor       |  0.0  |  0.0  |
|    bulletin board   |  0.0  |  0.0  |
|        shower       |  0.0  |  0.0  |
|       radiator      |  0.0  |  0.0  |
|        glass        |  0.0  |  0.0  |
|        clock        |  0.0  |  0.0  |
|         flag        |  0.0  |  0.0  |
+---------------------+-------+-------+
2021-08-13 15:07:30,557 - mmseg - INFO - Summary:
2021-08-13 15:07:30,558 - mmseg - INFO - 
+-------+------+-------+
|  aAcc | mIoU |  mAcc |
+-------+------+-------+
| 61.34 | 8.64 | 12.14 |
+-------+------+-------+
2021-08-13 15:07:30,679 - mmseg - INFO - Exp name: fcn_litehr18-without-head_512x512_160k_ade20k.py
2021-08-13 15:07:30,680 - mmseg - INFO - Iter(val) [250]	aAcc: 0.6134, mIoU: 0.0864, mAcc: 0.1214, IoU.wall: 0.4728, IoU.building: 0.6091, IoU.sky: 0.8646, IoU.floor: 0.5194, IoU.tree: 0.5565, IoU.ceiling: 0.6245, IoU.road: 0.6027, IoU.bed : 0.5334, IoU.windowpane: 0.3853, IoU.grass: 0.5238, IoU.cabinet: 0.2833, IoU.sidewalk: 0.2621, IoU.person: 0.3624, IoU.earth: 0.1615, IoU.door: 0.0577, IoU.table: 0.1607, IoU.mountain: 0.2966, IoU.plant: 0.1537, IoU.curtain: 0.2478, IoU.chair: 0.1898, IoU.car: 0.4762, IoU.water: 0.1026, IoU.painting: 0.4245, IoU.sofa: 0.2251, IoU.shelf: 0.0795, IoU.house: 0.2223, IoU.sea: 0.2501, IoU.mirror: 0.0227, IoU.rug: 0.0905, IoU.field: 0.1312, IoU.armchair: 0.0076, IoU.seat: 0.1358, IoU.fence: 0.0782, IoU.desk: 0.0031, IoU.rock: 0.0395, IoU.wardrobe: 0.0000, IoU.lamp: 0.0980, IoU.bathtub: 0.0287, IoU.railing: 0.0251, IoU.cushion: 0.0897, IoU.base: 0.0000, IoU.box: 0.0000, IoU.column: 0.0000, IoU.signboard: 0.0062, IoU.chest of drawers: 0.0161, IoU.counter: 0.0000, IoU.sand: 0.0760, IoU.sink: 0.1353, IoU.skyscraper: 0.2940, IoU.fireplace: 0.1363, IoU.refrigerator: 0.0000, IoU.grandstand: 0.0291, IoU.path: 0.0000, IoU.stairs: 0.0037, IoU.runway: 0.3465, IoU.case: 0.0029, IoU.pool table: 0.3581, IoU.pillow: 0.1390, IoU.screen door: 0.0000, IoU.stairway: 0.0164, IoU.river: 0.0471, IoU.bridge: 0.0000, IoU.bookcase: 0.0082, IoU.blind: 0.0000, IoU.coffee table: 0.0041, IoU.toilet: 0.2393, IoU.flower: 0.0242, IoU.book: 0.0595, IoU.hill: 0.0046, IoU.bench: 0.0005, IoU.countertop: 0.0000, IoU.stove: 0.0838, IoU.palm: 0.0000, IoU.kitchen island: 0.0000, IoU.computer: 0.0035, IoU.swivel chair: 0.0000, IoU.boat: 0.0000, IoU.bar: 0.0000, IoU.arcade machine: 0.0000, IoU.hovel: 0.0000, IoU.bus: 0.0012, IoU.towel: 0.0000, IoU.light: 0.0031, IoU.truck: 0.0000, IoU.tower: 0.0000, IoU.chandelier: 0.1141, IoU.awning: 0.0000, IoU.streetlight: 0.0000, IoU.booth: 0.0000, IoU.television receiver: 0.0456, IoU.airplane: 0.0215, IoU.dirt track: 0.0000, IoU.apparel: 0.0000, IoU.pole: 0.0000, IoU.land: 0.0000, IoU.bannister: 0.0000, IoU.escalator: 0.0000, IoU.ottoman: 0.0000, IoU.bottle: 0.0000, IoU.buffet: 0.0000, IoU.poster: 0.0000, IoU.stage: 0.0000, IoU.van: 0.0000, IoU.ship: 0.0000, IoU.fountain: 0.0000, IoU.conveyer belt: 0.0000, IoU.canopy: 0.0000, IoU.washer: 0.0000, IoU.plaything: 0.0000, IoU.swimming pool: 0.0449, IoU.stool: 0.0000, IoU.barrel: 0.0000, IoU.basket: 0.0000, IoU.waterfall: 0.2492, IoU.tent: 0.0000, IoU.bag: 0.0000, IoU.minibike: 0.0000, IoU.cradle: 0.0453, IoU.oven: 0.0000, IoU.ball: 0.0000, IoU.food: 0.0000, IoU.step: 0.0000, IoU.tank: 0.0000, IoU.trade name: 0.0000, IoU.microwave: 0.0000, IoU.pot: 0.0000, IoU.animal: 0.0000, IoU.bicycle: 0.0000, IoU.lake: 0.0000, IoU.dishwasher: 0.0000, IoU.screen: 0.0000, IoU.blanket: 0.0000, IoU.sculpture: 0.0000, IoU.hood: 0.0000, IoU.sconce: 0.0000, IoU.vase: 0.0000, IoU.traffic light: 0.0000, IoU.tray: 0.0000, IoU.ashcan: 0.0000, IoU.fan: 0.0000, IoU.pier: 0.0000, IoU.crt screen: 0.0000, IoU.plate: 0.0000, IoU.monitor: 0.0000, IoU.bulletin board: 0.0000, IoU.shower: 0.0000, IoU.radiator: 0.0000, IoU.glass: 0.0000, IoU.clock: 0.0000, IoU.flag: 0.0000, Acc.wall: 0.8214, Acc.building: 0.8559, Acc.sky: 0.9506, Acc.floor: 0.7407, Acc.tree: 0.7946, Acc.ceiling: 0.8684, Acc.road: 0.8392, Acc.bed : 0.6825, Acc.windowpane: 0.5379, Acc.grass: 0.8349, Acc.cabinet: 0.3473, Acc.sidewalk: 0.3397, Acc.person: 0.5127, Acc.earth: 0.2494, Acc.door: 0.0638, Acc.table: 0.2092, Acc.mountain: 0.4375, Acc.plant: 0.1681, Acc.curtain: 0.2798, Acc.chair: 0.2872, Acc.car: 0.6484, Acc.water: 0.1243, Acc.painting: 0.5447, Acc.sofa: 0.3439, Acc.shelf: 0.0936, Acc.house: 0.3000, Acc.sea: 0.7859, Acc.mirror: 0.0235, Acc.rug: 0.0928, Acc.field: 0.3194, Acc.armchair: 0.0077, Acc.seat: 0.1768, Acc.fence: 0.1219, Acc.desk: 0.0032, Acc.rock: 0.0470, Acc.wardrobe: 0.0000, Acc.lamp: 0.1042, Acc.bathtub: 0.0302, Acc.railing: 0.0282, Acc.cushion: 0.1042, Acc.base: 0.0000, Acc.box: 0.0000, Acc.column: 0.0000, Acc.signboard: 0.0063, Acc.chest of drawers: 0.0169, Acc.counter: 0.0000, Acc.sand: 0.1007, Acc.sink: 0.1696, Acc.skyscraper: 0.3874, Acc.fireplace: 0.1522, Acc.refrigerator: 0.0000, Acc.grandstand: 0.0365, Acc.path: 0.0000, Acc.stairs: 0.0038, Acc.runway: 0.4471, Acc.case: 0.0030, Acc.pool table: 0.6861, Acc.pillow: 0.1541, Acc.screen door: 0.0000, Acc.stairway: 0.0196, Acc.river: 0.0902, Acc.bridge: 0.0000, Acc.bookcase: 0.0083, Acc.blind: 0.0000, Acc.coffee table: 0.0041, Acc.toilet: 0.3219, Acc.flower: 0.0252, Acc.book: 0.0609, Acc.hill: 0.0049, Acc.bench: 0.0005, Acc.countertop: 0.0000, Acc.stove: 0.0935, Acc.palm: 0.0000, Acc.kitchen island: 0.0000, Acc.computer: 0.0037, Acc.swivel chair: 0.0000, Acc.boat: 0.0000, Acc.bar: 0.0000, Acc.arcade machine: 0.0000, Acc.hovel: 0.0000, Acc.bus: 0.0012, Acc.towel: 0.0000, Acc.light: 0.0031, Acc.truck: 0.0000, Acc.tower: 0.0000, Acc.chandelier: 0.1229, Acc.awning: 0.0000, Acc.streetlight: 0.0000, Acc.booth: 0.0000, Acc.television receiver: 0.0461, Acc.airplane: 0.0247, Acc.dirt track: 0.0000, Acc.apparel: 0.0000, Acc.pole: 0.0000, Acc.land: 0.0000, Acc.bannister: 0.0000, Acc.escalator: 0.0000, Acc.ottoman: 0.0000, Acc.bottle: 0.0000, Acc.buffet: 0.0000, Acc.poster: 0.0000, Acc.stage: 0.0000, Acc.van: 0.0000, Acc.ship: 0.0000, Acc.fountain: 0.0000, Acc.conveyer belt: 0.0000, Acc.canopy: 0.0000, Acc.washer: 0.0000, Acc.plaything: 0.0000, Acc.swimming pool: 0.0485, Acc.stool: 0.0000, Acc.barrel: 0.0000, Acc.basket: 0.0000, Acc.waterfall: 0.3979, Acc.tent: 0.0000, Acc.bag: 0.0000, Acc.minibike: 0.0000, Acc.cradle: 0.0458, Acc.oven: 0.0000, Acc.ball: 0.0000, Acc.food: 0.0000, Acc.step: 0.0000, Acc.tank: 0.0000, Acc.trade name: 0.0000, Acc.microwave: 0.0000, Acc.pot: 0.0000, Acc.animal: 0.0000, Acc.bicycle: 0.0000, Acc.lake: 0.0000, Acc.dishwasher: 0.0000, Acc.screen: 0.0000, Acc.blanket: 0.0000, Acc.sculpture: 0.0000, Acc.hood: 0.0000, Acc.sconce: 0.0000, Acc.vase: 0.0000, Acc.traffic light: 0.0000, Acc.tray: 0.0000, Acc.ashcan: 0.0000, Acc.fan: 0.0000, Acc.pier: 0.0000, Acc.crt screen: 0.0000, Acc.plate: 0.0000, Acc.monitor: 0.0000, Acc.bulletin board: 0.0000, Acc.shower: 0.0000, Acc.radiator: 0.0000, Acc.glass: 0.0000, Acc.clock: 0.0000, Acc.flag: 0.0000
2021-08-13 15:08:11,415 - mmseg - INFO - Iter [16050/160000]	lr: 9.102e-03, eta: 1 day, 11:45:57, time: 3.951, data_time: 3.149, memory: 4319, decode.loss_seg: 1.3400, decode.acc_seg: 47.4578, loss: 1.3400
2021-08-13 15:08:51,994 - mmseg - INFO - Iter [16100/160000]	lr: 9.099e-03, eta: 1 day, 11:44:36, time: 0.812, data_time: 0.010, memory: 4319, decode.loss_seg: 1.3754, decode.acc_seg: 45.9630, loss: 1.3754
2021-08-13 15:09:32,165 - mmseg - INFO - Iter [16150/160000]	lr: 9.096e-03, eta: 1 day, 11:43:11, time: 0.804, data_time: 0.010, memory: 4319, decode.loss_seg: 1.3421, decode.acc_seg: 46.7753, loss: 1.3421
2021-08-13 15:10:13,077 - mmseg - INFO - Iter [16200/160000]	lr: 9.093e-03, eta: 1 day, 11:41:52, time: 0.818, data_time: 0.010, memory: 4319, decode.loss_seg: 1.3739, decode.acc_seg: 46.6759, loss: 1.3739
2021-08-13 15:10:54,301 - mmseg - INFO - Iter [16250/160000]	lr: 9.090e-03, eta: 1 day, 11:40:37, time: 0.825, data_time: 0.010, memory: 4319, decode.loss_seg: 1.3513, decode.acc_seg: 46.5853, loss: 1.3513
2021-08-13 15:11:35,141 - mmseg - INFO - Iter [16300/160000]	lr: 9.088e-03, eta: 1 day, 11:39:18, time: 0.816, data_time: 0.010, memory: 4319, decode.loss_seg: 1.3434, decode.acc_seg: 47.7911, loss: 1.3434
2021-08-13 15:12:16,074 - mmseg - INFO - Iter [16350/160000]	lr: 9.085e-03, eta: 1 day, 11:38:01, time: 0.819, data_time: 0.010, memory: 4319, decode.loss_seg: 1.3189, decode.acc_seg: 48.1026, loss: 1.3189
2021-08-13 15:12:57,514 - mmseg - INFO - Iter [16400/160000]	lr: 9.082e-03, eta: 1 day, 11:36:48, time: 0.829, data_time: 0.010, memory: 4319, decode.loss_seg: 1.3378, decode.acc_seg: 47.3160, loss: 1.3378
2021-08-13 15:14:14,811 - mmseg - INFO - Iter [16450/160000]	lr: 9.079e-03, eta: 1 day, 11:40:49, time: 1.546, data_time: 0.719, memory: 4319, decode.loss_seg: 1.3285, decode.acc_seg: 47.0857, loss: 1.3285
2021-08-13 15:14:57,120 - mmseg - INFO - Iter [16500/160000]	lr: 9.076e-03, eta: 1 day, 11:39:43, time: 0.846, data_time: 0.011, memory: 4319, decode.loss_seg: 1.3422, decode.acc_seg: 48.5870, loss: 1.3422
2021-08-13 15:15:38,826 - mmseg - INFO - Iter [16550/160000]	lr: 9.073e-03, eta: 1 day, 11:38:32, time: 0.834, data_time: 0.011, memory: 4319, decode.loss_seg: 1.3492, decode.acc_seg: 46.9341, loss: 1.3492
2021-08-13 15:16:20,223 - mmseg - INFO - Iter [16600/160000]	lr: 9.071e-03, eta: 1 day, 11:37:18, time: 0.828, data_time: 0.011, memory: 4319, decode.loss_seg: 1.3400, decode.acc_seg: 47.9445, loss: 1.3400
2021-08-13 15:17:00,117 - mmseg - INFO - Iter [16650/160000]	lr: 9.068e-03, eta: 1 day, 11:35:52, time: 0.798, data_time: 0.012, memory: 4319, decode.loss_seg: 1.3392, decode.acc_seg: 46.7680, loss: 1.3392
2021-08-13 15:17:39,861 - mmseg - INFO - Iter [16700/160000]	lr: 9.065e-03, eta: 1 day, 11:34:25, time: 0.795, data_time: 0.011, memory: 4319, decode.loss_seg: 1.3609, decode.acc_seg: 47.5856, loss: 1.3609
2021-08-13 15:18:20,923 - mmseg - INFO - Iter [16750/160000]	lr: 9.062e-03, eta: 1 day, 11:33:09, time: 0.821, data_time: 0.011, memory: 4319, decode.loss_seg: 1.3471, decode.acc_seg: 46.3147, loss: 1.3471
2021-08-13 15:19:02,129 - mmseg - INFO - Iter [16800/160000]	lr: 9.059e-03, eta: 1 day, 11:31:55, time: 0.824, data_time: 0.011, memory: 4319, decode.loss_seg: 1.3613, decode.acc_seg: 46.5655, loss: 1.3613
2021-08-13 15:19:41,568 - mmseg - INFO - Iter [16850/160000]	lr: 9.057e-03, eta: 1 day, 11:30:26, time: 0.789, data_time: 0.011, memory: 4319, decode.loss_seg: 1.3392, decode.acc_seg: 47.2118, loss: 1.3392
2021-08-13 15:20:22,837 - mmseg - INFO - Iter [16900/160000]	lr: 9.054e-03, eta: 1 day, 11:29:12, time: 0.825, data_time: 0.011, memory: 4319, decode.loss_seg: 1.3189, decode.acc_seg: 47.6133, loss: 1.3189
2021-08-13 15:21:04,836 - mmseg - INFO - Iter [16950/160000]	lr: 9.051e-03, eta: 1 day, 11:28:06, time: 0.840, data_time: 0.012, memory: 4319, decode.loss_seg: 1.3267, decode.acc_seg: 48.3957, loss: 1.3267
2021-08-13 15:21:45,886 - mmseg - INFO - Exp name: fcn_litehr18-without-head_512x512_160k_ade20k.py
2021-08-13 15:21:45,888 - mmseg - INFO - Iter [17000/160000]	lr: 9.048e-03, eta: 1 day, 11:26:51, time: 0.821, data_time: 0.011, memory: 4319, decode.loss_seg: 1.3050, decode.acc_seg: 48.8306, loss: 1.3050
2021-08-13 15:23:03,555 - mmseg - INFO - Iter [17050/160000]	lr: 9.045e-03, eta: 1 day, 11:30:43, time: 1.553, data_time: 0.755, memory: 4319, decode.loss_seg: 1.3338, decode.acc_seg: 47.6659, loss: 1.3338
2021-08-13 15:23:45,225 - mmseg - INFO - Iter [17100/160000]	lr: 9.043e-03, eta: 1 day, 11:29:33, time: 0.833, data_time: 0.012, memory: 4319, decode.loss_seg: 1.3308, decode.acc_seg: 46.9775, loss: 1.3308
2021-08-13 15:24:25,793 - mmseg - INFO - Iter [17150/160000]	lr: 9.040e-03, eta: 1 day, 11:28:14, time: 0.812, data_time: 0.011, memory: 4319, decode.loss_seg: 1.3165, decode.acc_seg: 47.4493, loss: 1.3165
2021-08-13 15:25:06,944 - mmseg - INFO - Iter [17200/160000]	lr: 9.037e-03, eta: 1 day, 11:27:00, time: 0.823, data_time: 0.011, memory: 4319, decode.loss_seg: 1.3484, decode.acc_seg: 47.2360, loss: 1.3484
2021-08-13 15:25:49,717 - mmseg - INFO - Iter [17250/160000]	lr: 9.034e-03, eta: 1 day, 11:25:59, time: 0.855, data_time: 0.011, memory: 4319, decode.loss_seg: 1.3159, decode.acc_seg: 48.0673, loss: 1.3159
2021-08-13 15:26:30,189 - mmseg - INFO - Iter [17300/160000]	lr: 9.031e-03, eta: 1 day, 11:24:40, time: 0.810, data_time: 0.012, memory: 4319, decode.loss_seg: 1.3029, decode.acc_seg: 47.4124, loss: 1.3029
2021-08-13 15:27:11,274 - mmseg - INFO - Iter [17350/160000]	lr: 9.028e-03, eta: 1 day, 11:23:26, time: 0.821, data_time: 0.011, memory: 4319, decode.loss_seg: 1.3265, decode.acc_seg: 47.6067, loss: 1.3265
2021-08-13 15:27:52,880 - mmseg - INFO - Iter [17400/160000]	lr: 9.026e-03, eta: 1 day, 11:22:16, time: 0.832, data_time: 0.011, memory: 4319, decode.loss_seg: 1.3373, decode.acc_seg: 47.2367, loss: 1.3373
2021-08-13 15:28:34,382 - mmseg - INFO - Iter [17450/160000]	lr: 9.023e-03, eta: 1 day, 11:21:06, time: 0.830, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2939, decode.acc_seg: 47.5759, loss: 1.2939
2021-08-13 15:29:15,514 - mmseg - INFO - Iter [17500/160000]	lr: 9.020e-03, eta: 1 day, 11:19:53, time: 0.823, data_time: 0.011, memory: 4319, decode.loss_seg: 1.3278, decode.acc_seg: 48.1460, loss: 1.3278
2021-08-13 15:29:56,628 - mmseg - INFO - Iter [17550/160000]	lr: 9.017e-03, eta: 1 day, 11:18:39, time: 0.822, data_time: 0.010, memory: 4319, decode.loss_seg: 1.3352, decode.acc_seg: 48.1791, loss: 1.3352
2021-08-13 15:30:37,215 - mmseg - INFO - Iter [17600/160000]	lr: 9.014e-03, eta: 1 day, 11:17:22, time: 0.812, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2889, decode.acc_seg: 48.2479, loss: 1.2889
2021-08-13 15:31:18,350 - mmseg - INFO - Iter [17650/160000]	lr: 9.012e-03, eta: 1 day, 11:16:10, time: 0.823, data_time: 0.011, memory: 4319, decode.loss_seg: 1.3363, decode.acc_seg: 47.5663, loss: 1.3363
2021-08-13 15:32:33,736 - mmseg - INFO - Iter [17700/160000]	lr: 9.009e-03, eta: 1 day, 11:19:33, time: 1.508, data_time: 0.717, memory: 4319, decode.loss_seg: 1.3635, decode.acc_seg: 47.4659, loss: 1.3635
2021-08-13 15:33:15,503 - mmseg - INFO - Iter [17750/160000]	lr: 9.006e-03, eta: 1 day, 11:18:25, time: 0.835, data_time: 0.011, memory: 4319, decode.loss_seg: 1.3001, decode.acc_seg: 47.6325, loss: 1.3001
2021-08-13 15:33:56,005 - mmseg - INFO - Iter [17800/160000]	lr: 9.003e-03, eta: 1 day, 11:17:06, time: 0.810, data_time: 0.011, memory: 4319, decode.loss_seg: 1.3077, decode.acc_seg: 48.1873, loss: 1.3077
2021-08-13 15:34:37,467 - mmseg - INFO - Iter [17850/160000]	lr: 9.000e-03, eta: 1 day, 11:15:56, time: 0.829, data_time: 0.011, memory: 4319, decode.loss_seg: 1.3120, decode.acc_seg: 46.4056, loss: 1.3120
2021-08-13 15:35:18,296 - mmseg - INFO - Iter [17900/160000]	lr: 8.997e-03, eta: 1 day, 11:14:41, time: 0.817, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2990, decode.acc_seg: 47.5274, loss: 1.2990
2021-08-13 15:35:58,850 - mmseg - INFO - Iter [17950/160000]	lr: 8.995e-03, eta: 1 day, 11:13:24, time: 0.811, data_time: 0.012, memory: 4319, decode.loss_seg: 1.3207, decode.acc_seg: 47.4385, loss: 1.3207
2021-08-13 15:36:40,176 - mmseg - INFO - Exp name: fcn_litehr18-without-head_512x512_160k_ade20k.py
2021-08-13 15:36:40,176 - mmseg - INFO - Iter [18000/160000]	lr: 8.992e-03, eta: 1 day, 11:12:13, time: 0.827, data_time: 0.011, memory: 4319, decode.loss_seg: 1.3243, decode.acc_seg: 47.2883, loss: 1.3243
2021-08-13 15:37:21,683 - mmseg - INFO - Iter [18050/160000]	lr: 8.989e-03, eta: 1 day, 11:11:04, time: 0.830, data_time: 0.011, memory: 4319, decode.loss_seg: 1.3377, decode.acc_seg: 47.2472, loss: 1.3377
2021-08-13 15:38:02,599 - mmseg - INFO - Iter [18100/160000]	lr: 8.986e-03, eta: 1 day, 11:09:51, time: 0.819, data_time: 0.011, memory: 4319, decode.loss_seg: 1.3208, decode.acc_seg: 48.1101, loss: 1.3208
2021-08-13 15:38:44,082 - mmseg - INFO - Iter [18150/160000]	lr: 8.983e-03, eta: 1 day, 11:08:42, time: 0.830, data_time: 0.011, memory: 4319, decode.loss_seg: 1.3037, decode.acc_seg: 46.9479, loss: 1.3037
2021-08-13 15:39:24,637 - mmseg - INFO - Iter [18200/160000]	lr: 8.981e-03, eta: 1 day, 11:07:26, time: 0.811, data_time: 0.010, memory: 4319, decode.loss_seg: 1.3328, decode.acc_seg: 47.6412, loss: 1.3328
2021-08-13 15:40:05,134 - mmseg - INFO - Iter [18250/160000]	lr: 8.978e-03, eta: 1 day, 11:06:09, time: 0.810, data_time: 0.011, memory: 4319, decode.loss_seg: 1.3181, decode.acc_seg: 48.4998, loss: 1.3181
2021-08-13 15:41:20,180 - mmseg - INFO - Iter [18300/160000]	lr: 8.975e-03, eta: 1 day, 11:09:20, time: 1.500, data_time: 0.721, memory: 4319, decode.loss_seg: 1.3266, decode.acc_seg: 47.3498, loss: 1.3266
2021-08-13 15:42:02,817 - mmseg - INFO - Iter [18350/160000]	lr: 8.972e-03, eta: 1 day, 11:08:20, time: 0.853, data_time: 0.011, memory: 4319, decode.loss_seg: 1.3199, decode.acc_seg: 46.5847, loss: 1.3199
2021-08-13 15:42:43,495 - mmseg - INFO - Iter [18400/160000]	lr: 8.969e-03, eta: 1 day, 11:07:05, time: 0.814, data_time: 0.011, memory: 4319, decode.loss_seg: 1.3071, decode.acc_seg: 47.6154, loss: 1.3071
2021-08-13 15:43:24,053 - mmseg - INFO - Iter [18450/160000]	lr: 8.966e-03, eta: 1 day, 11:05:49, time: 0.811, data_time: 0.011, memory: 4319, decode.loss_seg: 1.3090, decode.acc_seg: 47.4880, loss: 1.3090
2021-08-13 15:44:05,593 - mmseg - INFO - Iter [18500/160000]	lr: 8.964e-03, eta: 1 day, 11:04:41, time: 0.831, data_time: 0.011, memory: 4319, decode.loss_seg: 1.3117, decode.acc_seg: 46.9703, loss: 1.3117
2021-08-13 15:44:46,594 - mmseg - INFO - Iter [18550/160000]	lr: 8.961e-03, eta: 1 day, 11:03:29, time: 0.820, data_time: 0.011, memory: 4319, decode.loss_seg: 1.3333, decode.acc_seg: 47.8359, loss: 1.3333
2021-08-13 15:45:27,535 - mmseg - INFO - Iter [18600/160000]	lr: 8.958e-03, eta: 1 day, 11:02:16, time: 0.818, data_time: 0.010, memory: 4319, decode.loss_seg: 1.2905, decode.acc_seg: 47.9678, loss: 1.2905
2021-08-13 15:46:10,143 - mmseg - INFO - Iter [18650/160000]	lr: 8.955e-03, eta: 1 day, 11:01:16, time: 0.853, data_time: 0.011, memory: 4319, decode.loss_seg: 1.3257, decode.acc_seg: 47.7337, loss: 1.3257
2021-08-13 15:46:51,309 - mmseg - INFO - Iter [18700/160000]	lr: 8.952e-03, eta: 1 day, 11:00:06, time: 0.824, data_time: 0.011, memory: 4319, decode.loss_seg: 1.3178, decode.acc_seg: 48.1390, loss: 1.3178
2021-08-13 15:47:31,534 - mmseg - INFO - Iter [18750/160000]	lr: 8.950e-03, eta: 1 day, 10:58:48, time: 0.805, data_time: 0.011, memory: 4319, decode.loss_seg: 1.3233, decode.acc_seg: 48.2291, loss: 1.3233
2021-08-13 15:48:12,804 - mmseg - INFO - Iter [18800/160000]	lr: 8.947e-03, eta: 1 day, 10:57:39, time: 0.825, data_time: 0.010, memory: 4319, decode.loss_seg: 1.3269, decode.acc_seg: 47.1993, loss: 1.3269
2021-08-13 15:48:54,900 - mmseg - INFO - Iter [18850/160000]	lr: 8.944e-03, eta: 1 day, 10:56:36, time: 0.842, data_time: 0.011, memory: 4319, decode.loss_seg: 1.3293, decode.acc_seg: 47.5277, loss: 1.3293
2021-08-13 15:49:36,572 - mmseg - INFO - Iter [18900/160000]	lr: 8.941e-03, eta: 1 day, 10:55:30, time: 0.833, data_time: 0.010, memory: 4319, decode.loss_seg: 1.3509, decode.acc_seg: 47.3797, loss: 1.3509
2021-08-13 15:50:54,444 - mmseg - INFO - Iter [18950/160000]	lr: 8.938e-03, eta: 1 day, 10:58:53, time: 1.558, data_time: 0.732, memory: 4319, decode.loss_seg: 1.3307, decode.acc_seg: 46.5603, loss: 1.3307
2021-08-13 15:51:36,145 - mmseg - INFO - Exp name: fcn_litehr18-without-head_512x512_160k_ade20k.py
2021-08-13 15:51:36,145 - mmseg - INFO - Iter [19000/160000]	lr: 8.935e-03, eta: 1 day, 10:57:47, time: 0.834, data_time: 0.011, memory: 4319, decode.loss_seg: 1.3059, decode.acc_seg: 47.4863, loss: 1.3059
2021-08-13 15:52:16,721 - mmseg - INFO - Iter [19050/160000]	lr: 8.933e-03, eta: 1 day, 10:56:32, time: 0.812, data_time: 0.011, memory: 4319, decode.loss_seg: 1.3383, decode.acc_seg: 47.0739, loss: 1.3383
2021-08-13 15:52:58,110 - mmseg - INFO - Iter [19100/160000]	lr: 8.930e-03, eta: 1 day, 10:55:23, time: 0.827, data_time: 0.011, memory: 4319, decode.loss_seg: 1.3054, decode.acc_seg: 48.0372, loss: 1.3054
2021-08-13 15:53:40,058 - mmseg - INFO - Iter [19150/160000]	lr: 8.927e-03, eta: 1 day, 10:54:19, time: 0.839, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2828, decode.acc_seg: 48.8956, loss: 1.2828
2021-08-13 15:54:22,060 - mmseg - INFO - Iter [19200/160000]	lr: 8.924e-03, eta: 1 day, 10:53:16, time: 0.840, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2877, decode.acc_seg: 47.8510, loss: 1.2877
2021-08-13 15:55:03,059 - mmseg - INFO - Iter [19250/160000]	lr: 8.921e-03, eta: 1 day, 10:52:05, time: 0.820, data_time: 0.010, memory: 4319, decode.loss_seg: 1.3461, decode.acc_seg: 47.7433, loss: 1.3461
2021-08-13 15:55:43,913 - mmseg - INFO - Iter [19300/160000]	lr: 8.918e-03, eta: 1 day, 10:50:53, time: 0.817, data_time: 0.011, memory: 4319, decode.loss_seg: 1.3088, decode.acc_seg: 48.7214, loss: 1.3088
2021-08-13 15:56:24,560 - mmseg - INFO - Iter [19350/160000]	lr: 8.916e-03, eta: 1 day, 10:49:40, time: 0.813, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2928, decode.acc_seg: 48.3418, loss: 1.2928
2021-08-13 15:57:06,463 - mmseg - INFO - Iter [19400/160000]	lr: 8.913e-03, eta: 1 day, 10:48:36, time: 0.839, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2749, decode.acc_seg: 48.1905, loss: 1.2749
2021-08-13 15:57:47,067 - mmseg - INFO - Iter [19450/160000]	lr: 8.910e-03, eta: 1 day, 10:47:23, time: 0.812, data_time: 0.010, memory: 4319, decode.loss_seg: 1.2718, decode.acc_seg: 47.6113, loss: 1.2718
2021-08-13 15:58:28,099 - mmseg - INFO - Iter [19500/160000]	lr: 8.907e-03, eta: 1 day, 10:46:12, time: 0.820, data_time: 0.011, memory: 4319, decode.loss_seg: 1.3017, decode.acc_seg: 48.2359, loss: 1.3017
2021-08-13 15:59:10,344 - mmseg - INFO - Iter [19550/160000]	lr: 8.904e-03, eta: 1 day, 10:45:11, time: 0.845, data_time: 0.010, memory: 4319, decode.loss_seg: 1.3259, decode.acc_seg: 48.6673, loss: 1.3259
2021-08-13 16:00:27,174 - mmseg - INFO - Iter [19600/160000]	lr: 8.902e-03, eta: 1 day, 10:48:18, time: 1.537, data_time: 0.733, memory: 4319, decode.loss_seg: 1.3045, decode.acc_seg: 47.7534, loss: 1.3045
2021-08-13 16:01:07,346 - mmseg - INFO - Iter [19650/160000]	lr: 8.899e-03, eta: 1 day, 10:47:02, time: 0.803, data_time: 0.011, memory: 4319, decode.loss_seg: 1.3222, decode.acc_seg: 47.2369, loss: 1.3222
2021-08-13 16:01:48,725 - mmseg - INFO - Iter [19700/160000]	lr: 8.896e-03, eta: 1 day, 10:45:54, time: 0.827, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2991, decode.acc_seg: 48.2699, loss: 1.2991
2021-08-13 16:02:30,050 - mmseg - INFO - Iter [19750/160000]	lr: 8.893e-03, eta: 1 day, 10:44:46, time: 0.827, data_time: 0.011, memory: 4319, decode.loss_seg: 1.3119, decode.acc_seg: 47.7282, loss: 1.3119
2021-08-13 16:03:11,659 - mmseg - INFO - Iter [19800/160000]	lr: 8.890e-03, eta: 1 day, 10:43:41, time: 0.832, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2849, decode.acc_seg: 47.6964, loss: 1.2849
2021-08-13 16:03:52,979 - mmseg - INFO - Iter [19850/160000]	lr: 8.887e-03, eta: 1 day, 10:42:33, time: 0.826, data_time: 0.011, memory: 4319, decode.loss_seg: 1.3146, decode.acc_seg: 47.5840, loss: 1.3146
2021-08-13 16:04:34,201 - mmseg - INFO - Iter [19900/160000]	lr: 8.885e-03, eta: 1 day, 10:41:25, time: 0.824, data_time: 0.011, memory: 4319, decode.loss_seg: 1.3354, decode.acc_seg: 47.6375, loss: 1.3354
2021-08-13 16:05:17,036 - mmseg - INFO - Iter [19950/160000]	lr: 8.882e-03, eta: 1 day, 10:40:28, time: 0.857, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2777, decode.acc_seg: 48.8369, loss: 1.2777
2021-08-13 16:05:58,054 - mmseg - INFO - Exp name: fcn_litehr18-without-head_512x512_160k_ade20k.py
2021-08-13 16:05:58,055 - mmseg - INFO - Iter [20000/160000]	lr: 8.879e-03, eta: 1 day, 10:39:18, time: 0.820, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2911, decode.acc_seg: 47.8826, loss: 1.2911
2021-08-13 16:06:39,617 - mmseg - INFO - Iter [20050/160000]	lr: 8.876e-03, eta: 1 day, 10:38:13, time: 0.832, data_time: 0.012, memory: 4319, decode.loss_seg: 1.2712, decode.acc_seg: 49.0339, loss: 1.2712
2021-08-13 16:07:21,396 - mmseg - INFO - Iter [20100/160000]	lr: 8.873e-03, eta: 1 day, 10:37:09, time: 0.835, data_time: 0.010, memory: 4319, decode.loss_seg: 1.3122, decode.acc_seg: 48.3506, loss: 1.3122
2021-08-13 16:08:02,175 - mmseg - INFO - Iter [20150/160000]	lr: 8.871e-03, eta: 1 day, 10:35:59, time: 0.815, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2984, decode.acc_seg: 48.5561, loss: 1.2984
2021-08-13 16:09:19,311 - mmseg - INFO - Iter [20200/160000]	lr: 8.868e-03, eta: 1 day, 10:39:00, time: 1.543, data_time: 0.721, memory: 4319, decode.loss_seg: 1.3146, decode.acc_seg: 48.3491, loss: 1.3146
2021-08-13 16:10:00,141 - mmseg - INFO - Iter [20250/160000]	lr: 8.865e-03, eta: 1 day, 10:37:49, time: 0.817, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2609, decode.acc_seg: 48.6607, loss: 1.2609
2021-08-13 16:10:41,658 - mmseg - INFO - Iter [20300/160000]	lr: 8.862e-03, eta: 1 day, 10:36:43, time: 0.829, data_time: 0.010, memory: 4319, decode.loss_seg: 1.3209, decode.acc_seg: 48.3420, loss: 1.3209
2021-08-13 16:11:22,454 - mmseg - INFO - Iter [20350/160000]	lr: 8.859e-03, eta: 1 day, 10:35:32, time: 0.816, data_time: 0.012, memory: 4319, decode.loss_seg: 1.2523, decode.acc_seg: 48.7871, loss: 1.2523
2021-08-13 16:12:04,006 - mmseg - INFO - Iter [20400/160000]	lr: 8.856e-03, eta: 1 day, 10:34:27, time: 0.831, data_time: 0.011, memory: 4319, decode.loss_seg: 1.3192, decode.acc_seg: 47.6904, loss: 1.3192
2021-08-13 16:12:45,821 - mmseg - INFO - Iter [20450/160000]	lr: 8.854e-03, eta: 1 day, 10:33:24, time: 0.836, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2935, decode.acc_seg: 48.9642, loss: 1.2935
2021-08-13 16:13:26,810 - mmseg - INFO - Iter [20500/160000]	lr: 8.851e-03, eta: 1 day, 10:32:15, time: 0.820, data_time: 0.011, memory: 4319, decode.loss_seg: 1.3160, decode.acc_seg: 48.4231, loss: 1.3160
2021-08-13 16:14:08,600 - mmseg - INFO - Iter [20550/160000]	lr: 8.848e-03, eta: 1 day, 10:31:11, time: 0.836, data_time: 0.010, memory: 4319, decode.loss_seg: 1.2780, decode.acc_seg: 47.9592, loss: 1.2780
2021-08-13 16:14:49,219 - mmseg - INFO - Iter [20600/160000]	lr: 8.845e-03, eta: 1 day, 10:30:00, time: 0.813, data_time: 0.010, memory: 4319, decode.loss_seg: 1.3012, decode.acc_seg: 48.2781, loss: 1.3012
2021-08-13 16:15:30,657 - mmseg - INFO - Iter [20650/160000]	lr: 8.842e-03, eta: 1 day, 10:28:54, time: 0.828, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2734, decode.acc_seg: 47.7105, loss: 1.2734
2021-08-13 16:16:12,552 - mmseg - INFO - Iter [20700/160000]	lr: 8.839e-03, eta: 1 day, 10:27:52, time: 0.838, data_time: 0.011, memory: 4319, decode.loss_seg: 1.3001, decode.acc_seg: 48.4424, loss: 1.3001
2021-08-13 16:16:53,893 - mmseg - INFO - Iter [20750/160000]	lr: 8.837e-03, eta: 1 day, 10:26:46, time: 0.827, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2961, decode.acc_seg: 47.9647, loss: 1.2961
2021-08-13 16:17:34,355 - mmseg - INFO - Iter [20800/160000]	lr: 8.834e-03, eta: 1 day, 10:25:35, time: 0.810, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2845, decode.acc_seg: 48.1157, loss: 1.2845
2021-08-13 16:18:49,118 - mmseg - INFO - Iter [20850/160000]	lr: 8.831e-03, eta: 1 day, 10:28:12, time: 1.495, data_time: 0.702, memory: 4319, decode.loss_seg: 1.2724, decode.acc_seg: 48.9075, loss: 1.2724
2021-08-13 16:19:30,442 - mmseg - INFO - Iter [20900/160000]	lr: 8.828e-03, eta: 1 day, 10:27:05, time: 0.826, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2558, decode.acc_seg: 47.6483, loss: 1.2558
2021-08-13 16:20:11,944 - mmseg - INFO - Iter [20950/160000]	lr: 8.825e-03, eta: 1 day, 10:26:00, time: 0.830, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2475, decode.acc_seg: 49.4558, loss: 1.2475
2021-08-13 16:20:53,137 - mmseg - INFO - Exp name: fcn_litehr18-without-head_512x512_160k_ade20k.py
2021-08-13 16:20:53,137 - mmseg - INFO - Iter [21000/160000]	lr: 8.823e-03, eta: 1 day, 10:24:53, time: 0.824, data_time: 0.012, memory: 4319, decode.loss_seg: 1.2829, decode.acc_seg: 49.9422, loss: 1.2829
2021-08-13 16:21:33,905 - mmseg - INFO - Iter [21050/160000]	lr: 8.820e-03, eta: 1 day, 10:23:44, time: 0.816, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2801, decode.acc_seg: 48.1037, loss: 1.2801
2021-08-13 16:22:14,364 - mmseg - INFO - Iter [21100/160000]	lr: 8.817e-03, eta: 1 day, 10:22:32, time: 0.809, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2615, decode.acc_seg: 48.3034, loss: 1.2615
2021-08-13 16:22:55,136 - mmseg - INFO - Iter [21150/160000]	lr: 8.814e-03, eta: 1 day, 10:21:23, time: 0.815, data_time: 0.010, memory: 4319, decode.loss_seg: 1.3130, decode.acc_seg: 47.9958, loss: 1.3130
2021-08-13 16:23:36,020 - mmseg - INFO - Iter [21200/160000]	lr: 8.811e-03, eta: 1 day, 10:20:15, time: 0.818, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2821, decode.acc_seg: 49.2343, loss: 1.2821
2021-08-13 16:24:17,651 - mmseg - INFO - Iter [21250/160000]	lr: 8.808e-03, eta: 1 day, 10:19:11, time: 0.832, data_time: 0.010, memory: 4319, decode.loss_seg: 1.2734, decode.acc_seg: 48.4613, loss: 1.2734
2021-08-13 16:24:58,541 - mmseg - INFO - Iter [21300/160000]	lr: 8.806e-03, eta: 1 day, 10:18:03, time: 0.818, data_time: 0.011, memory: 4319, decode.loss_seg: 1.3019, decode.acc_seg: 46.9856, loss: 1.3019
2021-08-13 16:25:39,491 - mmseg - INFO - Iter [21350/160000]	lr: 8.803e-03, eta: 1 day, 10:16:55, time: 0.819, data_time: 0.011, memory: 4319, decode.loss_seg: 1.3255, decode.acc_seg: 47.3046, loss: 1.3255
2021-08-13 16:26:20,452 - mmseg - INFO - Iter [21400/160000]	lr: 8.800e-03, eta: 1 day, 10:15:48, time: 0.819, data_time: 0.011, memory: 4319, decode.loss_seg: 1.3114, decode.acc_seg: 47.2362, loss: 1.3114
2021-08-13 16:27:01,859 - mmseg - INFO - Iter [21450/160000]	lr: 8.797e-03, eta: 1 day, 10:14:43, time: 0.828, data_time: 0.010, memory: 4319, decode.loss_seg: 1.2970, decode.acc_seg: 47.3921, loss: 1.2970
2021-08-13 16:28:17,866 - mmseg - INFO - Iter [21500/160000]	lr: 8.794e-03, eta: 1 day, 10:17:22, time: 1.521, data_time: 0.716, memory: 4319, decode.loss_seg: 1.2579, decode.acc_seg: 48.4597, loss: 1.2579
2021-08-13 16:28:58,639 - mmseg - INFO - Iter [21550/160000]	lr: 8.791e-03, eta: 1 day, 10:16:13, time: 0.815, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2944, decode.acc_seg: 48.2017, loss: 1.2944
2021-08-13 16:29:38,935 - mmseg - INFO - Iter [21600/160000]	lr: 8.789e-03, eta: 1 day, 10:15:01, time: 0.805, data_time: 0.012, memory: 4319, decode.loss_seg: 1.2589, decode.acc_seg: 48.7105, loss: 1.2589
2021-08-13 16:30:20,291 - mmseg - INFO - Iter [21650/160000]	lr: 8.786e-03, eta: 1 day, 10:13:56, time: 0.828, data_time: 0.012, memory: 4319, decode.loss_seg: 1.3053, decode.acc_seg: 49.0342, loss: 1.3053
2021-08-13 16:31:01,671 - mmseg - INFO - Iter [21700/160000]	lr: 8.783e-03, eta: 1 day, 10:12:51, time: 0.827, data_time: 0.011, memory: 4319, decode.loss_seg: 1.3118, decode.acc_seg: 47.7706, loss: 1.3118
2021-08-13 16:31:42,639 - mmseg - INFO - Iter [21750/160000]	lr: 8.780e-03, eta: 1 day, 10:11:44, time: 0.820, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2417, decode.acc_seg: 49.2875, loss: 1.2417
2021-08-13 16:32:23,548 - mmseg - INFO - Iter [21800/160000]	lr: 8.777e-03, eta: 1 day, 10:10:37, time: 0.818, data_time: 0.011, memory: 4319, decode.loss_seg: 1.3103, decode.acc_seg: 47.3830, loss: 1.3103
2021-08-13 16:33:04,670 - mmseg - INFO - Iter [21850/160000]	lr: 8.775e-03, eta: 1 day, 10:09:31, time: 0.822, data_time: 0.012, memory: 4319, decode.loss_seg: 1.2928, decode.acc_seg: 48.5248, loss: 1.2928
2021-08-13 16:33:45,981 - mmseg - INFO - Iter [21900/160000]	lr: 8.772e-03, eta: 1 day, 10:08:26, time: 0.826, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2414, decode.acc_seg: 49.7767, loss: 1.2414
2021-08-13 16:34:27,508 - mmseg - INFO - Iter [21950/160000]	lr: 8.769e-03, eta: 1 day, 10:07:23, time: 0.831, data_time: 0.011, memory: 4319, decode.loss_seg: 1.3088, decode.acc_seg: 47.6522, loss: 1.3088
2021-08-13 16:35:08,152 - mmseg - INFO - Exp name: fcn_litehr18-without-head_512x512_160k_ade20k.py
2021-08-13 16:35:08,152 - mmseg - INFO - Iter [22000/160000]	lr: 8.766e-03, eta: 1 day, 10:06:14, time: 0.813, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2561, decode.acc_seg: 49.1788, loss: 1.2561
2021-08-13 16:35:48,651 - mmseg - INFO - Iter [22050/160000]	lr: 8.763e-03, eta: 1 day, 10:05:05, time: 0.810, data_time: 0.011, memory: 4319, decode.loss_seg: 1.3208, decode.acc_seg: 48.5808, loss: 1.3208
2021-08-13 16:37:05,826 - mmseg - INFO - Iter [22100/160000]	lr: 8.760e-03, eta: 1 day, 10:07:45, time: 1.543, data_time: 0.737, memory: 4319, decode.loss_seg: 1.2942, decode.acc_seg: 47.5673, loss: 1.2942
2021-08-13 16:37:46,945 - mmseg - INFO - Iter [22150/160000]	lr: 8.758e-03, eta: 1 day, 10:06:39, time: 0.822, data_time: 0.010, memory: 4319, decode.loss_seg: 1.2517, decode.acc_seg: 48.7268, loss: 1.2517
2021-08-13 16:38:27,023 - mmseg - INFO - Iter [22200/160000]	lr: 8.755e-03, eta: 1 day, 10:05:26, time: 0.801, data_time: 0.010, memory: 4319, decode.loss_seg: 1.2689, decode.acc_seg: 49.5673, loss: 1.2689
2021-08-13 16:39:07,651 - mmseg - INFO - Iter [22250/160000]	lr: 8.752e-03, eta: 1 day, 10:04:18, time: 0.813, data_time: 0.010, memory: 4319, decode.loss_seg: 1.2438, decode.acc_seg: 48.5896, loss: 1.2438
2021-08-13 16:39:49,058 - mmseg - INFO - Iter [22300/160000]	lr: 8.749e-03, eta: 1 day, 10:03:14, time: 0.828, data_time: 0.010, memory: 4319, decode.loss_seg: 1.2692, decode.acc_seg: 48.5808, loss: 1.2692
2021-08-13 16:40:31,074 - mmseg - INFO - Iter [22350/160000]	lr: 8.746e-03, eta: 1 day, 10:02:14, time: 0.840, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2256, decode.acc_seg: 48.6012, loss: 1.2256
2021-08-13 16:41:12,927 - mmseg - INFO - Iter [22400/160000]	lr: 8.743e-03, eta: 1 day, 10:01:13, time: 0.837, data_time: 0.010, memory: 4319, decode.loss_seg: 1.2466, decode.acc_seg: 49.3445, loss: 1.2466
2021-08-13 16:41:55,257 - mmseg - INFO - Iter [22450/160000]	lr: 8.741e-03, eta: 1 day, 10:00:15, time: 0.846, data_time: 0.010, memory: 4319, decode.loss_seg: 1.2500, decode.acc_seg: 49.1220, loss: 1.2500
2021-08-13 16:42:37,266 - mmseg - INFO - Iter [22500/160000]	lr: 8.738e-03, eta: 1 day, 9:59:16, time: 0.840, data_time: 0.010, memory: 4319, decode.loss_seg: 1.2811, decode.acc_seg: 48.4728, loss: 1.2811
2021-08-13 16:43:20,166 - mmseg - INFO - Iter [22550/160000]	lr: 8.735e-03, eta: 1 day, 9:58:21, time: 0.858, data_time: 0.010, memory: 4319, decode.loss_seg: 1.2982, decode.acc_seg: 48.4309, loss: 1.2982
2021-08-13 16:44:02,386 - mmseg - INFO - Iter [22600/160000]	lr: 8.732e-03, eta: 1 day, 9:57:23, time: 0.844, data_time: 0.010, memory: 4319, decode.loss_seg: 1.3167, decode.acc_seg: 49.0653, loss: 1.3167
2021-08-13 16:44:44,620 - mmseg - INFO - Iter [22650/160000]	lr: 8.729e-03, eta: 1 day, 9:56:25, time: 0.845, data_time: 0.010, memory: 4319, decode.loss_seg: 1.2567, decode.acc_seg: 49.2534, loss: 1.2567
2021-08-13 16:45:25,239 - mmseg - INFO - Iter [22700/160000]	lr: 8.726e-03, eta: 1 day, 9:55:17, time: 0.812, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2791, decode.acc_seg: 47.2289, loss: 1.2791
2021-08-13 16:46:42,275 - mmseg - INFO - Iter [22750/160000]	lr: 8.724e-03, eta: 1 day, 9:57:49, time: 1.541, data_time: 0.668, memory: 4319, decode.loss_seg: 1.2630, decode.acc_seg: 48.0426, loss: 1.2630
2021-08-13 16:47:24,946 - mmseg - INFO - Iter [22800/160000]	lr: 8.721e-03, eta: 1 day, 9:56:53, time: 0.853, data_time: 0.010, memory: 4319, decode.loss_seg: 1.2280, decode.acc_seg: 48.5361, loss: 1.2280
2021-08-13 16:48:08,183 - mmseg - INFO - Iter [22850/160000]	lr: 8.718e-03, eta: 1 day, 9:56:01, time: 0.865, data_time: 0.010, memory: 4319, decode.loss_seg: 1.2767, decode.acc_seg: 48.5736, loss: 1.2767
2021-08-13 16:48:51,030 - mmseg - INFO - Iter [22900/160000]	lr: 8.715e-03, eta: 1 day, 9:55:06, time: 0.857, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2648, decode.acc_seg: 49.4542, loss: 1.2648
2021-08-13 16:49:33,759 - mmseg - INFO - Iter [22950/160000]	lr: 8.712e-03, eta: 1 day, 9:54:11, time: 0.854, data_time: 0.010, memory: 4319, decode.loss_seg: 1.2576, decode.acc_seg: 47.1681, loss: 1.2576
2021-08-13 16:50:16,172 - mmseg - INFO - Exp name: fcn_litehr18-without-head_512x512_160k_ade20k.py
2021-08-13 16:50:16,173 - mmseg - INFO - Iter [23000/160000]	lr: 8.710e-03, eta: 1 day, 9:53:14, time: 0.848, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2775, decode.acc_seg: 48.3251, loss: 1.2775
2021-08-13 16:50:57,045 - mmseg - INFO - Iter [23050/160000]	lr: 8.707e-03, eta: 1 day, 9:52:08, time: 0.818, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2661, decode.acc_seg: 50.2804, loss: 1.2661
2021-08-13 16:51:37,530 - mmseg - INFO - Iter [23100/160000]	lr: 8.704e-03, eta: 1 day, 9:50:59, time: 0.810, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2457, decode.acc_seg: 48.3448, loss: 1.2457
2021-08-13 16:52:18,772 - mmseg - INFO - Iter [23150/160000]	lr: 8.701e-03, eta: 1 day, 9:49:55, time: 0.825, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2433, decode.acc_seg: 49.1448, loss: 1.2433
2021-08-13 16:53:01,417 - mmseg - INFO - Iter [23200/160000]	lr: 8.698e-03, eta: 1 day, 9:49:00, time: 0.853, data_time: 0.010, memory: 4319, decode.loss_seg: 1.2788, decode.acc_seg: 47.9920, loss: 1.2788
2021-08-13 16:53:44,880 - mmseg - INFO - Iter [23250/160000]	lr: 8.695e-03, eta: 1 day, 9:48:09, time: 0.869, data_time: 0.010, memory: 4319, decode.loss_seg: 1.2736, decode.acc_seg: 48.4875, loss: 1.2736
2021-08-13 16:54:27,506 - mmseg - INFO - Iter [23300/160000]	lr: 8.693e-03, eta: 1 day, 9:47:14, time: 0.853, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2853, decode.acc_seg: 48.7097, loss: 1.2853
2021-08-13 16:55:45,345 - mmseg - INFO - Iter [23350/160000]	lr: 8.690e-03, eta: 1 day, 9:49:45, time: 1.557, data_time: 0.693, memory: 4319, decode.loss_seg: 1.2907, decode.acc_seg: 48.1846, loss: 1.2907
2021-08-13 16:56:25,485 - mmseg - INFO - Iter [23400/160000]	lr: 8.687e-03, eta: 1 day, 9:48:34, time: 0.802, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2756, decode.acc_seg: 48.6676, loss: 1.2756
2021-08-13 16:57:07,167 - mmseg - INFO - Iter [23450/160000]	lr: 8.684e-03, eta: 1 day, 9:47:33, time: 0.834, data_time: 0.011, memory: 4319, decode.loss_seg: 1.3113, decode.acc_seg: 48.3847, loss: 1.3113
2021-08-13 16:57:49,267 - mmseg - INFO - Iter [23500/160000]	lr: 8.681e-03, eta: 1 day, 9:46:34, time: 0.842, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2688, decode.acc_seg: 49.4253, loss: 1.2688
2021-08-13 16:58:29,963 - mmseg - INFO - Iter [23550/160000]	lr: 8.678e-03, eta: 1 day, 9:45:27, time: 0.814, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2390, decode.acc_seg: 47.7016, loss: 1.2390
2021-08-13 16:59:10,500 - mmseg - INFO - Iter [23600/160000]	lr: 8.676e-03, eta: 1 day, 9:44:20, time: 0.811, data_time: 0.012, memory: 4319, decode.loss_seg: 1.2822, decode.acc_seg: 48.3096, loss: 1.2822
2021-08-13 16:59:52,370 - mmseg - INFO - Iter [23650/160000]	lr: 8.673e-03, eta: 1 day, 9:43:20, time: 0.837, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2603, decode.acc_seg: 48.1630, loss: 1.2603
2021-08-13 17:00:32,928 - mmseg - INFO - Iter [23700/160000]	lr: 8.670e-03, eta: 1 day, 9:42:13, time: 0.811, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2434, decode.acc_seg: 48.9734, loss: 1.2434
2021-08-13 17:01:14,680 - mmseg - INFO - Iter [23750/160000]	lr: 8.667e-03, eta: 1 day, 9:41:12, time: 0.835, data_time: 0.010, memory: 4319, decode.loss_seg: 1.2174, decode.acc_seg: 49.3878, loss: 1.2174
2021-08-13 17:01:56,778 - mmseg - INFO - Iter [23800/160000]	lr: 8.664e-03, eta: 1 day, 9:40:14, time: 0.842, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2973, decode.acc_seg: 48.2011, loss: 1.2973
2021-08-13 17:02:37,898 - mmseg - INFO - Iter [23850/160000]	lr: 8.661e-03, eta: 1 day, 9:39:10, time: 0.823, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2997, decode.acc_seg: 48.8571, loss: 1.2997
2021-08-13 17:03:18,653 - mmseg - INFO - Iter [23900/160000]	lr: 8.659e-03, eta: 1 day, 9:38:05, time: 0.815, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2615, decode.acc_seg: 48.7998, loss: 1.2615
2021-08-13 17:04:00,969 - mmseg - INFO - Iter [23950/160000]	lr: 8.656e-03, eta: 1 day, 9:37:08, time: 0.846, data_time: 0.010, memory: 4319, decode.loss_seg: 1.2990, decode.acc_seg: 48.4785, loss: 1.2990
2021-08-13 17:05:17,956 - mmseg - INFO - Exp name: fcn_litehr18-without-head_512x512_160k_ade20k.py
2021-08-13 17:05:17,961 - mmseg - INFO - Iter [24000/160000]	lr: 8.653e-03, eta: 1 day, 9:39:28, time: 1.540, data_time: 0.723, memory: 4319, decode.loss_seg: 1.2489, decode.acc_seg: 49.1059, loss: 1.2489
2021-08-13 17:05:59,253 - mmseg - INFO - Iter [24050/160000]	lr: 8.650e-03, eta: 1 day, 9:38:25, time: 0.826, data_time: 0.010, memory: 4319, decode.loss_seg: 1.2412, decode.acc_seg: 49.0914, loss: 1.2412
2021-08-13 17:06:41,004 - mmseg - INFO - Iter [24100/160000]	lr: 8.647e-03, eta: 1 day, 9:37:24, time: 0.835, data_time: 0.010, memory: 4319, decode.loss_seg: 1.2486, decode.acc_seg: 48.4060, loss: 1.2486
2021-08-13 17:07:21,595 - mmseg - INFO - Iter [24150/160000]	lr: 8.644e-03, eta: 1 day, 9:36:18, time: 0.812, data_time: 0.010, memory: 4319, decode.loss_seg: 1.2535, decode.acc_seg: 48.7866, loss: 1.2535
2021-08-13 17:08:01,992 - mmseg - INFO - Iter [24200/160000]	lr: 8.642e-03, eta: 1 day, 9:35:10, time: 0.808, data_time: 0.010, memory: 4319, decode.loss_seg: 1.2646, decode.acc_seg: 49.2410, loss: 1.2646
2021-08-13 17:08:42,409 - mmseg - INFO - Iter [24250/160000]	lr: 8.639e-03, eta: 1 day, 9:34:02, time: 0.808, data_time: 0.010, memory: 4319, decode.loss_seg: 1.2439, decode.acc_seg: 49.1868, loss: 1.2439
2021-08-13 17:09:24,047 - mmseg - INFO - Iter [24300/160000]	lr: 8.636e-03, eta: 1 day, 9:33:02, time: 0.833, data_time: 0.010, memory: 4319, decode.loss_seg: 1.2691, decode.acc_seg: 47.6774, loss: 1.2691
2021-08-13 17:10:04,466 - mmseg - INFO - Iter [24350/160000]	lr: 8.633e-03, eta: 1 day, 9:31:54, time: 0.808, data_time: 0.010, memory: 4319, decode.loss_seg: 1.2605, decode.acc_seg: 49.1478, loss: 1.2605
2021-08-13 17:10:45,692 - mmseg - INFO - Iter [24400/160000]	lr: 8.630e-03, eta: 1 day, 9:30:52, time: 0.825, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2326, decode.acc_seg: 49.2240, loss: 1.2326
2021-08-13 17:11:28,291 - mmseg - INFO - Iter [24450/160000]	lr: 8.627e-03, eta: 1 day, 9:29:57, time: 0.852, data_time: 0.010, memory: 4319, decode.loss_seg: 1.2905, decode.acc_seg: 48.0952, loss: 1.2905
2021-08-13 17:12:10,905 - mmseg - INFO - Iter [24500/160000]	lr: 8.625e-03, eta: 1 day, 9:29:02, time: 0.852, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2707, decode.acc_seg: 48.7401, loss: 1.2707
2021-08-13 17:12:53,075 - mmseg - INFO - Iter [24550/160000]	lr: 8.622e-03, eta: 1 day, 9:28:05, time: 0.844, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2747, decode.acc_seg: 49.1856, loss: 1.2747
2021-08-13 17:13:35,146 - mmseg - INFO - Iter [24600/160000]	lr: 8.619e-03, eta: 1 day, 9:27:07, time: 0.842, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2899, decode.acc_seg: 48.0081, loss: 1.2899
2021-08-13 17:14:51,060 - mmseg - INFO - Iter [24650/160000]	lr: 8.616e-03, eta: 1 day, 9:29:15, time: 1.518, data_time: 0.682, memory: 4319, decode.loss_seg: 1.2785, decode.acc_seg: 49.0447, loss: 1.2785
2021-08-13 17:15:32,002 - mmseg - INFO - Iter [24700/160000]	lr: 8.613e-03, eta: 1 day, 9:28:11, time: 0.820, data_time: 0.012, memory: 4319, decode.loss_seg: 1.2418, decode.acc_seg: 48.4505, loss: 1.2418
2021-08-13 17:16:13,491 - mmseg - INFO - Iter [24750/160000]	lr: 8.610e-03, eta: 1 day, 9:27:10, time: 0.830, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2270, decode.acc_seg: 49.5023, loss: 1.2270
2021-08-13 17:16:55,231 - mmseg - INFO - Iter [24800/160000]	lr: 8.608e-03, eta: 1 day, 9:26:10, time: 0.835, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2341, decode.acc_seg: 49.3764, loss: 1.2341
2021-08-13 17:17:36,483 - mmseg - INFO - Iter [24850/160000]	lr: 8.605e-03, eta: 1 day, 9:25:08, time: 0.825, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2493, decode.acc_seg: 48.5760, loss: 1.2493
2021-08-13 17:18:19,102 - mmseg - INFO - Iter [24900/160000]	lr: 8.602e-03, eta: 1 day, 9:24:13, time: 0.853, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2634, decode.acc_seg: 48.2578, loss: 1.2634
2021-08-13 17:19:01,161 - mmseg - INFO - Iter [24950/160000]	lr: 8.599e-03, eta: 1 day, 9:23:16, time: 0.841, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2482, decode.acc_seg: 49.9737, loss: 1.2482
2021-08-13 17:19:41,871 - mmseg - INFO - Exp name: fcn_litehr18-without-head_512x512_160k_ade20k.py
2021-08-13 17:19:41,871 - mmseg - INFO - Iter [25000/160000]	lr: 8.596e-03, eta: 1 day, 9:22:11, time: 0.814, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2820, decode.acc_seg: 49.0744, loss: 1.2820
2021-08-13 17:20:22,944 - mmseg - INFO - Iter [25050/160000]	lr: 8.593e-03, eta: 1 day, 9:21:08, time: 0.821, data_time: 0.010, memory: 4319, decode.loss_seg: 1.2785, decode.acc_seg: 47.9891, loss: 1.2785
2021-08-13 17:21:04,283 - mmseg - INFO - Iter [25100/160000]	lr: 8.591e-03, eta: 1 day, 9:20:06, time: 0.827, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2536, decode.acc_seg: 49.7755, loss: 1.2536
2021-08-13 17:21:47,035 - mmseg - INFO - Iter [25150/160000]	lr: 8.588e-03, eta: 1 day, 9:19:12, time: 0.855, data_time: 0.010, memory: 4319, decode.loss_seg: 1.2381, decode.acc_seg: 48.6279, loss: 1.2381
2021-08-13 17:22:29,734 - mmseg - INFO - Iter [25200/160000]	lr: 8.585e-03, eta: 1 day, 9:18:18, time: 0.854, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2725, decode.acc_seg: 48.6837, loss: 1.2725
2021-08-13 17:23:47,786 - mmseg - INFO - Iter [25250/160000]	lr: 8.582e-03, eta: 1 day, 9:20:33, time: 1.561, data_time: 0.722, memory: 4319, decode.loss_seg: 1.2585, decode.acc_seg: 49.2701, loss: 1.2585
2021-08-13 17:24:29,492 - mmseg - INFO - Iter [25300/160000]	lr: 8.579e-03, eta: 1 day, 9:19:34, time: 0.834, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2139, decode.acc_seg: 49.9157, loss: 1.2139
2021-08-13 17:25:11,051 - mmseg - INFO - Iter [25350/160000]	lr: 8.576e-03, eta: 1 day, 9:18:33, time: 0.831, data_time: 0.010, memory: 4319, decode.loss_seg: 1.2397, decode.acc_seg: 48.8189, loss: 1.2397
2021-08-13 17:25:52,245 - mmseg - INFO - Iter [25400/160000]	lr: 8.574e-03, eta: 1 day, 9:17:31, time: 0.824, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2515, decode.acc_seg: 49.4644, loss: 1.2515
2021-08-13 17:26:34,203 - mmseg - INFO - Iter [25450/160000]	lr: 8.571e-03, eta: 1 day, 9:16:33, time: 0.839, data_time: 0.010, memory: 4319, decode.loss_seg: 1.2886, decode.acc_seg: 48.9317, loss: 1.2886
2021-08-13 17:27:15,070 - mmseg - INFO - Iter [25500/160000]	lr: 8.568e-03, eta: 1 day, 9:15:29, time: 0.817, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2794, decode.acc_seg: 49.5598, loss: 1.2794
2021-08-13 17:27:56,077 - mmseg - INFO - Iter [25550/160000]	lr: 8.565e-03, eta: 1 day, 9:14:26, time: 0.820, data_time: 0.010, memory: 4319, decode.loss_seg: 1.2573, decode.acc_seg: 48.1630, loss: 1.2573
2021-08-13 17:28:37,907 - mmseg - INFO - Iter [25600/160000]	lr: 8.562e-03, eta: 1 day, 9:13:28, time: 0.837, data_time: 0.010, memory: 4319, decode.loss_seg: 1.3028, decode.acc_seg: 47.6880, loss: 1.3028
2021-08-13 17:29:18,609 - mmseg - INFO - Iter [25650/160000]	lr: 8.559e-03, eta: 1 day, 9:12:23, time: 0.814, data_time: 0.010, memory: 4319, decode.loss_seg: 1.2276, decode.acc_seg: 49.8742, loss: 1.2276
2021-08-13 17:29:58,124 - mmseg - INFO - Iter [25700/160000]	lr: 8.557e-03, eta: 1 day, 9:11:13, time: 0.790, data_time: 0.010, memory: 4319, decode.loss_seg: 1.2580, decode.acc_seg: 48.1054, loss: 1.2580
2021-08-13 17:30:38,474 - mmseg - INFO - Iter [25750/160000]	lr: 8.554e-03, eta: 1 day, 9:10:07, time: 0.806, data_time: 0.010, memory: 4319, decode.loss_seg: 1.2773, decode.acc_seg: 48.2447, loss: 1.2773
2021-08-13 17:31:20,896 - mmseg - INFO - Iter [25800/160000]	lr: 8.551e-03, eta: 1 day, 9:09:12, time: 0.849, data_time: 0.010, memory: 4319, decode.loss_seg: 1.2415, decode.acc_seg: 48.9230, loss: 1.2415
2021-08-13 17:32:03,427 - mmseg - INFO - Iter [25850/160000]	lr: 8.548e-03, eta: 1 day, 9:08:17, time: 0.851, data_time: 0.010, memory: 4319, decode.loss_seg: 1.2603, decode.acc_seg: 49.3926, loss: 1.2603
2021-08-13 17:33:20,788 - mmseg - INFO - Iter [25900/160000]	lr: 8.545e-03, eta: 1 day, 9:10:23, time: 1.547, data_time: 0.718, memory: 4319, decode.loss_seg: 1.2266, decode.acc_seg: 49.6529, loss: 1.2266
2021-08-13 17:34:02,679 - mmseg - INFO - Iter [25950/160000]	lr: 8.542e-03, eta: 1 day, 9:09:25, time: 0.838, data_time: 0.013, memory: 4319, decode.loss_seg: 1.2378, decode.acc_seg: 48.6099, loss: 1.2378
2021-08-13 17:34:43,463 - mmseg - INFO - Exp name: fcn_litehr18-without-head_512x512_160k_ade20k.py
2021-08-13 17:34:43,463 - mmseg - INFO - Iter [26000/160000]	lr: 8.540e-03, eta: 1 day, 9:08:21, time: 0.816, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2088, decode.acc_seg: 49.5155, loss: 1.2088
2021-08-13 17:35:25,819 - mmseg - INFO - Iter [26050/160000]	lr: 8.537e-03, eta: 1 day, 9:07:26, time: 0.847, data_time: 0.010, memory: 4319, decode.loss_seg: 1.2328, decode.acc_seg: 49.5110, loss: 1.2328
2021-08-13 17:36:08,575 - mmseg - INFO - Iter [26100/160000]	lr: 8.534e-03, eta: 1 day, 9:06:32, time: 0.855, data_time: 0.010, memory: 4319, decode.loss_seg: 1.2197, decode.acc_seg: 49.4509, loss: 1.2197
2021-08-13 17:36:50,580 - mmseg - INFO - Iter [26150/160000]	lr: 8.531e-03, eta: 1 day, 9:05:35, time: 0.841, data_time: 0.012, memory: 4319, decode.loss_seg: 1.2577, decode.acc_seg: 48.3002, loss: 1.2577
2021-08-13 17:37:32,751 - mmseg - INFO - Iter [26200/160000]	lr: 8.528e-03, eta: 1 day, 9:04:38, time: 0.843, data_time: 0.010, memory: 4319, decode.loss_seg: 1.2763, decode.acc_seg: 48.7543, loss: 1.2763
2021-08-13 17:38:15,269 - mmseg - INFO - Iter [26250/160000]	lr: 8.525e-03, eta: 1 day, 9:03:44, time: 0.850, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2325, decode.acc_seg: 48.5200, loss: 1.2325
2021-08-13 17:38:57,933 - mmseg - INFO - Iter [26300/160000]	lr: 8.523e-03, eta: 1 day, 9:02:50, time: 0.854, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2778, decode.acc_seg: 47.7181, loss: 1.2778
2021-08-13 17:39:38,382 - mmseg - INFO - Iter [26350/160000]	lr: 8.520e-03, eta: 1 day, 9:01:45, time: 0.809, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2738, decode.acc_seg: 49.2477, loss: 1.2738
2021-08-13 17:40:19,845 - mmseg - INFO - Iter [26400/160000]	lr: 8.517e-03, eta: 1 day, 9:00:45, time: 0.829, data_time: 0.010, memory: 4319, decode.loss_seg: 1.2490, decode.acc_seg: 50.5456, loss: 1.2490
2021-08-13 17:41:01,972 - mmseg - INFO - Iter [26450/160000]	lr: 8.514e-03, eta: 1 day, 8:59:49, time: 0.843, data_time: 0.012, memory: 4319, decode.loss_seg: 1.2654, decode.acc_seg: 48.6461, loss: 1.2654
2021-08-13 17:41:42,769 - mmseg - INFO - Iter [26500/160000]	lr: 8.511e-03, eta: 1 day, 8:58:46, time: 0.816, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2268, decode.acc_seg: 49.6389, loss: 1.2268
2021-08-13 17:42:58,846 - mmseg - INFO - Iter [26550/160000]	lr: 8.508e-03, eta: 1 day, 9:00:40, time: 1.522, data_time: 0.714, memory: 4319, decode.loss_seg: 1.1882, decode.acc_seg: 50.1380, loss: 1.1882
2021-08-13 17:43:41,184 - mmseg - INFO - Iter [26600/160000]	lr: 8.506e-03, eta: 1 day, 8:59:45, time: 0.846, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2562, decode.acc_seg: 48.2841, loss: 1.2562
2021-08-13 17:44:22,212 - mmseg - INFO - Iter [26650/160000]	lr: 8.503e-03, eta: 1 day, 8:58:43, time: 0.821, data_time: 0.012, memory: 4319, decode.loss_seg: 1.2493, decode.acc_seg: 48.6538, loss: 1.2493
2021-08-13 17:45:03,386 - mmseg - INFO - Iter [26700/160000]	lr: 8.500e-03, eta: 1 day, 8:57:41, time: 0.823, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2483, decode.acc_seg: 48.3939, loss: 1.2483
2021-08-13 17:45:44,540 - mmseg - INFO - Iter [26750/160000]	lr: 8.497e-03, eta: 1 day, 8:56:40, time: 0.824, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1994, decode.acc_seg: 50.0881, loss: 1.1994
2021-08-13 17:46:26,245 - mmseg - INFO - Iter [26800/160000]	lr: 8.494e-03, eta: 1 day, 8:55:42, time: 0.834, data_time: 0.010, memory: 4319, decode.loss_seg: 1.2447, decode.acc_seg: 48.5900, loss: 1.2447
2021-08-13 17:47:07,720 - mmseg - INFO - Iter [26850/160000]	lr: 8.491e-03, eta: 1 day, 8:54:42, time: 0.829, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2516, decode.acc_seg: 48.5713, loss: 1.2516
2021-08-13 17:47:49,719 - mmseg - INFO - Iter [26900/160000]	lr: 8.489e-03, eta: 1 day, 8:53:45, time: 0.840, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2383, decode.acc_seg: 49.0463, loss: 1.2383
2021-08-13 17:48:29,973 - mmseg - INFO - Iter [26950/160000]	lr: 8.486e-03, eta: 1 day, 8:52:40, time: 0.805, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2114, decode.acc_seg: 49.9180, loss: 1.2114
2021-08-13 17:49:09,849 - mmseg - INFO - Exp name: fcn_litehr18-without-head_512x512_160k_ade20k.py
2021-08-13 17:49:09,851 - mmseg - INFO - Iter [27000/160000]	lr: 8.483e-03, eta: 1 day, 8:51:33, time: 0.797, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2553, decode.acc_seg: 49.2025, loss: 1.2553
2021-08-13 17:49:50,470 - mmseg - INFO - Iter [27050/160000]	lr: 8.480e-03, eta: 1 day, 8:50:30, time: 0.813, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2252, decode.acc_seg: 49.3012, loss: 1.2252
2021-08-13 17:50:31,370 - mmseg - INFO - Iter [27100/160000]	lr: 8.477e-03, eta: 1 day, 8:49:28, time: 0.818, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2660, decode.acc_seg: 48.9975, loss: 1.2660
2021-08-13 17:51:47,982 - mmseg - INFO - Iter [27150/160000]	lr: 8.474e-03, eta: 1 day, 8:51:20, time: 1.532, data_time: 0.746, memory: 4319, decode.loss_seg: 1.2483, decode.acc_seg: 49.5438, loss: 1.2483
2021-08-13 17:52:30,195 - mmseg - INFO - Iter [27200/160000]	lr: 8.472e-03, eta: 1 day, 8:50:25, time: 0.844, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2753, decode.acc_seg: 47.7279, loss: 1.2753
2021-08-13 17:53:10,853 - mmseg - INFO - Iter [27250/160000]	lr: 8.469e-03, eta: 1 day, 8:49:21, time: 0.813, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2218, decode.acc_seg: 50.0410, loss: 1.2218
2021-08-13 17:53:51,092 - mmseg - INFO - Iter [27300/160000]	lr: 8.466e-03, eta: 1 day, 8:48:16, time: 0.804, data_time: 0.012, memory: 4319, decode.loss_seg: 1.2181, decode.acc_seg: 50.6401, loss: 1.2181
2021-08-13 17:54:31,936 - mmseg - INFO - Iter [27350/160000]	lr: 8.463e-03, eta: 1 day, 8:47:14, time: 0.817, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2143, decode.acc_seg: 49.4066, loss: 1.2143
2021-08-13 17:55:11,707 - mmseg - INFO - Iter [27400/160000]	lr: 8.460e-03, eta: 1 day, 8:46:07, time: 0.796, data_time: 0.012, memory: 4319, decode.loss_seg: 1.2951, decode.acc_seg: 47.8654, loss: 1.2951
2021-08-13 17:55:52,553 - mmseg - INFO - Iter [27450/160000]	lr: 8.457e-03, eta: 1 day, 8:45:04, time: 0.817, data_time: 0.012, memory: 4319, decode.loss_seg: 1.2447, decode.acc_seg: 49.3105, loss: 1.2447
2021-08-13 17:56:32,477 - mmseg - INFO - Iter [27500/160000]	lr: 8.455e-03, eta: 1 day, 8:43:58, time: 0.799, data_time: 0.012, memory: 4319, decode.loss_seg: 1.2189, decode.acc_seg: 50.3247, loss: 1.2189
2021-08-13 17:57:14,272 - mmseg - INFO - Iter [27550/160000]	lr: 8.452e-03, eta: 1 day, 8:43:01, time: 0.836, data_time: 0.010, memory: 4319, decode.loss_seg: 1.2705, decode.acc_seg: 48.4238, loss: 1.2705
2021-08-13 17:57:54,783 - mmseg - INFO - Iter [27600/160000]	lr: 8.449e-03, eta: 1 day, 8:41:57, time: 0.810, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2421, decode.acc_seg: 49.2193, loss: 1.2421
2021-08-13 17:58:35,316 - mmseg - INFO - Iter [27650/160000]	lr: 8.446e-03, eta: 1 day, 8:40:54, time: 0.811, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2420, decode.acc_seg: 49.2049, loss: 1.2420
2021-08-13 17:59:15,463 - mmseg - INFO - Iter [27700/160000]	lr: 8.443e-03, eta: 1 day, 8:39:49, time: 0.803, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2175, decode.acc_seg: 50.3518, loss: 1.2175
2021-08-13 17:59:56,044 - mmseg - INFO - Iter [27750/160000]	lr: 8.440e-03, eta: 1 day, 8:38:46, time: 0.812, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2583, decode.acc_seg: 48.5279, loss: 1.2583
2021-08-13 18:02:08,920 - mmseg - INFO - Iter [27800/160000]	lr: 8.438e-03, eta: 1 day, 8:45:02, time: 2.657, data_time: 1.785, memory: 4319, decode.loss_seg: 1.2812, decode.acc_seg: 48.8100, loss: 1.2812
2021-08-13 18:02:49,304 - mmseg - INFO - Iter [27850/160000]	lr: 8.435e-03, eta: 1 day, 8:43:58, time: 0.808, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1989, decode.acc_seg: 50.0723, loss: 1.1989
2021-08-13 18:03:29,177 - mmseg - INFO - Iter [27900/160000]	lr: 8.432e-03, eta: 1 day, 8:42:51, time: 0.797, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2270, decode.acc_seg: 49.4689, loss: 1.2270
2021-08-13 18:04:09,432 - mmseg - INFO - Iter [27950/160000]	lr: 8.429e-03, eta: 1 day, 8:41:46, time: 0.805, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2424, decode.acc_seg: 49.0811, loss: 1.2424
2021-08-13 18:04:51,855 - mmseg - INFO - Exp name: fcn_litehr18-without-head_512x512_160k_ade20k.py
2021-08-13 18:04:51,855 - mmseg - INFO - Iter [28000/160000]	lr: 8.426e-03, eta: 1 day, 8:40:51, time: 0.848, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2127, decode.acc_seg: 49.6893, loss: 1.2127
2021-08-13 18:05:33,414 - mmseg - INFO - Iter [28050/160000]	lr: 8.423e-03, eta: 1 day, 8:39:53, time: 0.832, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2317, decode.acc_seg: 49.6040, loss: 1.2317
2021-08-13 18:06:14,326 - mmseg - INFO - Iter [28100/160000]	lr: 8.421e-03, eta: 1 day, 8:38:51, time: 0.818, data_time: 0.010, memory: 4319, decode.loss_seg: 1.2328, decode.acc_seg: 49.0677, loss: 1.2328
2021-08-13 18:06:54,518 - mmseg - INFO - Iter [28150/160000]	lr: 8.418e-03, eta: 1 day, 8:37:46, time: 0.804, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2117, decode.acc_seg: 49.8060, loss: 1.2117
2021-08-13 18:07:35,182 - mmseg - INFO - Iter [28200/160000]	lr: 8.415e-03, eta: 1 day, 8:36:43, time: 0.813, data_time: 0.010, memory: 4319, decode.loss_seg: 1.2110, decode.acc_seg: 50.2578, loss: 1.2110
2021-08-13 18:08:15,510 - mmseg - INFO - Iter [28250/160000]	lr: 8.412e-03, eta: 1 day, 8:35:39, time: 0.807, data_time: 0.010, memory: 4319, decode.loss_seg: 1.2853, decode.acc_seg: 49.2526, loss: 1.2853
2021-08-13 18:08:55,484 - mmseg - INFO - Iter [28300/160000]	lr: 8.409e-03, eta: 1 day, 8:34:33, time: 0.799, data_time: 0.010, memory: 4319, decode.loss_seg: 1.2004, decode.acc_seg: 49.7422, loss: 1.2004
2021-08-13 18:09:36,558 - mmseg - INFO - Iter [28350/160000]	lr: 8.406e-03, eta: 1 day, 8:33:33, time: 0.821, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2566, decode.acc_seg: 49.7835, loss: 1.2566
2021-08-13 18:11:02,687 - mmseg - INFO - Iter [28400/160000]	lr: 8.403e-03, eta: 1 day, 8:36:01, time: 1.723, data_time: 0.915, memory: 4319, decode.loss_seg: 1.2496, decode.acc_seg: 49.7942, loss: 1.2496
2021-08-13 18:11:43,352 - mmseg - INFO - Iter [28450/160000]	lr: 8.401e-03, eta: 1 day, 8:34:58, time: 0.814, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2418, decode.acc_seg: 49.1027, loss: 1.2418
2021-08-13 18:12:24,024 - mmseg - INFO - Iter [28500/160000]	lr: 8.398e-03, eta: 1 day, 8:33:56, time: 0.813, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2296, decode.acc_seg: 49.3492, loss: 1.2296
2021-08-13 18:13:04,106 - mmseg - INFO - Iter [28550/160000]	lr: 8.395e-03, eta: 1 day, 8:32:50, time: 0.801, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2357, decode.acc_seg: 48.8164, loss: 1.2357
2021-08-13 18:13:44,711 - mmseg - INFO - Iter [28600/160000]	lr: 8.392e-03, eta: 1 day, 8:31:48, time: 0.813, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1892, decode.acc_seg: 49.7463, loss: 1.1892
2021-08-13 18:14:24,756 - mmseg - INFO - Iter [28650/160000]	lr: 8.389e-03, eta: 1 day, 8:30:42, time: 0.801, data_time: 0.010, memory: 4319, decode.loss_seg: 1.2084, decode.acc_seg: 50.2375, loss: 1.2084
2021-08-13 18:15:05,254 - mmseg - INFO - Iter [28700/160000]	lr: 8.386e-03, eta: 1 day, 8:29:39, time: 0.810, data_time: 0.010, memory: 4319, decode.loss_seg: 1.2465, decode.acc_seg: 48.9732, loss: 1.2465
2021-08-13 18:15:45,417 - mmseg - INFO - Iter [28750/160000]	lr: 8.384e-03, eta: 1 day, 8:28:35, time: 0.803, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1984, decode.acc_seg: 49.7886, loss: 1.1984
2021-08-13 18:16:25,362 - mmseg - INFO - Iter [28800/160000]	lr: 8.381e-03, eta: 1 day, 8:27:29, time: 0.799, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1968, decode.acc_seg: 48.9455, loss: 1.1968
2021-08-13 18:17:06,144 - mmseg - INFO - Iter [28850/160000]	lr: 8.378e-03, eta: 1 day, 8:26:27, time: 0.815, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2387, decode.acc_seg: 50.1211, loss: 1.2387
2021-08-13 18:17:46,426 - mmseg - INFO - Iter [28900/160000]	lr: 8.375e-03, eta: 1 day, 8:25:24, time: 0.807, data_time: 0.012, memory: 4319, decode.loss_seg: 1.2405, decode.acc_seg: 48.7642, loss: 1.2405
2021-08-13 18:18:26,613 - mmseg - INFO - Iter [28950/160000]	lr: 8.372e-03, eta: 1 day, 8:24:20, time: 0.804, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2171, decode.acc_seg: 49.5000, loss: 1.2171
2021-08-13 18:19:06,601 - mmseg - INFO - Exp name: fcn_litehr18-without-head_512x512_160k_ade20k.py
2021-08-13 18:19:06,602 - mmseg - INFO - Iter [29000/160000]	lr: 8.369e-03, eta: 1 day, 8:23:15, time: 0.800, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2293, decode.acc_seg: 48.9380, loss: 1.2293
2021-08-13 18:20:23,998 - mmseg - INFO - Iter [29050/160000]	lr: 8.367e-03, eta: 1 day, 8:24:59, time: 1.547, data_time: 0.709, memory: 4319, decode.loss_seg: 1.2361, decode.acc_seg: 49.6165, loss: 1.2361
2021-08-13 18:21:04,964 - mmseg - INFO - Iter [29100/160000]	lr: 8.364e-03, eta: 1 day, 8:23:58, time: 0.819, data_time: 0.012, memory: 4319, decode.loss_seg: 1.1942, decode.acc_seg: 49.0907, loss: 1.1942
2021-08-13 18:21:45,673 - mmseg - INFO - Iter [29150/160000]	lr: 8.361e-03, eta: 1 day, 8:22:56, time: 0.815, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2084, decode.acc_seg: 50.0288, loss: 1.2084
2021-08-13 18:22:27,467 - mmseg - INFO - Iter [29200/160000]	lr: 8.358e-03, eta: 1 day, 8:21:59, time: 0.835, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2398, decode.acc_seg: 49.3633, loss: 1.2398
2021-08-13 18:23:09,039 - mmseg - INFO - Iter [29250/160000]	lr: 8.355e-03, eta: 1 day, 8:21:01, time: 0.832, data_time: 0.012, memory: 4319, decode.loss_seg: 1.1986, decode.acc_seg: 49.7757, loss: 1.1986
2021-08-13 18:23:49,371 - mmseg - INFO - Iter [29300/160000]	lr: 8.352e-03, eta: 1 day, 8:19:58, time: 0.807, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1937, decode.acc_seg: 49.9839, loss: 1.1937
2021-08-13 18:24:30,333 - mmseg - INFO - Iter [29350/160000]	lr: 8.350e-03, eta: 1 day, 8:18:58, time: 0.819, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2194, decode.acc_seg: 49.5699, loss: 1.2194
2021-08-13 18:25:11,083 - mmseg - INFO - Iter [29400/160000]	lr: 8.347e-03, eta: 1 day, 8:17:56, time: 0.815, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2390, decode.acc_seg: 49.3129, loss: 1.2390
2021-08-13 18:25:53,178 - mmseg - INFO - Iter [29450/160000]	lr: 8.344e-03, eta: 1 day, 8:17:01, time: 0.841, data_time: 0.010, memory: 4319, decode.loss_seg: 1.2474, decode.acc_seg: 49.0205, loss: 1.2474
2021-08-13 18:26:35,371 - mmseg - INFO - Iter [29500/160000]	lr: 8.341e-03, eta: 1 day, 8:16:06, time: 0.844, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2371, decode.acc_seg: 49.7775, loss: 1.2371
2021-08-13 18:27:17,016 - mmseg - INFO - Iter [29550/160000]	lr: 8.338e-03, eta: 1 day, 8:15:09, time: 0.833, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2396, decode.acc_seg: 49.7809, loss: 1.2396
2021-08-13 18:27:57,802 - mmseg - INFO - Iter [29600/160000]	lr: 8.335e-03, eta: 1 day, 8:14:08, time: 0.816, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2458, decode.acc_seg: 49.0632, loss: 1.2458
2021-08-13 18:28:39,758 - mmseg - INFO - Iter [29650/160000]	lr: 8.332e-03, eta: 1 day, 8:13:13, time: 0.839, data_time: 0.010, memory: 4319, decode.loss_seg: 1.1986, decode.acc_seg: 49.6084, loss: 1.1986
2021-08-13 18:29:55,941 - mmseg - INFO - Iter [29700/160000]	lr: 8.330e-03, eta: 1 day, 8:14:47, time: 1.524, data_time: 0.730, memory: 4319, decode.loss_seg: 1.1653, decode.acc_seg: 49.6547, loss: 1.1653
2021-08-13 18:30:37,510 - mmseg - INFO - Iter [29750/160000]	lr: 8.327e-03, eta: 1 day, 8:13:50, time: 0.832, data_time: 0.012, memory: 4319, decode.loss_seg: 1.2020, decode.acc_seg: 50.1103, loss: 1.2020
2021-08-13 18:31:18,446 - mmseg - INFO - Iter [29800/160000]	lr: 8.324e-03, eta: 1 day, 8:12:49, time: 0.819, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2138, decode.acc_seg: 49.6922, loss: 1.2138
2021-08-13 18:31:58,404 - mmseg - INFO - Iter [29850/160000]	lr: 8.321e-03, eta: 1 day, 8:11:45, time: 0.799, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2800, decode.acc_seg: 49.1716, loss: 1.2800
2021-08-13 18:32:38,489 - mmseg - INFO - Iter [29900/160000]	lr: 8.318e-03, eta: 1 day, 8:10:41, time: 0.802, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2143, decode.acc_seg: 49.6486, loss: 1.2143
2021-08-13 18:33:18,625 - mmseg - INFO - Iter [29950/160000]	lr: 8.315e-03, eta: 1 day, 8:09:37, time: 0.803, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1922, decode.acc_seg: 50.3172, loss: 1.1922
2021-08-13 18:33:59,441 - mmseg - INFO - Exp name: fcn_litehr18-without-head_512x512_160k_ade20k.py
2021-08-13 18:33:59,441 - mmseg - INFO - Iter [30000/160000]	lr: 8.313e-03, eta: 1 day, 8:08:37, time: 0.816, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2235, decode.acc_seg: 49.1667, loss: 1.2235
2021-08-13 18:34:39,240 - mmseg - INFO - Iter [30050/160000]	lr: 8.310e-03, eta: 1 day, 8:07:32, time: 0.796, data_time: 0.012, memory: 4319, decode.loss_seg: 1.2126, decode.acc_seg: 50.0885, loss: 1.2126
2021-08-13 18:35:19,198 - mmseg - INFO - Iter [30100/160000]	lr: 8.307e-03, eta: 1 day, 8:06:28, time: 0.799, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1985, decode.acc_seg: 49.8028, loss: 1.1985
2021-08-13 18:36:01,014 - mmseg - INFO - Iter [30150/160000]	lr: 8.304e-03, eta: 1 day, 8:05:32, time: 0.836, data_time: 0.012, memory: 4319, decode.loss_seg: 1.2200, decode.acc_seg: 50.3524, loss: 1.2200
2021-08-13 18:36:43,072 - mmseg - INFO - Iter [30200/160000]	lr: 8.301e-03, eta: 1 day, 8:04:37, time: 0.841, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2341, decode.acc_seg: 48.7584, loss: 1.2341
2021-08-13 18:37:23,292 - mmseg - INFO - Iter [30250/160000]	lr: 8.298e-03, eta: 1 day, 8:03:34, time: 0.805, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2333, decode.acc_seg: 50.3089, loss: 1.2333
2021-08-13 18:38:39,671 - mmseg - INFO - Iter [30300/160000]	lr: 8.296e-03, eta: 1 day, 8:05:06, time: 1.528, data_time: 0.741, memory: 4319, decode.loss_seg: 1.2549, decode.acc_seg: 48.0988, loss: 1.2549
2021-08-13 18:39:21,243 - mmseg - INFO - Iter [30350/160000]	lr: 8.293e-03, eta: 1 day, 8:04:09, time: 0.831, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2058, decode.acc_seg: 49.4454, loss: 1.2058
2021-08-13 18:40:01,353 - mmseg - INFO - Iter [30400/160000]	lr: 8.290e-03, eta: 1 day, 8:03:06, time: 0.802, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2103, decode.acc_seg: 50.4284, loss: 1.2103
2021-08-13 18:40:43,485 - mmseg - INFO - Iter [30450/160000]	lr: 8.287e-03, eta: 1 day, 8:02:11, time: 0.842, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2345, decode.acc_seg: 49.8673, loss: 1.2345
2021-08-13 18:41:23,196 - mmseg - INFO - Iter [30500/160000]	lr: 8.284e-03, eta: 1 day, 8:01:06, time: 0.795, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2136, decode.acc_seg: 49.5627, loss: 1.2136
2021-08-13 18:42:04,363 - mmseg - INFO - Iter [30550/160000]	lr: 8.281e-03, eta: 1 day, 8:00:08, time: 0.823, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1866, decode.acc_seg: 49.2118, loss: 1.1866
2021-08-13 18:42:46,324 - mmseg - INFO - Iter [30600/160000]	lr: 8.278e-03, eta: 1 day, 7:59:12, time: 0.839, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1939, decode.acc_seg: 49.5988, loss: 1.1939
2021-08-13 18:43:28,157 - mmseg - INFO - Iter [30650/160000]	lr: 8.276e-03, eta: 1 day, 7:58:17, time: 0.837, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2164, decode.acc_seg: 50.0056, loss: 1.2164
2021-08-13 18:44:10,031 - mmseg - INFO - Iter [30700/160000]	lr: 8.273e-03, eta: 1 day, 7:57:21, time: 0.838, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2172, decode.acc_seg: 50.0857, loss: 1.2172
2021-08-13 18:44:51,618 - mmseg - INFO - Iter [30750/160000]	lr: 8.270e-03, eta: 1 day, 7:56:24, time: 0.832, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2709, decode.acc_seg: 48.2416, loss: 1.2709
2021-08-13 18:45:31,209 - mmseg - INFO - Iter [30800/160000]	lr: 8.267e-03, eta: 1 day, 7:55:19, time: 0.792, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2111, decode.acc_seg: 49.7310, loss: 1.2111
2021-08-13 18:46:12,153 - mmseg - INFO - Iter [30850/160000]	lr: 8.264e-03, eta: 1 day, 7:54:20, time: 0.819, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1988, decode.acc_seg: 50.1842, loss: 1.1988
2021-08-13 18:46:52,695 - mmseg - INFO - Iter [30900/160000]	lr: 8.261e-03, eta: 1 day, 7:53:19, time: 0.811, data_time: 0.010, memory: 4319, decode.loss_seg: 1.2531, decode.acc_seg: 49.5227, loss: 1.2531
2021-08-13 18:48:08,491 - mmseg - INFO - Iter [30950/160000]	lr: 8.259e-03, eta: 1 day, 7:54:45, time: 1.516, data_time: 0.725, memory: 4319, decode.loss_seg: 1.2191, decode.acc_seg: 49.8280, loss: 1.2191
2021-08-13 18:48:49,931 - mmseg - INFO - Exp name: fcn_litehr18-without-head_512x512_160k_ade20k.py
2021-08-13 18:48:49,932 - mmseg - INFO - Iter [31000/160000]	lr: 8.256e-03, eta: 1 day, 7:53:48, time: 0.829, data_time: 0.012, memory: 4319, decode.loss_seg: 1.1789, decode.acc_seg: 50.7245, loss: 1.1789
2021-08-13 18:49:31,015 - mmseg - INFO - Iter [31050/160000]	lr: 8.253e-03, eta: 1 day, 7:52:49, time: 0.822, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2027, decode.acc_seg: 50.0143, loss: 1.2027
2021-08-13 18:50:12,675 - mmseg - INFO - Iter [31100/160000]	lr: 8.250e-03, eta: 1 day, 7:51:53, time: 0.833, data_time: 0.012, memory: 4319, decode.loss_seg: 1.1789, decode.acc_seg: 50.0841, loss: 1.1789
2021-08-13 18:50:54,982 - mmseg - INFO - Iter [31150/160000]	lr: 8.247e-03, eta: 1 day, 7:51:00, time: 0.847, data_time: 0.012, memory: 4319, decode.loss_seg: 1.2090, decode.acc_seg: 49.4819, loss: 1.2090
2021-08-13 18:51:36,158 - mmseg - INFO - Iter [31200/160000]	lr: 8.244e-03, eta: 1 day, 7:50:01, time: 0.824, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2528, decode.acc_seg: 48.8691, loss: 1.2528
2021-08-13 18:52:18,062 - mmseg - INFO - Iter [31250/160000]	lr: 8.241e-03, eta: 1 day, 7:49:06, time: 0.838, data_time: 0.010, memory: 4319, decode.loss_seg: 1.2368, decode.acc_seg: 49.5731, loss: 1.2368
2021-08-13 18:52:58,511 - mmseg - INFO - Iter [31300/160000]	lr: 8.239e-03, eta: 1 day, 7:48:05, time: 0.809, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2189, decode.acc_seg: 49.9514, loss: 1.2189
2021-08-13 18:53:38,464 - mmseg - INFO - Iter [31350/160000]	lr: 8.236e-03, eta: 1 day, 7:47:02, time: 0.799, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2461, decode.acc_seg: 49.8068, loss: 1.2461
2021-08-13 18:54:19,286 - mmseg - INFO - Iter [31400/160000]	lr: 8.233e-03, eta: 1 day, 7:46:03, time: 0.816, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2371, decode.acc_seg: 49.9462, loss: 1.2371
2021-08-13 18:55:00,437 - mmseg - INFO - Iter [31450/160000]	lr: 8.230e-03, eta: 1 day, 7:45:05, time: 0.823, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2173, decode.acc_seg: 49.4756, loss: 1.2173
2021-08-13 18:55:41,729 - mmseg - INFO - Iter [31500/160000]	lr: 8.227e-03, eta: 1 day, 7:44:07, time: 0.825, data_time: 0.010, memory: 4319, decode.loss_seg: 1.2345, decode.acc_seg: 48.5403, loss: 1.2345
2021-08-13 18:56:21,840 - mmseg - INFO - Iter [31550/160000]	lr: 8.224e-03, eta: 1 day, 7:43:05, time: 0.803, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2138, decode.acc_seg: 49.7334, loss: 1.2138
2021-08-13 18:57:39,254 - mmseg - INFO - Iter [31600/160000]	lr: 8.222e-03, eta: 1 day, 7:44:35, time: 1.548, data_time: 0.720, memory: 4319, decode.loss_seg: 1.1699, decode.acc_seg: 50.2565, loss: 1.1699
2021-08-13 18:58:20,051 - mmseg - INFO - Iter [31650/160000]	lr: 8.219e-03, eta: 1 day, 7:43:35, time: 0.816, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1841, decode.acc_seg: 51.0771, loss: 1.1841
2021-08-13 18:59:00,151 - mmseg - INFO - Iter [31700/160000]	lr: 8.216e-03, eta: 1 day, 7:42:33, time: 0.802, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2070, decode.acc_seg: 50.0881, loss: 1.2070
2021-08-13 18:59:41,599 - mmseg - INFO - Iter [31750/160000]	lr: 8.213e-03, eta: 1 day, 7:41:36, time: 0.829, data_time: 0.012, memory: 4319, decode.loss_seg: 1.1924, decode.acc_seg: 49.9002, loss: 1.1924
2021-08-13 19:00:21,762 - mmseg - INFO - Iter [31800/160000]	lr: 8.210e-03, eta: 1 day, 7:40:34, time: 0.803, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2199, decode.acc_seg: 49.5934, loss: 1.2199
2021-08-13 19:01:02,837 - mmseg - INFO - Iter [31850/160000]	lr: 8.207e-03, eta: 1 day, 7:39:36, time: 0.821, data_time: 0.012, memory: 4319, decode.loss_seg: 1.2144, decode.acc_seg: 48.3734, loss: 1.2144
2021-08-13 19:01:42,979 - mmseg - INFO - Iter [31900/160000]	lr: 8.204e-03, eta: 1 day, 7:38:34, time: 0.803, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2364, decode.acc_seg: 49.0568, loss: 1.2364
2021-08-13 19:02:24,972 - mmseg - INFO - Iter [31950/160000]	lr: 8.202e-03, eta: 1 day, 7:37:40, time: 0.840, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1934, decode.acc_seg: 50.0868, loss: 1.1934
2021-08-13 19:03:06,341 - mmseg - INFO - Saving checkpoint at 32000 iterations
2021-08-13 19:03:06,720 - mmseg - INFO - Exp name: fcn_litehr18-without-head_512x512_160k_ade20k.py
2021-08-13 19:03:06,726 - mmseg - INFO - Iter [32000/160000]	lr: 8.199e-03, eta: 1 day, 7:36:45, time: 0.835, data_time: 0.010, memory: 4319, decode.loss_seg: 1.2213, decode.acc_seg: 50.0002, loss: 1.2213
2021-08-13 19:05:26,513 - mmseg - INFO - per class results:
2021-08-13 19:05:26,523 - mmseg - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        | 53.38 |  83.9 |
|       building      | 66.38 | 81.69 |
|         sky         | 89.26 | 93.32 |
|        floor        | 56.08 | 81.74 |
|         tree        | 58.69 | 82.88 |
|       ceiling       | 64.03 | 77.15 |
|         road        | 58.09 | 90.48 |
|         bed         | 59.05 | 81.91 |
|      windowpane     | 38.46 |  63.3 |
|        grass        | 55.22 | 69.09 |
|       cabinet       | 34.93 | 53.16 |
|       sidewalk      | 19.94 | 23.13 |
|        person       | 43.54 | 53.64 |
|        earth        | 20.47 |  28.7 |
|         door        |  12.3 | 16.21 |
|        table        | 25.84 | 38.71 |
|       mountain      | 33.06 | 59.35 |
|        plant        |  29.2 | 36.74 |
|       curtain       | 34.43 | 58.69 |
|        chair        | 23.35 | 32.04 |
|         car         | 51.91 | 79.35 |
|        water        | 31.12 | 52.62 |
|       painting      | 46.75 | 59.31 |
|         sofa        | 23.77 | 29.03 |
|        shelf        | 16.01 | 21.26 |
|        house        | 29.52 | 39.71 |
|         sea         | 31.57 | 67.17 |
|        mirror       |  3.1  |  3.21 |
|         rug         | 12.48 | 13.13 |
|        field        | 19.99 | 47.82 |
|       armchair      |  4.17 |  4.47 |
|         seat        | 21.59 | 32.67 |
|        fence        | 11.09 | 14.47 |
|         desk        | 11.77 | 14.97 |
|         rock        |  6.75 |  9.4  |
|       wardrobe      |  0.03 |  0.03 |
|         lamp        | 21.56 | 25.44 |
|       bathtub       | 18.99 | 21.89 |
|       railing       | 11.48 | 14.44 |
|       cushion       | 10.88 | 12.73 |
|         base        |  0.0  |  0.0  |
|         box         |  0.24 |  0.24 |
|        column       |  0.12 |  0.12 |
|      signboard      |  5.83 |  6.32 |
|   chest of drawers  | 13.09 | 13.67 |
|       counter       |  3.19 |  3.38 |
|         sand        | 10.41 | 11.16 |
|         sink        | 22.49 | 37.91 |
|      skyscraper     | 36.44 | 63.89 |
|      fireplace      |  26.0 | 27.08 |
|     refrigerator    |  7.6  |  8.1  |
|      grandstand     |  16.7 | 28.39 |
|         path        |  0.06 |  0.06 |
|        stairs       |  0.62 |  0.63 |
|        runway       | 35.95 | 41.39 |
|         case        |  0.92 |  0.95 |
|      pool table     | 60.69 | 70.66 |
|        pillow       | 14.93 | 17.49 |
|     screen door     |  0.18 |  0.18 |
|       stairway      |  6.43 |  7.75 |
|        river        |  0.28 |  0.28 |
|        bridge       |  1.08 |  1.23 |
|       bookcase      |  9.15 | 10.56 |
|        blind        |  0.0  |  0.0  |
|     coffee table    | 13.99 | 17.18 |
|        toilet       | 42.82 | 60.72 |
|        flower       |  3.22 |  3.48 |
|         book        |  4.69 |  4.8  |
|         hill        |  0.0  |  0.0  |
|        bench        |  3.18 |  3.36 |
|      countertop     |  0.18 |  0.18 |
|        stove        | 22.98 |  30.9 |
|         palm        |  0.01 |  0.01 |
|    kitchen island   |  0.0  |  0.0  |
|       computer      | 15.34 | 18.15 |
|     swivel chair    |  2.38 |  2.46 |
|         boat        |  7.91 |  8.95 |
|         bar         |  2.59 |  2.65 |
|    arcade machine   |  0.0  |  0.0  |
|        hovel        |  0.0  |  0.0  |
|         bus         |  3.0  |  3.06 |
|        towel        |  0.69 |  0.69 |
|        light        |  3.9  |  4.02 |
|        truck        |  0.01 |  0.01 |
|        tower        |  0.0  |  0.0  |
|      chandelier     | 29.31 | 38.77 |
|        awning       |  0.8  |  0.81 |
|     streetlight     |  0.0  |  0.0  |
|        booth        |  0.0  |  0.0  |
| television receiver | 11.71 | 13.48 |
|       airplane      |  10.3 | 11.92 |
|      dirt track     |  0.0  |  0.0  |
|       apparel       |  0.0  |  0.0  |
|         pole        |  0.01 |  0.01 |
|         land        |  0.0  |  0.0  |
|      bannister      |  0.0  |  0.0  |
|      escalator      |  0.37 |  0.43 |
|       ottoman       |  0.0  |  0.0  |
|        bottle       |  0.0  |  0.0  |
|        buffet       |  0.0  |  0.0  |
|        poster       |  0.0  |  0.0  |
|        stage        |  0.0  |  0.0  |
|         van         |  0.0  |  0.0  |
|         ship        |  0.0  |  0.0  |
|       fountain      |  0.0  |  0.0  |
|    conveyer belt    |  0.0  |  0.0  |
|        canopy       |  0.0  |  0.0  |
|        washer       | 11.67 | 13.12 |
|      plaything      |  0.0  |  0.0  |
|    swimming pool    |  6.69 |  8.26 |
|        stool        |  0.0  |  0.0  |
|        barrel       |  0.0  |  0.0  |
|        basket       |  0.0  |  0.0  |
|      waterfall      | 20.04 |  43.8 |
|         tent        | 11.06 | 13.38 |
|         bag         |  0.0  |  0.0  |
|       minibike      |  0.0  |  0.0  |
|        cradle       | 30.79 | 49.39 |
|         oven        |  0.0  |  0.0  |
|         ball        | 12.37 | 39.59 |
|         food        |  6.12 |  6.52 |
|         step        |  0.0  |  0.0  |
|         tank        |  0.0  |  0.0  |
|      trade name     |  0.0  |  0.0  |
|      microwave      |  0.18 |  0.18 |
|         pot         |  0.0  |  0.0  |
|        animal       |  0.0  |  0.0  |
|       bicycle       |  0.0  |  0.0  |
|         lake        |  0.0  |  0.0  |
|      dishwasher     |  0.0  |  0.0  |
|        screen       | 23.05 | 28.86 |
|       blanket       |  0.0  |  0.0  |
|      sculpture      |  0.0  |  0.0  |
|         hood        |  0.0  |  0.0  |
|        sconce       |  0.0  |  0.0  |
|         vase        |  0.0  |  0.0  |
|    traffic light    |  0.0  |  0.0  |
|         tray        |  0.0  |  0.0  |
|        ashcan       |  0.0  |  0.0  |
|         fan         |  0.0  |  0.0  |
|         pier        |  0.0  |  0.0  |
|      crt screen     |  0.0  |  0.0  |
|        plate        |  0.0  |  0.0  |
|       monitor       |  0.0  |  0.0  |
|    bulletin board   |  0.0  |  0.0  |
|        shower       |  0.0  |  0.0  |
|       radiator      |  0.0  |  0.0  |
|        glass        |  0.0  |  0.0  |
|        clock        |  0.0  |  0.0  |
|         flag        |  0.0  |  0.0  |
+---------------------+-------+-------+
2021-08-13 19:05:26,523 - mmseg - INFO - Summary:
2021-08-13 19:05:26,524 - mmseg - INFO - 
+-------+-------+------+
|  aAcc |  mIoU | mAcc |
+-------+-------+------+
| 64.72 | 12.23 | 17.0 |
+-------+-------+------+
2021-08-13 19:05:26,673 - mmseg - INFO - Exp name: fcn_litehr18-without-head_512x512_160k_ade20k.py
2021-08-13 19:05:26,674 - mmseg - INFO - Iter(val) [250]	aAcc: 0.6472, mIoU: 0.1223, mAcc: 0.1700, IoU.wall: 0.5338, IoU.building: 0.6638, IoU.sky: 0.8926, IoU.floor: 0.5608, IoU.tree: 0.5869, IoU.ceiling: 0.6403, IoU.road: 0.5809, IoU.bed : 0.5905, IoU.windowpane: 0.3846, IoU.grass: 0.5522, IoU.cabinet: 0.3493, IoU.sidewalk: 0.1994, IoU.person: 0.4354, IoU.earth: 0.2047, IoU.door: 0.1230, IoU.table: 0.2584, IoU.mountain: 0.3306, IoU.plant: 0.2920, IoU.curtain: 0.3443, IoU.chair: 0.2335, IoU.car: 0.5191, IoU.water: 0.3112, IoU.painting: 0.4675, IoU.sofa: 0.2377, IoU.shelf: 0.1601, IoU.house: 0.2952, IoU.sea: 0.3157, IoU.mirror: 0.0310, IoU.rug: 0.1248, IoU.field: 0.1999, IoU.armchair: 0.0417, IoU.seat: 0.2159, IoU.fence: 0.1109, IoU.desk: 0.1177, IoU.rock: 0.0675, IoU.wardrobe: 0.0003, IoU.lamp: 0.2156, IoU.bathtub: 0.1899, IoU.railing: 0.1148, IoU.cushion: 0.1088, IoU.base: 0.0000, IoU.box: 0.0024, IoU.column: 0.0012, IoU.signboard: 0.0583, IoU.chest of drawers: 0.1309, IoU.counter: 0.0319, IoU.sand: 0.1041, IoU.sink: 0.2249, IoU.skyscraper: 0.3644, IoU.fireplace: 0.2600, IoU.refrigerator: 0.0760, IoU.grandstand: 0.1670, IoU.path: 0.0006, IoU.stairs: 0.0062, IoU.runway: 0.3595, IoU.case: 0.0092, IoU.pool table: 0.6069, IoU.pillow: 0.1493, IoU.screen door: 0.0018, IoU.stairway: 0.0643, IoU.river: 0.0028, IoU.bridge: 0.0108, IoU.bookcase: 0.0915, IoU.blind: 0.0000, IoU.coffee table: 0.1399, IoU.toilet: 0.4282, IoU.flower: 0.0322, IoU.book: 0.0469, IoU.hill: 0.0000, IoU.bench: 0.0318, IoU.countertop: 0.0018, IoU.stove: 0.2298, IoU.palm: 0.0001, IoU.kitchen island: 0.0000, IoU.computer: 0.1534, IoU.swivel chair: 0.0238, IoU.boat: 0.0791, IoU.bar: 0.0259, IoU.arcade machine: 0.0000, IoU.hovel: 0.0000, IoU.bus: 0.0300, IoU.towel: 0.0069, IoU.light: 0.0390, IoU.truck: 0.0001, IoU.tower: 0.0000, IoU.chandelier: 0.2931, IoU.awning: 0.0080, IoU.streetlight: 0.0000, IoU.booth: 0.0000, IoU.television receiver: 0.1171, IoU.airplane: 0.1030, IoU.dirt track: 0.0000, IoU.apparel: 0.0000, IoU.pole: 0.0001, IoU.land: 0.0000, IoU.bannister: 0.0000, IoU.escalator: 0.0037, IoU.ottoman: 0.0000, IoU.bottle: 0.0000, IoU.buffet: 0.0000, IoU.poster: 0.0000, IoU.stage: 0.0000, IoU.van: 0.0000, IoU.ship: 0.0000, IoU.fountain: 0.0000, IoU.conveyer belt: 0.0000, IoU.canopy: 0.0000, IoU.washer: 0.1167, IoU.plaything: 0.0000, IoU.swimming pool: 0.0669, IoU.stool: 0.0000, IoU.barrel: 0.0000, IoU.basket: 0.0000, IoU.waterfall: 0.2004, IoU.tent: 0.1106, IoU.bag: 0.0000, IoU.minibike: 0.0000, IoU.cradle: 0.3079, IoU.oven: 0.0000, IoU.ball: 0.1237, IoU.food: 0.0612, IoU.step: 0.0000, IoU.tank: 0.0000, IoU.trade name: 0.0000, IoU.microwave: 0.0018, IoU.pot: 0.0000, IoU.animal: 0.0000, IoU.bicycle: 0.0000, IoU.lake: 0.0000, IoU.dishwasher: 0.0000, IoU.screen: 0.2305, IoU.blanket: 0.0000, IoU.sculpture: 0.0000, IoU.hood: 0.0000, IoU.sconce: 0.0000, IoU.vase: 0.0000, IoU.traffic light: 0.0000, IoU.tray: 0.0000, IoU.ashcan: 0.0000, IoU.fan: 0.0000, IoU.pier: 0.0000, IoU.crt screen: 0.0000, IoU.plate: 0.0000, IoU.monitor: 0.0000, IoU.bulletin board: 0.0000, IoU.shower: 0.0000, IoU.radiator: 0.0000, IoU.glass: 0.0000, IoU.clock: 0.0000, IoU.flag: 0.0000, Acc.wall: 0.8390, Acc.building: 0.8169, Acc.sky: 0.9332, Acc.floor: 0.8174, Acc.tree: 0.8288, Acc.ceiling: 0.7715, Acc.road: 0.9048, Acc.bed : 0.8191, Acc.windowpane: 0.6330, Acc.grass: 0.6909, Acc.cabinet: 0.5316, Acc.sidewalk: 0.2313, Acc.person: 0.5364, Acc.earth: 0.2870, Acc.door: 0.1621, Acc.table: 0.3871, Acc.mountain: 0.5935, Acc.plant: 0.3674, Acc.curtain: 0.5869, Acc.chair: 0.3204, Acc.car: 0.7935, Acc.water: 0.5262, Acc.painting: 0.5931, Acc.sofa: 0.2903, Acc.shelf: 0.2126, Acc.house: 0.3971, Acc.sea: 0.6717, Acc.mirror: 0.0321, Acc.rug: 0.1313, Acc.field: 0.4782, Acc.armchair: 0.0447, Acc.seat: 0.3267, Acc.fence: 0.1447, Acc.desk: 0.1497, Acc.rock: 0.0940, Acc.wardrobe: 0.0003, Acc.lamp: 0.2544, Acc.bathtub: 0.2189, Acc.railing: 0.1444, Acc.cushion: 0.1273, Acc.base: 0.0000, Acc.box: 0.0024, Acc.column: 0.0012, Acc.signboard: 0.0632, Acc.chest of drawers: 0.1367, Acc.counter: 0.0338, Acc.sand: 0.1116, Acc.sink: 0.3791, Acc.skyscraper: 0.6389, Acc.fireplace: 0.2708, Acc.refrigerator: 0.0810, Acc.grandstand: 0.2839, Acc.path: 0.0006, Acc.stairs: 0.0063, Acc.runway: 0.4139, Acc.case: 0.0095, Acc.pool table: 0.7066, Acc.pillow: 0.1749, Acc.screen door: 0.0018, Acc.stairway: 0.0775, Acc.river: 0.0028, Acc.bridge: 0.0123, Acc.bookcase: 0.1056, Acc.blind: 0.0000, Acc.coffee table: 0.1718, Acc.toilet: 0.6072, Acc.flower: 0.0348, Acc.book: 0.0480, Acc.hill: 0.0000, Acc.bench: 0.0336, Acc.countertop: 0.0018, Acc.stove: 0.3090, Acc.palm: 0.0001, Acc.kitchen island: 0.0000, Acc.computer: 0.1815, Acc.swivel chair: 0.0246, Acc.boat: 0.0895, Acc.bar: 0.0265, Acc.arcade machine: 0.0000, Acc.hovel: 0.0000, Acc.bus: 0.0306, Acc.towel: 0.0069, Acc.light: 0.0402, Acc.truck: 0.0001, Acc.tower: 0.0000, Acc.chandelier: 0.3877, Acc.awning: 0.0081, Acc.streetlight: 0.0000, Acc.booth: 0.0000, Acc.television receiver: 0.1348, Acc.airplane: 0.1192, Acc.dirt track: 0.0000, Acc.apparel: 0.0000, Acc.pole: 0.0001, Acc.land: 0.0000, Acc.bannister: 0.0000, Acc.escalator: 0.0043, Acc.ottoman: 0.0000, Acc.bottle: 0.0000, Acc.buffet: 0.0000, Acc.poster: 0.0000, Acc.stage: 0.0000, Acc.van: 0.0000, Acc.ship: 0.0000, Acc.fountain: 0.0000, Acc.conveyer belt: 0.0000, Acc.canopy: 0.0000, Acc.washer: 0.1312, Acc.plaything: 0.0000, Acc.swimming pool: 0.0826, Acc.stool: 0.0000, Acc.barrel: 0.0000, Acc.basket: 0.0000, Acc.waterfall: 0.4380, Acc.tent: 0.1338, Acc.bag: 0.0000, Acc.minibike: 0.0000, Acc.cradle: 0.4939, Acc.oven: 0.0000, Acc.ball: 0.3959, Acc.food: 0.0652, Acc.step: 0.0000, Acc.tank: 0.0000, Acc.trade name: 0.0000, Acc.microwave: 0.0018, Acc.pot: 0.0000, Acc.animal: 0.0000, Acc.bicycle: 0.0000, Acc.lake: 0.0000, Acc.dishwasher: 0.0000, Acc.screen: 0.2886, Acc.blanket: 0.0000, Acc.sculpture: 0.0000, Acc.hood: 0.0000, Acc.sconce: 0.0000, Acc.vase: 0.0000, Acc.traffic light: 0.0000, Acc.tray: 0.0000, Acc.ashcan: 0.0000, Acc.fan: 0.0000, Acc.pier: 0.0000, Acc.crt screen: 0.0000, Acc.plate: 0.0000, Acc.monitor: 0.0000, Acc.bulletin board: 0.0000, Acc.shower: 0.0000, Acc.radiator: 0.0000, Acc.glass: 0.0000, Acc.clock: 0.0000, Acc.flag: 0.0000
2021-08-13 19:06:08,047 - mmseg - INFO - Iter [32050/160000]	lr: 8.196e-03, eta: 1 day, 7:45:06, time: 3.626, data_time: 2.811, memory: 4319, decode.loss_seg: 1.1938, decode.acc_seg: 50.5212, loss: 1.1938
2021-08-13 19:06:49,697 - mmseg - INFO - Iter [32100/160000]	lr: 8.193e-03, eta: 1 day, 7:44:10, time: 0.833, data_time: 0.010, memory: 4319, decode.loss_seg: 1.2074, decode.acc_seg: 49.7145, loss: 1.2074
2021-08-13 19:07:32,274 - mmseg - INFO - Iter [32150/160000]	lr: 8.190e-03, eta: 1 day, 7:43:17, time: 0.851, data_time: 0.010, memory: 4319, decode.loss_seg: 1.2296, decode.acc_seg: 50.2095, loss: 1.2296
2021-08-13 19:08:48,072 - mmseg - INFO - Iter [32200/160000]	lr: 8.187e-03, eta: 1 day, 7:44:36, time: 1.516, data_time: 0.700, memory: 4319, decode.loss_seg: 1.1803, decode.acc_seg: 49.5680, loss: 1.1803
2021-08-13 19:09:29,209 - mmseg - INFO - Iter [32250/160000]	lr: 8.185e-03, eta: 1 day, 7:43:37, time: 0.823, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1811, decode.acc_seg: 51.1665, loss: 1.1811
2021-08-13 19:10:10,102 - mmseg - INFO - Iter [32300/160000]	lr: 8.182e-03, eta: 1 day, 7:42:37, time: 0.818, data_time: 0.010, memory: 4319, decode.loss_seg: 1.2362, decode.acc_seg: 50.2525, loss: 1.2362
2021-08-13 19:10:50,755 - mmseg - INFO - Iter [32350/160000]	lr: 8.179e-03, eta: 1 day, 7:41:36, time: 0.813, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1949, decode.acc_seg: 49.6301, loss: 1.1949
2021-08-13 19:11:31,655 - mmseg - INFO - Iter [32400/160000]	lr: 8.176e-03, eta: 1 day, 7:40:37, time: 0.818, data_time: 0.010, memory: 4319, decode.loss_seg: 1.2061, decode.acc_seg: 49.1876, loss: 1.2061
2021-08-13 19:12:14,253 - mmseg - INFO - Iter [32450/160000]	lr: 8.173e-03, eta: 1 day, 7:39:44, time: 0.852, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1780, decode.acc_seg: 50.6987, loss: 1.1780
2021-08-13 19:12:56,103 - mmseg - INFO - Iter [32500/160000]	lr: 8.170e-03, eta: 1 day, 7:38:48, time: 0.837, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2139, decode.acc_seg: 49.0470, loss: 1.2139
2021-08-13 19:13:37,735 - mmseg - INFO - Iter [32550/160000]	lr: 8.167e-03, eta: 1 day, 7:37:52, time: 0.833, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2101, decode.acc_seg: 50.4125, loss: 1.2101
2021-08-13 19:14:18,379 - mmseg - INFO - Iter [32600/160000]	lr: 8.165e-03, eta: 1 day, 7:36:51, time: 0.813, data_time: 0.010, memory: 4319, decode.loss_seg: 1.1858, decode.acc_seg: 49.6286, loss: 1.1858
2021-08-13 19:15:00,582 - mmseg - INFO - Iter [32650/160000]	lr: 8.162e-03, eta: 1 day, 7:35:57, time: 0.844, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2261, decode.acc_seg: 49.5746, loss: 1.2261
2021-08-13 19:15:41,755 - mmseg - INFO - Iter [32700/160000]	lr: 8.159e-03, eta: 1 day, 7:34:59, time: 0.823, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1928, decode.acc_seg: 51.1047, loss: 1.1928
2021-08-13 19:16:23,346 - mmseg - INFO - Iter [32750/160000]	lr: 8.156e-03, eta: 1 day, 7:34:02, time: 0.832, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1857, decode.acc_seg: 49.7021, loss: 1.1857
2021-08-13 19:17:04,924 - mmseg - INFO - Iter [32800/160000]	lr: 8.153e-03, eta: 1 day, 7:33:05, time: 0.831, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2230, decode.acc_seg: 49.6335, loss: 1.2230
2021-08-13 19:18:21,562 - mmseg - INFO - Iter [32850/160000]	lr: 8.150e-03, eta: 1 day, 7:34:25, time: 1.533, data_time: 0.680, memory: 4319, decode.loss_seg: 1.2051, decode.acc_seg: 49.6522, loss: 1.2051
2021-08-13 19:19:03,440 - mmseg - INFO - Iter [32900/160000]	lr: 8.148e-03, eta: 1 day, 7:33:29, time: 0.838, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1877, decode.acc_seg: 49.6559, loss: 1.1877
2021-08-13 19:19:45,523 - mmseg - INFO - Iter [32950/160000]	lr: 8.145e-03, eta: 1 day, 7:32:34, time: 0.842, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2072, decode.acc_seg: 49.3692, loss: 1.2072
2021-08-13 19:20:27,121 - mmseg - INFO - Exp name: fcn_litehr18-without-head_512x512_160k_ade20k.py
2021-08-13 19:20:27,122 - mmseg - INFO - Iter [33000/160000]	lr: 8.142e-03, eta: 1 day, 7:31:38, time: 0.832, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2124, decode.acc_seg: 50.0093, loss: 1.2124
2021-08-13 19:21:08,281 - mmseg - INFO - Iter [33050/160000]	lr: 8.139e-03, eta: 1 day, 7:30:39, time: 0.823, data_time: 0.010, memory: 4319, decode.loss_seg: 1.1946, decode.acc_seg: 49.0149, loss: 1.1946
2021-08-13 19:21:49,931 - mmseg - INFO - Iter [33100/160000]	lr: 8.136e-03, eta: 1 day, 7:29:43, time: 0.833, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1706, decode.acc_seg: 51.0057, loss: 1.1706
2021-08-13 19:22:31,837 - mmseg - INFO - Iter [33150/160000]	lr: 8.133e-03, eta: 1 day, 7:28:48, time: 0.838, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1921, decode.acc_seg: 50.3067, loss: 1.1921
2021-08-13 19:23:13,278 - mmseg - INFO - Iter [33200/160000]	lr: 8.130e-03, eta: 1 day, 7:27:51, time: 0.829, data_time: 0.012, memory: 4319, decode.loss_seg: 1.1858, decode.acc_seg: 49.8943, loss: 1.1858
2021-08-13 19:23:54,137 - mmseg - INFO - Iter [33250/160000]	lr: 8.128e-03, eta: 1 day, 7:26:52, time: 0.817, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2176, decode.acc_seg: 49.3773, loss: 1.2176
2021-08-13 19:24:35,939 - mmseg - INFO - Iter [33300/160000]	lr: 8.125e-03, eta: 1 day, 7:25:56, time: 0.836, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2404, decode.acc_seg: 49.2689, loss: 1.2404
2021-08-13 19:25:17,658 - mmseg - INFO - Iter [33350/160000]	lr: 8.122e-03, eta: 1 day, 7:25:00, time: 0.834, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2352, decode.acc_seg: 49.7961, loss: 1.2352
2021-08-13 19:25:59,397 - mmseg - INFO - Iter [33400/160000]	lr: 8.119e-03, eta: 1 day, 7:24:05, time: 0.835, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1883, decode.acc_seg: 50.3515, loss: 1.1883
2021-08-13 19:27:13,579 - mmseg - INFO - Iter [33450/160000]	lr: 8.116e-03, eta: 1 day, 7:25:12, time: 1.484, data_time: 0.702, memory: 4319, decode.loss_seg: 1.2179, decode.acc_seg: 50.3461, loss: 1.2179
2021-08-13 19:27:54,946 - mmseg - INFO - Iter [33500/160000]	lr: 8.113e-03, eta: 1 day, 7:24:14, time: 0.827, data_time: 0.010, memory: 4319, decode.loss_seg: 1.1629, decode.acc_seg: 49.9414, loss: 1.1629
2021-08-13 19:28:36,629 - mmseg - INFO - Iter [33550/160000]	lr: 8.110e-03, eta: 1 day, 7:23:18, time: 0.834, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2070, decode.acc_seg: 50.6150, loss: 1.2070
2021-08-13 19:29:19,456 - mmseg - INFO - Iter [33600/160000]	lr: 8.108e-03, eta: 1 day, 7:22:27, time: 0.856, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2255, decode.acc_seg: 50.1886, loss: 1.2255
2021-08-13 19:30:00,833 - mmseg - INFO - Iter [33650/160000]	lr: 8.105e-03, eta: 1 day, 7:21:30, time: 0.828, data_time: 0.010, memory: 4319, decode.loss_seg: 1.2048, decode.acc_seg: 49.9579, loss: 1.2048
2021-08-13 19:30:41,519 - mmseg - INFO - Iter [33700/160000]	lr: 8.102e-03, eta: 1 day, 7:20:30, time: 0.814, data_time: 0.010, memory: 4319, decode.loss_seg: 1.1833, decode.acc_seg: 49.7371, loss: 1.1833
2021-08-13 19:31:21,945 - mmseg - INFO - Iter [33750/160000]	lr: 8.099e-03, eta: 1 day, 7:19:30, time: 0.808, data_time: 0.010, memory: 4319, decode.loss_seg: 1.2087, decode.acc_seg: 49.7830, loss: 1.2087
2021-08-13 19:32:02,586 - mmseg - INFO - Iter [33800/160000]	lr: 8.096e-03, eta: 1 day, 7:18:30, time: 0.813, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1817, decode.acc_seg: 50.7518, loss: 1.1817
2021-08-13 19:32:44,190 - mmseg - INFO - Iter [33850/160000]	lr: 8.093e-03, eta: 1 day, 7:17:34, time: 0.832, data_time: 0.010, memory: 4319, decode.loss_seg: 1.2176, decode.acc_seg: 49.4133, loss: 1.2176
2021-08-13 19:33:24,278 - mmseg - INFO - Iter [33900/160000]	lr: 8.090e-03, eta: 1 day, 7:16:32, time: 0.802, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2216, decode.acc_seg: 50.4009, loss: 1.2216
2021-08-13 19:34:04,354 - mmseg - INFO - Iter [33950/160000]	lr: 8.088e-03, eta: 1 day, 7:15:31, time: 0.801, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2477, decode.acc_seg: 49.6063, loss: 1.2477
2021-08-13 19:34:45,755 - mmseg - INFO - Exp name: fcn_litehr18-without-head_512x512_160k_ade20k.py
2021-08-13 19:34:45,756 - mmseg - INFO - Iter [34000/160000]	lr: 8.085e-03, eta: 1 day, 7:14:34, time: 0.828, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1913, decode.acc_seg: 49.9109, loss: 1.1913
2021-08-13 19:35:27,775 - mmseg - INFO - Iter [34050/160000]	lr: 8.082e-03, eta: 1 day, 7:13:40, time: 0.841, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1630, decode.acc_seg: 50.8464, loss: 1.1630
2021-08-13 19:36:44,269 - mmseg - INFO - Iter [34100/160000]	lr: 8.079e-03, eta: 1 day, 7:14:53, time: 1.530, data_time: 0.740, memory: 4319, decode.loss_seg: 1.1960, decode.acc_seg: 49.5246, loss: 1.1960
2021-08-13 19:37:24,633 - mmseg - INFO - Iter [34150/160000]	lr: 8.076e-03, eta: 1 day, 7:13:52, time: 0.807, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1776, decode.acc_seg: 49.1130, loss: 1.1776
2021-08-13 19:38:06,005 - mmseg - INFO - Iter [34200/160000]	lr: 8.073e-03, eta: 1 day, 7:12:55, time: 0.828, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1724, decode.acc_seg: 50.7528, loss: 1.1724
2021-08-13 19:38:47,050 - mmseg - INFO - Iter [34250/160000]	lr: 8.071e-03, eta: 1 day, 7:11:57, time: 0.821, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1942, decode.acc_seg: 49.9536, loss: 1.1942
2021-08-13 19:39:27,986 - mmseg - INFO - Iter [34300/160000]	lr: 8.068e-03, eta: 1 day, 7:10:59, time: 0.819, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1837, decode.acc_seg: 50.7940, loss: 1.1837
2021-08-13 19:40:08,258 - mmseg - INFO - Iter [34350/160000]	lr: 8.065e-03, eta: 1 day, 7:09:58, time: 0.805, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2165, decode.acc_seg: 49.2322, loss: 1.2165
2021-08-13 19:40:48,076 - mmseg - INFO - Iter [34400/160000]	lr: 8.062e-03, eta: 1 day, 7:08:56, time: 0.796, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1856, decode.acc_seg: 50.4038, loss: 1.1856
2021-08-13 19:41:28,671 - mmseg - INFO - Iter [34450/160000]	lr: 8.059e-03, eta: 1 day, 7:07:57, time: 0.812, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1764, decode.acc_seg: 50.3182, loss: 1.1764
2021-08-13 19:42:09,047 - mmseg - INFO - Iter [34500/160000]	lr: 8.056e-03, eta: 1 day, 7:06:57, time: 0.807, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2372, decode.acc_seg: 49.6958, loss: 1.2372
2021-08-13 19:42:50,445 - mmseg - INFO - Iter [34550/160000]	lr: 8.053e-03, eta: 1 day, 7:06:00, time: 0.829, data_time: 0.012, memory: 4319, decode.loss_seg: 1.2200, decode.acc_seg: 49.5452, loss: 1.2200
2021-08-13 19:43:31,034 - mmseg - INFO - Iter [34600/160000]	lr: 8.051e-03, eta: 1 day, 7:05:01, time: 0.811, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1920, decode.acc_seg: 50.4839, loss: 1.1920
2021-08-13 19:44:11,767 - mmseg - INFO - Iter [34650/160000]	lr: 8.048e-03, eta: 1 day, 7:04:02, time: 0.814, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1206, decode.acc_seg: 51.4106, loss: 1.1206
2021-08-13 19:44:52,735 - mmseg - INFO - Iter [34700/160000]	lr: 8.045e-03, eta: 1 day, 7:03:05, time: 0.820, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2310, decode.acc_seg: 49.3073, loss: 1.2310
2021-08-13 19:46:09,357 - mmseg - INFO - Iter [34750/160000]	lr: 8.042e-03, eta: 1 day, 7:04:15, time: 1.532, data_time: 0.714, memory: 4319, decode.loss_seg: 1.1777, decode.acc_seg: 49.6113, loss: 1.1777
2021-08-13 19:46:50,293 - mmseg - INFO - Iter [34800/160000]	lr: 8.039e-03, eta: 1 day, 7:03:17, time: 0.819, data_time: 0.012, memory: 4319, decode.loss_seg: 1.1861, decode.acc_seg: 50.8563, loss: 1.1861
2021-08-13 19:47:30,801 - mmseg - INFO - Iter [34850/160000]	lr: 8.036e-03, eta: 1 day, 7:02:18, time: 0.810, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1735, decode.acc_seg: 49.6616, loss: 1.1735
2021-08-13 19:48:10,901 - mmseg - INFO - Iter [34900/160000]	lr: 8.033e-03, eta: 1 day, 7:01:17, time: 0.802, data_time: 0.012, memory: 4319, decode.loss_seg: 1.2016, decode.acc_seg: 50.7481, loss: 1.2016
2021-08-13 19:48:51,457 - mmseg - INFO - Iter [34950/160000]	lr: 8.031e-03, eta: 1 day, 7:00:18, time: 0.811, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1714, decode.acc_seg: 50.4731, loss: 1.1714
2021-08-13 19:49:31,790 - mmseg - INFO - Exp name: fcn_litehr18-without-head_512x512_160k_ade20k.py
2021-08-13 19:49:31,791 - mmseg - INFO - Iter [35000/160000]	lr: 8.028e-03, eta: 1 day, 6:59:18, time: 0.807, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2010, decode.acc_seg: 50.2255, loss: 1.2010
2021-08-13 19:50:12,835 - mmseg - INFO - Iter [35050/160000]	lr: 8.025e-03, eta: 1 day, 6:58:20, time: 0.820, data_time: 0.010, memory: 4319, decode.loss_seg: 1.2036, decode.acc_seg: 48.8184, loss: 1.2036
2021-08-13 19:50:53,656 - mmseg - INFO - Iter [35100/160000]	lr: 8.022e-03, eta: 1 day, 6:57:22, time: 0.817, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1765, decode.acc_seg: 50.1755, loss: 1.1765
2021-08-13 19:51:34,048 - mmseg - INFO - Iter [35150/160000]	lr: 8.019e-03, eta: 1 day, 6:56:23, time: 0.808, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2261, decode.acc_seg: 50.2949, loss: 1.2261
2021-08-13 19:52:15,246 - mmseg - INFO - Iter [35200/160000]	lr: 8.016e-03, eta: 1 day, 6:55:26, time: 0.824, data_time: 0.012, memory: 4319, decode.loss_seg: 1.2109, decode.acc_seg: 50.4378, loss: 1.2109
2021-08-13 19:52:55,920 - mmseg - INFO - Iter [35250/160000]	lr: 8.013e-03, eta: 1 day, 6:54:27, time: 0.813, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1797, decode.acc_seg: 50.6879, loss: 1.1797
2021-08-13 19:53:37,564 - mmseg - INFO - Iter [35300/160000]	lr: 8.011e-03, eta: 1 day, 6:53:32, time: 0.833, data_time: 0.010, memory: 4319, decode.loss_seg: 1.1806, decode.acc_seg: 49.9611, loss: 1.1806
2021-08-13 19:54:53,032 - mmseg - INFO - Iter [35350/160000]	lr: 8.008e-03, eta: 1 day, 6:54:37, time: 1.509, data_time: 0.732, memory: 4319, decode.loss_seg: 1.2207, decode.acc_seg: 49.4181, loss: 1.2207
2021-08-13 19:55:33,733 - mmseg - INFO - Iter [35400/160000]	lr: 8.005e-03, eta: 1 day, 6:53:38, time: 0.814, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1916, decode.acc_seg: 50.6618, loss: 1.1916
2021-08-13 19:56:14,422 - mmseg - INFO - Iter [35450/160000]	lr: 8.002e-03, eta: 1 day, 6:52:40, time: 0.813, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2183, decode.acc_seg: 49.1335, loss: 1.2183
2021-08-13 19:56:55,141 - mmseg - INFO - Iter [35500/160000]	lr: 7.999e-03, eta: 1 day, 6:51:41, time: 0.814, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2026, decode.acc_seg: 50.2625, loss: 1.2026
2021-08-13 19:57:35,917 - mmseg - INFO - Iter [35550/160000]	lr: 7.996e-03, eta: 1 day, 6:50:43, time: 0.816, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1610, decode.acc_seg: 50.2270, loss: 1.1610
2021-08-13 19:58:16,227 - mmseg - INFO - Iter [35600/160000]	lr: 7.993e-03, eta: 1 day, 6:49:44, time: 0.806, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2189, decode.acc_seg: 49.0388, loss: 1.2189
2021-08-13 19:58:57,321 - mmseg - INFO - Iter [35650/160000]	lr: 7.991e-03, eta: 1 day, 6:48:47, time: 0.823, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2143, decode.acc_seg: 49.6991, loss: 1.2143
2021-08-13 19:59:38,484 - mmseg - INFO - Iter [35700/160000]	lr: 7.988e-03, eta: 1 day, 6:47:50, time: 0.823, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1551, decode.acc_seg: 50.7687, loss: 1.1551
2021-08-13 20:00:20,860 - mmseg - INFO - Iter [35750/160000]	lr: 7.985e-03, eta: 1 day, 6:46:58, time: 0.847, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1897, decode.acc_seg: 49.6842, loss: 1.1897
2021-08-13 20:01:01,477 - mmseg - INFO - Iter [35800/160000]	lr: 7.982e-03, eta: 1 day, 6:45:59, time: 0.813, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1955, decode.acc_seg: 50.2797, loss: 1.1955
2021-08-13 20:01:41,921 - mmseg - INFO - Iter [35850/160000]	lr: 7.979e-03, eta: 1 day, 6:45:01, time: 0.809, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1965, decode.acc_seg: 50.5351, loss: 1.1965
2021-08-13 20:02:22,333 - mmseg - INFO - Iter [35900/160000]	lr: 7.976e-03, eta: 1 day, 6:44:02, time: 0.808, data_time: 0.012, memory: 4319, decode.loss_seg: 1.1813, decode.acc_seg: 50.1955, loss: 1.1813
2021-08-13 20:03:03,742 - mmseg - INFO - Iter [35950/160000]	lr: 7.973e-03, eta: 1 day, 6:43:06, time: 0.828, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1917, decode.acc_seg: 49.9002, loss: 1.1917
2021-08-13 20:04:20,543 - mmseg - INFO - Exp name: fcn_litehr18-without-head_512x512_160k_ade20k.py
2021-08-13 20:04:20,548 - mmseg - INFO - Iter [36000/160000]	lr: 7.971e-03, eta: 1 day, 6:44:12, time: 1.536, data_time: 0.747, memory: 4319, decode.loss_seg: 1.1801, decode.acc_seg: 49.2204, loss: 1.1801
2021-08-13 20:05:00,816 - mmseg - INFO - Iter [36050/160000]	lr: 7.968e-03, eta: 1 day, 6:43:13, time: 0.806, data_time: 0.012, memory: 4319, decode.loss_seg: 1.2342, decode.acc_seg: 50.0983, loss: 1.2342
2021-08-13 20:05:42,059 - mmseg - INFO - Iter [36100/160000]	lr: 7.965e-03, eta: 1 day, 6:42:17, time: 0.825, data_time: 0.010, memory: 4319, decode.loss_seg: 1.1800, decode.acc_seg: 50.9198, loss: 1.1800
2021-08-13 20:06:22,016 - mmseg - INFO - Iter [36150/160000]	lr: 7.962e-03, eta: 1 day, 6:41:16, time: 0.799, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1572, decode.acc_seg: 50.7057, loss: 1.1572
2021-08-13 20:07:02,318 - mmseg - INFO - Iter [36200/160000]	lr: 7.959e-03, eta: 1 day, 6:40:17, time: 0.806, data_time: 0.010, memory: 4319, decode.loss_seg: 1.1443, decode.acc_seg: 50.5262, loss: 1.1443
2021-08-13 20:07:42,743 - mmseg - INFO - Iter [36250/160000]	lr: 7.956e-03, eta: 1 day, 6:39:18, time: 0.808, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1736, decode.acc_seg: 50.4518, loss: 1.1736
2021-08-13 20:08:23,370 - mmseg - INFO - Iter [36300/160000]	lr: 7.953e-03, eta: 1 day, 6:38:20, time: 0.813, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2503, decode.acc_seg: 49.9518, loss: 1.2503
2021-08-13 20:09:03,940 - mmseg - INFO - Iter [36350/160000]	lr: 7.951e-03, eta: 1 day, 6:37:22, time: 0.811, data_time: 0.010, memory: 4319, decode.loss_seg: 1.2094, decode.acc_seg: 50.3859, loss: 1.2094
2021-08-13 20:09:44,319 - mmseg - INFO - Iter [36400/160000]	lr: 7.948e-03, eta: 1 day, 6:36:23, time: 0.808, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1534, decode.acc_seg: 50.2763, loss: 1.1534
2021-08-13 20:10:25,051 - mmseg - INFO - Iter [36450/160000]	lr: 7.945e-03, eta: 1 day, 6:35:25, time: 0.814, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1799, decode.acc_seg: 50.1532, loss: 1.1799
2021-08-13 20:11:05,961 - mmseg - INFO - Iter [36500/160000]	lr: 7.942e-03, eta: 1 day, 6:34:28, time: 0.818, data_time: 0.010, memory: 4319, decode.loss_seg: 1.1913, decode.acc_seg: 50.0421, loss: 1.1913
2021-08-13 20:11:48,101 - mmseg - INFO - Iter [36550/160000]	lr: 7.939e-03, eta: 1 day, 6:33:36, time: 0.843, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1804, decode.acc_seg: 50.3990, loss: 1.1804
2021-08-13 20:13:04,744 - mmseg - INFO - Iter [36600/160000]	lr: 7.936e-03, eta: 1 day, 6:34:39, time: 1.533, data_time: 0.731, memory: 4319, decode.loss_seg: 1.2046, decode.acc_seg: 50.3465, loss: 1.2046
2021-08-13 20:13:46,487 - mmseg - INFO - Iter [36650/160000]	lr: 7.933e-03, eta: 1 day, 6:33:45, time: 0.834, data_time: 0.010, memory: 4319, decode.loss_seg: 1.1729, decode.acc_seg: 50.5459, loss: 1.1729
2021-08-13 20:14:27,016 - mmseg - INFO - Iter [36700/160000]	lr: 7.931e-03, eta: 1 day, 6:32:47, time: 0.811, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1785, decode.acc_seg: 50.8324, loss: 1.1785
2021-08-13 20:15:08,227 - mmseg - INFO - Iter [36750/160000]	lr: 7.928e-03, eta: 1 day, 6:31:51, time: 0.824, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1455, decode.acc_seg: 51.1738, loss: 1.1455
2021-08-13 20:15:48,387 - mmseg - INFO - Iter [36800/160000]	lr: 7.925e-03, eta: 1 day, 6:30:51, time: 0.803, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2305, decode.acc_seg: 50.3849, loss: 1.2305
2021-08-13 20:16:30,512 - mmseg - INFO - Iter [36850/160000]	lr: 7.922e-03, eta: 1 day, 6:29:58, time: 0.842, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2229, decode.acc_seg: 49.5283, loss: 1.2229
2021-08-13 20:17:12,219 - mmseg - INFO - Iter [36900/160000]	lr: 7.919e-03, eta: 1 day, 6:29:04, time: 0.834, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1940, decode.acc_seg: 49.9285, loss: 1.1940
2021-08-13 20:17:53,705 - mmseg - INFO - Iter [36950/160000]	lr: 7.916e-03, eta: 1 day, 6:28:09, time: 0.830, data_time: 0.012, memory: 4319, decode.loss_seg: 1.1854, decode.acc_seg: 50.9224, loss: 1.1854
2021-08-13 20:18:33,402 - mmseg - INFO - Exp name: fcn_litehr18-without-head_512x512_160k_ade20k.py
2021-08-13 20:18:33,402 - mmseg - INFO - Iter [37000/160000]	lr: 7.913e-03, eta: 1 day, 6:27:09, time: 0.794, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1830, decode.acc_seg: 50.0092, loss: 1.1830
2021-08-13 20:19:14,554 - mmseg - INFO - Iter [37050/160000]	lr: 7.911e-03, eta: 1 day, 6:26:13, time: 0.823, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1825, decode.acc_seg: 50.0652, loss: 1.1825
2021-08-13 20:19:56,498 - mmseg - INFO - Iter [37100/160000]	lr: 7.908e-03, eta: 1 day, 6:25:20, time: 0.838, data_time: 0.010, memory: 4319, decode.loss_seg: 1.1874, decode.acc_seg: 50.6623, loss: 1.1874
2021-08-13 20:20:39,254 - mmseg - INFO - Iter [37150/160000]	lr: 7.905e-03, eta: 1 day, 6:24:29, time: 0.855, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1706, decode.acc_seg: 49.2451, loss: 1.1706
2021-08-13 20:21:21,862 - mmseg - INFO - Iter [37200/160000]	lr: 7.902e-03, eta: 1 day, 6:23:38, time: 0.852, data_time: 0.010, memory: 4319, decode.loss_seg: 1.2330, decode.acc_seg: 50.1433, loss: 1.2330
2021-08-13 20:22:39,720 - mmseg - INFO - Iter [37250/160000]	lr: 7.899e-03, eta: 1 day, 6:24:43, time: 1.557, data_time: 0.725, memory: 4319, decode.loss_seg: 1.1752, decode.acc_seg: 49.7046, loss: 1.1752
2021-08-13 20:23:22,109 - mmseg - INFO - Iter [37300/160000]	lr: 7.896e-03, eta: 1 day, 6:23:51, time: 0.848, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1774, decode.acc_seg: 50.1331, loss: 1.1774
2021-08-13 20:24:02,824 - mmseg - INFO - Iter [37350/160000]	lr: 7.893e-03, eta: 1 day, 6:22:54, time: 0.814, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1738, decode.acc_seg: 50.5198, loss: 1.1738
2021-08-13 20:24:43,261 - mmseg - INFO - Iter [37400/160000]	lr: 7.891e-03, eta: 1 day, 6:21:56, time: 0.808, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2061, decode.acc_seg: 51.1520, loss: 1.2061
2021-08-13 20:25:24,134 - mmseg - INFO - Iter [37450/160000]	lr: 7.888e-03, eta: 1 day, 6:20:59, time: 0.817, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2176, decode.acc_seg: 50.3620, loss: 1.2176
2021-08-13 20:26:05,237 - mmseg - INFO - Iter [37500/160000]	lr: 7.885e-03, eta: 1 day, 6:20:03, time: 0.822, data_time: 0.012, memory: 4319, decode.loss_seg: 1.1619, decode.acc_seg: 50.3972, loss: 1.1619
2021-08-13 20:26:45,695 - mmseg - INFO - Iter [37550/160000]	lr: 7.882e-03, eta: 1 day, 6:19:05, time: 0.809, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1585, decode.acc_seg: 51.0670, loss: 1.1585
2021-08-13 20:27:27,052 - mmseg - INFO - Iter [37600/160000]	lr: 7.879e-03, eta: 1 day, 6:18:10, time: 0.827, data_time: 0.012, memory: 4319, decode.loss_seg: 1.1815, decode.acc_seg: 50.2971, loss: 1.1815
2021-08-13 20:28:08,333 - mmseg - INFO - Iter [37650/160000]	lr: 7.876e-03, eta: 1 day, 6:17:15, time: 0.826, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1895, decode.acc_seg: 49.8762, loss: 1.1895
2021-08-13 20:28:49,613 - mmseg - INFO - Iter [37700/160000]	lr: 7.873e-03, eta: 1 day, 6:16:20, time: 0.826, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1756, decode.acc_seg: 50.1391, loss: 1.1756
2021-08-13 20:29:29,108 - mmseg - INFO - Iter [37750/160000]	lr: 7.871e-03, eta: 1 day, 6:15:19, time: 0.790, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2088, decode.acc_seg: 50.2529, loss: 1.2088
2021-08-13 20:30:09,498 - mmseg - INFO - Iter [37800/160000]	lr: 7.868e-03, eta: 1 day, 6:14:21, time: 0.807, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1720, decode.acc_seg: 51.3987, loss: 1.1720
2021-08-13 20:30:50,013 - mmseg - INFO - Iter [37850/160000]	lr: 7.865e-03, eta: 1 day, 6:13:23, time: 0.811, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2013, decode.acc_seg: 49.4568, loss: 1.2013
2021-08-13 20:32:07,567 - mmseg - INFO - Iter [37900/160000]	lr: 7.862e-03, eta: 1 day, 6:14:25, time: 1.551, data_time: 0.705, memory: 4319, decode.loss_seg: 1.1365, decode.acc_seg: 50.4459, loss: 1.1365
2021-08-13 20:32:48,324 - mmseg - INFO - Iter [37950/160000]	lr: 7.859e-03, eta: 1 day, 6:13:28, time: 0.815, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1725, decode.acc_seg: 49.6933, loss: 1.1725
2021-08-13 20:33:29,333 - mmseg - INFO - Exp name: fcn_litehr18-without-head_512x512_160k_ade20k.py
2021-08-13 20:33:29,333 - mmseg - INFO - Iter [38000/160000]	lr: 7.856e-03, eta: 1 day, 6:12:32, time: 0.820, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2015, decode.acc_seg: 50.0562, loss: 1.2015
2021-08-13 20:34:09,970 - mmseg - INFO - Iter [38050/160000]	lr: 7.853e-03, eta: 1 day, 6:11:35, time: 0.813, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1869, decode.acc_seg: 51.1664, loss: 1.1869
2021-08-13 20:34:51,241 - mmseg - INFO - Iter [38100/160000]	lr: 7.851e-03, eta: 1 day, 6:10:40, time: 0.826, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1615, decode.acc_seg: 51.2019, loss: 1.1615
2021-08-13 20:35:32,691 - mmseg - INFO - Iter [38150/160000]	lr: 7.848e-03, eta: 1 day, 6:09:45, time: 0.828, data_time: 0.010, memory: 4319, decode.loss_seg: 1.1734, decode.acc_seg: 51.3105, loss: 1.1734
2021-08-13 20:36:14,812 - mmseg - INFO - Iter [38200/160000]	lr: 7.845e-03, eta: 1 day, 6:08:53, time: 0.843, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2028, decode.acc_seg: 49.8456, loss: 1.2028
2021-08-13 20:36:55,007 - mmseg - INFO - Iter [38250/160000]	lr: 7.842e-03, eta: 1 day, 6:07:55, time: 0.804, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1601, decode.acc_seg: 49.7677, loss: 1.1601
2021-08-13 20:37:36,286 - mmseg - INFO - Iter [38300/160000]	lr: 7.839e-03, eta: 1 day, 6:07:00, time: 0.826, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1706, decode.acc_seg: 50.9305, loss: 1.1706
2021-08-13 20:38:16,595 - mmseg - INFO - Iter [38350/160000]	lr: 7.836e-03, eta: 1 day, 6:06:02, time: 0.806, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1903, decode.acc_seg: 50.6968, loss: 1.1903
2021-08-13 20:38:57,687 - mmseg - INFO - Iter [38400/160000]	lr: 7.833e-03, eta: 1 day, 6:05:06, time: 0.822, data_time: 0.010, memory: 4319, decode.loss_seg: 1.1929, decode.acc_seg: 50.3065, loss: 1.1929
2021-08-13 20:39:38,304 - mmseg - INFO - Iter [38450/160000]	lr: 7.831e-03, eta: 1 day, 6:04:09, time: 0.812, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1816, decode.acc_seg: 51.3613, loss: 1.1816
2021-08-13 20:40:54,360 - mmseg - INFO - Iter [38500/160000]	lr: 7.828e-03, eta: 1 day, 6:05:04, time: 1.521, data_time: 0.707, memory: 4319, decode.loss_seg: 1.2053, decode.acc_seg: 49.0425, loss: 1.2053
2021-08-13 20:41:35,892 - mmseg - INFO - Iter [38550/160000]	lr: 7.825e-03, eta: 1 day, 6:04:10, time: 0.831, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1084, decode.acc_seg: 51.2516, loss: 1.1084
2021-08-13 20:42:17,537 - mmseg - INFO - Iter [38600/160000]	lr: 7.822e-03, eta: 1 day, 6:03:16, time: 0.833, data_time: 0.010, memory: 4319, decode.loss_seg: 1.1756, decode.acc_seg: 49.7571, loss: 1.1756
2021-08-13 20:42:58,258 - mmseg - INFO - Iter [38650/160000]	lr: 7.819e-03, eta: 1 day, 6:02:20, time: 0.815, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1247, decode.acc_seg: 51.1193, loss: 1.1247
2021-08-13 20:43:39,012 - mmseg - INFO - Iter [38700/160000]	lr: 7.816e-03, eta: 1 day, 6:01:23, time: 0.815, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1970, decode.acc_seg: 50.3596, loss: 1.1970
2021-08-13 20:44:19,504 - mmseg - INFO - Iter [38750/160000]	lr: 7.813e-03, eta: 1 day, 6:00:26, time: 0.809, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1827, decode.acc_seg: 50.6591, loss: 1.1827
2021-08-13 20:45:01,484 - mmseg - INFO - Iter [38800/160000]	lr: 7.811e-03, eta: 1 day, 5:59:34, time: 0.840, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2102, decode.acc_seg: 50.2991, loss: 1.2102
2021-08-13 20:45:41,465 - mmseg - INFO - Iter [38850/160000]	lr: 7.808e-03, eta: 1 day, 5:58:35, time: 0.799, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1997, decode.acc_seg: 50.6945, loss: 1.1997
2021-08-13 20:46:23,261 - mmseg - INFO - Iter [38900/160000]	lr: 7.805e-03, eta: 1 day, 5:57:42, time: 0.836, data_time: 0.010, memory: 4319, decode.loss_seg: 1.2149, decode.acc_seg: 49.5378, loss: 1.2149
2021-08-13 20:47:05,602 - mmseg - INFO - Iter [38950/160000]	lr: 7.802e-03, eta: 1 day, 5:56:50, time: 0.847, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2253, decode.acc_seg: 48.8550, loss: 1.2253
2021-08-13 20:47:47,476 - mmseg - INFO - Exp name: fcn_litehr18-without-head_512x512_160k_ade20k.py
2021-08-13 20:47:47,477 - mmseg - INFO - Iter [39000/160000]	lr: 7.799e-03, eta: 1 day, 5:55:58, time: 0.838, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1584, decode.acc_seg: 50.4550, loss: 1.1584
2021-08-13 20:48:28,179 - mmseg - INFO - Iter [39050/160000]	lr: 7.796e-03, eta: 1 day, 5:55:01, time: 0.814, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1463, decode.acc_seg: 50.2474, loss: 1.1463
2021-08-13 20:49:08,022 - mmseg - INFO - Iter [39100/160000]	lr: 7.793e-03, eta: 1 day, 5:54:02, time: 0.797, data_time: 0.010, memory: 4319, decode.loss_seg: 1.1867, decode.acc_seg: 49.8145, loss: 1.1867
2021-08-13 20:50:23,403 - mmseg - INFO - Iter [39150/160000]	lr: 7.790e-03, eta: 1 day, 5:54:53, time: 1.508, data_time: 0.722, memory: 4319, decode.loss_seg: 1.1657, decode.acc_seg: 49.7590, loss: 1.1657
2021-08-13 20:51:03,753 - mmseg - INFO - Iter [39200/160000]	lr: 7.788e-03, eta: 1 day, 5:53:55, time: 0.807, data_time: 0.012, memory: 4319, decode.loss_seg: 1.2049, decode.acc_seg: 50.4108, loss: 1.2049
2021-08-13 20:51:45,305 - mmseg - INFO - Iter [39250/160000]	lr: 7.785e-03, eta: 1 day, 5:53:02, time: 0.831, data_time: 0.010, memory: 4319, decode.loss_seg: 1.1530, decode.acc_seg: 51.1526, loss: 1.1530
2021-08-13 20:52:27,331 - mmseg - INFO - Iter [39300/160000]	lr: 7.782e-03, eta: 1 day, 5:52:09, time: 0.839, data_time: 0.010, memory: 4319, decode.loss_seg: 1.1536, decode.acc_seg: 51.0661, loss: 1.1536
2021-08-13 20:53:07,751 - mmseg - INFO - Iter [39350/160000]	lr: 7.779e-03, eta: 1 day, 5:51:12, time: 0.810, data_time: 0.012, memory: 4319, decode.loss_seg: 1.1684, decode.acc_seg: 50.5933, loss: 1.1684
2021-08-13 20:53:47,776 - mmseg - INFO - Iter [39400/160000]	lr: 7.776e-03, eta: 1 day, 5:50:14, time: 0.800, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1719, decode.acc_seg: 51.0745, loss: 1.1719
2021-08-13 20:54:27,558 - mmseg - INFO - Iter [39450/160000]	lr: 7.773e-03, eta: 1 day, 5:49:15, time: 0.796, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1727, decode.acc_seg: 51.2057, loss: 1.1727
2021-08-13 20:55:08,124 - mmseg - INFO - Iter [39500/160000]	lr: 7.770e-03, eta: 1 day, 5:48:18, time: 0.812, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1808, decode.acc_seg: 49.5243, loss: 1.1808
2021-08-13 20:55:49,263 - mmseg - INFO - Iter [39550/160000]	lr: 7.768e-03, eta: 1 day, 5:47:23, time: 0.822, data_time: 0.010, memory: 4319, decode.loss_seg: 1.1967, decode.acc_seg: 49.9065, loss: 1.1967
2021-08-13 20:56:29,876 - mmseg - INFO - Iter [39600/160000]	lr: 7.765e-03, eta: 1 day, 5:46:27, time: 0.813, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1684, decode.acc_seg: 50.7231, loss: 1.1684
2021-08-13 20:57:09,279 - mmseg - INFO - Iter [39650/160000]	lr: 7.762e-03, eta: 1 day, 5:45:27, time: 0.788, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1831, decode.acc_seg: 50.6673, loss: 1.1831
2021-08-13 20:57:49,261 - mmseg - INFO - Iter [39700/160000]	lr: 7.759e-03, eta: 1 day, 5:44:29, time: 0.800, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2052, decode.acc_seg: 50.2549, loss: 1.2052
2021-08-13 20:58:29,747 - mmseg - INFO - Iter [39750/160000]	lr: 7.756e-03, eta: 1 day, 5:43:32, time: 0.809, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1740, decode.acc_seg: 49.7928, loss: 1.1740
2021-08-13 20:59:45,341 - mmseg - INFO - Iter [39800/160000]	lr: 7.753e-03, eta: 1 day, 5:44:21, time: 1.512, data_time: 0.684, memory: 4319, decode.loss_seg: 1.1454, decode.acc_seg: 51.1887, loss: 1.1454
2021-08-13 21:00:26,799 - mmseg - INFO - Iter [39850/160000]	lr: 7.750e-03, eta: 1 day, 5:43:28, time: 0.829, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1885, decode.acc_seg: 49.6197, loss: 1.1885
2021-08-13 21:01:09,291 - mmseg - INFO - Iter [39900/160000]	lr: 7.747e-03, eta: 1 day, 5:42:37, time: 0.850, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1980, decode.acc_seg: 50.5529, loss: 1.1980
2021-08-13 21:01:49,957 - mmseg - INFO - Iter [39950/160000]	lr: 7.745e-03, eta: 1 day, 5:41:41, time: 0.814, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1814, decode.acc_seg: 50.7645, loss: 1.1814
2021-08-13 21:02:30,216 - mmseg - INFO - Exp name: fcn_litehr18-without-head_512x512_160k_ade20k.py
2021-08-13 21:02:30,217 - mmseg - INFO - Iter [40000/160000]	lr: 7.742e-03, eta: 1 day, 5:40:44, time: 0.805, data_time: 0.010, memory: 4319, decode.loss_seg: 1.1938, decode.acc_seg: 50.6168, loss: 1.1938
2021-08-13 21:03:12,836 - mmseg - INFO - Iter [40050/160000]	lr: 7.739e-03, eta: 1 day, 5:39:53, time: 0.852, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1653, decode.acc_seg: 50.8509, loss: 1.1653
2021-08-13 21:03:55,755 - mmseg - INFO - Iter [40100/160000]	lr: 7.736e-03, eta: 1 day, 5:39:04, time: 0.858, data_time: 0.010, memory: 4319, decode.loss_seg: 1.1876, decode.acc_seg: 49.9545, loss: 1.1876
2021-08-13 21:04:38,055 - mmseg - INFO - Iter [40150/160000]	lr: 7.733e-03, eta: 1 day, 5:38:13, time: 0.846, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1952, decode.acc_seg: 50.5459, loss: 1.1952
2021-08-13 21:05:18,956 - mmseg - INFO - Iter [40200/160000]	lr: 7.730e-03, eta: 1 day, 5:37:18, time: 0.818, data_time: 0.010, memory: 4319, decode.loss_seg: 1.1390, decode.acc_seg: 50.4534, loss: 1.1390
2021-08-13 21:06:00,263 - mmseg - INFO - Iter [40250/160000]	lr: 7.727e-03, eta: 1 day, 5:36:24, time: 0.826, data_time: 0.010, memory: 4319, decode.loss_seg: 1.1918, decode.acc_seg: 50.4550, loss: 1.1918
2021-08-13 21:06:41,542 - mmseg - INFO - Iter [40300/160000]	lr: 7.725e-03, eta: 1 day, 5:35:29, time: 0.825, data_time: 0.010, memory: 4319, decode.loss_seg: 1.2011, decode.acc_seg: 50.4226, loss: 1.2011
2021-08-13 21:07:23,640 - mmseg - INFO - Iter [40350/160000]	lr: 7.722e-03, eta: 1 day, 5:34:38, time: 0.842, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1522, decode.acc_seg: 50.6493, loss: 1.1522
2021-08-13 21:08:40,375 - mmseg - INFO - Iter [40400/160000]	lr: 7.719e-03, eta: 1 day, 5:35:29, time: 1.535, data_time: 0.707, memory: 4319, decode.loss_seg: 1.1779, decode.acc_seg: 49.5316, loss: 1.1779
2021-08-13 21:09:21,433 - mmseg - INFO - Iter [40450/160000]	lr: 7.716e-03, eta: 1 day, 5:34:34, time: 0.821, data_time: 0.012, memory: 4319, decode.loss_seg: 1.1821, decode.acc_seg: 50.5186, loss: 1.1821
2021-08-13 21:10:02,039 - mmseg - INFO - Iter [40500/160000]	lr: 7.713e-03, eta: 1 day, 5:33:38, time: 0.812, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1605, decode.acc_seg: 50.6264, loss: 1.1605
2021-08-13 21:10:44,230 - mmseg - INFO - Iter [40550/160000]	lr: 7.710e-03, eta: 1 day, 5:32:46, time: 0.844, data_time: 0.012, memory: 4319, decode.loss_seg: 1.2023, decode.acc_seg: 50.6464, loss: 1.2023
2021-08-13 21:11:26,025 - mmseg - INFO - Iter [40600/160000]	lr: 7.707e-03, eta: 1 day, 5:31:54, time: 0.836, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1605, decode.acc_seg: 50.0159, loss: 1.1605
2021-08-13 21:12:07,519 - mmseg - INFO - Iter [40650/160000]	lr: 7.705e-03, eta: 1 day, 5:31:01, time: 0.830, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1792, decode.acc_seg: 49.9898, loss: 1.1792
2021-08-13 21:12:47,685 - mmseg - INFO - Iter [40700/160000]	lr: 7.702e-03, eta: 1 day, 5:30:03, time: 0.803, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1633, decode.acc_seg: 50.4334, loss: 1.1633
2021-08-13 21:13:28,288 - mmseg - INFO - Iter [40750/160000]	lr: 7.699e-03, eta: 1 day, 5:29:07, time: 0.812, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1694, decode.acc_seg: 51.1973, loss: 1.1694
2021-08-13 21:14:09,366 - mmseg - INFO - Iter [40800/160000]	lr: 7.696e-03, eta: 1 day, 5:28:13, time: 0.822, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1972, decode.acc_seg: 50.2860, loss: 1.1972
2021-08-13 21:14:49,630 - mmseg - INFO - Iter [40850/160000]	lr: 7.693e-03, eta: 1 day, 5:27:16, time: 0.805, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1906, decode.acc_seg: 49.8508, loss: 1.1906
2021-08-13 21:15:29,215 - mmseg - INFO - Iter [40900/160000]	lr: 7.690e-03, eta: 1 day, 5:26:17, time: 0.792, data_time: 0.012, memory: 4319, decode.loss_seg: 1.2193, decode.acc_seg: 50.5340, loss: 1.2193
2021-08-13 21:16:09,805 - mmseg - INFO - Iter [40950/160000]	lr: 7.687e-03, eta: 1 day, 5:25:21, time: 0.812, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1801, decode.acc_seg: 51.3598, loss: 1.1801
2021-08-13 21:16:51,032 - mmseg - INFO - Exp name: fcn_litehr18-without-head_512x512_160k_ade20k.py
2021-08-13 21:16:51,033 - mmseg - INFO - Iter [41000/160000]	lr: 7.684e-03, eta: 1 day, 5:24:27, time: 0.825, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1495, decode.acc_seg: 50.8718, loss: 1.1495
2021-08-13 21:18:07,563 - mmseg - INFO - Iter [41050/160000]	lr: 7.682e-03, eta: 1 day, 5:25:16, time: 1.530, data_time: 0.727, memory: 4319, decode.loss_seg: 1.1517, decode.acc_seg: 51.5359, loss: 1.1517
2021-08-13 21:18:48,021 - mmseg - INFO - Iter [41100/160000]	lr: 7.679e-03, eta: 1 day, 5:24:19, time: 0.810, data_time: 0.010, memory: 4319, decode.loss_seg: 1.1279, decode.acc_seg: 51.5092, loss: 1.1279
2021-08-13 21:19:29,574 - mmseg - INFO - Iter [41150/160000]	lr: 7.676e-03, eta: 1 day, 5:23:26, time: 0.831, data_time: 0.010, memory: 4319, decode.loss_seg: 1.2002, decode.acc_seg: 50.7257, loss: 1.2002
2021-08-13 21:20:10,306 - mmseg - INFO - Iter [41200/160000]	lr: 7.673e-03, eta: 1 day, 5:22:31, time: 0.814, data_time: 0.010, memory: 4319, decode.loss_seg: 1.1645, decode.acc_seg: 51.5734, loss: 1.1645
2021-08-13 21:20:51,733 - mmseg - INFO - Iter [41250/160000]	lr: 7.670e-03, eta: 1 day, 5:21:38, time: 0.828, data_time: 0.010, memory: 4319, decode.loss_seg: 1.1948, decode.acc_seg: 50.6355, loss: 1.1948
2021-08-13 21:21:32,870 - mmseg - INFO - Iter [41300/160000]	lr: 7.667e-03, eta: 1 day, 5:20:43, time: 0.823, data_time: 0.010, memory: 4319, decode.loss_seg: 1.1418, decode.acc_seg: 50.7568, loss: 1.1418
2021-08-13 21:22:13,221 - mmseg - INFO - Iter [41350/160000]	lr: 7.664e-03, eta: 1 day, 5:19:47, time: 0.807, data_time: 0.010, memory: 4319, decode.loss_seg: 1.1764, decode.acc_seg: 50.8025, loss: 1.1764
2021-08-13 21:22:53,823 - mmseg - INFO - Iter [41400/160000]	lr: 7.661e-03, eta: 1 day, 5:18:51, time: 0.811, data_time: 0.010, memory: 4319, decode.loss_seg: 1.2025, decode.acc_seg: 49.6434, loss: 1.2025
2021-08-13 21:23:35,195 - mmseg - INFO - Iter [41450/160000]	lr: 7.659e-03, eta: 1 day, 5:17:58, time: 0.828, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1975, decode.acc_seg: 49.6741, loss: 1.1975
2021-08-13 21:24:15,417 - mmseg - INFO - Iter [41500/160000]	lr: 7.656e-03, eta: 1 day, 5:17:01, time: 0.805, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1931, decode.acc_seg: 50.3505, loss: 1.1931
2021-08-13 21:24:56,186 - mmseg - INFO - Iter [41550/160000]	lr: 7.653e-03, eta: 1 day, 5:16:06, time: 0.815, data_time: 0.010, memory: 4319, decode.loss_seg: 1.1526, decode.acc_seg: 50.2678, loss: 1.1526
2021-08-13 21:25:35,591 - mmseg - INFO - Iter [41600/160000]	lr: 7.650e-03, eta: 1 day, 5:15:07, time: 0.788, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1886, decode.acc_seg: 51.0016, loss: 1.1886
2021-08-13 21:26:52,413 - mmseg - INFO - Iter [41650/160000]	lr: 7.647e-03, eta: 1 day, 5:15:55, time: 1.536, data_time: 0.707, memory: 4319, decode.loss_seg: 1.1837, decode.acc_seg: 50.2518, loss: 1.1837
2021-08-13 21:27:33,626 - mmseg - INFO - Iter [41700/160000]	lr: 7.644e-03, eta: 1 day, 5:15:01, time: 0.824, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1105, decode.acc_seg: 51.1148, loss: 1.1105
2021-08-13 21:28:14,554 - mmseg - INFO - Iter [41750/160000]	lr: 7.641e-03, eta: 1 day, 5:14:06, time: 0.819, data_time: 0.010, memory: 4319, decode.loss_seg: 1.1376, decode.acc_seg: 52.2431, loss: 1.1376
2021-08-13 21:28:55,425 - mmseg - INFO - Iter [41800/160000]	lr: 7.639e-03, eta: 1 day, 5:13:11, time: 0.817, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1271, decode.acc_seg: 51.3914, loss: 1.1271
2021-08-13 21:29:35,750 - mmseg - INFO - Iter [41850/160000]	lr: 7.636e-03, eta: 1 day, 5:12:15, time: 0.806, data_time: 0.010, memory: 4319, decode.loss_seg: 1.2068, decode.acc_seg: 50.4736, loss: 1.2068
2021-08-13 21:30:17,000 - mmseg - INFO - Iter [41900/160000]	lr: 7.633e-03, eta: 1 day, 5:11:21, time: 0.824, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1785, decode.acc_seg: 49.9759, loss: 1.1785
2021-08-13 21:30:58,855 - mmseg - INFO - Iter [41950/160000]	lr: 7.630e-03, eta: 1 day, 5:10:30, time: 0.838, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2090, decode.acc_seg: 49.7313, loss: 1.2090
2021-08-13 21:31:39,311 - mmseg - INFO - Exp name: fcn_litehr18-without-head_512x512_160k_ade20k.py
2021-08-13 21:31:39,311 - mmseg - INFO - Iter [42000/160000]	lr: 7.627e-03, eta: 1 day, 5:09:34, time: 0.809, data_time: 0.012, memory: 4319, decode.loss_seg: 1.1516, decode.acc_seg: 50.4917, loss: 1.1516
2021-08-13 21:32:19,284 - mmseg - INFO - Iter [42050/160000]	lr: 7.624e-03, eta: 1 day, 5:08:37, time: 0.800, data_time: 0.010, memory: 4319, decode.loss_seg: 1.1233, decode.acc_seg: 50.6194, loss: 1.1233
2021-08-13 21:33:00,076 - mmseg - INFO - Iter [42100/160000]	lr: 7.621e-03, eta: 1 day, 5:07:42, time: 0.816, data_time: 0.010, memory: 4319, decode.loss_seg: 1.1755, decode.acc_seg: 49.8047, loss: 1.1755
2021-08-13 21:33:41,271 - mmseg - INFO - Iter [42150/160000]	lr: 7.618e-03, eta: 1 day, 5:06:48, time: 0.824, data_time: 0.010, memory: 4319, decode.loss_seg: 1.1618, decode.acc_seg: 50.4375, loss: 1.1618
2021-08-13 21:34:22,447 - mmseg - INFO - Iter [42200/160000]	lr: 7.616e-03, eta: 1 day, 5:05:55, time: 0.824, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1915, decode.acc_seg: 49.5816, loss: 1.1915
2021-08-13 21:35:04,101 - mmseg - INFO - Iter [42250/160000]	lr: 7.613e-03, eta: 1 day, 5:05:02, time: 0.833, data_time: 0.010, memory: 4319, decode.loss_seg: 1.2035, decode.acc_seg: 49.8834, loss: 1.2035
2021-08-13 21:36:19,279 - mmseg - INFO - Iter [42300/160000]	lr: 7.610e-03, eta: 1 day, 5:05:43, time: 1.504, data_time: 0.685, memory: 4319, decode.loss_seg: 1.1446, decode.acc_seg: 50.5652, loss: 1.1446
2021-08-13 21:37:00,543 - mmseg - INFO - Iter [42350/160000]	lr: 7.607e-03, eta: 1 day, 5:04:50, time: 0.825, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1329, decode.acc_seg: 50.8829, loss: 1.1329
2021-08-13 21:37:41,755 - mmseg - INFO - Iter [42400/160000]	lr: 7.604e-03, eta: 1 day, 5:03:56, time: 0.824, data_time: 0.010, memory: 4319, decode.loss_seg: 1.1437, decode.acc_seg: 50.4937, loss: 1.1437
2021-08-13 21:38:21,777 - mmseg - INFO - Iter [42450/160000]	lr: 7.601e-03, eta: 1 day, 5:02:59, time: 0.800, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1965, decode.acc_seg: 49.5062, loss: 1.1965
2021-08-13 21:39:02,655 - mmseg - INFO - Iter [42500/160000]	lr: 7.598e-03, eta: 1 day, 5:02:05, time: 0.818, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1747, decode.acc_seg: 51.2178, loss: 1.1747
2021-08-13 21:39:42,848 - mmseg - INFO - Iter [42550/160000]	lr: 7.595e-03, eta: 1 day, 5:01:09, time: 0.804, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1601, decode.acc_seg: 50.8333, loss: 1.1601
2021-08-13 21:40:23,038 - mmseg - INFO - Iter [42600/160000]	lr: 7.593e-03, eta: 1 day, 5:00:12, time: 0.804, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1772, decode.acc_seg: 51.1152, loss: 1.1772
2021-08-13 21:41:03,365 - mmseg - INFO - Iter [42650/160000]	lr: 7.590e-03, eta: 1 day, 4:59:16, time: 0.806, data_time: 0.010, memory: 4319, decode.loss_seg: 1.1761, decode.acc_seg: 50.3395, loss: 1.1761
2021-08-13 21:41:43,329 - mmseg - INFO - Iter [42700/160000]	lr: 7.587e-03, eta: 1 day, 4:58:20, time: 0.800, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1648, decode.acc_seg: 50.4274, loss: 1.1648
2021-08-13 21:42:24,591 - mmseg - INFO - Iter [42750/160000]	lr: 7.584e-03, eta: 1 day, 4:57:26, time: 0.825, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1606, decode.acc_seg: 51.3032, loss: 1.1606
2021-08-13 21:43:04,975 - mmseg - INFO - Iter [42800/160000]	lr: 7.581e-03, eta: 1 day, 4:56:31, time: 0.808, data_time: 0.010, memory: 4319, decode.loss_seg: 1.1173, decode.acc_seg: 53.0599, loss: 1.1173
2021-08-13 21:43:45,251 - mmseg - INFO - Iter [42850/160000]	lr: 7.578e-03, eta: 1 day, 4:55:35, time: 0.805, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1812, decode.acc_seg: 50.8684, loss: 1.1812
2021-08-13 21:44:26,190 - mmseg - INFO - Iter [42900/160000]	lr: 7.575e-03, eta: 1 day, 4:54:41, time: 0.819, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1778, decode.acc_seg: 50.1389, loss: 1.1778
2021-08-13 21:45:43,510 - mmseg - INFO - Iter [42950/160000]	lr: 7.572e-03, eta: 1 day, 4:55:26, time: 1.546, data_time: 0.726, memory: 4319, decode.loss_seg: 1.1302, decode.acc_seg: 50.6388, loss: 1.1302
2021-08-13 21:46:23,943 - mmseg - INFO - Exp name: fcn_litehr18-without-head_512x512_160k_ade20k.py
2021-08-13 21:46:23,944 - mmseg - INFO - Iter [43000/160000]	lr: 7.570e-03, eta: 1 day, 4:54:31, time: 0.809, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1035, decode.acc_seg: 51.8099, loss: 1.1035
2021-08-13 21:47:05,242 - mmseg - INFO - Iter [43050/160000]	lr: 7.567e-03, eta: 1 day, 4:53:37, time: 0.826, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1540, decode.acc_seg: 51.6489, loss: 1.1540
2021-08-13 21:47:46,682 - mmseg - INFO - Iter [43100/160000]	lr: 7.564e-03, eta: 1 day, 4:52:45, time: 0.829, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1863, decode.acc_seg: 49.6856, loss: 1.1863
2021-08-13 21:48:28,278 - mmseg - INFO - Iter [43150/160000]	lr: 7.561e-03, eta: 1 day, 4:51:53, time: 0.832, data_time: 0.010, memory: 4319, decode.loss_seg: 1.1234, decode.acc_seg: 51.6242, loss: 1.1234
2021-08-13 21:49:09,997 - mmseg - INFO - Iter [43200/160000]	lr: 7.558e-03, eta: 1 day, 4:51:01, time: 0.834, data_time: 0.010, memory: 4319, decode.loss_seg: 1.1683, decode.acc_seg: 51.4431, loss: 1.1683
2021-08-13 21:49:50,203 - mmseg - INFO - Iter [43250/160000]	lr: 7.555e-03, eta: 1 day, 4:50:05, time: 0.805, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2082, decode.acc_seg: 49.5828, loss: 1.2082
2021-08-13 21:50:30,485 - mmseg - INFO - Iter [43300/160000]	lr: 7.552e-03, eta: 1 day, 4:49:09, time: 0.805, data_time: 0.010, memory: 4319, decode.loss_seg: 1.1869, decode.acc_seg: 50.8783, loss: 1.1869
2021-08-13 21:51:11,685 - mmseg - INFO - Iter [43350/160000]	lr: 7.549e-03, eta: 1 day, 4:48:16, time: 0.824, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1739, decode.acc_seg: 50.4283, loss: 1.1739
2021-08-13 21:51:52,982 - mmseg - INFO - Iter [43400/160000]	lr: 7.547e-03, eta: 1 day, 4:47:23, time: 0.825, data_time: 0.010, memory: 4319, decode.loss_seg: 1.2078, decode.acc_seg: 49.9713, loss: 1.2078
2021-08-13 21:52:34,220 - mmseg - INFO - Iter [43450/160000]	lr: 7.544e-03, eta: 1 day, 4:46:30, time: 0.825, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1802, decode.acc_seg: 50.6209, loss: 1.1802
2021-08-13 21:53:15,116 - mmseg - INFO - Iter [43500/160000]	lr: 7.541e-03, eta: 1 day, 4:45:36, time: 0.818, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1473, decode.acc_seg: 51.8509, loss: 1.1473
2021-08-13 21:54:31,357 - mmseg - INFO - Iter [43550/160000]	lr: 7.538e-03, eta: 1 day, 4:46:17, time: 1.525, data_time: 0.698, memory: 4319, decode.loss_seg: 1.1501, decode.acc_seg: 51.3829, loss: 1.1501
2021-08-13 21:55:11,343 - mmseg - INFO - Iter [43600/160000]	lr: 7.535e-03, eta: 1 day, 4:45:20, time: 0.800, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1085, decode.acc_seg: 51.1997, loss: 1.1085
2021-08-13 21:55:52,127 - mmseg - INFO - Iter [43650/160000]	lr: 7.532e-03, eta: 1 day, 4:44:26, time: 0.815, data_time: 0.010, memory: 4319, decode.loss_seg: 1.1668, decode.acc_seg: 50.2094, loss: 1.1668
2021-08-13 21:56:33,396 - mmseg - INFO - Iter [43700/160000]	lr: 7.529e-03, eta: 1 day, 4:43:33, time: 0.826, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1345, decode.acc_seg: 51.3645, loss: 1.1345
2021-08-13 21:57:14,949 - mmseg - INFO - Iter [43750/160000]	lr: 7.527e-03, eta: 1 day, 4:42:41, time: 0.831, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1391, decode.acc_seg: 51.8068, loss: 1.1391
2021-08-13 21:57:54,954 - mmseg - INFO - Iter [43800/160000]	lr: 7.524e-03, eta: 1 day, 4:41:44, time: 0.801, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1846, decode.acc_seg: 49.6203, loss: 1.1846
2021-08-13 21:58:34,805 - mmseg - INFO - Iter [43850/160000]	lr: 7.521e-03, eta: 1 day, 4:40:48, time: 0.797, data_time: 0.010, memory: 4319, decode.loss_seg: 1.1245, decode.acc_seg: 51.6838, loss: 1.1245
2021-08-13 21:59:15,995 - mmseg - INFO - Iter [43900/160000]	lr: 7.518e-03, eta: 1 day, 4:39:55, time: 0.823, data_time: 0.010, memory: 4319, decode.loss_seg: 1.1405, decode.acc_seg: 51.2106, loss: 1.1405
2021-08-13 21:59:58,035 - mmseg - INFO - Iter [43950/160000]	lr: 7.515e-03, eta: 1 day, 4:39:04, time: 0.841, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2410, decode.acc_seg: 49.8877, loss: 1.2410
2021-08-13 22:00:40,295 - mmseg - INFO - Exp name: fcn_litehr18-without-head_512x512_160k_ade20k.py
2021-08-13 22:00:40,296 - mmseg - INFO - Iter [44000/160000]	lr: 7.512e-03, eta: 1 day, 4:38:14, time: 0.845, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1595, decode.acc_seg: 50.1174, loss: 1.1595
2021-08-13 22:01:22,562 - mmseg - INFO - Iter [44050/160000]	lr: 7.509e-03, eta: 1 day, 4:37:24, time: 0.845, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1611, decode.acc_seg: 50.4527, loss: 1.1611
2021-08-13 22:02:03,367 - mmseg - INFO - Iter [44100/160000]	lr: 7.506e-03, eta: 1 day, 4:36:30, time: 0.816, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1869, decode.acc_seg: 50.4229, loss: 1.1869
2021-08-13 22:02:43,916 - mmseg - INFO - Iter [44150/160000]	lr: 7.503e-03, eta: 1 day, 4:35:35, time: 0.811, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1373, decode.acc_seg: 51.7328, loss: 1.1373
2021-08-13 22:04:00,101 - mmseg - INFO - Iter [44200/160000]	lr: 7.501e-03, eta: 1 day, 4:36:14, time: 1.524, data_time: 0.705, memory: 4319, decode.loss_seg: 1.1499, decode.acc_seg: 51.7436, loss: 1.1499
2021-08-13 22:04:41,390 - mmseg - INFO - Iter [44250/160000]	lr: 7.498e-03, eta: 1 day, 4:35:21, time: 0.826, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1409, decode.acc_seg: 50.9353, loss: 1.1409
2021-08-13 22:05:23,085 - mmseg - INFO - Iter [44300/160000]	lr: 7.495e-03, eta: 1 day, 4:34:29, time: 0.834, data_time: 0.011, memory: 4319, decode.loss_seg: 1.2328, decode.acc_seg: 50.9005, loss: 1.2328
2021-08-13 22:06:04,082 - mmseg - INFO - Iter [44350/160000]	lr: 7.492e-03, eta: 1 day, 4:33:36, time: 0.820, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1504, decode.acc_seg: 51.1877, loss: 1.1504
2021-08-13 22:06:45,328 - mmseg - INFO - Iter [44400/160000]	lr: 7.489e-03, eta: 1 day, 4:32:43, time: 0.825, data_time: 0.010, memory: 4319, decode.loss_seg: 1.1777, decode.acc_seg: 50.4323, loss: 1.1777
2021-08-13 22:07:25,662 - mmseg - INFO - Iter [44450/160000]	lr: 7.486e-03, eta: 1 day, 4:31:48, time: 0.807, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1533, decode.acc_seg: 50.6107, loss: 1.1533
2021-08-13 22:08:06,084 - mmseg - INFO - Iter [44500/160000]	lr: 7.483e-03, eta: 1 day, 4:30:53, time: 0.808, data_time: 0.010, memory: 4319, decode.loss_seg: 1.1588, decode.acc_seg: 51.1589, loss: 1.1588
2021-08-13 22:08:47,504 - mmseg - INFO - Iter [44550/160000]	lr: 7.480e-03, eta: 1 day, 4:30:01, time: 0.828, data_time: 0.010, memory: 4319, decode.loss_seg: 1.1088, decode.acc_seg: 51.7716, loss: 1.1088
2021-08-13 22:09:28,039 - mmseg - INFO - Iter [44600/160000]	lr: 7.478e-03, eta: 1 day, 4:29:06, time: 0.810, data_time: 0.010, memory: 4319, decode.loss_seg: 1.1661, decode.acc_seg: 50.4590, loss: 1.1661
2021-08-13 22:10:08,998 - mmseg - INFO - Iter [44650/160000]	lr: 7.475e-03, eta: 1 day, 4:28:13, time: 0.819, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1740, decode.acc_seg: 50.8076, loss: 1.1740
2021-08-13 22:10:50,592 - mmseg - INFO - Iter [44700/160000]	lr: 7.472e-03, eta: 1 day, 4:27:21, time: 0.832, data_time: 0.010, memory: 4319, decode.loss_seg: 1.1571, decode.acc_seg: 51.9443, loss: 1.1571
2021-08-13 22:11:31,809 - mmseg - INFO - Iter [44750/160000]	lr: 7.469e-03, eta: 1 day, 4:26:28, time: 0.824, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1913, decode.acc_seg: 50.6812, loss: 1.1913
2021-08-13 22:12:13,195 - mmseg - INFO - Iter [44800/160000]	lr: 7.466e-03, eta: 1 day, 4:25:36, time: 0.828, data_time: 0.010, memory: 4319, decode.loss_seg: 1.1574, decode.acc_seg: 50.9848, loss: 1.1574
2021-08-13 22:13:29,334 - mmseg - INFO - Iter [44850/160000]	lr: 7.463e-03, eta: 1 day, 4:26:13, time: 1.523, data_time: 0.706, memory: 4319, decode.loss_seg: 1.1254, decode.acc_seg: 51.1607, loss: 1.1254
2021-08-13 22:14:10,717 - mmseg - INFO - Iter [44900/160000]	lr: 7.460e-03, eta: 1 day, 4:25:21, time: 0.827, data_time: 0.012, memory: 4319, decode.loss_seg: 1.1445, decode.acc_seg: 51.4417, loss: 1.1445
2021-08-13 22:14:52,185 - mmseg - INFO - Iter [44950/160000]	lr: 7.457e-03, eta: 1 day, 4:24:29, time: 0.830, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1475, decode.acc_seg: 51.4506, loss: 1.1475
2021-08-13 22:15:33,091 - mmseg - INFO - Exp name: fcn_litehr18-without-head_512x512_160k_ade20k.py
2021-08-13 22:15:33,092 - mmseg - INFO - Iter [45000/160000]	lr: 7.455e-03, eta: 1 day, 4:23:35, time: 0.818, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1460, decode.acc_seg: 51.2378, loss: 1.1460
2021-08-13 22:16:13,980 - mmseg - INFO - Iter [45050/160000]	lr: 7.452e-03, eta: 1 day, 4:22:42, time: 0.818, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1471, decode.acc_seg: 50.0017, loss: 1.1471
2021-08-13 22:16:55,243 - mmseg - INFO - Iter [45100/160000]	lr: 7.449e-03, eta: 1 day, 4:21:49, time: 0.825, data_time: 0.010, memory: 4319, decode.loss_seg: 1.1484, decode.acc_seg: 50.6039, loss: 1.1484
2021-08-13 22:17:35,648 - mmseg - INFO - Iter [45150/160000]	lr: 7.446e-03, eta: 1 day, 4:20:55, time: 0.808, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1334, decode.acc_seg: 51.0787, loss: 1.1334
2021-08-13 22:18:16,488 - mmseg - INFO - Iter [45200/160000]	lr: 7.443e-03, eta: 1 day, 4:20:01, time: 0.816, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1514, decode.acc_seg: 50.3768, loss: 1.1514
2021-08-13 22:18:57,077 - mmseg - INFO - Iter [45250/160000]	lr: 7.440e-03, eta: 1 day, 4:19:07, time: 0.812, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1933, decode.acc_seg: 50.2455, loss: 1.1933
2021-08-13 22:19:38,543 - mmseg - INFO - Iter [45300/160000]	lr: 7.437e-03, eta: 1 day, 4:18:15, time: 0.829, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1735, decode.acc_seg: 51.0031, loss: 1.1735
2021-08-13 22:20:18,835 - mmseg - INFO - Iter [45350/160000]	lr: 7.434e-03, eta: 1 day, 4:17:20, time: 0.806, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1731, decode.acc_seg: 49.8462, loss: 1.1731
2021-08-13 22:21:00,485 - mmseg - INFO - Iter [45400/160000]	lr: 7.432e-03, eta: 1 day, 4:16:29, time: 0.833, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1662, decode.acc_seg: 51.5401, loss: 1.1662
2021-08-13 22:22:17,590 - mmseg - INFO - Iter [45450/160000]	lr: 7.429e-03, eta: 1 day, 4:17:07, time: 1.542, data_time: 0.713, memory: 4319, decode.loss_seg: 1.1778, decode.acc_seg: 51.1117, loss: 1.1778
2021-08-13 22:22:59,088 - mmseg - INFO - Iter [45500/160000]	lr: 7.426e-03, eta: 1 day, 4:16:15, time: 0.830, data_time: 0.012, memory: 4319, decode.loss_seg: 1.1070, decode.acc_seg: 51.2207, loss: 1.1070
2021-08-13 22:23:40,158 - mmseg - INFO - Iter [45550/160000]	lr: 7.423e-03, eta: 1 day, 4:15:22, time: 0.821, data_time: 0.010, memory: 4319, decode.loss_seg: 1.1383, decode.acc_seg: 51.6641, loss: 1.1383
2021-08-13 22:24:21,999 - mmseg - INFO - Iter [45600/160000]	lr: 7.420e-03, eta: 1 day, 4:14:31, time: 0.837, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1670, decode.acc_seg: 51.0176, loss: 1.1670
2021-08-13 22:25:03,680 - mmseg - INFO - Iter [45650/160000]	lr: 7.417e-03, eta: 1 day, 4:13:40, time: 0.834, data_time: 0.010, memory: 4319, decode.loss_seg: 1.1395, decode.acc_seg: 51.1873, loss: 1.1395
2021-08-13 22:25:44,602 - mmseg - INFO - Iter [45700/160000]	lr: 7.414e-03, eta: 1 day, 4:12:46, time: 0.818, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1622, decode.acc_seg: 51.0256, loss: 1.1622
2021-08-13 22:26:25,827 - mmseg - INFO - Iter [45750/160000]	lr: 7.411e-03, eta: 1 day, 4:11:54, time: 0.824, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1918, decode.acc_seg: 50.3729, loss: 1.1918
2021-08-13 22:27:06,030 - mmseg - INFO - Iter [45800/160000]	lr: 7.409e-03, eta: 1 day, 4:10:59, time: 0.804, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1466, decode.acc_seg: 51.0021, loss: 1.1466
2021-08-13 22:27:47,428 - mmseg - INFO - Iter [45850/160000]	lr: 7.406e-03, eta: 1 day, 4:10:07, time: 0.828, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1873, decode.acc_seg: 50.4766, loss: 1.1873
2021-08-13 22:28:29,675 - mmseg - INFO - Iter [45900/160000]	lr: 7.403e-03, eta: 1 day, 4:09:17, time: 0.845, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1686, decode.acc_seg: 50.7962, loss: 1.1686
2021-08-13 22:29:10,960 - mmseg - INFO - Iter [45950/160000]	lr: 7.400e-03, eta: 1 day, 4:08:25, time: 0.826, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1305, decode.acc_seg: 51.4625, loss: 1.1305
2021-08-13 22:29:52,304 - mmseg - INFO - Exp name: fcn_litehr18-without-head_512x512_160k_ade20k.py
2021-08-13 22:29:52,305 - mmseg - INFO - Iter [46000/160000]	lr: 7.397e-03, eta: 1 day, 4:07:33, time: 0.826, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1811, decode.acc_seg: 51.3387, loss: 1.1811
2021-08-13 22:30:34,084 - mmseg - INFO - Iter [46050/160000]	lr: 7.394e-03, eta: 1 day, 4:06:42, time: 0.836, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1407, decode.acc_seg: 50.8165, loss: 1.1407
2021-08-13 22:31:51,463 - mmseg - INFO - Iter [46100/160000]	lr: 7.391e-03, eta: 1 day, 4:07:19, time: 1.548, data_time: 0.737, memory: 4319, decode.loss_seg: 1.1354, decode.acc_seg: 51.2004, loss: 1.1354
2021-08-13 22:32:33,444 - mmseg - INFO - Iter [46150/160000]	lr: 7.388e-03, eta: 1 day, 4:06:29, time: 0.840, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1452, decode.acc_seg: 51.2108, loss: 1.1452
2021-08-13 22:33:15,526 - mmseg - INFO - Iter [46200/160000]	lr: 7.385e-03, eta: 1 day, 4:05:38, time: 0.841, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1762, decode.acc_seg: 50.9490, loss: 1.1762
2021-08-13 22:33:56,478 - mmseg - INFO - Iter [46250/160000]	lr: 7.383e-03, eta: 1 day, 4:04:45, time: 0.820, data_time: 0.012, memory: 4319, decode.loss_seg: 1.1611, decode.acc_seg: 51.0490, loss: 1.1611
2021-08-13 22:34:38,067 - mmseg - INFO - Iter [46300/160000]	lr: 7.380e-03, eta: 1 day, 4:03:54, time: 0.832, data_time: 0.010, memory: 4319, decode.loss_seg: 1.1401, decode.acc_seg: 50.4899, loss: 1.1401
2021-08-13 22:35:19,874 - mmseg - INFO - Iter [46350/160000]	lr: 7.377e-03, eta: 1 day, 4:03:03, time: 0.836, data_time: 0.010, memory: 4319, decode.loss_seg: 1.1651, decode.acc_seg: 49.8086, loss: 1.1651
2021-08-13 22:36:01,392 - mmseg - INFO - Iter [46400/160000]	lr: 7.374e-03, eta: 1 day, 4:02:12, time: 0.830, data_time: 0.010, memory: 4319, decode.loss_seg: 1.1673, decode.acc_seg: 50.0269, loss: 1.1673
2021-08-13 22:36:43,981 - mmseg - INFO - Iter [46450/160000]	lr: 7.371e-03, eta: 1 day, 4:01:23, time: 0.852, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1458, decode.acc_seg: 51.5012, loss: 1.1458
2021-08-13 22:37:25,152 - mmseg - INFO - Iter [46500/160000]	lr: 7.368e-03, eta: 1 day, 4:00:30, time: 0.824, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1554, decode.acc_seg: 50.9222, loss: 1.1554
2021-08-13 22:38:05,701 - mmseg - INFO - Iter [46550/160000]	lr: 7.365e-03, eta: 1 day, 3:59:36, time: 0.810, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1287, decode.acc_seg: 51.6285, loss: 1.1287
2021-08-13 22:38:47,926 - mmseg - INFO - Iter [46600/160000]	lr: 7.362e-03, eta: 1 day, 3:58:47, time: 0.845, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1570, decode.acc_seg: 51.2496, loss: 1.1570
2021-08-13 22:39:30,278 - mmseg - INFO - Iter [46650/160000]	lr: 7.360e-03, eta: 1 day, 3:57:57, time: 0.847, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1576, decode.acc_seg: 51.5610, loss: 1.1576
2021-08-13 22:40:47,403 - mmseg - INFO - Iter [46700/160000]	lr: 7.357e-03, eta: 1 day, 3:58:32, time: 1.543, data_time: 0.707, memory: 4319, decode.loss_seg: 1.1765, decode.acc_seg: 50.9288, loss: 1.1765
2021-08-13 22:41:28,641 - mmseg - INFO - Iter [46750/160000]	lr: 7.354e-03, eta: 1 day, 3:57:40, time: 0.825, data_time: 0.012, memory: 4319, decode.loss_seg: 1.1426, decode.acc_seg: 51.3515, loss: 1.1426
2021-08-13 22:42:09,821 - mmseg - INFO - Iter [46800/160000]	lr: 7.351e-03, eta: 1 day, 3:56:48, time: 0.823, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1350, decode.acc_seg: 50.4436, loss: 1.1350
2021-08-13 22:42:51,959 - mmseg - INFO - Iter [46850/160000]	lr: 7.348e-03, eta: 1 day, 3:55:58, time: 0.843, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1011, decode.acc_seg: 51.3090, loss: 1.1011
2021-08-13 22:43:32,734 - mmseg - INFO - Iter [46900/160000]	lr: 7.345e-03, eta: 1 day, 3:55:04, time: 0.815, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1751, decode.acc_seg: 51.2146, loss: 1.1751
2021-08-13 22:44:13,965 - mmseg - INFO - Iter [46950/160000]	lr: 7.342e-03, eta: 1 day, 3:54:12, time: 0.825, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1530, decode.acc_seg: 52.1436, loss: 1.1530
2021-08-13 22:44:55,811 - mmseg - INFO - Exp name: fcn_litehr18-without-head_512x512_160k_ade20k.py
2021-08-13 22:44:55,813 - mmseg - INFO - Iter [47000/160000]	lr: 7.339e-03, eta: 1 day, 3:53:22, time: 0.837, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1342, decode.acc_seg: 51.6755, loss: 1.1342
2021-08-13 22:45:36,382 - mmseg - INFO - Iter [47050/160000]	lr: 7.336e-03, eta: 1 day, 3:52:28, time: 0.811, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1813, decode.acc_seg: 50.1513, loss: 1.1813
2021-08-13 22:46:19,045 - mmseg - INFO - Iter [47100/160000]	lr: 7.334e-03, eta: 1 day, 3:51:39, time: 0.853, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1259, decode.acc_seg: 50.8415, loss: 1.1259
2021-08-13 22:47:00,923 - mmseg - INFO - Iter [47150/160000]	lr: 7.331e-03, eta: 1 day, 3:50:49, time: 0.838, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1440, decode.acc_seg: 51.6887, loss: 1.1440
2021-08-13 22:47:42,626 - mmseg - INFO - Iter [47200/160000]	lr: 7.328e-03, eta: 1 day, 3:49:58, time: 0.834, data_time: 0.010, memory: 4319, decode.loss_seg: 1.1875, decode.acc_seg: 50.7046, loss: 1.1875
2021-08-13 22:48:23,657 - mmseg - INFO - Iter [47250/160000]	lr: 7.325e-03, eta: 1 day, 3:49:05, time: 0.820, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1653, decode.acc_seg: 50.5723, loss: 1.1653
2021-08-13 22:49:04,754 - mmseg - INFO - Iter [47300/160000]	lr: 7.322e-03, eta: 1 day, 3:48:13, time: 0.822, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1947, decode.acc_seg: 50.6036, loss: 1.1947
2021-08-13 22:50:21,387 - mmseg - INFO - Iter [47350/160000]	lr: 7.319e-03, eta: 1 day, 3:48:45, time: 1.532, data_time: 0.737, memory: 4319, decode.loss_seg: 1.1388, decode.acc_seg: 51.0537, loss: 1.1388
2021-08-13 22:51:01,327 - mmseg - INFO - Iter [47400/160000]	lr: 7.316e-03, eta: 1 day, 3:47:50, time: 0.799, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1399, decode.acc_seg: 50.1312, loss: 1.1399
2021-08-13 22:51:41,024 - mmseg - INFO - Iter [47450/160000]	lr: 7.313e-03, eta: 1 day, 3:46:55, time: 0.794, data_time: 0.010, memory: 4319, decode.loss_seg: 1.1508, decode.acc_seg: 50.5200, loss: 1.1508
2021-08-13 22:52:21,058 - mmseg - INFO - Iter [47500/160000]	lr: 7.311e-03, eta: 1 day, 3:46:00, time: 0.800, data_time: 0.010, memory: 4319, decode.loss_seg: 1.1571, decode.acc_seg: 51.1446, loss: 1.1571
2021-08-13 22:53:01,070 - mmseg - INFO - Iter [47550/160000]	lr: 7.308e-03, eta: 1 day, 3:45:05, time: 0.801, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1580, decode.acc_seg: 50.5955, loss: 1.1580
2021-08-13 22:53:40,412 - mmseg - INFO - Iter [47600/160000]	lr: 7.305e-03, eta: 1 day, 3:44:08, time: 0.787, data_time: 0.010, memory: 4319, decode.loss_seg: 1.1165, decode.acc_seg: 51.8732, loss: 1.1165
2021-08-13 22:54:21,437 - mmseg - INFO - Iter [47650/160000]	lr: 7.302e-03, eta: 1 day, 3:43:16, time: 0.820, data_time: 0.010, memory: 4319, decode.loss_seg: 1.1940, decode.acc_seg: 51.3129, loss: 1.1940
2021-08-13 22:55:03,055 - mmseg - INFO - Iter [47700/160000]	lr: 7.299e-03, eta: 1 day, 3:42:25, time: 0.833, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1234, decode.acc_seg: 52.8167, loss: 1.1234
2021-08-13 22:55:43,704 - mmseg - INFO - Iter [47750/160000]	lr: 7.296e-03, eta: 1 day, 3:41:32, time: 0.813, data_time: 0.010, memory: 4319, decode.loss_seg: 1.1622, decode.acc_seg: 50.1320, loss: 1.1622
2021-08-13 22:56:25,152 - mmseg - INFO - Iter [47800/160000]	lr: 7.293e-03, eta: 1 day, 3:40:40, time: 0.829, data_time: 0.011, memory: 4319, decode.loss_seg: 1.1336, decode.acc_seg: 51.6693, loss: 1.1336
2021-08-13 22:57:06,350 - mmseg - INFO - Iter [47850/160000]	lr: 7.290e-03, eta: 1 day, 3:39:49, time: 0.824, data_time: 0.010, memory: 4319, decode.loss_seg: 1.1652, decode.acc_seg: 51.2395, loss: 1.1652
2021-08-13 22:57:46,859 - mmseg - INFO - Iter [47900/160000]	lr: 7.287e-03, eta: 1 day, 3:38:55, time: 0.810, data_time: 0.010, memory: 4319, decode.loss_seg: 1.1402, decode.acc_seg: 51.1937, loss: 1.1402
2021-08-13 22:58:27,248 - mmseg - INFO - Iter [47950/160000]	lr: 7.285e-03, eta: 1 day, 3:38:01, time: 0.808, data_time: 0.010, memory: 4319, decode.loss_seg: 1.1586, decode.acc_seg: 51.9495, loss: 1.1586
2021-08-13 22:59:43,141 - mmseg - INFO - Saving checkpoint at 48000 iterations
2021-08-13 22:59:43,368 - mmseg - INFO - Exp name: fcn_litehr18-without-head_512x512_160k_ade20k.py
2021-08-13 22:59:43,369 - mmseg - INFO - Iter [48000/160000]	lr: 7.282e-03, eta: 1 day, 3:38:31, time: 1.522, data_time: 0.725, memory: 4319, decode.loss_seg: 1.1111, decode.acc_seg: 51.2671, loss: 1.1111
