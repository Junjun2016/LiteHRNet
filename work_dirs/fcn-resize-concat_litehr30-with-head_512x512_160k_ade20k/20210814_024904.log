2021-08-14 02:49:04,225 - mmseg - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.7.6 (default, Jan  8 2020, 19:59:22) [GCC 7.3.0]
CUDA available: True
GPU 0,1,2,3,4,5,6,7: TITAN Xp
CUDA_HOME: /mnt/lustre/share/polaris/dep/cuda-9.0-cudnn7.6.5
NVCC: Cuda compilation tools, release 9.0, V9.0.176
GCC: gcc (GCC) 5.4.0
PyTorch: 1.5.0
PyTorch compiling details: PyTorch built with:
  - GCC 5.4
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.1 Product Build 20200208 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v0.21.1 (Git Hash 912ce228837d1ce28e1a61806118835de03f5751)
  - OpenMP 201307 (a.k.a. OpenMP 4.0)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 9.0
  - NVCC architecture flags: -gencode;arch=compute_52,code=sm_52;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_70,code=compute_70
  - CuDNN 7.6.5
  - Magma 2.5.0
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_INTERNAL_THREADPOOL_IMPL -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=ON, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

TorchVision: 0.6.0
OpenCV: 4.2.0
MMCV: 1.3.11
MMCV Compiler: n/a
MMCV CUDA Compiler: n/a
MMSegmentation: 0.16.0+2bb6f37
------------------------------------------------------------

2021-08-14 02:49:04,226 - mmseg - INFO - Distributed training: True
2021-08-14 02:49:04,617 - mmseg - INFO - Config:
norm_cfg = dict(type='SyncBN', requires_grad=True)
model = dict(
    type='EncoderDecoder',
    backbone=dict(
        type='LiteHRNet',
        norm_cfg=dict(type='SyncBN', requires_grad=True),
        norm_eval=False,
        extra=dict(
            stem=dict(stem_channels=32, out_channels=32, expand_ratio=1),
            num_stages=3,
            stages_spec=dict(
                num_modules=(3, 8, 3),
                num_branches=(2, 3, 4),
                num_blocks=(2, 2, 2),
                module_type=('LITE', 'LITE', 'LITE'),
                with_fuse=(True, True, True),
                reduce_ratios=(8, 8, 8),
                num_channels=((40, 80), (40, 80, 160), (40, 80, 160, 320))),
            with_head=True)),
    decode_head=dict(
        type='FCNHead',
        in_channels=[40, 40, 80, 160],
        in_index=(0, 1, 2, 3),
        channels=320,
        input_transform='resize_concat',
        kernel_size=1,
        num_convs=1,
        concat_input=False,
        dropout_ratio=-1,
        num_classes=150,
        norm_cfg=dict(type='SyncBN', requires_grad=True),
        align_corners=False,
        loss_decode=dict(
            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0)),
    train_cfg=dict(),
    test_cfg=dict(mode='whole'))
dataset_type = 'ADE20KDataset'
data_root = 'data/ade/ADEChallengeData2016'
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
crop_size = (512, 512)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations', reduce_zero_label=True),
    dict(type='Resize', img_scale=(2048, 512), ratio_range=(0.5, 2.0)),
    dict(type='RandomCrop', crop_size=(512, 512), cat_max_ratio=0.75),
    dict(type='RandomFlip', prob=0.5),
    dict(type='PhotoMetricDistortion'),
    dict(
        type='Normalize',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='Pad', size=(512, 512), pad_val=0, seg_pad_val=255),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_semantic_seg'])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(2048, 512),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
data = dict(
    samples_per_gpu=4,
    workers_per_gpu=4,
    train=dict(
        type='ADE20KDataset',
        data_root='data/ade/ADEChallengeData2016',
        img_dir='images/training',
        ann_dir='annotations/training',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations', reduce_zero_label=True),
            dict(type='Resize', img_scale=(2048, 512), ratio_range=(0.5, 2.0)),
            dict(type='RandomCrop', crop_size=(512, 512), cat_max_ratio=0.75),
            dict(type='RandomFlip', prob=0.5),
            dict(type='PhotoMetricDistortion'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='Pad', size=(512, 512), pad_val=0, seg_pad_val=255),
            dict(type='DefaultFormatBundle'),
            dict(type='Collect', keys=['img', 'gt_semantic_seg'])
        ]),
    val=dict(
        type='ADE20KDataset',
        data_root='data/ade/ADEChallengeData2016',
        img_dir='images/validation',
        ann_dir='annotations/validation',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(2048, 512),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]),
    test=dict(
        type='ADE20KDataset',
        data_root='data/ade/ADEChallengeData2016',
        img_dir='images/validation',
        ann_dir='annotations/validation',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(2048, 512),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]))
log_config = dict(
    interval=50, hooks=[dict(type='TextLoggerHook', by_epoch=False)])
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]
cudnn_benchmark = True
optimizer = dict(type='SGD', lr=0.01, momentum=0.9, weight_decay=0.0005)
optimizer_config = dict()
lr_config = dict(policy='poly', power=0.9, min_lr=0.0001, by_epoch=False)
runner = dict(type='IterBasedRunner', max_iters=160000)
checkpoint_config = dict(by_epoch=False, interval=16000)
evaluation = dict(interval=16000, metric='mIoU')
work_dir = './work_dirs/fcn-resize-concat_litehr30-with-head_512x512_160k_ade20k'
gpu_ids = range(0, 1)

2021-08-14 02:49:04,618 - mmseg - INFO - Set random seed to 0, deterministic: False
2021-08-14 02:49:05,207 - mmseg - INFO - initialize LiteHRNet with init_cfg [{'type': 'Normal', 'std': 0.001, 'layer': 'Conv2d'}, {'type': 'Constant', 'val': 1, 'layer': ['_BatchNorm', 'GroupNorm']}]
2021-08-14 02:49:05,783 - mmseg - INFO - initialize FCNHead with init_cfg {'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
Name of parameter - Initialization information

backbone.stem.conv1.conv.weight - torch.Size([32, 3, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.stem.conv1.bn.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stem.conv1.bn.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stem.branch1.0.conv.weight - torch.Size([16, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stem.branch1.0.bn.weight - torch.Size([16]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stem.branch1.0.bn.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stem.branch1.1.conv.weight - torch.Size([16, 16, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stem.branch1.1.bn.weight - torch.Size([16]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stem.branch1.1.bn.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stem.expand_conv.conv.weight - torch.Size([32, 16, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.stem.expand_conv.bn.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stem.expand_conv.bn.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stem.depthwise_conv.conv.weight - torch.Size([32, 1, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.stem.depthwise_conv.bn.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stem.depthwise_conv.bn.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stem.linear_conv.conv.weight - torch.Size([16, 32, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.stem.linear_conv.bn.weight - torch.Size([16]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stem.linear_conv.bn.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.transition0.0.0.weight - torch.Size([32, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.transition0.0.1.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.transition0.0.1.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.transition0.0.2.weight - torch.Size([40, 32, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.transition0.0.3.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.transition0.0.3.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.transition0.1.0.0.weight - torch.Size([32, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.transition0.1.0.1.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.transition0.1.0.1.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.transition0.1.0.2.weight - torch.Size([80, 32, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.transition0.1.0.3.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.transition0.1.0.3.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.0.cross_resolution_weighting.conv1.conv.weight - torch.Size([7, 60, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.layers.0.cross_resolution_weighting.conv1.bn.weight - torch.Size([7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.0.cross_resolution_weighting.conv1.bn.bias - torch.Size([7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.0.cross_resolution_weighting.conv2.conv.weight - torch.Size([60, 7, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.layers.0.cross_resolution_weighting.conv2.bn.weight - torch.Size([60]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.0.cross_resolution_weighting.conv2.bn.bias - torch.Size([60]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.0.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.layers.0.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.0.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.0.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.layers.0.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.0.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.0.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.layers.0.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.0.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.layers.0.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.0.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.layers.0.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.0.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.layers.0.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.1.cross_resolution_weighting.conv1.conv.weight - torch.Size([7, 60, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.layers.1.cross_resolution_weighting.conv1.bn.weight - torch.Size([7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.1.cross_resolution_weighting.conv1.bn.bias - torch.Size([7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.1.cross_resolution_weighting.conv2.conv.weight - torch.Size([60, 7, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.layers.1.cross_resolution_weighting.conv2.bn.weight - torch.Size([60]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.1.cross_resolution_weighting.conv2.bn.bias - torch.Size([60]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.1.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.layers.1.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.1.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.1.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.layers.1.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.1.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.1.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.layers.1.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.1.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.layers.1.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.1.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.layers.1.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.1.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.layers.1.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.fuse_layers.0.1.0.weight - torch.Size([40, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.fuse_layers.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.fuse_layers.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.fuse_layers.1.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.fuse_layers.1.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.fuse_layers.1.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.fuse_layers.1.0.0.2.weight - torch.Size([80, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.fuse_layers.1.0.0.3.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.fuse_layers.1.0.0.3.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.0.cross_resolution_weighting.conv1.conv.weight - torch.Size([7, 60, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.layers.0.cross_resolution_weighting.conv1.bn.weight - torch.Size([7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.0.cross_resolution_weighting.conv1.bn.bias - torch.Size([7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.0.cross_resolution_weighting.conv2.conv.weight - torch.Size([60, 7, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.layers.0.cross_resolution_weighting.conv2.bn.weight - torch.Size([60]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.0.cross_resolution_weighting.conv2.bn.bias - torch.Size([60]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.0.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.layers.0.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.0.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.0.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.layers.0.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.0.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.0.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.layers.0.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.0.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.layers.0.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.0.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.layers.0.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.0.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.layers.0.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.1.cross_resolution_weighting.conv1.conv.weight - torch.Size([7, 60, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.layers.1.cross_resolution_weighting.conv1.bn.weight - torch.Size([7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.1.cross_resolution_weighting.conv1.bn.bias - torch.Size([7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.1.cross_resolution_weighting.conv2.conv.weight - torch.Size([60, 7, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.layers.1.cross_resolution_weighting.conv2.bn.weight - torch.Size([60]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.1.cross_resolution_weighting.conv2.bn.bias - torch.Size([60]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.1.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.layers.1.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.1.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.1.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.layers.1.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.1.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.1.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.layers.1.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.1.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.layers.1.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.1.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.layers.1.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.1.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.layers.1.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.fuse_layers.0.1.0.weight - torch.Size([40, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.fuse_layers.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.fuse_layers.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.fuse_layers.1.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.fuse_layers.1.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.fuse_layers.1.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.fuse_layers.1.0.0.2.weight - torch.Size([80, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.fuse_layers.1.0.0.3.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.fuse_layers.1.0.0.3.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.0.cross_resolution_weighting.conv1.conv.weight - torch.Size([7, 60, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.2.layers.0.cross_resolution_weighting.conv1.bn.weight - torch.Size([7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.0.cross_resolution_weighting.conv1.bn.bias - torch.Size([7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.0.cross_resolution_weighting.conv2.conv.weight - torch.Size([60, 7, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.2.layers.0.cross_resolution_weighting.conv2.bn.weight - torch.Size([60]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.0.cross_resolution_weighting.conv2.bn.bias - torch.Size([60]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.0.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.2.layers.0.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.0.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.0.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.2.layers.0.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.0.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.0.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.2.layers.0.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.0.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.2.layers.0.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.0.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.2.layers.0.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.0.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.2.layers.0.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.1.cross_resolution_weighting.conv1.conv.weight - torch.Size([7, 60, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.2.layers.1.cross_resolution_weighting.conv1.bn.weight - torch.Size([7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.1.cross_resolution_weighting.conv1.bn.bias - torch.Size([7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.1.cross_resolution_weighting.conv2.conv.weight - torch.Size([60, 7, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.2.layers.1.cross_resolution_weighting.conv2.bn.weight - torch.Size([60]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.1.cross_resolution_weighting.conv2.bn.bias - torch.Size([60]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.1.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.2.layers.1.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.1.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.1.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.2.layers.1.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.1.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.1.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.2.layers.1.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.1.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.2.layers.1.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.1.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.2.layers.1.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.1.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.2.layers.1.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.fuse_layers.0.1.0.weight - torch.Size([40, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.2.fuse_layers.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.fuse_layers.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.fuse_layers.1.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.2.fuse_layers.1.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.fuse_layers.1.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.fuse_layers.1.0.0.2.weight - torch.Size([80, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.2.fuse_layers.1.0.0.3.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.fuse_layers.1.0.0.3.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.transition1.2.0.0.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.transition1.2.0.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.transition1.2.0.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.transition1.2.0.2.weight - torch.Size([160, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.transition1.2.0.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.transition1.2.0.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.0.cross_resolution_weighting.conv1.conv.weight - torch.Size([17, 140, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.0.cross_resolution_weighting.conv1.bn.weight - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.0.cross_resolution_weighting.conv1.bn.bias - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.0.cross_resolution_weighting.conv2.conv.weight - torch.Size([140, 17, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.0.cross_resolution_weighting.conv2.bn.weight - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.0.cross_resolution_weighting.conv2.bn.bias - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.0.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.0.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.0.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.0.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.0.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.0.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.0.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.0.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.0.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.0.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.0.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.0.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.0.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.0.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.0.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.0.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.0.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.0.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.0.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.0.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.0.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.1.cross_resolution_weighting.conv1.conv.weight - torch.Size([17, 140, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.1.cross_resolution_weighting.conv1.bn.weight - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.1.cross_resolution_weighting.conv1.bn.bias - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.1.cross_resolution_weighting.conv2.conv.weight - torch.Size([140, 17, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.1.cross_resolution_weighting.conv2.bn.weight - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.1.cross_resolution_weighting.conv2.bn.bias - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.1.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.1.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.1.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.1.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.1.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.1.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.1.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.1.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.1.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.1.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.1.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.1.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.1.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.1.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.1.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.1.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.1.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.1.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.1.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.1.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.1.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.0.1.0.weight - torch.Size([40, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.fuse_layers.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.0.2.0.weight - torch.Size([40, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.fuse_layers.0.2.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.0.2.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.1.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.fuse_layers.1.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.1.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.1.0.0.2.weight - torch.Size([80, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.fuse_layers.1.0.0.3.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.1.0.0.3.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.1.2.0.weight - torch.Size([80, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.fuse_layers.1.2.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.1.2.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.2.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.fuse_layers.2.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.2.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.2.0.0.2.weight - torch.Size([40, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.fuse_layers.2.0.0.3.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.2.0.0.3.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.2.0.1.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.fuse_layers.2.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.2.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.2.0.1.2.weight - torch.Size([160, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.fuse_layers.2.0.1.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.2.0.1.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.2.1.0.0.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.fuse_layers.2.1.0.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.2.1.0.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.2.1.0.2.weight - torch.Size([160, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.fuse_layers.2.1.0.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.2.1.0.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.0.cross_resolution_weighting.conv1.conv.weight - torch.Size([17, 140, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.0.cross_resolution_weighting.conv1.bn.weight - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.0.cross_resolution_weighting.conv1.bn.bias - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.0.cross_resolution_weighting.conv2.conv.weight - torch.Size([140, 17, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.0.cross_resolution_weighting.conv2.bn.weight - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.0.cross_resolution_weighting.conv2.bn.bias - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.0.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.0.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.0.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.0.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.0.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.0.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.0.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.0.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.0.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.0.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.0.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.0.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.0.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.0.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.0.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.0.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.0.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.0.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.0.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.0.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.0.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.1.cross_resolution_weighting.conv1.conv.weight - torch.Size([17, 140, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.1.cross_resolution_weighting.conv1.bn.weight - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.1.cross_resolution_weighting.conv1.bn.bias - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.1.cross_resolution_weighting.conv2.conv.weight - torch.Size([140, 17, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.1.cross_resolution_weighting.conv2.bn.weight - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.1.cross_resolution_weighting.conv2.bn.bias - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.1.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.1.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.1.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.1.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.1.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.1.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.1.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.1.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.1.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.1.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.1.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.1.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.1.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.1.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.1.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.1.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.1.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.1.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.1.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.1.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.1.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.0.1.0.weight - torch.Size([40, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.fuse_layers.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.0.2.0.weight - torch.Size([40, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.fuse_layers.0.2.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.0.2.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.1.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.fuse_layers.1.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.1.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.1.0.0.2.weight - torch.Size([80, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.fuse_layers.1.0.0.3.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.1.0.0.3.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.1.2.0.weight - torch.Size([80, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.fuse_layers.1.2.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.1.2.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.2.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.fuse_layers.2.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.2.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.2.0.0.2.weight - torch.Size([40, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.fuse_layers.2.0.0.3.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.2.0.0.3.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.2.0.1.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.fuse_layers.2.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.2.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.2.0.1.2.weight - torch.Size([160, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.fuse_layers.2.0.1.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.2.0.1.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.2.1.0.0.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.fuse_layers.2.1.0.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.2.1.0.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.2.1.0.2.weight - torch.Size([160, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.fuse_layers.2.1.0.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.2.1.0.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.0.cross_resolution_weighting.conv1.conv.weight - torch.Size([17, 140, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.0.cross_resolution_weighting.conv1.bn.weight - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.0.cross_resolution_weighting.conv1.bn.bias - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.0.cross_resolution_weighting.conv2.conv.weight - torch.Size([140, 17, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.0.cross_resolution_weighting.conv2.bn.weight - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.0.cross_resolution_weighting.conv2.bn.bias - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.0.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.0.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.0.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.0.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.0.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.0.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.0.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.0.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.0.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.0.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.0.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.0.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.0.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.0.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.0.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.0.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.0.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.0.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.0.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.0.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.0.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.1.cross_resolution_weighting.conv1.conv.weight - torch.Size([17, 140, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.1.cross_resolution_weighting.conv1.bn.weight - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.1.cross_resolution_weighting.conv1.bn.bias - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.1.cross_resolution_weighting.conv2.conv.weight - torch.Size([140, 17, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.1.cross_resolution_weighting.conv2.bn.weight - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.1.cross_resolution_weighting.conv2.bn.bias - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.1.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.1.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.1.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.1.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.1.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.1.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.1.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.1.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.1.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.1.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.1.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.1.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.1.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.1.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.1.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.1.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.1.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.1.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.1.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.1.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.1.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.0.1.0.weight - torch.Size([40, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.fuse_layers.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.0.2.0.weight - torch.Size([40, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.fuse_layers.0.2.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.0.2.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.1.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.fuse_layers.1.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.1.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.1.0.0.2.weight - torch.Size([80, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.fuse_layers.1.0.0.3.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.1.0.0.3.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.1.2.0.weight - torch.Size([80, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.fuse_layers.1.2.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.1.2.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.2.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.fuse_layers.2.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.2.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.2.0.0.2.weight - torch.Size([40, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.fuse_layers.2.0.0.3.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.2.0.0.3.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.2.0.1.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.fuse_layers.2.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.2.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.2.0.1.2.weight - torch.Size([160, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.fuse_layers.2.0.1.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.2.0.1.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.2.1.0.0.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.fuse_layers.2.1.0.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.2.1.0.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.2.1.0.2.weight - torch.Size([160, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.fuse_layers.2.1.0.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.2.1.0.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.0.cross_resolution_weighting.conv1.conv.weight - torch.Size([17, 140, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.0.cross_resolution_weighting.conv1.bn.weight - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.0.cross_resolution_weighting.conv1.bn.bias - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.0.cross_resolution_weighting.conv2.conv.weight - torch.Size([140, 17, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.0.cross_resolution_weighting.conv2.bn.weight - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.0.cross_resolution_weighting.conv2.bn.bias - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.0.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.0.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.0.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.0.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.0.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.0.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.0.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.0.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.0.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.0.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.0.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.0.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.0.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.0.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.0.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.0.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.0.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.0.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.0.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.0.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.0.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.1.cross_resolution_weighting.conv1.conv.weight - torch.Size([17, 140, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.1.cross_resolution_weighting.conv1.bn.weight - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.1.cross_resolution_weighting.conv1.bn.bias - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.1.cross_resolution_weighting.conv2.conv.weight - torch.Size([140, 17, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.1.cross_resolution_weighting.conv2.bn.weight - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.1.cross_resolution_weighting.conv2.bn.bias - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.1.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.1.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.1.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.1.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.1.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.1.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.1.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.1.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.1.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.1.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.1.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.1.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.1.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.1.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.1.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.1.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.1.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.1.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.1.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.1.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.1.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.0.1.0.weight - torch.Size([40, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.fuse_layers.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.0.2.0.weight - torch.Size([40, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.fuse_layers.0.2.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.0.2.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.1.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.fuse_layers.1.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.1.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.1.0.0.2.weight - torch.Size([80, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.fuse_layers.1.0.0.3.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.1.0.0.3.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.1.2.0.weight - torch.Size([80, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.fuse_layers.1.2.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.1.2.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.2.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.fuse_layers.2.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.2.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.2.0.0.2.weight - torch.Size([40, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.fuse_layers.2.0.0.3.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.2.0.0.3.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.2.0.1.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.fuse_layers.2.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.2.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.2.0.1.2.weight - torch.Size([160, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.fuse_layers.2.0.1.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.2.0.1.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.2.1.0.0.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.fuse_layers.2.1.0.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.2.1.0.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.2.1.0.2.weight - torch.Size([160, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.fuse_layers.2.1.0.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.2.1.0.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.0.cross_resolution_weighting.conv1.conv.weight - torch.Size([17, 140, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.layers.0.cross_resolution_weighting.conv1.bn.weight - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.0.cross_resolution_weighting.conv1.bn.bias - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.0.cross_resolution_weighting.conv2.conv.weight - torch.Size([140, 17, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.layers.0.cross_resolution_weighting.conv2.bn.weight - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.0.cross_resolution_weighting.conv2.bn.bias - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.0.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.layers.0.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.0.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.0.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.layers.0.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.0.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.0.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.layers.0.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.0.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.0.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.layers.0.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.0.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.layers.0.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.0.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.layers.0.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.0.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.layers.0.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.0.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.layers.0.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.0.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.layers.0.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.1.cross_resolution_weighting.conv1.conv.weight - torch.Size([17, 140, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.layers.1.cross_resolution_weighting.conv1.bn.weight - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.1.cross_resolution_weighting.conv1.bn.bias - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.1.cross_resolution_weighting.conv2.conv.weight - torch.Size([140, 17, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.layers.1.cross_resolution_weighting.conv2.bn.weight - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.1.cross_resolution_weighting.conv2.bn.bias - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.1.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.layers.1.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.1.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.1.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.layers.1.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.1.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.1.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.layers.1.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.1.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.1.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.layers.1.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.1.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.layers.1.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.1.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.layers.1.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.1.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.layers.1.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.1.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.layers.1.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.1.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.layers.1.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.fuse_layers.0.1.0.weight - torch.Size([40, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.fuse_layers.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.fuse_layers.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.fuse_layers.0.2.0.weight - torch.Size([40, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.fuse_layers.0.2.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.fuse_layers.0.2.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.fuse_layers.1.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.fuse_layers.1.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.fuse_layers.1.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.fuse_layers.1.0.0.2.weight - torch.Size([80, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.fuse_layers.1.0.0.3.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.fuse_layers.1.0.0.3.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.fuse_layers.1.2.0.weight - torch.Size([80, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.fuse_layers.1.2.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.fuse_layers.1.2.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.fuse_layers.2.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.fuse_layers.2.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.fuse_layers.2.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.fuse_layers.2.0.0.2.weight - torch.Size([40, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.fuse_layers.2.0.0.3.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.fuse_layers.2.0.0.3.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.fuse_layers.2.0.1.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.fuse_layers.2.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.fuse_layers.2.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.fuse_layers.2.0.1.2.weight - torch.Size([160, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.fuse_layers.2.0.1.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.fuse_layers.2.0.1.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.fuse_layers.2.1.0.0.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.fuse_layers.2.1.0.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.fuse_layers.2.1.0.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.fuse_layers.2.1.0.2.weight - torch.Size([160, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.fuse_layers.2.1.0.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.fuse_layers.2.1.0.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.0.cross_resolution_weighting.conv1.conv.weight - torch.Size([17, 140, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.layers.0.cross_resolution_weighting.conv1.bn.weight - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.0.cross_resolution_weighting.conv1.bn.bias - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.0.cross_resolution_weighting.conv2.conv.weight - torch.Size([140, 17, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.layers.0.cross_resolution_weighting.conv2.bn.weight - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.0.cross_resolution_weighting.conv2.bn.bias - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.0.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.layers.0.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.0.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.0.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.layers.0.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.0.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.0.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.layers.0.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.0.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.0.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.layers.0.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.0.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.layers.0.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.0.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.layers.0.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.0.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.layers.0.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.0.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.layers.0.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.0.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.layers.0.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.1.cross_resolution_weighting.conv1.conv.weight - torch.Size([17, 140, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.layers.1.cross_resolution_weighting.conv1.bn.weight - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.1.cross_resolution_weighting.conv1.bn.bias - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.1.cross_resolution_weighting.conv2.conv.weight - torch.Size([140, 17, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.layers.1.cross_resolution_weighting.conv2.bn.weight - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.1.cross_resolution_weighting.conv2.bn.bias - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.1.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.layers.1.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.1.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.1.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.layers.1.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.1.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.1.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.layers.1.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.1.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.1.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.layers.1.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.1.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.layers.1.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.1.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.layers.1.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.1.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.layers.1.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.1.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.layers.1.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.1.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.layers.1.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.fuse_layers.0.1.0.weight - torch.Size([40, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.fuse_layers.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.fuse_layers.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.fuse_layers.0.2.0.weight - torch.Size([40, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.fuse_layers.0.2.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.fuse_layers.0.2.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.fuse_layers.1.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.fuse_layers.1.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.fuse_layers.1.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.fuse_layers.1.0.0.2.weight - torch.Size([80, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.fuse_layers.1.0.0.3.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.fuse_layers.1.0.0.3.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.fuse_layers.1.2.0.weight - torch.Size([80, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.fuse_layers.1.2.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.fuse_layers.1.2.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.fuse_layers.2.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.fuse_layers.2.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.fuse_layers.2.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.fuse_layers.2.0.0.2.weight - torch.Size([40, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.fuse_layers.2.0.0.3.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.fuse_layers.2.0.0.3.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.fuse_layers.2.0.1.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.fuse_layers.2.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.fuse_layers.2.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.fuse_layers.2.0.1.2.weight - torch.Size([160, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.fuse_layers.2.0.1.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.fuse_layers.2.0.1.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.fuse_layers.2.1.0.0.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.fuse_layers.2.1.0.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.fuse_layers.2.1.0.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.fuse_layers.2.1.0.2.weight - torch.Size([160, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.fuse_layers.2.1.0.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.fuse_layers.2.1.0.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.0.cross_resolution_weighting.conv1.conv.weight - torch.Size([17, 140, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.layers.0.cross_resolution_weighting.conv1.bn.weight - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.0.cross_resolution_weighting.conv1.bn.bias - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.0.cross_resolution_weighting.conv2.conv.weight - torch.Size([140, 17, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.layers.0.cross_resolution_weighting.conv2.bn.weight - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.0.cross_resolution_weighting.conv2.bn.bias - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.0.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.layers.0.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.0.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.0.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.layers.0.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.0.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.0.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.layers.0.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.0.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.0.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.layers.0.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.0.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.layers.0.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.0.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.layers.0.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.0.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.layers.0.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.0.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.layers.0.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.0.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.layers.0.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.1.cross_resolution_weighting.conv1.conv.weight - torch.Size([17, 140, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.layers.1.cross_resolution_weighting.conv1.bn.weight - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.1.cross_resolution_weighting.conv1.bn.bias - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.1.cross_resolution_weighting.conv2.conv.weight - torch.Size([140, 17, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.layers.1.cross_resolution_weighting.conv2.bn.weight - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.1.cross_resolution_weighting.conv2.bn.bias - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.1.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.layers.1.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.1.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.1.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.layers.1.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.1.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.1.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.layers.1.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.1.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.1.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.layers.1.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.1.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.layers.1.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.1.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.layers.1.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.1.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.layers.1.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.1.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.layers.1.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.1.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.layers.1.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.fuse_layers.0.1.0.weight - torch.Size([40, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.fuse_layers.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.fuse_layers.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.fuse_layers.0.2.0.weight - torch.Size([40, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.fuse_layers.0.2.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.fuse_layers.0.2.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.fuse_layers.1.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.fuse_layers.1.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.fuse_layers.1.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.fuse_layers.1.0.0.2.weight - torch.Size([80, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.fuse_layers.1.0.0.3.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.fuse_layers.1.0.0.3.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.fuse_layers.1.2.0.weight - torch.Size([80, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.fuse_layers.1.2.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.fuse_layers.1.2.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.fuse_layers.2.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.fuse_layers.2.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.fuse_layers.2.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.fuse_layers.2.0.0.2.weight - torch.Size([40, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.fuse_layers.2.0.0.3.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.fuse_layers.2.0.0.3.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.fuse_layers.2.0.1.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.fuse_layers.2.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.fuse_layers.2.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.fuse_layers.2.0.1.2.weight - torch.Size([160, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.fuse_layers.2.0.1.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.fuse_layers.2.0.1.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.fuse_layers.2.1.0.0.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.fuse_layers.2.1.0.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.fuse_layers.2.1.0.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.fuse_layers.2.1.0.2.weight - torch.Size([160, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.fuse_layers.2.1.0.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.fuse_layers.2.1.0.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.0.cross_resolution_weighting.conv1.conv.weight - torch.Size([17, 140, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.layers.0.cross_resolution_weighting.conv1.bn.weight - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.0.cross_resolution_weighting.conv1.bn.bias - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.0.cross_resolution_weighting.conv2.conv.weight - torch.Size([140, 17, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.layers.0.cross_resolution_weighting.conv2.bn.weight - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.0.cross_resolution_weighting.conv2.bn.bias - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.0.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.layers.0.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.0.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.0.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.layers.0.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.0.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.0.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.layers.0.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.0.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.0.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.layers.0.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.0.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.layers.0.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.0.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.layers.0.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.0.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.layers.0.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.0.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.layers.0.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.0.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.layers.0.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.1.cross_resolution_weighting.conv1.conv.weight - torch.Size([17, 140, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.layers.1.cross_resolution_weighting.conv1.bn.weight - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.1.cross_resolution_weighting.conv1.bn.bias - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.1.cross_resolution_weighting.conv2.conv.weight - torch.Size([140, 17, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.layers.1.cross_resolution_weighting.conv2.bn.weight - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.1.cross_resolution_weighting.conv2.bn.bias - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.1.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.layers.1.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.1.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.1.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.layers.1.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.1.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.1.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.layers.1.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.1.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.1.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.layers.1.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.1.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.layers.1.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.1.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.layers.1.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.1.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.layers.1.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.1.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.layers.1.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.1.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.layers.1.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.fuse_layers.0.1.0.weight - torch.Size([40, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.fuse_layers.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.fuse_layers.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.fuse_layers.0.2.0.weight - torch.Size([40, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.fuse_layers.0.2.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.fuse_layers.0.2.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.fuse_layers.1.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.fuse_layers.1.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.fuse_layers.1.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.fuse_layers.1.0.0.2.weight - torch.Size([80, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.fuse_layers.1.0.0.3.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.fuse_layers.1.0.0.3.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.fuse_layers.1.2.0.weight - torch.Size([80, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.fuse_layers.1.2.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.fuse_layers.1.2.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.fuse_layers.2.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.fuse_layers.2.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.fuse_layers.2.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.fuse_layers.2.0.0.2.weight - torch.Size([40, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.fuse_layers.2.0.0.3.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.fuse_layers.2.0.0.3.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.fuse_layers.2.0.1.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.fuse_layers.2.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.fuse_layers.2.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.fuse_layers.2.0.1.2.weight - torch.Size([160, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.fuse_layers.2.0.1.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.fuse_layers.2.0.1.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.fuse_layers.2.1.0.0.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.fuse_layers.2.1.0.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.fuse_layers.2.1.0.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.fuse_layers.2.1.0.2.weight - torch.Size([160, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.fuse_layers.2.1.0.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.fuse_layers.2.1.0.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.transition2.3.0.0.weight - torch.Size([160, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.transition2.3.0.1.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.transition2.3.0.1.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.transition2.3.0.2.weight - torch.Size([320, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.transition2.3.0.3.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.transition2.3.0.3.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.cross_resolution_weighting.conv1.conv.weight - torch.Size([37, 300, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.0.cross_resolution_weighting.conv1.bn.weight - torch.Size([37]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.cross_resolution_weighting.conv1.bn.bias - torch.Size([37]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.cross_resolution_weighting.conv2.conv.weight - torch.Size([300, 37, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.0.cross_resolution_weighting.conv2.bn.weight - torch.Size([300]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.cross_resolution_weighting.conv2.bn.bias - torch.Size([300]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.0.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.0.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.0.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.depthwise_convs.3.conv.weight - torch.Size([160, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.0.depthwise_convs.3.bn.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.depthwise_convs.3.bn.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.0.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.0.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.0.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.0.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.0.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.0.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.spatial_weighting.3.conv1.conv.weight - torch.Size([40, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.0.spatial_weighting.3.conv1.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.spatial_weighting.3.conv2.conv.weight - torch.Size([160, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.0.spatial_weighting.3.conv2.conv.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.cross_resolution_weighting.conv1.conv.weight - torch.Size([37, 300, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.1.cross_resolution_weighting.conv1.bn.weight - torch.Size([37]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.cross_resolution_weighting.conv1.bn.bias - torch.Size([37]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.cross_resolution_weighting.conv2.conv.weight - torch.Size([300, 37, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.1.cross_resolution_weighting.conv2.bn.weight - torch.Size([300]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.cross_resolution_weighting.conv2.bn.bias - torch.Size([300]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.1.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.1.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.1.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.depthwise_convs.3.conv.weight - torch.Size([160, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.1.depthwise_convs.3.bn.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.depthwise_convs.3.bn.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.1.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.1.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.1.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.1.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.1.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.1.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.spatial_weighting.3.conv1.conv.weight - torch.Size([40, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.1.spatial_weighting.3.conv1.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.spatial_weighting.3.conv2.conv.weight - torch.Size([160, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.1.spatial_weighting.3.conv2.conv.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.0.1.0.weight - torch.Size([40, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.0.2.0.weight - torch.Size([40, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.0.2.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.0.2.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.0.3.0.weight - torch.Size([40, 320, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.0.3.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.0.3.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.1.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.1.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.1.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.1.0.0.2.weight - torch.Size([80, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.1.0.0.3.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.1.0.0.3.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.1.2.0.weight - torch.Size([80, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.1.2.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.1.2.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.1.3.0.weight - torch.Size([80, 320, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.1.3.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.1.3.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.2.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.2.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.2.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.2.0.0.2.weight - torch.Size([40, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.2.0.0.3.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.2.0.0.3.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.2.0.1.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.2.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.2.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.2.0.1.2.weight - torch.Size([160, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.2.0.1.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.2.0.1.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.2.1.0.0.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.2.1.0.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.2.1.0.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.2.1.0.2.weight - torch.Size([160, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.2.1.0.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.2.1.0.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.2.3.0.weight - torch.Size([160, 320, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.2.3.1.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.2.3.1.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.3.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.0.0.2.weight - torch.Size([40, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.3.0.0.3.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.0.0.3.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.0.1.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.3.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.0.1.2.weight - torch.Size([40, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.3.0.1.3.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.0.1.3.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.0.2.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.3.0.2.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.0.2.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.0.2.2.weight - torch.Size([320, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.3.0.2.3.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.0.2.3.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.1.0.0.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.3.1.0.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.1.0.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.1.0.2.weight - torch.Size([80, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.3.1.0.3.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.1.0.3.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.1.1.0.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.3.1.1.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.1.1.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.1.1.2.weight - torch.Size([320, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.3.1.1.3.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.1.1.3.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.2.0.0.weight - torch.Size([160, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.3.2.0.1.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.2.0.1.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.2.0.2.weight - torch.Size([320, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.3.2.0.3.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.2.0.3.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.cross_resolution_weighting.conv1.conv.weight - torch.Size([37, 300, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.0.cross_resolution_weighting.conv1.bn.weight - torch.Size([37]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.cross_resolution_weighting.conv1.bn.bias - torch.Size([37]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.cross_resolution_weighting.conv2.conv.weight - torch.Size([300, 37, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.0.cross_resolution_weighting.conv2.bn.weight - torch.Size([300]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.cross_resolution_weighting.conv2.bn.bias - torch.Size([300]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.0.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.0.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.0.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.depthwise_convs.3.conv.weight - torch.Size([160, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.0.depthwise_convs.3.bn.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.depthwise_convs.3.bn.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.0.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.0.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.0.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.0.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.0.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.0.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.spatial_weighting.3.conv1.conv.weight - torch.Size([40, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.0.spatial_weighting.3.conv1.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.spatial_weighting.3.conv2.conv.weight - torch.Size([160, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.0.spatial_weighting.3.conv2.conv.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.cross_resolution_weighting.conv1.conv.weight - torch.Size([37, 300, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.1.cross_resolution_weighting.conv1.bn.weight - torch.Size([37]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.cross_resolution_weighting.conv1.bn.bias - torch.Size([37]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.cross_resolution_weighting.conv2.conv.weight - torch.Size([300, 37, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.1.cross_resolution_weighting.conv2.bn.weight - torch.Size([300]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.cross_resolution_weighting.conv2.bn.bias - torch.Size([300]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.1.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.1.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.1.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.depthwise_convs.3.conv.weight - torch.Size([160, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.1.depthwise_convs.3.bn.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.depthwise_convs.3.bn.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.1.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.1.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.1.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.1.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.1.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.1.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.spatial_weighting.3.conv1.conv.weight - torch.Size([40, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.1.spatial_weighting.3.conv1.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.spatial_weighting.3.conv2.conv.weight - torch.Size([160, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.1.spatial_weighting.3.conv2.conv.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.0.1.0.weight - torch.Size([40, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.0.2.0.weight - torch.Size([40, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.0.2.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.0.2.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.0.3.0.weight - torch.Size([40, 320, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.0.3.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.0.3.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.1.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.1.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.1.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.1.0.0.2.weight - torch.Size([80, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.1.0.0.3.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.1.0.0.3.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.1.2.0.weight - torch.Size([80, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.1.2.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.1.2.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.1.3.0.weight - torch.Size([80, 320, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.1.3.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.1.3.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.2.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.2.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.2.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.2.0.0.2.weight - torch.Size([40, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.2.0.0.3.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.2.0.0.3.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.2.0.1.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.2.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.2.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.2.0.1.2.weight - torch.Size([160, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.2.0.1.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.2.0.1.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.2.1.0.0.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.2.1.0.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.2.1.0.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.2.1.0.2.weight - torch.Size([160, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.2.1.0.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.2.1.0.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.2.3.0.weight - torch.Size([160, 320, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.2.3.1.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.2.3.1.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.3.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.0.0.2.weight - torch.Size([40, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.3.0.0.3.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.0.0.3.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.0.1.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.3.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.0.1.2.weight - torch.Size([40, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.3.0.1.3.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.0.1.3.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.0.2.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.3.0.2.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.0.2.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.0.2.2.weight - torch.Size([320, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.3.0.2.3.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.0.2.3.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.1.0.0.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.3.1.0.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.1.0.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.1.0.2.weight - torch.Size([80, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.3.1.0.3.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.1.0.3.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.1.1.0.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.3.1.1.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.1.1.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.1.1.2.weight - torch.Size([320, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.3.1.1.3.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.1.1.3.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.2.0.0.weight - torch.Size([160, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.3.2.0.1.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.2.0.1.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.2.0.2.weight - torch.Size([320, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.3.2.0.3.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.2.0.3.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.0.cross_resolution_weighting.conv1.conv.weight - torch.Size([37, 300, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.0.cross_resolution_weighting.conv1.bn.weight - torch.Size([37]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.0.cross_resolution_weighting.conv1.bn.bias - torch.Size([37]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.0.cross_resolution_weighting.conv2.conv.weight - torch.Size([300, 37, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.0.cross_resolution_weighting.conv2.bn.weight - torch.Size([300]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.0.cross_resolution_weighting.conv2.bn.bias - torch.Size([300]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.0.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.0.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.0.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.0.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.0.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.0.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.0.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.0.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.0.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.0.depthwise_convs.3.conv.weight - torch.Size([160, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.0.depthwise_convs.3.bn.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.0.depthwise_convs.3.bn.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.0.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.0.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.0.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.0.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.0.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.0.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.0.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.0.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.0.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.0.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.0.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.0.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.0.spatial_weighting.3.conv1.conv.weight - torch.Size([40, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.0.spatial_weighting.3.conv1.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.0.spatial_weighting.3.conv2.conv.weight - torch.Size([160, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.0.spatial_weighting.3.conv2.conv.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.1.cross_resolution_weighting.conv1.conv.weight - torch.Size([37, 300, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.1.cross_resolution_weighting.conv1.bn.weight - torch.Size([37]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.1.cross_resolution_weighting.conv1.bn.bias - torch.Size([37]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.1.cross_resolution_weighting.conv2.conv.weight - torch.Size([300, 37, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.1.cross_resolution_weighting.conv2.bn.weight - torch.Size([300]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.1.cross_resolution_weighting.conv2.bn.bias - torch.Size([300]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.1.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.1.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.1.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.1.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.1.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.1.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.1.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.1.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.1.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.1.depthwise_convs.3.conv.weight - torch.Size([160, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.1.depthwise_convs.3.bn.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.1.depthwise_convs.3.bn.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.1.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.1.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.1.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.1.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.1.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.1.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.1.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.1.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.1.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.1.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.1.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.1.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.1.spatial_weighting.3.conv1.conv.weight - torch.Size([40, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.1.spatial_weighting.3.conv1.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.1.spatial_weighting.3.conv2.conv.weight - torch.Size([160, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.1.spatial_weighting.3.conv2.conv.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.0.1.0.weight - torch.Size([40, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.0.2.0.weight - torch.Size([40, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.0.2.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.0.2.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.0.3.0.weight - torch.Size([40, 320, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.0.3.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.0.3.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.1.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.1.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.1.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.1.0.0.2.weight - torch.Size([80, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.1.0.0.3.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.1.0.0.3.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.1.2.0.weight - torch.Size([80, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.1.2.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.1.2.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.1.3.0.weight - torch.Size([80, 320, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.1.3.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.1.3.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.2.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.2.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.2.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.2.0.0.2.weight - torch.Size([40, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.2.0.0.3.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.2.0.0.3.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.2.0.1.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.2.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.2.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.2.0.1.2.weight - torch.Size([160, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.2.0.1.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.2.0.1.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.2.1.0.0.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.2.1.0.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.2.1.0.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.2.1.0.2.weight - torch.Size([160, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.2.1.0.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.2.1.0.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.2.3.0.weight - torch.Size([160, 320, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.2.3.1.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.2.3.1.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.3.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.0.0.2.weight - torch.Size([40, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.3.0.0.3.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.0.0.3.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.0.1.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.3.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.0.1.2.weight - torch.Size([40, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.3.0.1.3.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.0.1.3.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.0.2.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.3.0.2.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.0.2.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.0.2.2.weight - torch.Size([320, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.3.0.2.3.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.0.2.3.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.1.0.0.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.3.1.0.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.1.0.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.1.0.2.weight - torch.Size([80, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.3.1.0.3.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.1.0.3.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.1.1.0.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.3.1.1.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.1.1.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.1.1.2.weight - torch.Size([320, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.3.1.1.3.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.1.1.3.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.2.0.0.weight - torch.Size([160, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.3.2.0.1.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.2.0.1.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.2.0.2.weight - torch.Size([320, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.3.2.0.3.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.2.0.3.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.head_layer.projects.0.depthwise_conv.conv.weight - torch.Size([320, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.head_layer.projects.0.depthwise_conv.bn.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.head_layer.projects.0.depthwise_conv.bn.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.head_layer.projects.0.pointwise_conv.conv.weight - torch.Size([160, 320, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.head_layer.projects.0.pointwise_conv.bn.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.head_layer.projects.0.pointwise_conv.bn.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.head_layer.projects.1.depthwise_conv.conv.weight - torch.Size([160, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.head_layer.projects.1.depthwise_conv.bn.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.head_layer.projects.1.depthwise_conv.bn.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.head_layer.projects.1.pointwise_conv.conv.weight - torch.Size([80, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.head_layer.projects.1.pointwise_conv.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.head_layer.projects.1.pointwise_conv.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.head_layer.projects.2.depthwise_conv.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.head_layer.projects.2.depthwise_conv.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.head_layer.projects.2.depthwise_conv.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.head_layer.projects.2.pointwise_conv.conv.weight - torch.Size([40, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.head_layer.projects.2.pointwise_conv.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.head_layer.projects.2.pointwise_conv.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.head_layer.projects.3.depthwise_conv.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.head_layer.projects.3.depthwise_conv.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.head_layer.projects.3.depthwise_conv.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.head_layer.projects.3.pointwise_conv.conv.weight - torch.Size([40, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.head_layer.projects.3.pointwise_conv.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.head_layer.projects.3.pointwise_conv.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.conv_seg.weight - torch.Size([150, 320, 1, 1]): 
NormalInit: mean=0, std=0.01, bias=0 

decode_head.conv_seg.bias - torch.Size([150]): 
NormalInit: mean=0, std=0.01, bias=0 

decode_head.convs.0.conv.weight - torch.Size([320, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.convs.0.bn.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.convs.0.bn.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  
2021-08-14 02:49:05,840 - mmseg - INFO - EncoderDecoder(
  (backbone): LiteHRNet(
    (stem): Stem(
      (conv1): ConvModule(
        (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (branch1): Sequential(
        (0): ConvModule(
          (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)
          (bn): SyncBatchNorm(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): ConvModule(
          (conv): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): SyncBatchNorm(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (expand_conv): ConvModule(
        (conv): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (depthwise_conv): ConvModule(
        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)
        (bn): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (linear_conv): ConvModule(
        (conv): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): SyncBatchNorm(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (transition0): ModuleList(
      (0): Sequential(
        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
        (1): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Conv2d(32, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (3): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (4): ReLU()
      )
      (1): Sequential(
        (0): Sequential(
          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)
          (1): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Conv2d(32, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU()
        )
      )
    )
    (stage0): Sequential(
      (0): LiteHRModule(
        (layers): Sequential(
          (0): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(60, 7, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(7, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
          (1): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(60, 7, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(7, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
        )
        (fuse_layers): ModuleList(
          (0): ModuleList(
            (0): None
            (1): Sequential(
              (0): Conv2d(80, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
          )
          (1): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): None
          )
        )
        (relu): ReLU()
      )
      (1): LiteHRModule(
        (layers): Sequential(
          (0): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(60, 7, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(7, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
          (1): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(60, 7, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(7, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
        )
        (fuse_layers): ModuleList(
          (0): ModuleList(
            (0): None
            (1): Sequential(
              (0): Conv2d(80, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
          )
          (1): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): None
          )
        )
        (relu): ReLU()
      )
      (2): LiteHRModule(
        (layers): Sequential(
          (0): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(60, 7, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(7, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
          (1): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(60, 7, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(7, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
        )
        (fuse_layers): ModuleList(
          (0): ModuleList(
            (0): None
            (1): Sequential(
              (0): Conv2d(80, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
          )
          (1): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): None
          )
        )
        (relu): ReLU()
      )
    )
    (transition1): ModuleList(
      (0): None
      (1): None
      (2): Sequential(
        (0): Sequential(
          (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=80, bias=False)
          (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Conv2d(80, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU()
        )
      )
    )
    (stage1): Sequential(
      (0): LiteHRModule(
        (layers): Sequential(
          (0): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(140, 17, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(17, 140, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
          (1): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(140, 17, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(17, 140, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
        )
        (fuse_layers): ModuleList(
          (0): ModuleList(
            (0): None
            (1): Sequential(
              (0): Conv2d(80, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
            (2): Sequential(
              (0): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=4.0, mode=nearest)
            )
          )
          (1): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): None
            (2): Sequential(
              (0): Conv2d(160, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
          )
          (2): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (1): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=80, bias=False)
                (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(80, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): None
          )
        )
        (relu): ReLU()
      )
      (1): LiteHRModule(
        (layers): Sequential(
          (0): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(140, 17, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(17, 140, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
          (1): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(140, 17, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(17, 140, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
        )
        (fuse_layers): ModuleList(
          (0): ModuleList(
            (0): None
            (1): Sequential(
              (0): Conv2d(80, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
            (2): Sequential(
              (0): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=4.0, mode=nearest)
            )
          )
          (1): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): None
            (2): Sequential(
              (0): Conv2d(160, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
          )
          (2): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (1): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=80, bias=False)
                (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(80, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): None
          )
        )
        (relu): ReLU()
      )
      (2): LiteHRModule(
        (layers): Sequential(
          (0): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(140, 17, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(17, 140, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
          (1): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(140, 17, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(17, 140, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
        )
        (fuse_layers): ModuleList(
          (0): ModuleList(
            (0): None
            (1): Sequential(
              (0): Conv2d(80, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
            (2): Sequential(
              (0): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=4.0, mode=nearest)
            )
          )
          (1): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): None
            (2): Sequential(
              (0): Conv2d(160, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
          )
          (2): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (1): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=80, bias=False)
                (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(80, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): None
          )
        )
        (relu): ReLU()
      )
      (3): LiteHRModule(
        (layers): Sequential(
          (0): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(140, 17, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(17, 140, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
          (1): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(140, 17, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(17, 140, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
        )
        (fuse_layers): ModuleList(
          (0): ModuleList(
            (0): None
            (1): Sequential(
              (0): Conv2d(80, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
            (2): Sequential(
              (0): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=4.0, mode=nearest)
            )
          )
          (1): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): None
            (2): Sequential(
              (0): Conv2d(160, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
          )
          (2): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (1): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=80, bias=False)
                (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(80, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): None
          )
        )
        (relu): ReLU()
      )
      (4): LiteHRModule(
        (layers): Sequential(
          (0): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(140, 17, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(17, 140, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
          (1): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(140, 17, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(17, 140, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
        )
        (fuse_layers): ModuleList(
          (0): ModuleList(
            (0): None
            (1): Sequential(
              (0): Conv2d(80, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
            (2): Sequential(
              (0): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=4.0, mode=nearest)
            )
          )
          (1): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): None
            (2): Sequential(
              (0): Conv2d(160, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
          )
          (2): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (1): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=80, bias=False)
                (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(80, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): None
          )
        )
        (relu): ReLU()
      )
      (5): LiteHRModule(
        (layers): Sequential(
          (0): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(140, 17, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(17, 140, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
          (1): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(140, 17, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(17, 140, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
        )
        (fuse_layers): ModuleList(
          (0): ModuleList(
            (0): None
            (1): Sequential(
              (0): Conv2d(80, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
            (2): Sequential(
              (0): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=4.0, mode=nearest)
            )
          )
          (1): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): None
            (2): Sequential(
              (0): Conv2d(160, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
          )
          (2): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (1): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=80, bias=False)
                (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(80, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): None
          )
        )
        (relu): ReLU()
      )
      (6): LiteHRModule(
        (layers): Sequential(
          (0): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(140, 17, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(17, 140, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
          (1): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(140, 17, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(17, 140, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
        )
        (fuse_layers): ModuleList(
          (0): ModuleList(
            (0): None
            (1): Sequential(
              (0): Conv2d(80, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
            (2): Sequential(
              (0): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=4.0, mode=nearest)
            )
          )
          (1): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): None
            (2): Sequential(
              (0): Conv2d(160, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
          )
          (2): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (1): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=80, bias=False)
                (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(80, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): None
          )
        )
        (relu): ReLU()
      )
      (7): LiteHRModule(
        (layers): Sequential(
          (0): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(140, 17, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(17, 140, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
          (1): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(140, 17, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(17, 140, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
        )
        (fuse_layers): ModuleList(
          (0): ModuleList(
            (0): None
            (1): Sequential(
              (0): Conv2d(80, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
            (2): Sequential(
              (0): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=4.0, mode=nearest)
            )
          )
          (1): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): None
            (2): Sequential(
              (0): Conv2d(160, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
          )
          (2): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (1): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=80, bias=False)
                (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(80, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): None
          )
        )
        (relu): ReLU()
      )
    )
    (transition2): ModuleList(
      (0): None
      (1): None
      (2): None
      (3): Sequential(
        (0): Sequential(
          (0): Conv2d(160, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=160, bias=False)
          (1): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Conv2d(160, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): SyncBatchNorm(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU()
        )
      )
    )
    (stage2): Sequential(
      (0): LiteHRModule(
        (layers): Sequential(
          (0): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(300, 37, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(37, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(37, 300, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): ConvModule(
                (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (3): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
          (1): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(300, 37, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(37, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(37, 300, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): ConvModule(
                (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (3): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
        )
        (fuse_layers): ModuleList(
          (0): ModuleList(
            (0): None
            (1): Sequential(
              (0): Conv2d(80, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
            (2): Sequential(
              (0): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=4.0, mode=nearest)
            )
            (3): Sequential(
              (0): Conv2d(320, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=8.0, mode=nearest)
            )
          )
          (1): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): None
            (2): Sequential(
              (0): Conv2d(160, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
            (3): Sequential(
              (0): Conv2d(320, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=4.0, mode=nearest)
            )
          )
          (2): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (1): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=80, bias=False)
                (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(80, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): None
            (3): Sequential(
              (0): Conv2d(320, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
          )
          (3): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (1): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (2): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=80, bias=False)
                (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (1): Sequential(
                (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=80, bias=False)
                (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(80, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): Sequential(
              (0): Sequential(
                (0): Conv2d(160, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=160, bias=False)
                (1): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(160, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): None
          )
        )
        (relu): ReLU()
      )
      (1): LiteHRModule(
        (layers): Sequential(
          (0): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(300, 37, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(37, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(37, 300, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): ConvModule(
                (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (3): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
          (1): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(300, 37, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(37, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(37, 300, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): ConvModule(
                (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (3): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
        )
        (fuse_layers): ModuleList(
          (0): ModuleList(
            (0): None
            (1): Sequential(
              (0): Conv2d(80, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
            (2): Sequential(
              (0): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=4.0, mode=nearest)
            )
            (3): Sequential(
              (0): Conv2d(320, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=8.0, mode=nearest)
            )
          )
          (1): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): None
            (2): Sequential(
              (0): Conv2d(160, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
            (3): Sequential(
              (0): Conv2d(320, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=4.0, mode=nearest)
            )
          )
          (2): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (1): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=80, bias=False)
                (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(80, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): None
            (3): Sequential(
              (0): Conv2d(320, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
          )
          (3): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (1): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (2): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=80, bias=False)
                (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (1): Sequential(
                (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=80, bias=False)
                (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(80, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): Sequential(
              (0): Sequential(
                (0): Conv2d(160, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=160, bias=False)
                (1): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(160, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): None
          )
        )
        (relu): ReLU()
      )
      (2): LiteHRModule(
        (layers): Sequential(
          (0): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(300, 37, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(37, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(37, 300, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): ConvModule(
                (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (3): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
          (1): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(300, 37, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(37, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(37, 300, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): ConvModule(
                (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (3): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
        )
        (fuse_layers): ModuleList(
          (0): ModuleList(
            (0): None
            (1): Sequential(
              (0): Conv2d(80, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
            (2): Sequential(
              (0): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=4.0, mode=nearest)
            )
            (3): Sequential(
              (0): Conv2d(320, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=8.0, mode=nearest)
            )
          )
          (1): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): None
            (2): Sequential(
              (0): Conv2d(160, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
            (3): Sequential(
              (0): Conv2d(320, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=4.0, mode=nearest)
            )
          )
          (2): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (1): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=80, bias=False)
                (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(80, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): None
            (3): Sequential(
              (0): Conv2d(320, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
          )
          (3): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (1): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (2): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=80, bias=False)
                (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (1): Sequential(
                (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=80, bias=False)
                (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(80, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): Sequential(
              (0): Sequential(
                (0): Conv2d(160, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=160, bias=False)
                (1): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(160, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): None
          )
        )
        (relu): ReLU()
      )
    )
    (head_layer): IterativeHead(
      (projects): ModuleList(
        (0): DepthwiseSeparableConvModule(
          (depthwise_conv): ConvModule(
            (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)
            (bn): SyncBatchNorm(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise_conv): ConvModule(
            (conv): Conv2d(320, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (activate): ReLU(inplace=True)
          )
        )
        (1): DepthwiseSeparableConvModule(
          (depthwise_conv): ConvModule(
            (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
            (bn): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise_conv): ConvModule(
            (conv): Conv2d(160, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (activate): ReLU(inplace=True)
          )
        )
        (2): DepthwiseSeparableConvModule(
          (depthwise_conv): ConvModule(
            (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
            (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise_conv): ConvModule(
            (conv): Conv2d(80, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (activate): ReLU(inplace=True)
          )
        )
        (3): DepthwiseSeparableConvModule(
          (depthwise_conv): ConvModule(
            (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
            (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise_conv): ConvModule(
            (conv): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (activate): ReLU(inplace=True)
          )
        )
      )
    )
  )
  init_cfg=[{'type': 'Normal', 'std': 0.001, 'layer': 'Conv2d'}, {'type': 'Constant', 'val': 1, 'layer': ['_BatchNorm', 'GroupNorm']}]
  (decode_head): FCNHead(
    input_transform=resize_concat, ignore_index=255, align_corners=False
    (loss_decode): CrossEntropyLoss()
    (conv_seg): Conv2d(320, 150, kernel_size=(1, 1), stride=(1, 1))
    (convs): Sequential(
      (0): ConvModule(
        (conv): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): SyncBatchNorm(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
)
2021-08-14 02:49:06,432 - mmseg - INFO - Loaded 20210 images
2021-08-14 02:49:11,768 - mmseg - INFO - Loaded 2000 images
2021-08-14 02:49:11,768 - mmseg - INFO - Start running, host: hejunjun@SH-IDC2-172-20-20-74, work_dir: /mnt/lustrenew/hejunjun/mmseg_dev/lite_hrnet/mmsegmentation/work_dirs/fcn-resize-concat_litehr30-with-head_512x512_160k_ade20k
2021-08-14 02:49:11,769 - mmseg - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(NORMAL      ) CheckpointHook                     
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
2021-08-14 02:49:11,769 - mmseg - INFO - workflow: [('train', 1)], max: 160000 iters
2021-08-14 02:50:56,817 - mmseg - INFO - Iter [50/160000]	lr: 9.997e-03, eta: 2 days, 15:41:30, time: 1.434, data_time: 0.018, memory: 9759, decode.loss_seg: 2.9619, decode.acc_seg: 18.4109, loss: 2.9619
2021-08-14 02:52:00,330 - mmseg - INFO - Iter [100/160000]	lr: 9.994e-03, eta: 2 days, 12:03:24, time: 1.271, data_time: 0.015, memory: 9759, decode.loss_seg: 2.5167, decode.acc_seg: 24.1101, loss: 2.5167
2021-08-14 02:53:04,512 - mmseg - INFO - Iter [150/160000]	lr: 9.992e-03, eta: 2 days, 11:01:00, time: 1.283, data_time: 0.015, memory: 9759, decode.loss_seg: 2.4905, decode.acc_seg: 24.6880, loss: 2.4905
2021-08-14 02:54:08,817 - mmseg - INFO - Iter [200/160000]	lr: 9.989e-03, eta: 2 days, 10:31:15, time: 1.286, data_time: 0.014, memory: 9759, decode.loss_seg: 2.4080, decode.acc_seg: 26.4996, loss: 2.4080
2021-08-14 02:55:12,986 - mmseg - INFO - Iter [250/160000]	lr: 9.986e-03, eta: 2 days, 10:11:46, time: 1.284, data_time: 0.014, memory: 9759, decode.loss_seg: 2.3329, decode.acc_seg: 27.7921, loss: 2.3329
2021-08-14 02:56:17,924 - mmseg - INFO - Iter [300/160000]	lr: 9.983e-03, eta: 2 days, 10:04:48, time: 1.298, data_time: 0.014, memory: 9759, decode.loss_seg: 2.2785, decode.acc_seg: 28.0046, loss: 2.2785
2021-08-14 02:57:21,562 - mmseg - INFO - Iter [350/160000]	lr: 9.981e-03, eta: 2 days, 9:49:37, time: 1.272, data_time: 0.015, memory: 9759, decode.loss_seg: 2.2670, decode.acc_seg: 27.4336, loss: 2.2670
2021-08-14 02:58:28,061 - mmseg - INFO - Iter [400/160000]	lr: 9.978e-03, eta: 2 days, 9:57:29, time: 1.331, data_time: 0.015, memory: 9759, decode.loss_seg: 2.2507, decode.acc_seg: 29.4144, loss: 2.2507
2021-08-14 02:59:35,394 - mmseg - INFO - Iter [450/160000]	lr: 9.975e-03, eta: 2 days, 10:07:43, time: 1.346, data_time: 0.014, memory: 9759, decode.loss_seg: 2.1542, decode.acc_seg: 29.5475, loss: 2.1542
2021-08-14 03:00:43,870 - mmseg - INFO - Iter [500/160000]	lr: 9.972e-03, eta: 2 days, 10:22:02, time: 1.370, data_time: 0.015, memory: 9759, decode.loss_seg: 2.1701, decode.acc_seg: 30.5180, loss: 2.1701
2021-08-14 03:01:51,631 - mmseg - INFO - Iter [550/160000]	lr: 9.969e-03, eta: 2 days, 10:30:18, time: 1.356, data_time: 0.015, memory: 9759, decode.loss_seg: 2.1372, decode.acc_seg: 30.4643, loss: 2.1372
2021-08-14 03:02:56,172 - mmseg - INFO - Iter [600/160000]	lr: 9.967e-03, eta: 2 days, 10:22:36, time: 1.291, data_time: 0.014, memory: 9759, decode.loss_seg: 2.1164, decode.acc_seg: 32.4300, loss: 2.1164
2021-08-14 03:04:38,045 - mmseg - INFO - Iter [650/160000]	lr: 9.964e-03, eta: 2 days, 12:48:14, time: 2.037, data_time: 0.764, memory: 9759, decode.loss_seg: 2.0825, decode.acc_seg: 31.5635, loss: 2.0825
2021-08-14 03:05:41,353 - mmseg - INFO - Iter [700/160000]	lr: 9.961e-03, eta: 2 days, 12:26:49, time: 1.267, data_time: 0.015, memory: 9759, decode.loss_seg: 2.0971, decode.acc_seg: 30.9870, loss: 2.0971
2021-08-14 03:06:47,168 - mmseg - INFO - Iter [750/160000]	lr: 9.958e-03, eta: 2 days, 12:16:49, time: 1.316, data_time: 0.014, memory: 9759, decode.loss_seg: 2.0780, decode.acc_seg: 32.5856, loss: 2.0780
2021-08-14 03:07:51,599 - mmseg - INFO - Iter [800/160000]	lr: 9.955e-03, eta: 2 days, 12:03:26, time: 1.289, data_time: 0.016, memory: 9759, decode.loss_seg: 1.9892, decode.acc_seg: 34.4066, loss: 1.9892
2021-08-14 03:08:56,142 - mmseg - INFO - Iter [850/160000]	lr: 9.953e-03, eta: 2 days, 11:51:48, time: 1.291, data_time: 0.015, memory: 9759, decode.loss_seg: 1.9733, decode.acc_seg: 33.5088, loss: 1.9733
2021-08-14 03:10:01,054 - mmseg - INFO - Iter [900/160000]	lr: 9.950e-03, eta: 2 days, 11:42:21, time: 1.298, data_time: 0.015, memory: 9759, decode.loss_seg: 1.9860, decode.acc_seg: 33.5228, loss: 1.9860
2021-08-14 03:11:04,758 - mmseg - INFO - Iter [950/160000]	lr: 9.947e-03, eta: 2 days, 11:30:35, time: 1.275, data_time: 0.016, memory: 9759, decode.loss_seg: 1.9553, decode.acc_seg: 33.3965, loss: 1.9553
2021-08-14 03:12:08,022 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 03:12:08,023 - mmseg - INFO - Iter [1000/160000]	lr: 9.944e-03, eta: 2 days, 11:18:39, time: 1.265, data_time: 0.015, memory: 9759, decode.loss_seg: 1.9767, decode.acc_seg: 34.8292, loss: 1.9767
2021-08-14 03:13:10,587 - mmseg - INFO - Iter [1050/160000]	lr: 9.942e-03, eta: 2 days, 11:05:53, time: 1.251, data_time: 0.016, memory: 9759, decode.loss_seg: 1.9585, decode.acc_seg: 33.3160, loss: 1.9585
2021-08-14 03:14:14,939 - mmseg - INFO - Iter [1100/160000]	lr: 9.939e-03, eta: 2 days, 10:58:35, time: 1.287, data_time: 0.016, memory: 9759, decode.loss_seg: 1.9315, decode.acc_seg: 34.8753, loss: 1.9315
2021-08-14 03:15:21,605 - mmseg - INFO - Iter [1150/160000]	lr: 9.936e-03, eta: 2 days, 10:57:04, time: 1.333, data_time: 0.015, memory: 9759, decode.loss_seg: 1.9438, decode.acc_seg: 34.7566, loss: 1.9438
2021-08-14 03:16:31,516 - mmseg - INFO - Iter [1200/160000]	lr: 9.933e-03, eta: 2 days, 11:02:49, time: 1.398, data_time: 0.015, memory: 9759, decode.loss_seg: 1.8955, decode.acc_seg: 35.5225, loss: 1.8955
2021-08-14 03:17:38,745 - mmseg - INFO - Iter [1250/160000]	lr: 9.930e-03, eta: 2 days, 11:02:29, time: 1.346, data_time: 0.015, memory: 9759, decode.loss_seg: 1.8673, decode.acc_seg: 36.3689, loss: 1.8673
2021-08-14 03:19:16,768 - mmseg - INFO - Iter [1300/160000]	lr: 9.928e-03, eta: 2 days, 12:04:33, time: 1.960, data_time: 0.656, memory: 9759, decode.loss_seg: 1.9296, decode.acc_seg: 34.9001, loss: 1.9296
2021-08-14 03:20:21,520 - mmseg - INFO - Iter [1350/160000]	lr: 9.925e-03, eta: 2 days, 11:56:44, time: 1.295, data_time: 0.014, memory: 9759, decode.loss_seg: 1.8435, decode.acc_seg: 36.7778, loss: 1.8435
2021-08-14 03:21:27,945 - mmseg - INFO - Iter [1400/160000]	lr: 9.922e-03, eta: 2 days, 11:52:35, time: 1.328, data_time: 0.015, memory: 9759, decode.loss_seg: 1.8698, decode.acc_seg: 35.1202, loss: 1.8698
2021-08-14 03:22:34,928 - mmseg - INFO - Iter [1450/160000]	lr: 9.919e-03, eta: 2 days, 11:49:33, time: 1.338, data_time: 0.015, memory: 9759, decode.loss_seg: 1.8284, decode.acc_seg: 35.9104, loss: 1.8284
2021-08-14 03:23:43,245 - mmseg - INFO - Iter [1500/160000]	lr: 9.916e-03, eta: 2 days, 11:49:21, time: 1.369, data_time: 0.017, memory: 9759, decode.loss_seg: 1.8555, decode.acc_seg: 35.9977, loss: 1.8555
2021-08-14 03:24:50,862 - mmseg - INFO - Iter [1550/160000]	lr: 9.914e-03, eta: 2 days, 11:47:37, time: 1.352, data_time: 0.014, memory: 9759, decode.loss_seg: 1.7825, decode.acc_seg: 37.0634, loss: 1.7825
2021-08-14 03:25:54,568 - mmseg - INFO - Iter [1600/160000]	lr: 9.911e-03, eta: 2 days, 11:39:29, time: 1.274, data_time: 0.014, memory: 9759, decode.loss_seg: 1.8402, decode.acc_seg: 36.0176, loss: 1.8402
2021-08-14 03:26:58,861 - mmseg - INFO - Iter [1650/160000]	lr: 9.908e-03, eta: 2 days, 11:32:45, time: 1.286, data_time: 0.014, memory: 9759, decode.loss_seg: 1.7752, decode.acc_seg: 36.9520, loss: 1.7752
2021-08-14 03:28:07,272 - mmseg - INFO - Iter [1700/160000]	lr: 9.905e-03, eta: 2 days, 11:32:45, time: 1.368, data_time: 0.013, memory: 9759, decode.loss_seg: 1.8149, decode.acc_seg: 37.4602, loss: 1.8149
2021-08-14 03:29:14,943 - mmseg - INFO - Iter [1750/160000]	lr: 9.903e-03, eta: 2 days, 11:31:32, time: 1.353, data_time: 0.013, memory: 9759, decode.loss_seg: 1.8013, decode.acc_seg: 37.7118, loss: 1.8013
2021-08-14 03:30:24,471 - mmseg - INFO - Iter [1800/160000]	lr: 9.900e-03, eta: 2 days, 11:33:04, time: 1.391, data_time: 0.014, memory: 9759, decode.loss_seg: 1.7831, decode.acc_seg: 37.9201, loss: 1.7831
2021-08-14 03:31:33,868 - mmseg - INFO - Iter [1850/160000]	lr: 9.897e-03, eta: 2 days, 11:34:17, time: 1.388, data_time: 0.014, memory: 9759, decode.loss_seg: 1.7708, decode.acc_seg: 37.3478, loss: 1.7708
2021-08-14 03:33:17,311 - mmseg - INFO - Iter [1900/160000]	lr: 9.894e-03, eta: 2 days, 12:22:39, time: 2.070, data_time: 0.667, memory: 9759, decode.loss_seg: 1.7974, decode.acc_seg: 37.8561, loss: 1.7974
2021-08-14 03:34:22,898 - mmseg - INFO - Iter [1950/160000]	lr: 9.891e-03, eta: 2 days, 12:17:11, time: 1.311, data_time: 0.014, memory: 9759, decode.loss_seg: 1.7460, decode.acc_seg: 36.5348, loss: 1.7460
2021-08-14 03:35:30,208 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 03:35:30,208 - mmseg - INFO - Iter [2000/160000]	lr: 9.889e-03, eta: 2 days, 12:14:16, time: 1.346, data_time: 0.013, memory: 9759, decode.loss_seg: 1.7865, decode.acc_seg: 37.2700, loss: 1.7865
2021-08-14 03:36:37,286 - mmseg - INFO - Iter [2050/160000]	lr: 9.886e-03, eta: 2 days, 12:11:08, time: 1.342, data_time: 0.013, memory: 9759, decode.loss_seg: 1.6906, decode.acc_seg: 39.6852, loss: 1.6906
2021-08-14 03:37:43,994 - mmseg - INFO - Iter [2100/160000]	lr: 9.883e-03, eta: 2 days, 12:07:40, time: 1.335, data_time: 0.014, memory: 9759, decode.loss_seg: 1.7769, decode.acc_seg: 37.9458, loss: 1.7769
2021-08-14 03:38:48,646 - mmseg - INFO - Iter [2150/160000]	lr: 9.880e-03, eta: 2 days, 12:01:44, time: 1.293, data_time: 0.013, memory: 9759, decode.loss_seg: 1.7650, decode.acc_seg: 37.1777, loss: 1.7650
2021-08-14 03:39:54,734 - mmseg - INFO - Iter [2200/160000]	lr: 9.877e-03, eta: 2 days, 11:57:50, time: 1.323, data_time: 0.014, memory: 9759, decode.loss_seg: 1.6925, decode.acc_seg: 38.5611, loss: 1.6925
2021-08-14 03:40:59,096 - mmseg - INFO - Iter [2250/160000]	lr: 9.875e-03, eta: 2 days, 11:51:55, time: 1.286, data_time: 0.013, memory: 9759, decode.loss_seg: 1.7216, decode.acc_seg: 38.4889, loss: 1.7216
2021-08-14 03:42:00,736 - mmseg - INFO - Iter [2300/160000]	lr: 9.872e-03, eta: 2 days, 11:43:12, time: 1.234, data_time: 0.014, memory: 9759, decode.loss_seg: 1.7431, decode.acc_seg: 38.0183, loss: 1.7431
2021-08-14 03:43:06,084 - mmseg - INFO - Iter [2350/160000]	lr: 9.869e-03, eta: 2 days, 11:38:53, time: 1.306, data_time: 0.013, memory: 9759, decode.loss_seg: 1.7414, decode.acc_seg: 38.4579, loss: 1.7414
2021-08-14 03:44:09,228 - mmseg - INFO - Iter [2400/160000]	lr: 9.866e-03, eta: 2 days, 11:32:20, time: 1.263, data_time: 0.014, memory: 9759, decode.loss_seg: 1.6897, decode.acc_seg: 39.9150, loss: 1.6897
2021-08-14 03:45:13,578 - mmseg - INFO - Iter [2450/160000]	lr: 9.864e-03, eta: 2 days, 11:27:16, time: 1.287, data_time: 0.014, memory: 9759, decode.loss_seg: 1.6739, decode.acc_seg: 39.7911, loss: 1.6739
2021-08-14 03:46:19,288 - mmseg - INFO - Iter [2500/160000]	lr: 9.861e-03, eta: 2 days, 11:23:50, time: 1.315, data_time: 0.014, memory: 9759, decode.loss_seg: 1.7305, decode.acc_seg: 39.1083, loss: 1.7305
2021-08-14 03:47:59,129 - mmseg - INFO - Iter [2550/160000]	lr: 9.858e-03, eta: 2 days, 11:55:36, time: 1.997, data_time: 0.677, memory: 9759, decode.loss_seg: 1.6491, decode.acc_seg: 39.9551, loss: 1.6491
2021-08-14 03:49:01,991 - mmseg - INFO - Iter [2600/160000]	lr: 9.855e-03, eta: 2 days, 11:48:43, time: 1.257, data_time: 0.014, memory: 9759, decode.loss_seg: 1.6190, decode.acc_seg: 39.9991, loss: 1.6190
2021-08-14 03:50:05,949 - mmseg - INFO - Iter [2650/160000]	lr: 9.852e-03, eta: 2 days, 11:43:09, time: 1.278, data_time: 0.014, memory: 9759, decode.loss_seg: 1.7000, decode.acc_seg: 39.8915, loss: 1.7000
2021-08-14 03:51:08,305 - mmseg - INFO - Iter [2700/160000]	lr: 9.850e-03, eta: 2 days, 11:36:16, time: 1.248, data_time: 0.014, memory: 9759, decode.loss_seg: 1.6879, decode.acc_seg: 39.9514, loss: 1.6879
2021-08-14 03:52:12,295 - mmseg - INFO - Iter [2750/160000]	lr: 9.847e-03, eta: 2 days, 11:31:08, time: 1.280, data_time: 0.014, memory: 9759, decode.loss_seg: 1.6900, decode.acc_seg: 38.8719, loss: 1.6900
2021-08-14 03:53:14,833 - mmseg - INFO - Iter [2800/160000]	lr: 9.844e-03, eta: 2 days, 11:24:46, time: 1.251, data_time: 0.013, memory: 9759, decode.loss_seg: 1.5854, decode.acc_seg: 40.3678, loss: 1.5854
2021-08-14 03:54:17,457 - mmseg - INFO - Iter [2850/160000]	lr: 9.841e-03, eta: 2 days, 11:18:39, time: 1.252, data_time: 0.014, memory: 9759, decode.loss_seg: 1.6687, decode.acc_seg: 39.3401, loss: 1.6687
2021-08-14 03:55:20,849 - mmseg - INFO - Iter [2900/160000]	lr: 9.838e-03, eta: 2 days, 11:13:26, time: 1.268, data_time: 0.014, memory: 9759, decode.loss_seg: 1.6125, decode.acc_seg: 40.9130, loss: 1.6125
2021-08-14 03:56:24,727 - mmseg - INFO - Iter [2950/160000]	lr: 9.836e-03, eta: 2 days, 11:08:47, time: 1.278, data_time: 0.015, memory: 9759, decode.loss_seg: 1.6002, decode.acc_seg: 41.0966, loss: 1.6002
2021-08-14 03:57:29,892 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 03:57:29,893 - mmseg - INFO - Iter [3000/160000]	lr: 9.833e-03, eta: 2 days, 11:05:21, time: 1.303, data_time: 0.014, memory: 9759, decode.loss_seg: 1.6525, decode.acc_seg: 39.9775, loss: 1.6525
2021-08-14 03:58:34,613 - mmseg - INFO - Iter [3050/160000]	lr: 9.830e-03, eta: 2 days, 11:01:37, time: 1.294, data_time: 0.014, memory: 9759, decode.loss_seg: 1.6619, decode.acc_seg: 40.0596, loss: 1.6619
2021-08-14 03:59:38,740 - mmseg - INFO - Iter [3100/160000]	lr: 9.827e-03, eta: 2 days, 10:57:28, time: 1.283, data_time: 0.015, memory: 9759, decode.loss_seg: 1.6357, decode.acc_seg: 40.6083, loss: 1.6357
2021-08-14 04:00:43,503 - mmseg - INFO - Iter [3150/160000]	lr: 9.824e-03, eta: 2 days, 10:53:57, time: 1.295, data_time: 0.013, memory: 9759, decode.loss_seg: 1.6181, decode.acc_seg: 41.3708, loss: 1.6181
2021-08-14 04:02:20,484 - mmseg - INFO - Iter [3200/160000]	lr: 9.822e-03, eta: 2 days, 11:16:50, time: 1.940, data_time: 0.674, memory: 9759, decode.loss_seg: 1.6349, decode.acc_seg: 39.8678, loss: 1.6349
2021-08-14 04:03:25,739 - mmseg - INFO - Iter [3250/160000]	lr: 9.819e-03, eta: 2 days, 11:13:25, time: 1.304, data_time: 0.012, memory: 9759, decode.loss_seg: 1.6537, decode.acc_seg: 41.2632, loss: 1.6537
2021-08-14 04:04:31,974 - mmseg - INFO - Iter [3300/160000]	lr: 9.816e-03, eta: 2 days, 11:10:53, time: 1.325, data_time: 0.014, memory: 9759, decode.loss_seg: 1.6218, decode.acc_seg: 41.1497, loss: 1.6218
2021-08-14 04:05:37,468 - mmseg - INFO - Iter [3350/160000]	lr: 9.813e-03, eta: 2 days, 11:07:49, time: 1.310, data_time: 0.013, memory: 9759, decode.loss_seg: 1.6061, decode.acc_seg: 41.3826, loss: 1.6061
2021-08-14 04:06:42,372 - mmseg - INFO - Iter [3400/160000]	lr: 9.811e-03, eta: 2 days, 11:04:22, time: 1.298, data_time: 0.015, memory: 9759, decode.loss_seg: 1.5830, decode.acc_seg: 42.0211, loss: 1.5830
2021-08-14 04:07:45,382 - mmseg - INFO - Iter [3450/160000]	lr: 9.808e-03, eta: 2 days, 10:59:32, time: 1.260, data_time: 0.014, memory: 9759, decode.loss_seg: 1.6211, decode.acc_seg: 40.8141, loss: 1.6211
2021-08-14 04:08:49,589 - mmseg - INFO - Iter [3500/160000]	lr: 9.805e-03, eta: 2 days, 10:55:43, time: 1.285, data_time: 0.013, memory: 9759, decode.loss_seg: 1.5998, decode.acc_seg: 40.9136, loss: 1.5998
2021-08-14 04:09:55,800 - mmseg - INFO - Iter [3550/160000]	lr: 9.802e-03, eta: 2 days, 10:53:26, time: 1.324, data_time: 0.013, memory: 9759, decode.loss_seg: 1.5728, decode.acc_seg: 40.7842, loss: 1.5728
2021-08-14 04:11:00,217 - mmseg - INFO - Iter [3600/160000]	lr: 9.799e-03, eta: 2 days, 10:49:54, time: 1.289, data_time: 0.014, memory: 9759, decode.loss_seg: 1.5787, decode.acc_seg: 42.1117, loss: 1.5787
2021-08-14 04:12:03,000 - mmseg - INFO - Iter [3650/160000]	lr: 9.797e-03, eta: 2 days, 10:45:14, time: 1.255, data_time: 0.012, memory: 9759, decode.loss_seg: 1.5708, decode.acc_seg: 41.8074, loss: 1.5708
2021-08-14 04:13:04,696 - mmseg - INFO - Iter [3700/160000]	lr: 9.794e-03, eta: 2 days, 10:39:55, time: 1.234, data_time: 0.014, memory: 9759, decode.loss_seg: 1.5639, decode.acc_seg: 42.0149, loss: 1.5639
2021-08-14 04:14:08,404 - mmseg - INFO - Iter [3750/160000]	lr: 9.791e-03, eta: 2 days, 10:36:08, time: 1.275, data_time: 0.013, memory: 9759, decode.loss_seg: 1.5474, decode.acc_seg: 41.9631, loss: 1.5474
2021-08-14 04:15:45,509 - mmseg - INFO - Iter [3800/160000]	lr: 9.788e-03, eta: 2 days, 10:55:17, time: 1.942, data_time: 0.695, memory: 9759, decode.loss_seg: 1.5951, decode.acc_seg: 41.8141, loss: 1.5951
2021-08-14 04:16:49,086 - mmseg - INFO - Iter [3850/160000]	lr: 9.785e-03, eta: 2 days, 10:51:14, time: 1.272, data_time: 0.014, memory: 9759, decode.loss_seg: 1.5595, decode.acc_seg: 41.7249, loss: 1.5595
2021-08-14 04:17:52,177 - mmseg - INFO - Iter [3900/160000]	lr: 9.783e-03, eta: 2 days, 10:46:54, time: 1.261, data_time: 0.012, memory: 9759, decode.loss_seg: 1.5019, decode.acc_seg: 42.8285, loss: 1.5019
2021-08-14 04:18:54,036 - mmseg - INFO - Iter [3950/160000]	lr: 9.780e-03, eta: 2 days, 10:41:54, time: 1.238, data_time: 0.013, memory: 9759, decode.loss_seg: 1.5834, decode.acc_seg: 42.1435, loss: 1.5834
2021-08-14 04:19:55,500 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 04:19:55,500 - mmseg - INFO - Iter [4000/160000]	lr: 9.777e-03, eta: 2 days, 10:36:43, time: 1.229, data_time: 0.013, memory: 9759, decode.loss_seg: 1.5233, decode.acc_seg: 42.7418, loss: 1.5233
2021-08-14 04:21:00,025 - mmseg - INFO - Iter [4050/160000]	lr: 9.774e-03, eta: 2 days, 10:33:33, time: 1.289, data_time: 0.013, memory: 9759, decode.loss_seg: 1.5568, decode.acc_seg: 42.2069, loss: 1.5568
2021-08-14 04:22:06,700 - mmseg - INFO - Iter [4100/160000]	lr: 9.771e-03, eta: 2 days, 10:31:51, time: 1.333, data_time: 0.014, memory: 9759, decode.loss_seg: 1.5623, decode.acc_seg: 41.6092, loss: 1.5623
2021-08-14 04:23:13,647 - mmseg - INFO - Iter [4150/160000]	lr: 9.769e-03, eta: 2 days, 10:30:21, time: 1.340, data_time: 0.014, memory: 9759, decode.loss_seg: 1.5542, decode.acc_seg: 41.4945, loss: 1.5542
2021-08-14 04:24:17,302 - mmseg - INFO - Iter [4200/160000]	lr: 9.766e-03, eta: 2 days, 10:26:49, time: 1.273, data_time: 0.013, memory: 9759, decode.loss_seg: 1.5486, decode.acc_seg: 41.5920, loss: 1.5486
2021-08-14 04:25:20,930 - mmseg - INFO - Iter [4250/160000]	lr: 9.763e-03, eta: 2 days, 10:23:17, time: 1.272, data_time: 0.014, memory: 9759, decode.loss_seg: 1.5127, decode.acc_seg: 43.0312, loss: 1.5127
2021-08-14 04:26:25,157 - mmseg - INFO - Iter [4300/160000]	lr: 9.760e-03, eta: 2 days, 10:20:13, time: 1.285, data_time: 0.014, memory: 9759, decode.loss_seg: 1.5135, decode.acc_seg: 42.4068, loss: 1.5135
2021-08-14 04:27:29,081 - mmseg - INFO - Iter [4350/160000]	lr: 9.757e-03, eta: 2 days, 10:16:59, time: 1.278, data_time: 0.013, memory: 9759, decode.loss_seg: 1.5370, decode.acc_seg: 42.6644, loss: 1.5370
2021-08-14 04:28:32,255 - mmseg - INFO - Iter [4400/160000]	lr: 9.755e-03, eta: 2 days, 10:13:23, time: 1.264, data_time: 0.013, memory: 9759, decode.loss_seg: 1.5205, decode.acc_seg: 42.5195, loss: 1.5205
2021-08-14 04:30:09,655 - mmseg - INFO - Iter [4450/160000]	lr: 9.752e-03, eta: 2 days, 10:29:46, time: 1.948, data_time: 0.716, memory: 9759, decode.loss_seg: 1.4993, decode.acc_seg: 43.2367, loss: 1.4993
2021-08-14 04:31:12,664 - mmseg - INFO - Iter [4500/160000]	lr: 9.749e-03, eta: 2 days, 10:25:55, time: 1.259, data_time: 0.014, memory: 9759, decode.loss_seg: 1.5133, decode.acc_seg: 41.6864, loss: 1.5133
2021-08-14 04:32:15,438 - mmseg - INFO - Iter [4550/160000]	lr: 9.746e-03, eta: 2 days, 10:22:03, time: 1.256, data_time: 0.014, memory: 9759, decode.loss_seg: 1.5552, decode.acc_seg: 41.8919, loss: 1.5552
2021-08-14 04:33:19,221 - mmseg - INFO - Iter [4600/160000]	lr: 9.744e-03, eta: 2 days, 10:18:46, time: 1.275, data_time: 0.013, memory: 9759, decode.loss_seg: 1.5364, decode.acc_seg: 43.0798, loss: 1.5364
2021-08-14 04:34:22,389 - mmseg - INFO - Iter [4650/160000]	lr: 9.741e-03, eta: 2 days, 10:15:12, time: 1.264, data_time: 0.014, memory: 9759, decode.loss_seg: 1.4455, decode.acc_seg: 43.7131, loss: 1.4455
2021-08-14 04:35:25,678 - mmseg - INFO - Iter [4700/160000]	lr: 9.738e-03, eta: 2 days, 10:11:46, time: 1.266, data_time: 0.013, memory: 9759, decode.loss_seg: 1.4748, decode.acc_seg: 43.3430, loss: 1.4748
2021-08-14 04:36:30,016 - mmseg - INFO - Iter [4750/160000]	lr: 9.735e-03, eta: 2 days, 10:08:57, time: 1.287, data_time: 0.013, memory: 9759, decode.loss_seg: 1.4927, decode.acc_seg: 42.9491, loss: 1.4927
2021-08-14 04:37:33,116 - mmseg - INFO - Iter [4800/160000]	lr: 9.732e-03, eta: 2 days, 10:05:29, time: 1.261, data_time: 0.013, memory: 9759, decode.loss_seg: 1.4723, decode.acc_seg: 43.9037, loss: 1.4723
2021-08-14 04:38:37,544 - mmseg - INFO - Iter [4850/160000]	lr: 9.730e-03, eta: 2 days, 10:02:48, time: 1.289, data_time: 0.014, memory: 9759, decode.loss_seg: 1.5234, decode.acc_seg: 43.2863, loss: 1.5234
2021-08-14 04:39:40,418 - mmseg - INFO - Iter [4900/160000]	lr: 9.727e-03, eta: 2 days, 9:59:19, time: 1.257, data_time: 0.013, memory: 9759, decode.loss_seg: 1.4672, decode.acc_seg: 44.8722, loss: 1.4672
2021-08-14 04:40:47,130 - mmseg - INFO - Iter [4950/160000]	lr: 9.724e-03, eta: 2 days, 9:57:52, time: 1.334, data_time: 0.013, memory: 9759, decode.loss_seg: 1.5341, decode.acc_seg: 42.3643, loss: 1.5341
2021-08-14 04:41:53,851 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 04:41:53,851 - mmseg - INFO - Iter [5000/160000]	lr: 9.721e-03, eta: 2 days, 9:56:27, time: 1.334, data_time: 0.013, memory: 9759, decode.loss_seg: 1.5003, decode.acc_seg: 43.1676, loss: 1.5003
2021-08-14 04:43:32,822 - mmseg - INFO - Iter [5050/160000]	lr: 9.718e-03, eta: 2 days, 10:11:33, time: 1.980, data_time: 0.691, memory: 9759, decode.loss_seg: 1.4961, decode.acc_seg: 43.2100, loss: 1.4961
2021-08-14 04:44:35,090 - mmseg - INFO - Iter [5100/160000]	lr: 9.716e-03, eta: 2 days, 10:07:44, time: 1.245, data_time: 0.013, memory: 9759, decode.loss_seg: 1.3819, decode.acc_seg: 44.3990, loss: 1.3819
2021-08-14 04:45:38,812 - mmseg - INFO - Iter [5150/160000]	lr: 9.713e-03, eta: 2 days, 10:04:41, time: 1.274, data_time: 0.014, memory: 9759, decode.loss_seg: 1.4929, decode.acc_seg: 42.7480, loss: 1.4929
2021-08-14 04:46:41,531 - mmseg - INFO - Iter [5200/160000]	lr: 9.710e-03, eta: 2 days, 10:01:11, time: 1.255, data_time: 0.013, memory: 9759, decode.loss_seg: 1.4787, decode.acc_seg: 43.9205, loss: 1.4787
2021-08-14 04:47:43,968 - mmseg - INFO - Iter [5250/160000]	lr: 9.707e-03, eta: 2 days, 9:57:35, time: 1.249, data_time: 0.013, memory: 9759, decode.loss_seg: 1.4442, decode.acc_seg: 44.8497, loss: 1.4442
2021-08-14 04:48:47,671 - mmseg - INFO - Iter [5300/160000]	lr: 9.704e-03, eta: 2 days, 9:54:39, time: 1.274, data_time: 0.014, memory: 9759, decode.loss_seg: 1.4819, decode.acc_seg: 43.7421, loss: 1.4819
2021-08-14 04:49:50,737 - mmseg - INFO - Iter [5350/160000]	lr: 9.702e-03, eta: 2 days, 9:51:26, time: 1.261, data_time: 0.013, memory: 9759, decode.loss_seg: 1.5157, decode.acc_seg: 43.3517, loss: 1.5157
2021-08-14 04:50:54,737 - mmseg - INFO - Iter [5400/160000]	lr: 9.699e-03, eta: 2 days, 9:48:43, time: 1.280, data_time: 0.013, memory: 9759, decode.loss_seg: 1.4876, decode.acc_seg: 44.9277, loss: 1.4876
2021-08-14 04:51:59,530 - mmseg - INFO - Iter [5450/160000]	lr: 9.696e-03, eta: 2 days, 9:46:25, time: 1.297, data_time: 0.014, memory: 9759, decode.loss_seg: 1.4289, decode.acc_seg: 44.5843, loss: 1.4289
2021-08-14 04:53:05,160 - mmseg - INFO - Iter [5500/160000]	lr: 9.693e-03, eta: 2 days, 9:44:30, time: 1.312, data_time: 0.013, memory: 9759, decode.loss_seg: 1.3986, decode.acc_seg: 44.5979, loss: 1.3986
2021-08-14 04:54:12,153 - mmseg - INFO - Iter [5550/160000]	lr: 9.690e-03, eta: 2 days, 9:43:15, time: 1.340, data_time: 0.014, memory: 9759, decode.loss_seg: 1.4710, decode.acc_seg: 44.4995, loss: 1.4710
2021-08-14 04:55:19,644 - mmseg - INFO - Iter [5600/160000]	lr: 9.688e-03, eta: 2 days, 9:42:14, time: 1.350, data_time: 0.014, memory: 9759, decode.loss_seg: 1.4027, decode.acc_seg: 43.7477, loss: 1.4027
2021-08-14 04:56:25,569 - mmseg - INFO - Iter [5650/160000]	lr: 9.685e-03, eta: 2 days, 9:40:31, time: 1.319, data_time: 0.014, memory: 9759, decode.loss_seg: 1.4203, decode.acc_seg: 44.2569, loss: 1.4203
2021-08-14 04:58:05,032 - mmseg - INFO - Iter [5700/160000]	lr: 9.682e-03, eta: 2 days, 9:53:55, time: 1.989, data_time: 0.650, memory: 9759, decode.loss_seg: 1.4494, decode.acc_seg: 43.6865, loss: 1.4494
2021-08-14 04:59:07,770 - mmseg - INFO - Iter [5750/160000]	lr: 9.679e-03, eta: 2 days, 9:50:39, time: 1.255, data_time: 0.013, memory: 9759, decode.loss_seg: 1.4321, decode.acc_seg: 43.1398, loss: 1.4321
2021-08-14 05:00:12,356 - mmseg - INFO - Iter [5800/160000]	lr: 9.676e-03, eta: 2 days, 9:48:14, time: 1.292, data_time: 0.013, memory: 9759, decode.loss_seg: 1.4552, decode.acc_seg: 44.5131, loss: 1.4552
2021-08-14 05:01:15,207 - mmseg - INFO - Iter [5850/160000]	lr: 9.674e-03, eta: 2 days, 9:45:05, time: 1.257, data_time: 0.014, memory: 9759, decode.loss_seg: 1.4377, decode.acc_seg: 43.8492, loss: 1.4377
2021-08-14 05:02:19,161 - mmseg - INFO - Iter [5900/160000]	lr: 9.671e-03, eta: 2 days, 9:42:26, time: 1.279, data_time: 0.013, memory: 9759, decode.loss_seg: 1.4504, decode.acc_seg: 44.3967, loss: 1.4504
2021-08-14 05:03:23,857 - mmseg - INFO - Iter [5950/160000]	lr: 9.668e-03, eta: 2 days, 9:40:09, time: 1.294, data_time: 0.013, memory: 9759, decode.loss_seg: 1.4498, decode.acc_seg: 43.1897, loss: 1.4498
2021-08-14 05:04:27,541 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 05:04:27,541 - mmseg - INFO - Iter [6000/160000]	lr: 9.665e-03, eta: 2 days, 9:37:27, time: 1.274, data_time: 0.013, memory: 9759, decode.loss_seg: 1.3947, decode.acc_seg: 44.2890, loss: 1.3947
2021-08-14 05:05:28,025 - mmseg - INFO - Iter [6050/160000]	lr: 9.663e-03, eta: 2 days, 9:33:24, time: 1.209, data_time: 0.013, memory: 9759, decode.loss_seg: 1.4145, decode.acc_seg: 45.2906, loss: 1.4145
2021-08-14 05:06:31,470 - mmseg - INFO - Iter [6100/160000]	lr: 9.660e-03, eta: 2 days, 9:30:40, time: 1.269, data_time: 0.014, memory: 9759, decode.loss_seg: 1.4375, decode.acc_seg: 44.3681, loss: 1.4375
2021-08-14 05:07:34,823 - mmseg - INFO - Iter [6150/160000]	lr: 9.657e-03, eta: 2 days, 9:27:55, time: 1.267, data_time: 0.015, memory: 9759, decode.loss_seg: 1.4228, decode.acc_seg: 46.3412, loss: 1.4228
2021-08-14 05:08:35,779 - mmseg - INFO - Iter [6200/160000]	lr: 9.654e-03, eta: 2 days, 9:24:12, time: 1.219, data_time: 0.013, memory: 9759, decode.loss_seg: 1.4060, decode.acc_seg: 45.9102, loss: 1.4060
2021-08-14 05:09:39,667 - mmseg - INFO - Iter [6250/160000]	lr: 9.651e-03, eta: 2 days, 9:21:43, time: 1.277, data_time: 0.012, memory: 9759, decode.loss_seg: 1.4390, decode.acc_seg: 44.3000, loss: 1.4390
2021-08-14 05:10:44,087 - mmseg - INFO - Iter [6300/160000]	lr: 9.649e-03, eta: 2 days, 9:19:30, time: 1.288, data_time: 0.013, memory: 9759, decode.loss_seg: 1.4759, decode.acc_seg: 44.3360, loss: 1.4759
2021-08-14 05:12:23,016 - mmseg - INFO - Iter [6350/160000]	lr: 9.646e-03, eta: 2 days, 9:31:11, time: 1.978, data_time: 0.707, memory: 9759, decode.loss_seg: 1.4524, decode.acc_seg: 45.4468, loss: 1.4524
2021-08-14 05:13:26,286 - mmseg - INFO - Iter [6400/160000]	lr: 9.643e-03, eta: 2 days, 9:28:26, time: 1.266, data_time: 0.014, memory: 9759, decode.loss_seg: 1.3837, decode.acc_seg: 45.5650, loss: 1.3837
2021-08-14 05:14:30,961 - mmseg - INFO - Iter [6450/160000]	lr: 9.640e-03, eta: 2 days, 9:26:14, time: 1.293, data_time: 0.013, memory: 9759, decode.loss_seg: 1.3996, decode.acc_seg: 44.5167, loss: 1.3996
2021-08-14 05:15:34,134 - mmseg - INFO - Iter [6500/160000]	lr: 9.637e-03, eta: 2 days, 9:23:29, time: 1.264, data_time: 0.013, memory: 9759, decode.loss_seg: 1.4464, decode.acc_seg: 44.0562, loss: 1.4464
2021-08-14 05:16:35,488 - mmseg - INFO - Iter [6550/160000]	lr: 9.635e-03, eta: 2 days, 9:20:02, time: 1.227, data_time: 0.012, memory: 9759, decode.loss_seg: 1.4174, decode.acc_seg: 44.1499, loss: 1.4174
2021-08-14 05:17:43,756 - mmseg - INFO - Iter [6600/160000]	lr: 9.632e-03, eta: 2 days, 9:19:18, time: 1.365, data_time: 0.013, memory: 9759, decode.loss_seg: 1.3966, decode.acc_seg: 44.8095, loss: 1.3966
2021-08-14 05:18:48,546 - mmseg - INFO - Iter [6650/160000]	lr: 9.629e-03, eta: 2 days, 9:17:15, time: 1.297, data_time: 0.014, memory: 9759, decode.loss_seg: 1.4106, decode.acc_seg: 44.9442, loss: 1.4106
2021-08-14 05:19:51,492 - mmseg - INFO - Iter [6700/160000]	lr: 9.626e-03, eta: 2 days, 9:14:29, time: 1.258, data_time: 0.013, memory: 9759, decode.loss_seg: 1.3784, decode.acc_seg: 46.7275, loss: 1.3784
2021-08-14 05:20:54,136 - mmseg - INFO - Iter [6750/160000]	lr: 9.623e-03, eta: 2 days, 9:11:38, time: 1.254, data_time: 0.013, memory: 9759, decode.loss_seg: 1.3951, decode.acc_seg: 44.7996, loss: 1.3951
2021-08-14 05:22:00,891 - mmseg - INFO - Iter [6800/160000]	lr: 9.621e-03, eta: 2 days, 9:10:22, time: 1.335, data_time: 0.015, memory: 9759, decode.loss_seg: 1.4274, decode.acc_seg: 45.4644, loss: 1.4274
2021-08-14 05:23:05,618 - mmseg - INFO - Iter [6850/160000]	lr: 9.618e-03, eta: 2 days, 9:08:20, time: 1.295, data_time: 0.015, memory: 9759, decode.loss_seg: 1.4275, decode.acc_seg: 44.9250, loss: 1.4275
2021-08-14 05:24:09,662 - mmseg - INFO - Iter [6900/160000]	lr: 9.615e-03, eta: 2 days, 9:06:03, time: 1.280, data_time: 0.013, memory: 9759, decode.loss_seg: 1.4073, decode.acc_seg: 46.1465, loss: 1.4073
2021-08-14 05:25:47,151 - mmseg - INFO - Iter [6950/160000]	lr: 9.612e-03, eta: 2 days, 9:16:04, time: 1.950, data_time: 0.691, memory: 9759, decode.loss_seg: 1.3611, decode.acc_seg: 45.4099, loss: 1.3611
2021-08-14 05:26:51,887 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 05:26:51,887 - mmseg - INFO - Iter [7000/160000]	lr: 9.609e-03, eta: 2 days, 9:14:00, time: 1.296, data_time: 0.015, memory: 9759, decode.loss_seg: 1.3880, decode.acc_seg: 45.2939, loss: 1.3880
2021-08-14 05:27:56,376 - mmseg - INFO - Iter [7050/160000]	lr: 9.607e-03, eta: 2 days, 9:11:50, time: 1.289, data_time: 0.013, memory: 9759, decode.loss_seg: 1.4017, decode.acc_seg: 45.6021, loss: 1.4017
2021-08-14 05:29:02,696 - mmseg - INFO - Iter [7100/160000]	lr: 9.604e-03, eta: 2 days, 9:10:22, time: 1.326, data_time: 0.014, memory: 9759, decode.loss_seg: 1.3956, decode.acc_seg: 44.8190, loss: 1.3956
2021-08-14 05:30:07,930 - mmseg - INFO - Iter [7150/160000]	lr: 9.601e-03, eta: 2 days, 9:08:30, time: 1.305, data_time: 0.014, memory: 9759, decode.loss_seg: 1.3781, decode.acc_seg: 45.7405, loss: 1.3781
2021-08-14 05:31:11,910 - mmseg - INFO - Iter [7200/160000]	lr: 9.598e-03, eta: 2 days, 9:06:13, time: 1.280, data_time: 0.014, memory: 9759, decode.loss_seg: 1.3238, decode.acc_seg: 45.8251, loss: 1.3238
2021-08-14 05:32:14,913 - mmseg - INFO - Iter [7250/160000]	lr: 9.595e-03, eta: 2 days, 9:03:36, time: 1.261, data_time: 0.013, memory: 9759, decode.loss_seg: 1.3659, decode.acc_seg: 46.4443, loss: 1.3659
2021-08-14 05:33:18,962 - mmseg - INFO - Iter [7300/160000]	lr: 9.593e-03, eta: 2 days, 9:01:21, time: 1.280, data_time: 0.013, memory: 9759, decode.loss_seg: 1.3900, decode.acc_seg: 46.0325, loss: 1.3900
2021-08-14 05:34:23,770 - mmseg - INFO - Iter [7350/160000]	lr: 9.590e-03, eta: 2 days, 8:59:24, time: 1.296, data_time: 0.014, memory: 9759, decode.loss_seg: 1.3870, decode.acc_seg: 45.5686, loss: 1.3870
2021-08-14 05:35:28,863 - mmseg - INFO - Iter [7400/160000]	lr: 9.587e-03, eta: 2 days, 8:57:34, time: 1.303, data_time: 0.014, memory: 9759, decode.loss_seg: 1.3411, decode.acc_seg: 45.9515, loss: 1.3411
2021-08-14 05:36:33,676 - mmseg - INFO - Iter [7450/160000]	lr: 9.584e-03, eta: 2 days, 8:55:38, time: 1.296, data_time: 0.013, memory: 9759, decode.loss_seg: 1.3877, decode.acc_seg: 46.6093, loss: 1.3877
2021-08-14 05:37:36,495 - mmseg - INFO - Iter [7500/160000]	lr: 9.581e-03, eta: 2 days, 8:53:02, time: 1.256, data_time: 0.013, memory: 9759, decode.loss_seg: 1.4449, decode.acc_seg: 45.0956, loss: 1.4449
2021-08-14 05:38:37,532 - mmseg - INFO - Iter [7550/160000]	lr: 9.579e-03, eta: 2 days, 8:49:52, time: 1.221, data_time: 0.014, memory: 9759, decode.loss_seg: 1.3716, decode.acc_seg: 45.9062, loss: 1.3716
2021-08-14 05:40:16,411 - mmseg - INFO - Iter [7600/160000]	lr: 9.576e-03, eta: 2 days, 8:59:22, time: 1.977, data_time: 0.703, memory: 9759, decode.loss_seg: 1.3259, decode.acc_seg: 46.0973, loss: 1.3259
2021-08-14 05:41:18,128 - mmseg - INFO - Iter [7650/160000]	lr: 9.573e-03, eta: 2 days, 8:56:24, time: 1.235, data_time: 0.013, memory: 9759, decode.loss_seg: 1.3593, decode.acc_seg: 45.9391, loss: 1.3593
2021-08-14 05:42:22,597 - mmseg - INFO - Iter [7700/160000]	lr: 9.570e-03, eta: 2 days, 8:54:21, time: 1.289, data_time: 0.014, memory: 9759, decode.loss_seg: 1.3430, decode.acc_seg: 46.8294, loss: 1.3430
2021-08-14 05:43:24,949 - mmseg - INFO - Iter [7750/160000]	lr: 9.567e-03, eta: 2 days, 8:51:37, time: 1.247, data_time: 0.013, memory: 9759, decode.loss_seg: 1.3641, decode.acc_seg: 45.5609, loss: 1.3641
2021-08-14 05:44:28,404 - mmseg - INFO - Iter [7800/160000]	lr: 9.565e-03, eta: 2 days, 8:49:16, time: 1.269, data_time: 0.012, memory: 9759, decode.loss_seg: 1.3745, decode.acc_seg: 45.1334, loss: 1.3745
2021-08-14 05:45:29,793 - mmseg - INFO - Iter [7850/160000]	lr: 9.562e-03, eta: 2 days, 8:46:17, time: 1.228, data_time: 0.013, memory: 9759, decode.loss_seg: 1.3351, decode.acc_seg: 46.2989, loss: 1.3351
2021-08-14 05:46:31,609 - mmseg - INFO - Iter [7900/160000]	lr: 9.559e-03, eta: 2 days, 8:43:27, time: 1.237, data_time: 0.013, memory: 9759, decode.loss_seg: 1.3775, decode.acc_seg: 45.5599, loss: 1.3775
2021-08-14 05:47:36,969 - mmseg - INFO - Iter [7950/160000]	lr: 9.556e-03, eta: 2 days, 8:41:46, time: 1.307, data_time: 0.015, memory: 9759, decode.loss_seg: 1.3571, decode.acc_seg: 46.4067, loss: 1.3571
2021-08-14 05:48:43,288 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 05:48:43,288 - mmseg - INFO - Iter [8000/160000]	lr: 9.553e-03, eta: 2 days, 8:40:23, time: 1.326, data_time: 0.015, memory: 9759, decode.loss_seg: 1.3609, decode.acc_seg: 45.9656, loss: 1.3609
2021-08-14 05:49:46,636 - mmseg - INFO - Iter [8050/160000]	lr: 9.551e-03, eta: 2 days, 8:38:05, time: 1.267, data_time: 0.014, memory: 9759, decode.loss_seg: 1.3336, decode.acc_seg: 46.4992, loss: 1.3336
2021-08-14 05:50:49,186 - mmseg - INFO - Iter [8100/160000]	lr: 9.548e-03, eta: 2 days, 8:35:32, time: 1.251, data_time: 0.013, memory: 9759, decode.loss_seg: 1.3619, decode.acc_seg: 46.9506, loss: 1.3619
2021-08-14 05:51:51,219 - mmseg - INFO - Iter [8150/160000]	lr: 9.545e-03, eta: 2 days, 8:32:52, time: 1.241, data_time: 0.012, memory: 9759, decode.loss_seg: 1.3717, decode.acc_seg: 46.3467, loss: 1.3717
2021-08-14 05:52:52,553 - mmseg - INFO - Iter [8200/160000]	lr: 9.542e-03, eta: 2 days, 8:30:00, time: 1.227, data_time: 0.014, memory: 9759, decode.loss_seg: 1.3584, decode.acc_seg: 45.3735, loss: 1.3584
2021-08-14 05:54:30,814 - mmseg - INFO - Iter [8250/160000]	lr: 9.539e-03, eta: 2 days, 8:38:27, time: 1.965, data_time: 0.711, memory: 9759, decode.loss_seg: 1.2966, decode.acc_seg: 46.9348, loss: 1.2966
2021-08-14 05:55:36,129 - mmseg - INFO - Iter [8300/160000]	lr: 9.537e-03, eta: 2 days, 8:36:46, time: 1.306, data_time: 0.014, memory: 9759, decode.loss_seg: 1.3673, decode.acc_seg: 46.2524, loss: 1.3673
2021-08-14 05:56:39,707 - mmseg - INFO - Iter [8350/160000]	lr: 9.534e-03, eta: 2 days, 8:34:33, time: 1.272, data_time: 0.013, memory: 9759, decode.loss_seg: 1.3585, decode.acc_seg: 46.8238, loss: 1.3585
2021-08-14 05:57:46,087 - mmseg - INFO - Iter [8400/160000]	lr: 9.531e-03, eta: 2 days, 8:33:11, time: 1.327, data_time: 0.014, memory: 9759, decode.loss_seg: 1.3168, decode.acc_seg: 46.6588, loss: 1.3168
2021-08-14 05:58:53,359 - mmseg - INFO - Iter [8450/160000]	lr: 9.528e-03, eta: 2 days, 8:32:07, time: 1.345, data_time: 0.014, memory: 9759, decode.loss_seg: 1.3379, decode.acc_seg: 46.0590, loss: 1.3379
2021-08-14 06:00:00,354 - mmseg - INFO - Iter [8500/160000]	lr: 9.525e-03, eta: 2 days, 8:30:58, time: 1.341, data_time: 0.014, memory: 9759, decode.loss_seg: 1.3363, decode.acc_seg: 46.0760, loss: 1.3363
2021-08-14 06:01:07,186 - mmseg - INFO - Iter [8550/160000]	lr: 9.523e-03, eta: 2 days, 8:29:45, time: 1.336, data_time: 0.012, memory: 9759, decode.loss_seg: 1.3622, decode.acc_seg: 45.8755, loss: 1.3622
2021-08-14 06:02:09,538 - mmseg - INFO - Iter [8600/160000]	lr: 9.520e-03, eta: 2 days, 8:27:13, time: 1.247, data_time: 0.013, memory: 9759, decode.loss_seg: 1.3377, decode.acc_seg: 46.6306, loss: 1.3377
2021-08-14 06:03:15,640 - mmseg - INFO - Iter [8650/160000]	lr: 9.517e-03, eta: 2 days, 8:25:48, time: 1.322, data_time: 0.013, memory: 9759, decode.loss_seg: 1.3486, decode.acc_seg: 46.5332, loss: 1.3486
2021-08-14 06:04:18,497 - mmseg - INFO - Iter [8700/160000]	lr: 9.514e-03, eta: 2 days, 8:23:27, time: 1.258, data_time: 0.014, memory: 9759, decode.loss_seg: 1.3201, decode.acc_seg: 47.0603, loss: 1.3201
2021-08-14 06:05:23,398 - mmseg - INFO - Iter [8750/160000]	lr: 9.511e-03, eta: 2 days, 8:21:41, time: 1.297, data_time: 0.013, memory: 9759, decode.loss_seg: 1.3202, decode.acc_seg: 46.5671, loss: 1.3202
2021-08-14 06:06:26,175 - mmseg - INFO - Iter [8800/160000]	lr: 9.509e-03, eta: 2 days, 8:19:21, time: 1.257, data_time: 0.014, memory: 9759, decode.loss_seg: 1.3227, decode.acc_seg: 46.1253, loss: 1.3227
2021-08-14 06:08:13,439 - mmseg - INFO - Iter [8850/160000]	lr: 9.506e-03, eta: 2 days, 8:29:41, time: 2.145, data_time: 0.836, memory: 9759, decode.loss_seg: 1.3556, decode.acc_seg: 46.0185, loss: 1.3556
2021-08-14 06:09:17,876 - mmseg - INFO - Iter [8900/160000]	lr: 9.503e-03, eta: 2 days, 8:27:45, time: 1.289, data_time: 0.015, memory: 9759, decode.loss_seg: 1.2996, decode.acc_seg: 47.0220, loss: 1.2996
2021-08-14 06:10:20,896 - mmseg - INFO - Iter [8950/160000]	lr: 9.500e-03, eta: 2 days, 8:25:27, time: 1.261, data_time: 0.014, memory: 9759, decode.loss_seg: 1.3059, decode.acc_seg: 46.7756, loss: 1.3059
2021-08-14 06:11:24,829 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 06:11:24,829 - mmseg - INFO - Iter [9000/160000]	lr: 9.497e-03, eta: 2 days, 8:23:24, time: 1.278, data_time: 0.013, memory: 9759, decode.loss_seg: 1.3362, decode.acc_seg: 46.4745, loss: 1.3362
2021-08-14 06:12:26,534 - mmseg - INFO - Iter [9050/160000]	lr: 9.495e-03, eta: 2 days, 8:20:45, time: 1.235, data_time: 0.013, memory: 9759, decode.loss_seg: 1.3184, decode.acc_seg: 46.8066, loss: 1.3184
2021-08-14 06:13:32,276 - mmseg - INFO - Iter [9100/160000]	lr: 9.492e-03, eta: 2 days, 8:19:13, time: 1.314, data_time: 0.014, memory: 9759, decode.loss_seg: 1.3036, decode.acc_seg: 46.6260, loss: 1.3036
2021-08-14 06:14:36,898 - mmseg - INFO - Iter [9150/160000]	lr: 9.489e-03, eta: 2 days, 8:17:24, time: 1.293, data_time: 0.013, memory: 9759, decode.loss_seg: 1.3413, decode.acc_seg: 47.3232, loss: 1.3413
2021-08-14 06:15:41,397 - mmseg - INFO - Iter [9200/160000]	lr: 9.486e-03, eta: 2 days, 8:15:34, time: 1.291, data_time: 0.014, memory: 9759, decode.loss_seg: 1.3281, decode.acc_seg: 46.4846, loss: 1.3281
2021-08-14 06:16:45,136 - mmseg - INFO - Iter [9250/160000]	lr: 9.483e-03, eta: 2 days, 8:13:30, time: 1.274, data_time: 0.012, memory: 9759, decode.loss_seg: 1.2646, decode.acc_seg: 46.8378, loss: 1.2646
2021-08-14 06:17:50,875 - mmseg - INFO - Iter [9300/160000]	lr: 9.481e-03, eta: 2 days, 8:12:01, time: 1.315, data_time: 0.013, memory: 9759, decode.loss_seg: 1.3162, decode.acc_seg: 46.7358, loss: 1.3162
2021-08-14 06:18:53,459 - mmseg - INFO - Iter [9350/160000]	lr: 9.478e-03, eta: 2 days, 8:09:40, time: 1.252, data_time: 0.013, memory: 9759, decode.loss_seg: 1.3615, decode.acc_seg: 46.6940, loss: 1.3615
2021-08-14 06:19:58,146 - mmseg - INFO - Iter [9400/160000]	lr: 9.475e-03, eta: 2 days, 8:07:54, time: 1.294, data_time: 0.014, memory: 9759, decode.loss_seg: 1.3063, decode.acc_seg: 46.6535, loss: 1.3063
2021-08-14 06:21:01,592 - mmseg - INFO - Iter [9450/160000]	lr: 9.472e-03, eta: 2 days, 8:05:49, time: 1.269, data_time: 0.013, memory: 9759, decode.loss_seg: 1.3458, decode.acc_seg: 45.6583, loss: 1.3458
2021-08-14 06:22:40,599 - mmseg - INFO - Iter [9500/160000]	lr: 9.469e-03, eta: 2 days, 8:13:08, time: 1.979, data_time: 0.714, memory: 9759, decode.loss_seg: 1.2613, decode.acc_seg: 48.6596, loss: 1.2613
2021-08-14 06:23:46,845 - mmseg - INFO - Iter [9550/160000]	lr: 9.467e-03, eta: 2 days, 8:11:45, time: 1.326, data_time: 0.014, memory: 9759, decode.loss_seg: 1.2955, decode.acc_seg: 46.9028, loss: 1.2955
2021-08-14 06:24:51,618 - mmseg - INFO - Iter [9600/160000]	lr: 9.464e-03, eta: 2 days, 8:10:00, time: 1.296, data_time: 0.013, memory: 9759, decode.loss_seg: 1.3190, decode.acc_seg: 47.3812, loss: 1.3190
2021-08-14 06:25:58,623 - mmseg - INFO - Iter [9650/160000]	lr: 9.461e-03, eta: 2 days, 8:08:49, time: 1.340, data_time: 0.013, memory: 9759, decode.loss_seg: 1.3282, decode.acc_seg: 47.2049, loss: 1.3282
2021-08-14 06:27:05,298 - mmseg - INFO - Iter [9700/160000]	lr: 9.458e-03, eta: 2 days, 8:07:33, time: 1.333, data_time: 0.014, memory: 9759, decode.loss_seg: 1.2975, decode.acc_seg: 46.7831, loss: 1.2975
2021-08-14 06:28:11,927 - mmseg - INFO - Iter [9750/160000]	lr: 9.455e-03, eta: 2 days, 8:06:17, time: 1.334, data_time: 0.015, memory: 9759, decode.loss_seg: 1.2549, decode.acc_seg: 49.0596, loss: 1.2549
2021-08-14 06:29:17,709 - mmseg - INFO - Iter [9800/160000]	lr: 9.453e-03, eta: 2 days, 8:04:48, time: 1.316, data_time: 0.015, memory: 9759, decode.loss_seg: 1.2975, decode.acc_seg: 47.2486, loss: 1.2975
2021-08-14 06:30:20,844 - mmseg - INFO - Iter [9850/160000]	lr: 9.450e-03, eta: 2 days, 8:02:38, time: 1.262, data_time: 0.013, memory: 9759, decode.loss_seg: 1.2801, decode.acc_seg: 47.7761, loss: 1.2801
2021-08-14 06:31:25,849 - mmseg - INFO - Iter [9900/160000]	lr: 9.447e-03, eta: 2 days, 8:00:58, time: 1.300, data_time: 0.013, memory: 9759, decode.loss_seg: 1.3033, decode.acc_seg: 48.5485, loss: 1.3033
2021-08-14 06:32:30,629 - mmseg - INFO - Iter [9950/160000]	lr: 9.444e-03, eta: 2 days, 7:59:15, time: 1.296, data_time: 0.013, memory: 9759, decode.loss_seg: 1.2828, decode.acc_seg: 46.4664, loss: 1.2828
2021-08-14 06:33:34,244 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 06:33:34,245 - mmseg - INFO - Iter [10000/160000]	lr: 9.441e-03, eta: 2 days, 7:57:15, time: 1.272, data_time: 0.014, memory: 9759, decode.loss_seg: 1.3114, decode.acc_seg: 47.3922, loss: 1.3114
2021-08-14 06:34:36,215 - mmseg - INFO - Iter [10050/160000]	lr: 9.439e-03, eta: 2 days, 7:54:50, time: 1.240, data_time: 0.014, memory: 9759, decode.loss_seg: 1.2815, decode.acc_seg: 47.7539, loss: 1.2815
2021-08-14 06:36:14,836 - mmseg - INFO - Iter [10100/160000]	lr: 9.436e-03, eta: 2 days, 8:01:30, time: 1.972, data_time: 0.659, memory: 9759, decode.loss_seg: 1.3096, decode.acc_seg: 46.7727, loss: 1.3096
2021-08-14 06:37:16,738 - mmseg - INFO - Iter [10150/160000]	lr: 9.433e-03, eta: 2 days, 7:59:04, time: 1.239, data_time: 0.015, memory: 9759, decode.loss_seg: 1.2494, decode.acc_seg: 48.3701, loss: 1.2494
2021-08-14 06:38:17,571 - mmseg - INFO - Iter [10200/160000]	lr: 9.430e-03, eta: 2 days, 7:56:22, time: 1.216, data_time: 0.013, memory: 9759, decode.loss_seg: 1.2496, decode.acc_seg: 48.9962, loss: 1.2496
2021-08-14 06:39:20,319 - mmseg - INFO - Iter [10250/160000]	lr: 9.427e-03, eta: 2 days, 7:54:10, time: 1.255, data_time: 0.014, memory: 9759, decode.loss_seg: 1.2894, decode.acc_seg: 47.6220, loss: 1.2894
2021-08-14 06:40:22,884 - mmseg - INFO - Iter [10300/160000]	lr: 9.425e-03, eta: 2 days, 7:51:56, time: 1.251, data_time: 0.013, memory: 9759, decode.loss_seg: 1.2734, decode.acc_seg: 47.9118, loss: 1.2734
2021-08-14 06:41:25,201 - mmseg - INFO - Iter [10350/160000]	lr: 9.422e-03, eta: 2 days, 7:49:38, time: 1.246, data_time: 0.013, memory: 9759, decode.loss_seg: 1.2893, decode.acc_seg: 47.3875, loss: 1.2893
2021-08-14 06:42:27,393 - mmseg - INFO - Iter [10400/160000]	lr: 9.419e-03, eta: 2 days, 7:47:20, time: 1.244, data_time: 0.014, memory: 9759, decode.loss_seg: 1.2781, decode.acc_seg: 47.7927, loss: 1.2781
2021-08-14 06:43:28,728 - mmseg - INFO - Iter [10450/160000]	lr: 9.416e-03, eta: 2 days, 7:44:49, time: 1.226, data_time: 0.013, memory: 9759, decode.loss_seg: 1.3015, decode.acc_seg: 47.1577, loss: 1.3015
2021-08-14 06:44:31,527 - mmseg - INFO - Iter [10500/160000]	lr: 9.413e-03, eta: 2 days, 7:42:41, time: 1.256, data_time: 0.013, memory: 9759, decode.loss_seg: 1.2752, decode.acc_seg: 47.1806, loss: 1.2752
2021-08-14 06:45:34,623 - mmseg - INFO - Iter [10550/160000]	lr: 9.411e-03, eta: 2 days, 7:40:38, time: 1.262, data_time: 0.013, memory: 9759, decode.loss_seg: 1.2917, decode.acc_seg: 47.1708, loss: 1.2917
2021-08-14 06:46:40,174 - mmseg - INFO - Iter [10600/160000]	lr: 9.408e-03, eta: 2 days, 7:39:09, time: 1.310, data_time: 0.013, memory: 9759, decode.loss_seg: 1.2663, decode.acc_seg: 48.7286, loss: 1.2663
2021-08-14 06:47:42,736 - mmseg - INFO - Iter [10650/160000]	lr: 9.405e-03, eta: 2 days, 7:37:00, time: 1.252, data_time: 0.014, memory: 9759, decode.loss_seg: 1.2615, decode.acc_seg: 47.6524, loss: 1.2615
2021-08-14 06:48:45,104 - mmseg - INFO - Iter [10700/160000]	lr: 9.402e-03, eta: 2 days, 7:34:48, time: 1.247, data_time: 0.013, memory: 9759, decode.loss_seg: 1.3141, decode.acc_seg: 47.3402, loss: 1.3141
2021-08-14 06:50:24,292 - mmseg - INFO - Iter [10750/160000]	lr: 9.399e-03, eta: 2 days, 7:41:07, time: 1.983, data_time: 0.722, memory: 9759, decode.loss_seg: 1.2647, decode.acc_seg: 47.4320, loss: 1.2647
2021-08-14 06:51:28,706 - mmseg - INFO - Iter [10800/160000]	lr: 9.397e-03, eta: 2 days, 7:39:22, time: 1.288, data_time: 0.014, memory: 9759, decode.loss_seg: 1.2379, decode.acc_seg: 47.9455, loss: 1.2379
2021-08-14 06:52:32,845 - mmseg - INFO - Iter [10850/160000]	lr: 9.394e-03, eta: 2 days, 7:37:34, time: 1.284, data_time: 0.013, memory: 9759, decode.loss_seg: 1.2820, decode.acc_seg: 47.9208, loss: 1.2820
2021-08-14 06:53:34,481 - mmseg - INFO - Iter [10900/160000]	lr: 9.391e-03, eta: 2 days, 7:35:12, time: 1.233, data_time: 0.014, memory: 9759, decode.loss_seg: 1.2911, decode.acc_seg: 47.6451, loss: 1.2911
2021-08-14 06:54:35,798 - mmseg - INFO - Iter [10950/160000]	lr: 9.388e-03, eta: 2 days, 7:32:45, time: 1.226, data_time: 0.014, memory: 9759, decode.loss_seg: 1.2494, decode.acc_seg: 47.1890, loss: 1.2494
2021-08-14 06:55:38,657 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 06:55:38,657 - mmseg - INFO - Iter [11000/160000]	lr: 9.385e-03, eta: 2 days, 7:30:41, time: 1.258, data_time: 0.014, memory: 9759, decode.loss_seg: 1.2829, decode.acc_seg: 48.2201, loss: 1.2829
2021-08-14 06:56:42,883 - mmseg - INFO - Iter [11050/160000]	lr: 9.383e-03, eta: 2 days, 7:28:56, time: 1.285, data_time: 0.013, memory: 9759, decode.loss_seg: 1.2889, decode.acc_seg: 47.5023, loss: 1.2889
2021-08-14 06:57:46,841 - mmseg - INFO - Iter [11100/160000]	lr: 9.380e-03, eta: 2 days, 7:27:07, time: 1.279, data_time: 0.013, memory: 9759, decode.loss_seg: 1.2714, decode.acc_seg: 47.3627, loss: 1.2714
2021-08-14 06:58:51,965 - mmseg - INFO - Iter [11150/160000]	lr: 9.377e-03, eta: 2 days, 7:25:35, time: 1.303, data_time: 0.015, memory: 9759, decode.loss_seg: 1.2896, decode.acc_seg: 47.0506, loss: 1.2896
2021-08-14 06:59:54,864 - mmseg - INFO - Iter [11200/160000]	lr: 9.374e-03, eta: 2 days, 7:23:33, time: 1.258, data_time: 0.013, memory: 9759, decode.loss_seg: 1.2432, decode.acc_seg: 48.4242, loss: 1.2432
2021-08-14 07:00:58,284 - mmseg - INFO - Iter [11250/160000]	lr: 9.371e-03, eta: 2 days, 7:21:38, time: 1.268, data_time: 0.014, memory: 9759, decode.loss_seg: 1.2850, decode.acc_seg: 47.2279, loss: 1.2850
2021-08-14 07:02:01,606 - mmseg - INFO - Iter [11300/160000]	lr: 9.369e-03, eta: 2 days, 7:19:43, time: 1.267, data_time: 0.014, memory: 9759, decode.loss_seg: 1.2965, decode.acc_seg: 47.5339, loss: 1.2965
2021-08-14 07:03:05,976 - mmseg - INFO - Iter [11350/160000]	lr: 9.366e-03, eta: 2 days, 7:18:02, time: 1.288, data_time: 0.015, memory: 9759, decode.loss_seg: 1.2457, decode.acc_seg: 48.8681, loss: 1.2457
2021-08-14 07:04:43,000 - mmseg - INFO - Iter [11400/160000]	lr: 9.363e-03, eta: 2 days, 7:23:27, time: 1.940, data_time: 0.695, memory: 9759, decode.loss_seg: 1.2401, decode.acc_seg: 48.0421, loss: 1.2401
2021-08-14 07:05:50,434 - mmseg - INFO - Iter [11450/160000]	lr: 9.360e-03, eta: 2 days, 7:22:25, time: 1.350, data_time: 0.016, memory: 9759, decode.loss_seg: 1.2950, decode.acc_seg: 47.9847, loss: 1.2950
2021-08-14 07:06:54,318 - mmseg - INFO - Iter [11500/160000]	lr: 9.357e-03, eta: 2 days, 7:20:36, time: 1.277, data_time: 0.013, memory: 9759, decode.loss_seg: 1.2725, decode.acc_seg: 47.5400, loss: 1.2725
2021-08-14 07:08:02,158 - mmseg - INFO - Iter [11550/160000]	lr: 9.354e-03, eta: 2 days, 7:19:38, time: 1.356, data_time: 0.013, memory: 9759, decode.loss_seg: 1.2679, decode.acc_seg: 48.8166, loss: 1.2679
2021-08-14 07:09:10,086 - mmseg - INFO - Iter [11600/160000]	lr: 9.352e-03, eta: 2 days, 7:18:41, time: 1.358, data_time: 0.014, memory: 9759, decode.loss_seg: 1.2432, decode.acc_seg: 48.5393, loss: 1.2432
2021-08-14 07:10:18,285 - mmseg - INFO - Iter [11650/160000]	lr: 9.349e-03, eta: 2 days, 7:17:49, time: 1.364, data_time: 0.014, memory: 9759, decode.loss_seg: 1.2567, decode.acc_seg: 48.7480, loss: 1.2567
2021-08-14 07:11:26,413 - mmseg - INFO - Iter [11700/160000]	lr: 9.346e-03, eta: 2 days, 7:16:55, time: 1.363, data_time: 0.014, memory: 9759, decode.loss_seg: 1.2282, decode.acc_seg: 49.4697, loss: 1.2282
2021-08-14 07:12:31,261 - mmseg - INFO - Iter [11750/160000]	lr: 9.343e-03, eta: 2 days, 7:15:20, time: 1.298, data_time: 0.013, memory: 9759, decode.loss_seg: 1.2222, decode.acc_seg: 49.0493, loss: 1.2222
2021-08-14 07:13:33,814 - mmseg - INFO - Iter [11800/160000]	lr: 9.340e-03, eta: 2 days, 7:13:15, time: 1.251, data_time: 0.014, memory: 9759, decode.loss_seg: 1.2646, decode.acc_seg: 48.3682, loss: 1.2646
2021-08-14 07:14:37,566 - mmseg - INFO - Iter [11850/160000]	lr: 9.338e-03, eta: 2 days, 7:11:27, time: 1.275, data_time: 0.014, memory: 9759, decode.loss_seg: 1.2952, decode.acc_seg: 47.1522, loss: 1.2952
2021-08-14 07:15:39,738 - mmseg - INFO - Iter [11900/160000]	lr: 9.335e-03, eta: 2 days, 7:09:19, time: 1.244, data_time: 0.013, memory: 9759, decode.loss_seg: 1.2351, decode.acc_seg: 47.7413, loss: 1.2351
2021-08-14 07:16:42,759 - mmseg - INFO - Iter [11950/160000]	lr: 9.332e-03, eta: 2 days, 7:07:22, time: 1.260, data_time: 0.013, memory: 9759, decode.loss_seg: 1.2503, decode.acc_seg: 49.0517, loss: 1.2503
2021-08-14 07:18:21,809 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 07:18:21,813 - mmseg - INFO - Iter [12000/160000]	lr: 9.329e-03, eta: 2 days, 7:12:50, time: 1.980, data_time: 0.724, memory: 9759, decode.loss_seg: 1.2606, decode.acc_seg: 48.0239, loss: 1.2606
2021-08-14 07:19:26,220 - mmseg - INFO - Iter [12050/160000]	lr: 9.326e-03, eta: 2 days, 7:11:09, time: 1.288, data_time: 0.014, memory: 9759, decode.loss_seg: 1.2529, decode.acc_seg: 47.9062, loss: 1.2529
2021-08-14 07:20:32,261 - mmseg - INFO - Iter [12100/160000]	lr: 9.324e-03, eta: 2 days, 7:09:49, time: 1.321, data_time: 0.014, memory: 9759, decode.loss_seg: 1.2351, decode.acc_seg: 48.7440, loss: 1.2351
2021-08-14 07:21:34,885 - mmseg - INFO - Iter [12150/160000]	lr: 9.321e-03, eta: 2 days, 7:07:47, time: 1.253, data_time: 0.014, memory: 9759, decode.loss_seg: 1.2496, decode.acc_seg: 48.2829, loss: 1.2496
2021-08-14 07:22:36,899 - mmseg - INFO - Iter [12200/160000]	lr: 9.318e-03, eta: 2 days, 7:05:38, time: 1.240, data_time: 0.014, memory: 9759, decode.loss_seg: 1.2716, decode.acc_seg: 47.5259, loss: 1.2716
2021-08-14 07:23:40,621 - mmseg - INFO - Iter [12250/160000]	lr: 9.315e-03, eta: 2 days, 7:03:50, time: 1.275, data_time: 0.014, memory: 9759, decode.loss_seg: 1.2332, decode.acc_seg: 49.6398, loss: 1.2332
2021-08-14 07:24:43,460 - mmseg - INFO - Iter [12300/160000]	lr: 9.312e-03, eta: 2 days, 7:01:52, time: 1.257, data_time: 0.013, memory: 9759, decode.loss_seg: 1.2423, decode.acc_seg: 48.2463, loss: 1.2423
2021-08-14 07:25:47,072 - mmseg - INFO - Iter [12350/160000]	lr: 9.310e-03, eta: 2 days, 7:00:04, time: 1.272, data_time: 0.013, memory: 9759, decode.loss_seg: 1.2292, decode.acc_seg: 48.7534, loss: 1.2292
2021-08-14 07:26:51,352 - mmseg - INFO - Iter [12400/160000]	lr: 9.307e-03, eta: 2 days, 6:58:23, time: 1.285, data_time: 0.013, memory: 9759, decode.loss_seg: 1.2129, decode.acc_seg: 48.3628, loss: 1.2129
2021-08-14 07:27:54,309 - mmseg - INFO - Iter [12450/160000]	lr: 9.304e-03, eta: 2 days, 6:56:28, time: 1.259, data_time: 0.014, memory: 9759, decode.loss_seg: 1.2503, decode.acc_seg: 48.1874, loss: 1.2503
2021-08-14 07:28:57,954 - mmseg - INFO - Iter [12500/160000]	lr: 9.301e-03, eta: 2 days, 6:54:42, time: 1.274, data_time: 0.015, memory: 9759, decode.loss_seg: 1.2501, decode.acc_seg: 49.3786, loss: 1.2501
2021-08-14 07:30:01,833 - mmseg - INFO - Iter [12550/160000]	lr: 9.298e-03, eta: 2 days, 6:52:57, time: 1.277, data_time: 0.012, memory: 9759, decode.loss_seg: 1.2435, decode.acc_seg: 47.7066, loss: 1.2435
2021-08-14 07:31:05,037 - mmseg - INFO - Iter [12600/160000]	lr: 9.296e-03, eta: 2 days, 6:51:06, time: 1.264, data_time: 0.014, memory: 9759, decode.loss_seg: 1.2181, decode.acc_seg: 49.0992, loss: 1.2181
2021-08-14 07:32:44,034 - mmseg - INFO - Iter [12650/160000]	lr: 9.293e-03, eta: 2 days, 6:56:12, time: 1.980, data_time: 0.715, memory: 9759, decode.loss_seg: 1.2129, decode.acc_seg: 48.9086, loss: 1.2129
2021-08-14 07:33:46,131 - mmseg - INFO - Iter [12700/160000]	lr: 9.290e-03, eta: 2 days, 6:54:07, time: 1.242, data_time: 0.014, memory: 9759, decode.loss_seg: 1.2043, decode.acc_seg: 49.0123, loss: 1.2043
2021-08-14 07:34:48,208 - mmseg - INFO - Iter [12750/160000]	lr: 9.287e-03, eta: 2 days, 6:52:02, time: 1.241, data_time: 0.013, memory: 9759, decode.loss_seg: 1.1931, decode.acc_seg: 49.5452, loss: 1.1931
2021-08-14 07:35:50,447 - mmseg - INFO - Iter [12800/160000]	lr: 9.284e-03, eta: 2 days, 6:49:59, time: 1.245, data_time: 0.015, memory: 9759, decode.loss_seg: 1.2302, decode.acc_seg: 49.0102, loss: 1.2302
2021-08-14 07:36:54,093 - mmseg - INFO - Iter [12850/160000]	lr: 9.282e-03, eta: 2 days, 6:48:13, time: 1.273, data_time: 0.014, memory: 9759, decode.loss_seg: 1.2082, decode.acc_seg: 49.0323, loss: 1.2082
2021-08-14 07:37:59,736 - mmseg - INFO - Iter [12900/160000]	lr: 9.279e-03, eta: 2 days, 6:46:50, time: 1.313, data_time: 0.013, memory: 9759, decode.loss_seg: 1.2114, decode.acc_seg: 48.5995, loss: 1.2114
2021-08-14 07:39:05,289 - mmseg - INFO - Iter [12950/160000]	lr: 9.276e-03, eta: 2 days, 6:45:26, time: 1.311, data_time: 0.016, memory: 9759, decode.loss_seg: 1.2230, decode.acc_seg: 49.4937, loss: 1.2230
2021-08-14 07:40:10,677 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 07:40:10,677 - mmseg - INFO - Iter [13000/160000]	lr: 9.273e-03, eta: 2 days, 6:44:01, time: 1.308, data_time: 0.015, memory: 9759, decode.loss_seg: 1.2369, decode.acc_seg: 49.3179, loss: 1.2369
2021-08-14 07:41:14,178 - mmseg - INFO - Iter [13050/160000]	lr: 9.270e-03, eta: 2 days, 6:42:14, time: 1.270, data_time: 0.013, memory: 9759, decode.loss_seg: 1.2221, decode.acc_seg: 49.0626, loss: 1.2221
2021-08-14 07:42:17,227 - mmseg - INFO - Iter [13100/160000]	lr: 9.267e-03, eta: 2 days, 6:40:23, time: 1.261, data_time: 0.013, memory: 9759, decode.loss_seg: 1.1922, decode.acc_seg: 48.0779, loss: 1.1922
2021-08-14 07:43:18,988 - mmseg - INFO - Iter [13150/160000]	lr: 9.265e-03, eta: 2 days, 6:38:17, time: 1.235, data_time: 0.013, memory: 9759, decode.loss_seg: 1.2605, decode.acc_seg: 47.5720, loss: 1.2605
2021-08-14 07:44:22,937 - mmseg - INFO - Iter [13200/160000]	lr: 9.262e-03, eta: 2 days, 6:36:37, time: 1.279, data_time: 0.014, memory: 9759, decode.loss_seg: 1.2168, decode.acc_seg: 49.1722, loss: 1.2168
2021-08-14 07:45:30,742 - mmseg - INFO - Iter [13250/160000]	lr: 9.259e-03, eta: 2 days, 6:35:39, time: 1.356, data_time: 0.013, memory: 9759, decode.loss_seg: 1.2361, decode.acc_seg: 48.1977, loss: 1.2361
2021-08-14 07:47:08,845 - mmseg - INFO - Iter [13300/160000]	lr: 9.256e-03, eta: 2 days, 6:40:16, time: 1.963, data_time: 0.659, memory: 9759, decode.loss_seg: 1.2110, decode.acc_seg: 48.5894, loss: 1.2110
2021-08-14 07:48:14,071 - mmseg - INFO - Iter [13350/160000]	lr: 9.253e-03, eta: 2 days, 6:38:48, time: 1.304, data_time: 0.014, memory: 9759, decode.loss_seg: 1.1916, decode.acc_seg: 49.1742, loss: 1.1916
2021-08-14 07:49:17,412 - mmseg - INFO - Iter [13400/160000]	lr: 9.251e-03, eta: 2 days, 6:37:00, time: 1.267, data_time: 0.015, memory: 9759, decode.loss_seg: 1.1855, decode.acc_seg: 49.7940, loss: 1.1855
2021-08-14 07:50:22,710 - mmseg - INFO - Iter [13450/160000]	lr: 9.248e-03, eta: 2 days, 6:35:33, time: 1.305, data_time: 0.014, memory: 9759, decode.loss_seg: 1.2404, decode.acc_seg: 48.6282, loss: 1.2404
2021-08-14 07:51:27,175 - mmseg - INFO - Iter [13500/160000]	lr: 9.245e-03, eta: 2 days, 6:33:59, time: 1.291, data_time: 0.014, memory: 9759, decode.loss_seg: 1.2280, decode.acc_seg: 48.5513, loss: 1.2280
2021-08-14 07:52:31,037 - mmseg - INFO - Iter [13550/160000]	lr: 9.242e-03, eta: 2 days, 6:32:17, time: 1.276, data_time: 0.013, memory: 9759, decode.loss_seg: 1.1700, decode.acc_seg: 49.2924, loss: 1.1700
2021-08-14 07:53:35,510 - mmseg - INFO - Iter [13600/160000]	lr: 9.239e-03, eta: 2 days, 6:30:43, time: 1.290, data_time: 0.013, memory: 9759, decode.loss_seg: 1.2293, decode.acc_seg: 49.5618, loss: 1.2293
2021-08-14 07:54:38,855 - mmseg - INFO - Iter [13650/160000]	lr: 9.237e-03, eta: 2 days, 6:28:56, time: 1.267, data_time: 0.013, memory: 9759, decode.loss_seg: 1.2007, decode.acc_seg: 49.7389, loss: 1.2007
2021-08-14 07:55:41,918 - mmseg - INFO - Iter [13700/160000]	lr: 9.234e-03, eta: 2 days, 6:27:07, time: 1.261, data_time: 0.013, memory: 9759, decode.loss_seg: 1.2437, decode.acc_seg: 48.7697, loss: 1.2437
2021-08-14 07:56:46,903 - mmseg - INFO - Iter [13750/160000]	lr: 9.231e-03, eta: 2 days, 6:25:39, time: 1.300, data_time: 0.013, memory: 9759, decode.loss_seg: 1.2272, decode.acc_seg: 48.8537, loss: 1.2272
2021-08-14 07:57:49,836 - mmseg - INFO - Iter [13800/160000]	lr: 9.228e-03, eta: 2 days, 6:23:49, time: 1.258, data_time: 0.013, memory: 9759, decode.loss_seg: 1.2031, decode.acc_seg: 49.2295, loss: 1.2031
2021-08-14 07:58:51,481 - mmseg - INFO - Iter [13850/160000]	lr: 9.225e-03, eta: 2 days, 6:21:45, time: 1.232, data_time: 0.012, memory: 9759, decode.loss_seg: 1.2364, decode.acc_seg: 48.5316, loss: 1.2364
2021-08-14 08:00:30,458 - mmseg - INFO - Iter [13900/160000]	lr: 9.223e-03, eta: 2 days, 6:26:15, time: 1.980, data_time: 0.713, memory: 9759, decode.loss_seg: 1.2299, decode.acc_seg: 48.6460, loss: 1.2299
2021-08-14 08:01:33,758 - mmseg - INFO - Iter [13950/160000]	lr: 9.220e-03, eta: 2 days, 6:24:29, time: 1.266, data_time: 0.014, memory: 9759, decode.loss_seg: 1.1983, decode.acc_seg: 48.8071, loss: 1.1983
2021-08-14 08:02:35,125 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 08:02:35,126 - mmseg - INFO - Iter [14000/160000]	lr: 9.217e-03, eta: 2 days, 6:22:22, time: 1.228, data_time: 0.013, memory: 9759, decode.loss_seg: 1.2221, decode.acc_seg: 49.6012, loss: 1.2221
2021-08-14 08:03:37,945 - mmseg - INFO - Iter [14050/160000]	lr: 9.214e-03, eta: 2 days, 6:20:31, time: 1.255, data_time: 0.013, memory: 9759, decode.loss_seg: 1.1659, decode.acc_seg: 49.4802, loss: 1.1659
2021-08-14 08:04:40,731 - mmseg - INFO - Iter [14100/160000]	lr: 9.211e-03, eta: 2 days, 6:18:41, time: 1.257, data_time: 0.013, memory: 9759, decode.loss_seg: 1.2293, decode.acc_seg: 48.0879, loss: 1.2293
2021-08-14 08:05:44,817 - mmseg - INFO - Iter [14150/160000]	lr: 9.208e-03, eta: 2 days, 6:17:03, time: 1.281, data_time: 0.013, memory: 9759, decode.loss_seg: 1.2248, decode.acc_seg: 48.5358, loss: 1.2248
2021-08-14 08:06:47,968 - mmseg - INFO - Iter [14200/160000]	lr: 9.206e-03, eta: 2 days, 6:15:17, time: 1.264, data_time: 0.014, memory: 9759, decode.loss_seg: 1.2000, decode.acc_seg: 49.7893, loss: 1.2000
2021-08-14 08:07:50,125 - mmseg - INFO - Iter [14250/160000]	lr: 9.203e-03, eta: 2 days, 6:13:20, time: 1.242, data_time: 0.014, memory: 9759, decode.loss_seg: 1.2033, decode.acc_seg: 49.3628, loss: 1.2033
2021-08-14 08:08:53,701 - mmseg - INFO - Iter [14300/160000]	lr: 9.200e-03, eta: 2 days, 6:11:39, time: 1.272, data_time: 0.014, memory: 9759, decode.loss_seg: 1.2026, decode.acc_seg: 48.4574, loss: 1.2026
2021-08-14 08:09:54,903 - mmseg - INFO - Iter [14350/160000]	lr: 9.197e-03, eta: 2 days, 6:09:34, time: 1.224, data_time: 0.012, memory: 9759, decode.loss_seg: 1.1804, decode.acc_seg: 50.0097, loss: 1.1804
2021-08-14 08:10:56,054 - mmseg - INFO - Iter [14400/160000]	lr: 9.194e-03, eta: 2 days, 6:07:29, time: 1.223, data_time: 0.013, memory: 9759, decode.loss_seg: 1.2117, decode.acc_seg: 49.7958, loss: 1.2117
2021-08-14 08:11:59,259 - mmseg - INFO - Iter [14450/160000]	lr: 9.192e-03, eta: 2 days, 6:05:44, time: 1.263, data_time: 0.013, memory: 9759, decode.loss_seg: 1.1962, decode.acc_seg: 49.4995, loss: 1.1962
2021-08-14 08:13:03,237 - mmseg - INFO - Iter [14500/160000]	lr: 9.189e-03, eta: 2 days, 6:04:08, time: 1.280, data_time: 0.016, memory: 9759, decode.loss_seg: 1.1632, decode.acc_seg: 50.9003, loss: 1.1632
2021-08-14 08:14:41,497 - mmseg - INFO - Iter [14550/160000]	lr: 9.186e-03, eta: 2 days, 6:08:14, time: 1.965, data_time: 0.698, memory: 9759, decode.loss_seg: 1.2138, decode.acc_seg: 48.4390, loss: 1.2138
2021-08-14 08:15:43,414 - mmseg - INFO - Iter [14600/160000]	lr: 9.183e-03, eta: 2 days, 6:06:17, time: 1.239, data_time: 0.014, memory: 9759, decode.loss_seg: 1.2011, decode.acc_seg: 49.2686, loss: 1.2011
2021-08-14 08:16:45,704 - mmseg - INFO - Iter [14650/160000]	lr: 9.180e-03, eta: 2 days, 6:04:24, time: 1.246, data_time: 0.012, memory: 9759, decode.loss_seg: 1.1964, decode.acc_seg: 49.1561, loss: 1.1964
2021-08-14 08:17:46,867 - mmseg - INFO - Iter [14700/160000]	lr: 9.178e-03, eta: 2 days, 6:02:19, time: 1.223, data_time: 0.014, memory: 9759, decode.loss_seg: 1.1767, decode.acc_seg: 49.2014, loss: 1.1767
2021-08-14 08:18:48,287 - mmseg - INFO - Iter [14750/160000]	lr: 9.175e-03, eta: 2 days, 6:00:18, time: 1.229, data_time: 0.013, memory: 9759, decode.loss_seg: 1.1722, decode.acc_seg: 49.3474, loss: 1.1722
2021-08-14 08:19:52,343 - mmseg - INFO - Iter [14800/160000]	lr: 9.172e-03, eta: 2 days, 5:58:43, time: 1.282, data_time: 0.013, memory: 9759, decode.loss_seg: 1.2213, decode.acc_seg: 49.5201, loss: 1.2213
2021-08-14 08:20:55,817 - mmseg - INFO - Iter [14850/160000]	lr: 9.169e-03, eta: 2 days, 5:57:02, time: 1.269, data_time: 0.014, memory: 9759, decode.loss_seg: 1.1887, decode.acc_seg: 49.9784, loss: 1.1887
2021-08-14 08:21:58,840 - mmseg - INFO - Iter [14900/160000]	lr: 9.166e-03, eta: 2 days, 5:55:18, time: 1.261, data_time: 0.013, memory: 9759, decode.loss_seg: 1.1989, decode.acc_seg: 49.5510, loss: 1.1989
2021-08-14 08:23:01,252 - mmseg - INFO - Iter [14950/160000]	lr: 9.163e-03, eta: 2 days, 5:53:27, time: 1.248, data_time: 0.013, memory: 9759, decode.loss_seg: 1.1850, decode.acc_seg: 49.5734, loss: 1.1850
2021-08-14 08:24:03,786 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 08:24:03,786 - mmseg - INFO - Iter [15000/160000]	lr: 9.161e-03, eta: 2 days, 5:51:38, time: 1.251, data_time: 0.013, memory: 9759, decode.loss_seg: 1.1991, decode.acc_seg: 49.1975, loss: 1.1991
2021-08-14 08:25:05,781 - mmseg - INFO - Iter [15050/160000]	lr: 9.158e-03, eta: 2 days, 5:49:45, time: 1.240, data_time: 0.013, memory: 9759, decode.loss_seg: 1.1514, decode.acc_seg: 50.0732, loss: 1.1514
2021-08-14 08:26:09,047 - mmseg - INFO - Iter [15100/160000]	lr: 9.155e-03, eta: 2 days, 5:48:04, time: 1.266, data_time: 0.015, memory: 9759, decode.loss_seg: 1.1743, decode.acc_seg: 49.3685, loss: 1.1743
2021-08-14 08:27:47,579 - mmseg - INFO - Iter [15150/160000]	lr: 9.152e-03, eta: 2 days, 5:52:00, time: 1.970, data_time: 0.736, memory: 9759, decode.loss_seg: 1.1587, decode.acc_seg: 50.2472, loss: 1.1587
2021-08-14 08:28:51,642 - mmseg - INFO - Iter [15200/160000]	lr: 9.149e-03, eta: 2 days, 5:50:25, time: 1.281, data_time: 0.014, memory: 9759, decode.loss_seg: 1.1632, decode.acc_seg: 49.1931, loss: 1.1632
2021-08-14 08:29:53,814 - mmseg - INFO - Iter [15250/160000]	lr: 9.147e-03, eta: 2 days, 5:48:34, time: 1.244, data_time: 0.015, memory: 9759, decode.loss_seg: 1.1839, decode.acc_seg: 49.5737, loss: 1.1839
2021-08-14 08:30:55,860 - mmseg - INFO - Iter [15300/160000]	lr: 9.144e-03, eta: 2 days, 5:46:40, time: 1.241, data_time: 0.014, memory: 9759, decode.loss_seg: 1.2052, decode.acc_seg: 50.5024, loss: 1.2052
2021-08-14 08:31:57,244 - mmseg - INFO - Iter [15350/160000]	lr: 9.141e-03, eta: 2 days, 5:44:41, time: 1.227, data_time: 0.014, memory: 9759, decode.loss_seg: 1.1850, decode.acc_seg: 49.3486, loss: 1.1850
2021-08-14 08:32:59,941 - mmseg - INFO - Iter [15400/160000]	lr: 9.138e-03, eta: 2 days, 5:42:55, time: 1.254, data_time: 0.015, memory: 9759, decode.loss_seg: 1.2036, decode.acc_seg: 49.9637, loss: 1.2036
2021-08-14 08:34:01,245 - mmseg - INFO - Iter [15450/160000]	lr: 9.135e-03, eta: 2 days, 5:40:57, time: 1.227, data_time: 0.016, memory: 9759, decode.loss_seg: 1.1941, decode.acc_seg: 50.5258, loss: 1.1941
2021-08-14 08:35:03,370 - mmseg - INFO - Iter [15500/160000]	lr: 9.133e-03, eta: 2 days, 5:39:06, time: 1.242, data_time: 0.014, memory: 9759, decode.loss_seg: 1.1806, decode.acc_seg: 49.0126, loss: 1.1806
2021-08-14 08:36:04,853 - mmseg - INFO - Iter [15550/160000]	lr: 9.130e-03, eta: 2 days, 5:37:09, time: 1.230, data_time: 0.014, memory: 9759, decode.loss_seg: 1.1831, decode.acc_seg: 49.0429, loss: 1.1831
2021-08-14 08:37:05,781 - mmseg - INFO - Iter [15600/160000]	lr: 9.127e-03, eta: 2 days, 5:35:08, time: 1.218, data_time: 0.013, memory: 9759, decode.loss_seg: 1.1801, decode.acc_seg: 49.2243, loss: 1.1801
2021-08-14 08:38:10,754 - mmseg - INFO - Iter [15650/160000]	lr: 9.124e-03, eta: 2 days, 5:33:44, time: 1.299, data_time: 0.015, memory: 9759, decode.loss_seg: 1.1857, decode.acc_seg: 49.7791, loss: 1.1857
2021-08-14 08:39:14,461 - mmseg - INFO - Iter [15700/160000]	lr: 9.121e-03, eta: 2 days, 5:32:09, time: 1.274, data_time: 0.015, memory: 9759, decode.loss_seg: 1.1971, decode.acc_seg: 49.7977, loss: 1.1971
2021-08-14 08:40:17,377 - mmseg - INFO - Iter [15750/160000]	lr: 9.118e-03, eta: 2 days, 5:30:26, time: 1.258, data_time: 0.014, memory: 9759, decode.loss_seg: 1.1460, decode.acc_seg: 49.4155, loss: 1.1460
2021-08-14 08:41:56,720 - mmseg - INFO - Iter [15800/160000]	lr: 9.116e-03, eta: 2 days, 5:34:17, time: 1.987, data_time: 0.680, memory: 9759, decode.loss_seg: 1.1757, decode.acc_seg: 50.1720, loss: 1.1757
2021-08-14 08:42:59,943 - mmseg - INFO - Iter [15850/160000]	lr: 9.113e-03, eta: 2 days, 5:32:37, time: 1.265, data_time: 0.014, memory: 9759, decode.loss_seg: 1.1592, decode.acc_seg: 49.0156, loss: 1.1592
2021-08-14 08:44:02,173 - mmseg - INFO - Iter [15900/160000]	lr: 9.110e-03, eta: 2 days, 5:30:48, time: 1.244, data_time: 0.013, memory: 9759, decode.loss_seg: 1.1516, decode.acc_seg: 51.3354, loss: 1.1516
2021-08-14 08:45:06,324 - mmseg - INFO - Iter [15950/160000]	lr: 9.107e-03, eta: 2 days, 5:29:17, time: 1.283, data_time: 0.014, memory: 9759, decode.loss_seg: 1.1491, decode.acc_seg: 49.6680, loss: 1.1491
2021-08-14 08:46:11,714 - mmseg - INFO - Saving checkpoint at 16000 iterations
2021-08-14 08:46:12,038 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 08:46:12,041 - mmseg - INFO - Iter [16000/160000]	lr: 9.104e-03, eta: 2 days, 5:28:00, time: 1.315, data_time: 0.015, memory: 9759, decode.loss_seg: 1.2148, decode.acc_seg: 49.4251, loss: 1.2148
2021-08-14 08:48:54,576 - mmseg - INFO - per class results:
2021-08-14 08:48:54,591 - mmseg - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        | 52.23 | 81.62 |
|       building      | 65.79 | 80.68 |
|         sky         | 87.07 | 94.73 |
|        floor        | 53.27 | 81.74 |
|         tree        |  56.9 | 77.61 |
|       ceiling       | 62.97 | 84.81 |
|         road        | 63.04 | 78.08 |
|         bed         | 55.88 | 76.81 |
|      windowpane     | 38.41 | 58.66 |
|        grass        | 53.01 | 76.22 |
|       cabinet       | 33.12 | 44.21 |
|       sidewalk      |  31.7 | 40.55 |
|        person       | 39.29 | 65.52 |
|        earth        | 22.22 | 38.78 |
|         door        |  7.98 |  9.01 |
|        table        | 18.39 | 24.09 |
|       mountain      | 31.28 | 48.09 |
|        plant        | 19.78 | 21.94 |
|       curtain       | 29.22 | 49.82 |
|        chair        | 18.92 | 25.62 |
|         car         | 51.76 | 73.84 |
|        water        | 11.78 | 15.99 |
|       painting      | 40.62 | 53.62 |
|         sofa        | 29.94 | 46.02 |
|        shelf        | 10.07 | 12.67 |
|        house        | 26.68 | 41.81 |
|         sea         | 18.83 | 69.33 |
|        mirror       |  14.4 | 16.71 |
|         rug         | 18.25 | 20.11 |
|        field        | 18.43 | 39.03 |
|       armchair      |  5.51 |  6.56 |
|         seat        | 19.15 | 24.18 |
|        fence        |  6.05 |  7.1  |
|         desk        |  6.54 |  6.94 |
|         rock        |  7.61 | 10.03 |
|       wardrobe      |  1.43 |  1.46 |
|         lamp        | 18.54 | 22.58 |
|       bathtub       | 11.77 | 12.85 |
|       railing       |  8.42 |  9.09 |
|       cushion       | 12.48 | 17.01 |
|         base        |  0.05 |  0.05 |
|         box         |  0.0  |  0.0  |
|        column       |  3.76 |  4.06 |
|      signboard      |  4.52 |  5.13 |
|   chest of drawers  | 19.14 | 25.76 |
|       counter       |  5.2  |  5.43 |
|         sand        | 14.12 | 23.31 |
|         sink        | 16.88 | 23.43 |
|      skyscraper     | 32.88 | 58.44 |
|      fireplace      | 40.54 | 44.64 |
|     refrigerator    |  7.0  |  7.46 |
|      grandstand     |  2.86 |  4.53 |
|         path        |  2.27 |  2.44 |
|        stairs       |  6.12 |  6.23 |
|        runway       | 44.38 | 68.42 |
|         case        |  9.87 | 12.19 |
|      pool table     | 33.53 | 65.95 |
|        pillow       | 19.53 | 23.17 |
|     screen door     |  0.3  |  0.3  |
|       stairway      |  3.96 |  4.7  |
|        river        |  4.07 | 10.04 |
|        bridge       |  5.58 |  7.07 |
|       bookcase      |  2.81 |  2.88 |
|        blind        |  1.44 |  1.49 |
|     coffee table    | 16.35 | 21.29 |
|        toilet       |  33.3 | 55.46 |
|        flower       |  7.67 |  9.28 |
|         book        |  7.84 |  8.15 |
|         hill        |  2.4  |  3.18 |
|        bench        |  5.92 |  6.13 |
|      countertop     |  3.81 |  3.96 |
|        stove        | 23.15 | 33.92 |
|         palm        |  2.07 |  2.07 |
|    kitchen island   |  3.07 |  3.12 |
|       computer      |  6.57 |  7.03 |
|     swivel chair    |  5.1  |  5.21 |
|         boat        |  2.93 |  3.36 |
|         bar         |  3.81 |  3.94 |
|    arcade machine   |  0.31 |  0.37 |
|        hovel        |  0.78 |  0.78 |
|         bus         | 19.54 | 19.71 |
|        towel        |  0.37 |  0.37 |
|        light        |  8.25 |  9.01 |
|        truck        |  0.91 |  1.14 |
|        tower        | 12.01 | 12.07 |
|      chandelier     | 29.75 | 40.82 |
|        awning       |  0.01 |  0.01 |
|     streetlight     |  0.42 |  0.43 |
|        booth        |  0.0  |  0.0  |
| television receiver | 16.96 | 18.91 |
|       airplane      | 12.18 | 23.34 |
|      dirt track     |  0.0  |  0.0  |
|       apparel       |  0.89 |  1.12 |
|         pole        |  0.44 |  0.45 |
|         land        |  0.0  |  0.0  |
|      bannister      |  0.0  |  0.0  |
|      escalator      |  0.89 |  0.97 |
|       ottoman       |  0.0  |  0.0  |
|        bottle       |  0.0  |  0.0  |
|        buffet       |  0.0  |  0.0  |
|        poster       |  0.0  |  0.0  |
|        stage        |  0.0  |  0.0  |
|         van         |  0.0  |  0.0  |
|         ship        |  0.0  |  0.0  |
|       fountain      |  0.0  |  0.0  |
|    conveyer belt    |  0.0  |  0.0  |
|        canopy       |  0.0  |  0.0  |
|        washer       | 17.45 | 19.45 |
|      plaything      |  0.01 |  0.01 |
|    swimming pool    |  0.41 |  0.56 |
|        stool        |  0.0  |  0.0  |
|        barrel       |  0.0  |  0.0  |
|        basket       |  0.0  |  0.0  |
|      waterfall      | 22.22 | 64.15 |
|         tent        | 37.75 | 43.13 |
|         bag         |  0.0  |  0.0  |
|       minibike      |  0.0  |  0.0  |
|        cradle       | 41.62 | 43.99 |
|         oven        |  0.01 |  0.01 |
|         ball        |  5.66 |  7.92 |
|         food        |  7.26 |  7.61 |
|         step        |  0.0  |  0.0  |
|         tank        |  0.0  |  0.0  |
|      trade name     |  0.05 |  0.05 |
|      microwave      |  6.15 |  6.27 |
|         pot         |  0.0  |  0.0  |
|        animal       |  0.0  |  0.0  |
|       bicycle       |  0.0  |  0.0  |
|         lake        |  0.0  |  0.0  |
|      dishwasher     |  2.55 |  2.58 |
|        screen       | 31.75 | 40.02 |
|       blanket       |  0.0  |  0.0  |
|      sculpture      |  0.0  |  0.0  |
|         hood        |  1.89 |  1.9  |
|        sconce       |  0.0  |  0.0  |
|         vase        |  0.02 |  0.02 |
|    traffic light    |  0.0  |  0.0  |
|         tray        |  0.0  |  0.0  |
|        ashcan       |  0.0  |  0.0  |
|         fan         |  0.0  |  0.0  |
|         pier        |  0.0  |  0.0  |
|      crt screen     |  0.0  |  0.0  |
|        plate        |  0.0  |  0.0  |
|       monitor       |  0.0  |  0.0  |
|    bulletin board   |  0.0  |  0.0  |
|        shower       |  0.0  |  0.0  |
|       radiator      |  0.0  |  0.0  |
|        glass        |  0.0  |  0.0  |
|        clock        |  0.0  |  0.0  |
|         flag        |  0.0  |  0.0  |
+---------------------+-------+-------+
2021-08-14 08:48:54,591 - mmseg - INFO - Summary:
2021-08-14 08:48:54,592 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 63.44 | 12.41 | 17.37 |
+-------+-------+-------+
2021-08-14 08:48:54,702 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 08:48:54,703 - mmseg - INFO - Iter(val) [250]	aAcc: 0.6344, mIoU: 0.1241, mAcc: 0.1737, IoU.wall: 0.5223, IoU.building: 0.6579, IoU.sky: 0.8707, IoU.floor: 0.5327, IoU.tree: 0.5690, IoU.ceiling: 0.6297, IoU.road: 0.6304, IoU.bed : 0.5588, IoU.windowpane: 0.3841, IoU.grass: 0.5301, IoU.cabinet: 0.3312, IoU.sidewalk: 0.3170, IoU.person: 0.3929, IoU.earth: 0.2222, IoU.door: 0.0798, IoU.table: 0.1839, IoU.mountain: 0.3128, IoU.plant: 0.1978, IoU.curtain: 0.2922, IoU.chair: 0.1892, IoU.car: 0.5176, IoU.water: 0.1178, IoU.painting: 0.4062, IoU.sofa: 0.2994, IoU.shelf: 0.1007, IoU.house: 0.2668, IoU.sea: 0.1883, IoU.mirror: 0.1440, IoU.rug: 0.1825, IoU.field: 0.1843, IoU.armchair: 0.0551, IoU.seat: 0.1915, IoU.fence: 0.0605, IoU.desk: 0.0654, IoU.rock: 0.0761, IoU.wardrobe: 0.0143, IoU.lamp: 0.1854, IoU.bathtub: 0.1177, IoU.railing: 0.0842, IoU.cushion: 0.1248, IoU.base: 0.0005, IoU.box: 0.0000, IoU.column: 0.0376, IoU.signboard: 0.0452, IoU.chest of drawers: 0.1914, IoU.counter: 0.0520, IoU.sand: 0.1412, IoU.sink: 0.1688, IoU.skyscraper: 0.3288, IoU.fireplace: 0.4054, IoU.refrigerator: 0.0700, IoU.grandstand: 0.0286, IoU.path: 0.0227, IoU.stairs: 0.0612, IoU.runway: 0.4438, IoU.case: 0.0987, IoU.pool table: 0.3353, IoU.pillow: 0.1953, IoU.screen door: 0.0030, IoU.stairway: 0.0396, IoU.river: 0.0407, IoU.bridge: 0.0558, IoU.bookcase: 0.0281, IoU.blind: 0.0144, IoU.coffee table: 0.1635, IoU.toilet: 0.3330, IoU.flower: 0.0767, IoU.book: 0.0784, IoU.hill: 0.0240, IoU.bench: 0.0592, IoU.countertop: 0.0381, IoU.stove: 0.2315, IoU.palm: 0.0207, IoU.kitchen island: 0.0307, IoU.computer: 0.0657, IoU.swivel chair: 0.0510, IoU.boat: 0.0293, IoU.bar: 0.0381, IoU.arcade machine: 0.0031, IoU.hovel: 0.0078, IoU.bus: 0.1954, IoU.towel: 0.0037, IoU.light: 0.0825, IoU.truck: 0.0091, IoU.tower: 0.1201, IoU.chandelier: 0.2975, IoU.awning: 0.0001, IoU.streetlight: 0.0042, IoU.booth: 0.0000, IoU.television receiver: 0.1696, IoU.airplane: 0.1218, IoU.dirt track: 0.0000, IoU.apparel: 0.0089, IoU.pole: 0.0044, IoU.land: 0.0000, IoU.bannister: 0.0000, IoU.escalator: 0.0089, IoU.ottoman: 0.0000, IoU.bottle: 0.0000, IoU.buffet: 0.0000, IoU.poster: 0.0000, IoU.stage: 0.0000, IoU.van: 0.0000, IoU.ship: 0.0000, IoU.fountain: 0.0000, IoU.conveyer belt: 0.0000, IoU.canopy: 0.0000, IoU.washer: 0.1745, IoU.plaything: 0.0001, IoU.swimming pool: 0.0041, IoU.stool: 0.0000, IoU.barrel: 0.0000, IoU.basket: 0.0000, IoU.waterfall: 0.2222, IoU.tent: 0.3775, IoU.bag: 0.0000, IoU.minibike: 0.0000, IoU.cradle: 0.4162, IoU.oven: 0.0001, IoU.ball: 0.0566, IoU.food: 0.0726, IoU.step: 0.0000, IoU.tank: 0.0000, IoU.trade name: 0.0005, IoU.microwave: 0.0615, IoU.pot: 0.0000, IoU.animal: 0.0000, IoU.bicycle: 0.0000, IoU.lake: 0.0000, IoU.dishwasher: 0.0255, IoU.screen: 0.3175, IoU.blanket: 0.0000, IoU.sculpture: 0.0000, IoU.hood: 0.0189, IoU.sconce: 0.0000, IoU.vase: 0.0002, IoU.traffic light: 0.0000, IoU.tray: 0.0000, IoU.ashcan: 0.0000, IoU.fan: 0.0000, IoU.pier: 0.0000, IoU.crt screen: 0.0000, IoU.plate: 0.0000, IoU.monitor: 0.0000, IoU.bulletin board: 0.0000, IoU.shower: 0.0000, IoU.radiator: 0.0000, IoU.glass: 0.0000, IoU.clock: 0.0000, IoU.flag: 0.0000, Acc.wall: 0.8162, Acc.building: 0.8068, Acc.sky: 0.9473, Acc.floor: 0.8174, Acc.tree: 0.7761, Acc.ceiling: 0.8481, Acc.road: 0.7808, Acc.bed : 0.7681, Acc.windowpane: 0.5866, Acc.grass: 0.7622, Acc.cabinet: 0.4421, Acc.sidewalk: 0.4055, Acc.person: 0.6552, Acc.earth: 0.3878, Acc.door: 0.0901, Acc.table: 0.2409, Acc.mountain: 0.4809, Acc.plant: 0.2194, Acc.curtain: 0.4982, Acc.chair: 0.2562, Acc.car: 0.7384, Acc.water: 0.1599, Acc.painting: 0.5362, Acc.sofa: 0.4602, Acc.shelf: 0.1267, Acc.house: 0.4181, Acc.sea: 0.6933, Acc.mirror: 0.1671, Acc.rug: 0.2011, Acc.field: 0.3903, Acc.armchair: 0.0656, Acc.seat: 0.2418, Acc.fence: 0.0710, Acc.desk: 0.0694, Acc.rock: 0.1003, Acc.wardrobe: 0.0146, Acc.lamp: 0.2258, Acc.bathtub: 0.1285, Acc.railing: 0.0909, Acc.cushion: 0.1701, Acc.base: 0.0005, Acc.box: 0.0000, Acc.column: 0.0406, Acc.signboard: 0.0513, Acc.chest of drawers: 0.2576, Acc.counter: 0.0543, Acc.sand: 0.2331, Acc.sink: 0.2343, Acc.skyscraper: 0.5844, Acc.fireplace: 0.4464, Acc.refrigerator: 0.0746, Acc.grandstand: 0.0453, Acc.path: 0.0244, Acc.stairs: 0.0623, Acc.runway: 0.6842, Acc.case: 0.1219, Acc.pool table: 0.6595, Acc.pillow: 0.2317, Acc.screen door: 0.0030, Acc.stairway: 0.0470, Acc.river: 0.1004, Acc.bridge: 0.0707, Acc.bookcase: 0.0288, Acc.blind: 0.0149, Acc.coffee table: 0.2129, Acc.toilet: 0.5546, Acc.flower: 0.0928, Acc.book: 0.0815, Acc.hill: 0.0318, Acc.bench: 0.0613, Acc.countertop: 0.0396, Acc.stove: 0.3392, Acc.palm: 0.0207, Acc.kitchen island: 0.0312, Acc.computer: 0.0703, Acc.swivel chair: 0.0521, Acc.boat: 0.0336, Acc.bar: 0.0394, Acc.arcade machine: 0.0037, Acc.hovel: 0.0078, Acc.bus: 0.1971, Acc.towel: 0.0037, Acc.light: 0.0901, Acc.truck: 0.0114, Acc.tower: 0.1207, Acc.chandelier: 0.4082, Acc.awning: 0.0001, Acc.streetlight: 0.0043, Acc.booth: 0.0000, Acc.television receiver: 0.1891, Acc.airplane: 0.2334, Acc.dirt track: 0.0000, Acc.apparel: 0.0112, Acc.pole: 0.0045, Acc.land: 0.0000, Acc.bannister: 0.0000, Acc.escalator: 0.0097, Acc.ottoman: 0.0000, Acc.bottle: 0.0000, Acc.buffet: 0.0000, Acc.poster: 0.0000, Acc.stage: 0.0000, Acc.van: 0.0000, Acc.ship: 0.0000, Acc.fountain: 0.0000, Acc.conveyer belt: 0.0000, Acc.canopy: 0.0000, Acc.washer: 0.1945, Acc.plaything: 0.0001, Acc.swimming pool: 0.0056, Acc.stool: 0.0000, Acc.barrel: 0.0000, Acc.basket: 0.0000, Acc.waterfall: 0.6415, Acc.tent: 0.4313, Acc.bag: 0.0000, Acc.minibike: 0.0000, Acc.cradle: 0.4399, Acc.oven: 0.0001, Acc.ball: 0.0792, Acc.food: 0.0761, Acc.step: 0.0000, Acc.tank: 0.0000, Acc.trade name: 0.0005, Acc.microwave: 0.0627, Acc.pot: 0.0000, Acc.animal: 0.0000, Acc.bicycle: 0.0000, Acc.lake: 0.0000, Acc.dishwasher: 0.0258, Acc.screen: 0.4002, Acc.blanket: 0.0000, Acc.sculpture: 0.0000, Acc.hood: 0.0190, Acc.sconce: 0.0000, Acc.vase: 0.0002, Acc.traffic light: 0.0000, Acc.tray: 0.0000, Acc.ashcan: 0.0000, Acc.fan: 0.0000, Acc.pier: 0.0000, Acc.crt screen: 0.0000, Acc.plate: 0.0000, Acc.monitor: 0.0000, Acc.bulletin board: 0.0000, Acc.shower: 0.0000, Acc.radiator: 0.0000, Acc.glass: 0.0000, Acc.clock: 0.0000, Acc.flag: 0.0000
2021-08-14 08:49:56,548 - mmseg - INFO - Iter [16050/160000]	lr: 9.102e-03, eta: 2 days, 5:50:28, time: 4.490, data_time: 3.269, memory: 9759, decode.loss_seg: 1.1791, decode.acc_seg: 49.9843, loss: 1.1791
2021-08-14 08:50:59,118 - mmseg - INFO - Iter [16100/160000]	lr: 9.099e-03, eta: 2 days, 5:48:38, time: 1.251, data_time: 0.016, memory: 9759, decode.loss_seg: 1.2046, decode.acc_seg: 48.6526, loss: 1.2046
2021-08-14 08:52:03,727 - mmseg - INFO - Iter [16150/160000]	lr: 9.096e-03, eta: 2 days, 5:47:06, time: 1.292, data_time: 0.015, memory: 9759, decode.loss_seg: 1.1662, decode.acc_seg: 49.5390, loss: 1.1662
2021-08-14 08:53:07,987 - mmseg - INFO - Iter [16200/160000]	lr: 9.093e-03, eta: 2 days, 5:45:32, time: 1.286, data_time: 0.015, memory: 9759, decode.loss_seg: 1.2081, decode.acc_seg: 49.2167, loss: 1.2081
2021-08-14 08:54:11,973 - mmseg - INFO - Iter [16250/160000]	lr: 9.090e-03, eta: 2 days, 5:43:55, time: 1.279, data_time: 0.015, memory: 9759, decode.loss_seg: 1.1962, decode.acc_seg: 48.9124, loss: 1.1962
2021-08-14 08:55:16,014 - mmseg - INFO - Iter [16300/160000]	lr: 9.088e-03, eta: 2 days, 5:42:20, time: 1.281, data_time: 0.015, memory: 9759, decode.loss_seg: 1.1652, decode.acc_seg: 50.6765, loss: 1.1652
2021-08-14 08:56:19,066 - mmseg - INFO - Iter [16350/160000]	lr: 9.085e-03, eta: 2 days, 5:40:35, time: 1.261, data_time: 0.014, memory: 9759, decode.loss_seg: 1.1443, decode.acc_seg: 50.8543, loss: 1.1443
2021-08-14 08:57:21,496 - mmseg - INFO - Iter [16400/160000]	lr: 9.082e-03, eta: 2 days, 5:38:46, time: 1.249, data_time: 0.015, memory: 9759, decode.loss_seg: 1.1632, decode.acc_seg: 50.1868, loss: 1.1632
2021-08-14 08:58:59,168 - mmseg - INFO - Iter [16450/160000]	lr: 9.079e-03, eta: 2 days, 5:42:04, time: 1.953, data_time: 0.693, memory: 9759, decode.loss_seg: 1.1600, decode.acc_seg: 49.7845, loss: 1.1600
2021-08-14 09:00:00,920 - mmseg - INFO - Iter [16500/160000]	lr: 9.076e-03, eta: 2 days, 5:40:08, time: 1.236, data_time: 0.014, memory: 9759, decode.loss_seg: 1.1710, decode.acc_seg: 51.3893, loss: 1.1710
2021-08-14 09:01:03,890 - mmseg - INFO - Iter [16550/160000]	lr: 9.073e-03, eta: 2 days, 5:38:23, time: 1.259, data_time: 0.016, memory: 9759, decode.loss_seg: 1.1693, decode.acc_seg: 49.6846, loss: 1.1693
2021-08-14 09:02:07,762 - mmseg - INFO - Iter [16600/160000]	lr: 9.071e-03, eta: 2 days, 5:36:46, time: 1.277, data_time: 0.016, memory: 9759, decode.loss_seg: 1.1555, decode.acc_seg: 51.0585, loss: 1.1555
2021-08-14 09:03:11,006 - mmseg - INFO - Iter [16650/160000]	lr: 9.068e-03, eta: 2 days, 5:35:04, time: 1.266, data_time: 0.016, memory: 9759, decode.loss_seg: 1.1543, decode.acc_seg: 50.0275, loss: 1.1543
2021-08-14 09:04:13,437 - mmseg - INFO - Iter [16700/160000]	lr: 9.065e-03, eta: 2 days, 5:33:15, time: 1.248, data_time: 0.017, memory: 9759, decode.loss_seg: 1.1751, decode.acc_seg: 50.6864, loss: 1.1751
2021-08-14 09:05:18,328 - mmseg - INFO - Iter [16750/160000]	lr: 9.062e-03, eta: 2 days, 5:31:47, time: 1.298, data_time: 0.015, memory: 9759, decode.loss_seg: 1.1715, decode.acc_seg: 49.0517, loss: 1.1715
2021-08-14 09:06:21,446 - mmseg - INFO - Iter [16800/160000]	lr: 9.059e-03, eta: 2 days, 5:30:05, time: 1.263, data_time: 0.016, memory: 9759, decode.loss_seg: 1.1848, decode.acc_seg: 49.2819, loss: 1.1848
2021-08-14 09:07:24,012 - mmseg - INFO - Iter [16850/160000]	lr: 9.057e-03, eta: 2 days, 5:28:18, time: 1.251, data_time: 0.015, memory: 9759, decode.loss_seg: 1.1714, decode.acc_seg: 49.6948, loss: 1.1714
2021-08-14 09:08:27,313 - mmseg - INFO - Iter [16900/160000]	lr: 9.054e-03, eta: 2 days, 5:26:37, time: 1.266, data_time: 0.016, memory: 9759, decode.loss_seg: 1.1408, decode.acc_seg: 50.5987, loss: 1.1408
2021-08-14 09:09:30,493 - mmseg - INFO - Iter [16950/160000]	lr: 9.051e-03, eta: 2 days, 5:24:56, time: 1.264, data_time: 0.016, memory: 9759, decode.loss_seg: 1.1657, decode.acc_seg: 50.9378, loss: 1.1657
2021-08-14 09:10:33,538 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 09:10:33,538 - mmseg - INFO - Iter [17000/160000]	lr: 9.048e-03, eta: 2 days, 5:23:14, time: 1.260, data_time: 0.016, memory: 9759, decode.loss_seg: 1.1508, decode.acc_seg: 51.1972, loss: 1.1508
2021-08-14 09:12:10,300 - mmseg - INFO - Iter [17050/160000]	lr: 9.045e-03, eta: 2 days, 5:26:14, time: 1.935, data_time: 0.723, memory: 9759, decode.loss_seg: 1.1587, decode.acc_seg: 50.7105, loss: 1.1587
2021-08-14 09:13:13,227 - mmseg - INFO - Iter [17100/160000]	lr: 9.043e-03, eta: 2 days, 5:24:30, time: 1.258, data_time: 0.015, memory: 9759, decode.loss_seg: 1.1447, decode.acc_seg: 50.0467, loss: 1.1447
2021-08-14 09:14:14,630 - mmseg - INFO - Iter [17150/160000]	lr: 9.040e-03, eta: 2 days, 5:22:34, time: 1.228, data_time: 0.015, memory: 9759, decode.loss_seg: 1.1477, decode.acc_seg: 50.1248, loss: 1.1477
2021-08-14 09:15:16,068 - mmseg - INFO - Iter [17200/160000]	lr: 9.037e-03, eta: 2 days, 5:20:39, time: 1.229, data_time: 0.016, memory: 9759, decode.loss_seg: 1.1831, decode.acc_seg: 50.0787, loss: 1.1831
2021-08-14 09:16:22,462 - mmseg - INFO - Iter [17250/160000]	lr: 9.034e-03, eta: 2 days, 5:19:24, time: 1.327, data_time: 0.015, memory: 9759, decode.loss_seg: 1.1394, decode.acc_seg: 50.8120, loss: 1.1394
2021-08-14 09:17:28,503 - mmseg - INFO - Iter [17300/160000]	lr: 9.031e-03, eta: 2 days, 5:18:07, time: 1.322, data_time: 0.016, memory: 9759, decode.loss_seg: 1.1255, decode.acc_seg: 50.2879, loss: 1.1255
2021-08-14 09:18:33,197 - mmseg - INFO - Iter [17350/160000]	lr: 9.028e-03, eta: 2 days, 5:16:39, time: 1.293, data_time: 0.016, memory: 9759, decode.loss_seg: 1.1533, decode.acc_seg: 50.2434, loss: 1.1533
2021-08-14 09:19:36,933 - mmseg - INFO - Iter [17400/160000]	lr: 9.026e-03, eta: 2 days, 5:15:03, time: 1.276, data_time: 0.017, memory: 9759, decode.loss_seg: 1.1651, decode.acc_seg: 49.9510, loss: 1.1651
2021-08-14 09:20:39,603 - mmseg - INFO - Iter [17450/160000]	lr: 9.023e-03, eta: 2 days, 5:13:19, time: 1.253, data_time: 0.015, memory: 9759, decode.loss_seg: 1.1305, decode.acc_seg: 50.3096, loss: 1.1305
2021-08-14 09:21:41,766 - mmseg - INFO - Iter [17500/160000]	lr: 9.020e-03, eta: 2 days, 5:11:31, time: 1.243, data_time: 0.016, memory: 9759, decode.loss_seg: 1.1623, decode.acc_seg: 50.6445, loss: 1.1623
2021-08-14 09:22:47,293 - mmseg - INFO - Iter [17550/160000]	lr: 9.017e-03, eta: 2 days, 5:10:10, time: 1.311, data_time: 0.014, memory: 9759, decode.loss_seg: 1.1558, decode.acc_seg: 50.7648, loss: 1.1558
2021-08-14 09:23:52,542 - mmseg - INFO - Iter [17600/160000]	lr: 9.014e-03, eta: 2 days, 5:08:47, time: 1.305, data_time: 0.016, memory: 9759, decode.loss_seg: 1.1282, decode.acc_seg: 50.8415, loss: 1.1282
2021-08-14 09:24:56,465 - mmseg - INFO - Iter [17650/160000]	lr: 9.012e-03, eta: 2 days, 5:07:13, time: 1.278, data_time: 0.015, memory: 9759, decode.loss_seg: 1.1671, decode.acc_seg: 50.2560, loss: 1.1671
2021-08-14 09:26:34,319 - mmseg - INFO - Iter [17700/160000]	lr: 9.009e-03, eta: 2 days, 5:10:13, time: 1.958, data_time: 0.665, memory: 9759, decode.loss_seg: 1.1981, decode.acc_seg: 49.9583, loss: 1.1981
2021-08-14 09:27:38,006 - mmseg - INFO - Iter [17750/160000]	lr: 9.006e-03, eta: 2 days, 5:08:37, time: 1.273, data_time: 0.014, memory: 9759, decode.loss_seg: 1.1217, decode.acc_seg: 50.5003, loss: 1.1217
2021-08-14 09:28:40,397 - mmseg - INFO - Iter [17800/160000]	lr: 9.003e-03, eta: 2 days, 5:06:51, time: 1.247, data_time: 0.014, memory: 9759, decode.loss_seg: 1.1332, decode.acc_seg: 51.2805, loss: 1.1332
2021-08-14 09:29:42,161 - mmseg - INFO - Iter [17850/160000]	lr: 9.000e-03, eta: 2 days, 5:05:00, time: 1.236, data_time: 0.016, memory: 9759, decode.loss_seg: 1.1313, decode.acc_seg: 49.6306, loss: 1.1313
2021-08-14 09:30:46,015 - mmseg - INFO - Iter [17900/160000]	lr: 8.997e-03, eta: 2 days, 5:03:26, time: 1.277, data_time: 0.015, memory: 9759, decode.loss_seg: 1.1172, decode.acc_seg: 50.5138, loss: 1.1172
2021-08-14 09:31:46,937 - mmseg - INFO - Iter [17950/160000]	lr: 8.995e-03, eta: 2 days, 5:01:29, time: 1.218, data_time: 0.015, memory: 9759, decode.loss_seg: 1.1460, decode.acc_seg: 50.3447, loss: 1.1460
2021-08-14 09:32:50,065 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 09:32:50,066 - mmseg - INFO - Iter [18000/160000]	lr: 8.992e-03, eta: 2 days, 4:59:50, time: 1.263, data_time: 0.015, memory: 9759, decode.loss_seg: 1.1376, decode.acc_seg: 50.3547, loss: 1.1376
2021-08-14 09:33:54,579 - mmseg - INFO - Iter [18050/160000]	lr: 8.989e-03, eta: 2 days, 4:58:22, time: 1.290, data_time: 0.014, memory: 9759, decode.loss_seg: 1.1525, decode.acc_seg: 50.2781, loss: 1.1525
2021-08-14 09:35:01,463 - mmseg - INFO - Iter [18100/160000]	lr: 8.986e-03, eta: 2 days, 4:57:12, time: 1.337, data_time: 0.015, memory: 9759, decode.loss_seg: 1.1475, decode.acc_seg: 50.8622, loss: 1.1475
2021-08-14 09:36:03,533 - mmseg - INFO - Iter [18150/160000]	lr: 8.983e-03, eta: 2 days, 4:55:26, time: 1.242, data_time: 0.016, memory: 9759, decode.loss_seg: 1.1401, decode.acc_seg: 49.5197, loss: 1.1401
2021-08-14 09:37:09,902 - mmseg - INFO - Iter [18200/160000]	lr: 8.981e-03, eta: 2 days, 4:54:12, time: 1.327, data_time: 0.015, memory: 9759, decode.loss_seg: 1.1601, decode.acc_seg: 50.6560, loss: 1.1601
2021-08-14 09:38:16,888 - mmseg - INFO - Iter [18250/160000]	lr: 8.978e-03, eta: 2 days, 4:53:04, time: 1.340, data_time: 0.016, memory: 9759, decode.loss_seg: 1.1603, decode.acc_seg: 51.1271, loss: 1.1603
2021-08-14 09:39:57,593 - mmseg - INFO - Iter [18300/160000]	lr: 8.975e-03, eta: 2 days, 4:56:16, time: 2.015, data_time: 0.736, memory: 9759, decode.loss_seg: 1.1442, decode.acc_seg: 50.2515, loss: 1.1442
2021-08-14 09:41:00,603 - mmseg - INFO - Iter [18350/160000]	lr: 8.972e-03, eta: 2 days, 4:54:37, time: 1.261, data_time: 0.016, memory: 9759, decode.loss_seg: 1.1388, decode.acc_seg: 49.7207, loss: 1.1388
2021-08-14 09:42:02,401 - mmseg - INFO - Iter [18400/160000]	lr: 8.969e-03, eta: 2 days, 4:52:48, time: 1.236, data_time: 0.014, memory: 9759, decode.loss_seg: 1.1429, decode.acc_seg: 50.4355, loss: 1.1429
2021-08-14 09:43:04,975 - mmseg - INFO - Iter [18450/160000]	lr: 8.966e-03, eta: 2 days, 4:51:05, time: 1.251, data_time: 0.014, memory: 9759, decode.loss_seg: 1.1416, decode.acc_seg: 50.2526, loss: 1.1416
2021-08-14 09:44:09,066 - mmseg - INFO - Iter [18500/160000]	lr: 8.964e-03, eta: 2 days, 4:49:34, time: 1.283, data_time: 0.015, memory: 9759, decode.loss_seg: 1.1362, decode.acc_seg: 49.9063, loss: 1.1362
2021-08-14 09:45:10,767 - mmseg - INFO - Iter [18550/160000]	lr: 8.961e-03, eta: 2 days, 4:47:44, time: 1.233, data_time: 0.015, memory: 9759, decode.loss_seg: 1.1482, decode.acc_seg: 50.6883, loss: 1.1482
2021-08-14 09:46:12,792 - mmseg - INFO - Iter [18600/160000]	lr: 8.958e-03, eta: 2 days, 4:45:58, time: 1.241, data_time: 0.016, memory: 9759, decode.loss_seg: 1.1274, decode.acc_seg: 50.4800, loss: 1.1274
2021-08-14 09:47:16,739 - mmseg - INFO - Iter [18650/160000]	lr: 8.955e-03, eta: 2 days, 4:44:26, time: 1.279, data_time: 0.016, memory: 9759, decode.loss_seg: 1.1458, decode.acc_seg: 50.9855, loss: 1.1458
2021-08-14 09:48:19,792 - mmseg - INFO - Iter [18700/160000]	lr: 8.952e-03, eta: 2 days, 4:42:48, time: 1.261, data_time: 0.016, memory: 9759, decode.loss_seg: 1.1379, decode.acc_seg: 50.9444, loss: 1.1379
2021-08-14 09:49:20,164 - mmseg - INFO - Iter [18750/160000]	lr: 8.950e-03, eta: 2 days, 4:40:50, time: 1.208, data_time: 0.016, memory: 9759, decode.loss_seg: 1.1322, decode.acc_seg: 51.4381, loss: 1.1322
2021-08-14 09:50:21,439 - mmseg - INFO - Iter [18800/160000]	lr: 8.947e-03, eta: 2 days, 4:38:59, time: 1.226, data_time: 0.016, memory: 9759, decode.loss_seg: 1.1401, decode.acc_seg: 50.5943, loss: 1.1401
2021-08-14 09:51:24,255 - mmseg - INFO - Iter [18850/160000]	lr: 8.944e-03, eta: 2 days, 4:37:19, time: 1.256, data_time: 0.016, memory: 9759, decode.loss_seg: 1.1541, decode.acc_seg: 50.2630, loss: 1.1541
2021-08-14 09:52:28,090 - mmseg - INFO - Iter [18900/160000]	lr: 8.941e-03, eta: 2 days, 4:35:48, time: 1.277, data_time: 0.016, memory: 9759, decode.loss_seg: 1.1622, decode.acc_seg: 50.4628, loss: 1.1622
2021-08-14 09:54:07,499 - mmseg - INFO - Iter [18950/160000]	lr: 8.938e-03, eta: 2 days, 4:38:41, time: 1.988, data_time: 0.696, memory: 9759, decode.loss_seg: 1.1559, decode.acc_seg: 49.6624, loss: 1.1559
2021-08-14 09:55:10,623 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 09:55:10,623 - mmseg - INFO - Iter [19000/160000]	lr: 8.935e-03, eta: 2 days, 4:37:04, time: 1.264, data_time: 0.016, memory: 9759, decode.loss_seg: 1.1145, decode.acc_seg: 50.9582, loss: 1.1145
2021-08-14 09:56:12,647 - mmseg - INFO - Iter [19050/160000]	lr: 8.933e-03, eta: 2 days, 4:35:19, time: 1.240, data_time: 0.014, memory: 9759, decode.loss_seg: 1.1526, decode.acc_seg: 49.9680, loss: 1.1526
2021-08-14 09:57:16,715 - mmseg - INFO - Iter [19100/160000]	lr: 8.930e-03, eta: 2 days, 4:33:49, time: 1.281, data_time: 0.015, memory: 9759, decode.loss_seg: 1.1232, decode.acc_seg: 51.2227, loss: 1.1232
2021-08-14 09:58:17,928 - mmseg - INFO - Iter [19150/160000]	lr: 8.927e-03, eta: 2 days, 4:31:58, time: 1.224, data_time: 0.014, memory: 9759, decode.loss_seg: 1.1000, decode.acc_seg: 51.8809, loss: 1.1000
2021-08-14 09:59:20,104 - mmseg - INFO - Iter [19200/160000]	lr: 8.924e-03, eta: 2 days, 4:30:15, time: 1.243, data_time: 0.015, memory: 9759, decode.loss_seg: 1.1204, decode.acc_seg: 50.5842, loss: 1.1204
2021-08-14 10:00:24,586 - mmseg - INFO - Iter [19250/160000]	lr: 8.921e-03, eta: 2 days, 4:28:48, time: 1.288, data_time: 0.014, memory: 9759, decode.loss_seg: 1.1614, decode.acc_seg: 50.6941, loss: 1.1614
2021-08-14 10:01:30,917 - mmseg - INFO - Iter [19300/160000]	lr: 8.918e-03, eta: 2 days, 4:27:35, time: 1.327, data_time: 0.015, memory: 9759, decode.loss_seg: 1.1404, decode.acc_seg: 51.6748, loss: 1.1404
2021-08-14 10:02:37,317 - mmseg - INFO - Iter [19350/160000]	lr: 8.916e-03, eta: 2 days, 4:26:23, time: 1.328, data_time: 0.014, memory: 9759, decode.loss_seg: 1.1160, decode.acc_seg: 51.4573, loss: 1.1160
2021-08-14 10:03:43,654 - mmseg - INFO - Iter [19400/160000]	lr: 8.913e-03, eta: 2 days, 4:25:10, time: 1.327, data_time: 0.015, memory: 9759, decode.loss_seg: 1.1007, decode.acc_seg: 51.0093, loss: 1.1007
2021-08-14 10:04:48,226 - mmseg - INFO - Iter [19450/160000]	lr: 8.910e-03, eta: 2 days, 4:23:45, time: 1.292, data_time: 0.014, memory: 9759, decode.loss_seg: 1.0949, decode.acc_seg: 50.4703, loss: 1.0949
2021-08-14 10:05:52,271 - mmseg - INFO - Iter [19500/160000]	lr: 8.907e-03, eta: 2 days, 4:22:16, time: 1.281, data_time: 0.015, memory: 9759, decode.loss_seg: 1.1138, decode.acc_seg: 51.1565, loss: 1.1138
2021-08-14 10:06:53,425 - mmseg - INFO - Iter [19550/160000]	lr: 8.904e-03, eta: 2 days, 4:20:26, time: 1.222, data_time: 0.015, memory: 9759, decode.loss_seg: 1.1689, decode.acc_seg: 51.2906, loss: 1.1689
2021-08-14 10:08:32,886 - mmseg - INFO - Iter [19600/160000]	lr: 8.902e-03, eta: 2 days, 4:23:11, time: 1.990, data_time: 0.740, memory: 9759, decode.loss_seg: 1.1192, decode.acc_seg: 50.7609, loss: 1.1192
2021-08-14 10:09:35,922 - mmseg - INFO - Iter [19650/160000]	lr: 8.899e-03, eta: 2 days, 4:21:34, time: 1.260, data_time: 0.015, memory: 9759, decode.loss_seg: 1.1249, decode.acc_seg: 50.4318, loss: 1.1249
2021-08-14 10:10:38,619 - mmseg - INFO - Iter [19700/160000]	lr: 8.896e-03, eta: 2 days, 4:19:55, time: 1.254, data_time: 0.014, memory: 9759, decode.loss_seg: 1.0971, decode.acc_seg: 51.6952, loss: 1.0971
2021-08-14 10:11:44,368 - mmseg - INFO - Iter [19750/160000]	lr: 8.893e-03, eta: 2 days, 4:18:38, time: 1.315, data_time: 0.013, memory: 9759, decode.loss_seg: 1.1287, decode.acc_seg: 50.8194, loss: 1.1287
2021-08-14 10:12:45,544 - mmseg - INFO - Iter [19800/160000]	lr: 8.890e-03, eta: 2 days, 4:16:49, time: 1.224, data_time: 0.014, memory: 9759, decode.loss_seg: 1.1069, decode.acc_seg: 50.7948, loss: 1.1069
2021-08-14 10:13:49,054 - mmseg - INFO - Iter [19850/160000]	lr: 8.887e-03, eta: 2 days, 4:15:16, time: 1.270, data_time: 0.014, memory: 9759, decode.loss_seg: 1.1369, decode.acc_seg: 50.1544, loss: 1.1369
2021-08-14 10:14:55,167 - mmseg - INFO - Iter [19900/160000]	lr: 8.885e-03, eta: 2 days, 4:14:02, time: 1.322, data_time: 0.014, memory: 9759, decode.loss_seg: 1.1510, decode.acc_seg: 50.6759, loss: 1.1510
2021-08-14 10:15:58,588 - mmseg - INFO - Iter [19950/160000]	lr: 8.882e-03, eta: 2 days, 4:12:29, time: 1.269, data_time: 0.015, memory: 9759, decode.loss_seg: 1.1136, decode.acc_seg: 51.5932, loss: 1.1136
2021-08-14 10:17:01,534 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 10:17:01,534 - mmseg - INFO - Iter [20000/160000]	lr: 8.879e-03, eta: 2 days, 4:10:53, time: 1.259, data_time: 0.014, memory: 9759, decode.loss_seg: 1.1118, decode.acc_seg: 50.8824, loss: 1.1118
2021-08-14 10:18:02,860 - mmseg - INFO - Iter [20050/160000]	lr: 8.876e-03, eta: 2 days, 4:09:06, time: 1.227, data_time: 0.014, memory: 9759, decode.loss_seg: 1.1008, decode.acc_seg: 51.8243, loss: 1.1008
2021-08-14 10:19:08,082 - mmseg - INFO - Iter [20100/160000]	lr: 8.873e-03, eta: 2 days, 4:07:46, time: 1.304, data_time: 0.014, memory: 9759, decode.loss_seg: 1.1316, decode.acc_seg: 51.3829, loss: 1.1316
2021-08-14 10:20:11,466 - mmseg - INFO - Iter [20150/160000]	lr: 8.871e-03, eta: 2 days, 4:06:13, time: 1.268, data_time: 0.013, memory: 9759, decode.loss_seg: 1.1192, decode.acc_seg: 51.6055, loss: 1.1192
2021-08-14 10:21:48,019 - mmseg - INFO - Iter [20200/160000]	lr: 8.868e-03, eta: 2 days, 4:08:30, time: 1.931, data_time: 0.708, memory: 9759, decode.loss_seg: 1.1293, decode.acc_seg: 51.4419, loss: 1.1293
2021-08-14 10:22:49,934 - mmseg - INFO - Iter [20250/160000]	lr: 8.865e-03, eta: 2 days, 4:06:47, time: 1.239, data_time: 0.016, memory: 9759, decode.loss_seg: 1.0780, decode.acc_seg: 51.6114, loss: 1.0780
2021-08-14 10:23:52,444 - mmseg - INFO - Iter [20300/160000]	lr: 8.862e-03, eta: 2 days, 4:05:08, time: 1.250, data_time: 0.015, memory: 9759, decode.loss_seg: 1.1338, decode.acc_seg: 51.3226, loss: 1.1338
2021-08-14 10:24:56,802 - mmseg - INFO - Iter [20350/160000]	lr: 8.859e-03, eta: 2 days, 4:03:42, time: 1.287, data_time: 0.016, memory: 9759, decode.loss_seg: 1.0779, decode.acc_seg: 51.7154, loss: 1.0779
2021-08-14 10:26:00,820 - mmseg - INFO - Iter [20400/160000]	lr: 8.856e-03, eta: 2 days, 4:02:14, time: 1.279, data_time: 0.015, memory: 9759, decode.loss_seg: 1.1453, decode.acc_seg: 50.6421, loss: 1.1453
2021-08-14 10:27:06,931 - mmseg - INFO - Iter [20450/160000]	lr: 8.854e-03, eta: 2 days, 4:01:00, time: 1.323, data_time: 0.015, memory: 9759, decode.loss_seg: 1.1125, decode.acc_seg: 51.7307, loss: 1.1125
2021-08-14 10:28:10,358 - mmseg - INFO - Iter [20500/160000]	lr: 8.851e-03, eta: 2 days, 3:59:28, time: 1.268, data_time: 0.015, memory: 9759, decode.loss_seg: 1.1437, decode.acc_seg: 51.1246, loss: 1.1437
2021-08-14 10:29:11,533 - mmseg - INFO - Iter [20550/160000]	lr: 8.848e-03, eta: 2 days, 3:57:41, time: 1.224, data_time: 0.015, memory: 9759, decode.loss_seg: 1.1064, decode.acc_seg: 50.6415, loss: 1.1064
2021-08-14 10:30:14,451 - mmseg - INFO - Iter [20600/160000]	lr: 8.845e-03, eta: 2 days, 3:56:05, time: 1.257, data_time: 0.014, memory: 9759, decode.loss_seg: 1.1145, decode.acc_seg: 51.3508, loss: 1.1145
2021-08-14 10:31:18,057 - mmseg - INFO - Iter [20650/160000]	lr: 8.842e-03, eta: 2 days, 3:54:35, time: 1.273, data_time: 0.017, memory: 9759, decode.loss_seg: 1.1032, decode.acc_seg: 50.4013, loss: 1.1032
2021-08-14 10:32:23,573 - mmseg - INFO - Iter [20700/160000]	lr: 8.839e-03, eta: 2 days, 3:53:18, time: 1.311, data_time: 0.015, memory: 9759, decode.loss_seg: 1.1087, decode.acc_seg: 51.5178, loss: 1.1087
2021-08-14 10:33:27,861 - mmseg - INFO - Iter [20750/160000]	lr: 8.837e-03, eta: 2 days, 3:51:52, time: 1.286, data_time: 0.014, memory: 9759, decode.loss_seg: 1.1233, decode.acc_seg: 50.7676, loss: 1.1233
2021-08-14 10:34:32,126 - mmseg - INFO - Iter [20800/160000]	lr: 8.834e-03, eta: 2 days, 3:50:26, time: 1.285, data_time: 0.014, memory: 9759, decode.loss_seg: 1.1196, decode.acc_seg: 51.0656, loss: 1.1196
2021-08-14 10:36:10,716 - mmseg - INFO - Iter [20850/160000]	lr: 8.831e-03, eta: 2 days, 3:52:50, time: 1.971, data_time: 0.720, memory: 9759, decode.loss_seg: 1.0990, decode.acc_seg: 51.7243, loss: 1.0990
2021-08-14 10:37:17,249 - mmseg - INFO - Iter [20900/160000]	lr: 8.828e-03, eta: 2 days, 3:51:39, time: 1.331, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0758, decode.acc_seg: 50.7774, loss: 1.0758
2021-08-14 10:38:22,281 - mmseg - INFO - Iter [20950/160000]	lr: 8.825e-03, eta: 2 days, 3:50:18, time: 1.301, data_time: 0.016, memory: 9759, decode.loss_seg: 1.0540, decode.acc_seg: 52.9272, loss: 1.0540
2021-08-14 10:39:24,584 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 10:39:24,584 - mmseg - INFO - Iter [21000/160000]	lr: 8.823e-03, eta: 2 days, 3:48:39, time: 1.246, data_time: 0.015, memory: 9759, decode.loss_seg: 1.1070, decode.acc_seg: 52.7321, loss: 1.1070
2021-08-14 10:40:27,271 - mmseg - INFO - Iter [21050/160000]	lr: 8.820e-03, eta: 2 days, 3:47:03, time: 1.254, data_time: 0.016, memory: 9759, decode.loss_seg: 1.1155, decode.acc_seg: 50.5852, loss: 1.1155
2021-08-14 10:41:29,677 - mmseg - INFO - Iter [21100/160000]	lr: 8.817e-03, eta: 2 days, 3:45:25, time: 1.248, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0884, decode.acc_seg: 51.3298, loss: 1.0884
2021-08-14 10:42:32,332 - mmseg - INFO - Iter [21150/160000]	lr: 8.814e-03, eta: 2 days, 3:43:49, time: 1.253, data_time: 0.015, memory: 9759, decode.loss_seg: 1.1338, decode.acc_seg: 50.9720, loss: 1.1338
2021-08-14 10:43:34,752 - mmseg - INFO - Iter [21200/160000]	lr: 8.811e-03, eta: 2 days, 3:42:12, time: 1.248, data_time: 0.014, memory: 9759, decode.loss_seg: 1.0974, decode.acc_seg: 52.3399, loss: 1.0974
2021-08-14 10:44:35,399 - mmseg - INFO - Iter [21250/160000]	lr: 8.808e-03, eta: 2 days, 3:40:23, time: 1.213, data_time: 0.013, memory: 9759, decode.loss_seg: 1.0910, decode.acc_seg: 51.7009, loss: 1.0910
2021-08-14 10:45:37,760 - mmseg - INFO - Iter [21300/160000]	lr: 8.806e-03, eta: 2 days, 3:38:45, time: 1.247, data_time: 0.014, memory: 9759, decode.loss_seg: 1.1302, decode.acc_seg: 49.8697, loss: 1.1302
2021-08-14 10:46:43,103 - mmseg - INFO - Iter [21350/160000]	lr: 8.803e-03, eta: 2 days, 3:37:27, time: 1.307, data_time: 0.014, memory: 9759, decode.loss_seg: 1.1341, decode.acc_seg: 50.8631, loss: 1.1341
2021-08-14 10:47:45,177 - mmseg - INFO - Iter [21400/160000]	lr: 8.800e-03, eta: 2 days, 3:35:48, time: 1.241, data_time: 0.015, memory: 9759, decode.loss_seg: 1.1357, decode.acc_seg: 50.3571, loss: 1.1357
2021-08-14 10:48:50,033 - mmseg - INFO - Iter [21450/160000]	lr: 8.797e-03, eta: 2 days, 3:34:27, time: 1.297, data_time: 0.015, memory: 9759, decode.loss_seg: 1.1214, decode.acc_seg: 50.5097, loss: 1.1214
2021-08-14 10:50:27,534 - mmseg - INFO - Iter [21500/160000]	lr: 8.794e-03, eta: 2 days, 3:36:37, time: 1.951, data_time: 0.726, memory: 9759, decode.loss_seg: 1.0858, decode.acc_seg: 51.3677, loss: 1.0858
2021-08-14 10:51:29,275 - mmseg - INFO - Iter [21550/160000]	lr: 8.791e-03, eta: 2 days, 3:34:55, time: 1.234, data_time: 0.015, memory: 9759, decode.loss_seg: 1.1000, decode.acc_seg: 51.3777, loss: 1.1000
2021-08-14 10:52:32,863 - mmseg - INFO - Iter [21600/160000]	lr: 8.789e-03, eta: 2 days, 3:33:26, time: 1.272, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0681, decode.acc_seg: 52.1149, loss: 1.0681
2021-08-14 10:53:35,514 - mmseg - INFO - Iter [21650/160000]	lr: 8.786e-03, eta: 2 days, 3:31:51, time: 1.253, data_time: 0.015, memory: 9759, decode.loss_seg: 1.1109, decode.acc_seg: 52.2878, loss: 1.1109
2021-08-14 10:54:38,628 - mmseg - INFO - Iter [21700/160000]	lr: 8.783e-03, eta: 2 days, 3:30:19, time: 1.262, data_time: 0.016, memory: 9759, decode.loss_seg: 1.1318, decode.acc_seg: 50.8238, loss: 1.1318
2021-08-14 10:55:42,438 - mmseg - INFO - Iter [21750/160000]	lr: 8.780e-03, eta: 2 days, 3:28:51, time: 1.277, data_time: 0.016, memory: 9759, decode.loss_seg: 1.0759, decode.acc_seg: 51.9748, loss: 1.0759
2021-08-14 10:56:49,474 - mmseg - INFO - Iter [21800/160000]	lr: 8.777e-03, eta: 2 days, 3:27:44, time: 1.340, data_time: 0.015, memory: 9759, decode.loss_seg: 1.1309, decode.acc_seg: 50.2757, loss: 1.1309
2021-08-14 10:57:57,647 - mmseg - INFO - Iter [21850/160000]	lr: 8.775e-03, eta: 2 days, 3:26:44, time: 1.363, data_time: 0.015, memory: 9759, decode.loss_seg: 1.1006, decode.acc_seg: 51.8970, loss: 1.1006
2021-08-14 10:59:02,112 - mmseg - INFO - Iter [21900/160000]	lr: 8.772e-03, eta: 2 days, 3:25:21, time: 1.290, data_time: 0.016, memory: 9759, decode.loss_seg: 1.0652, decode.acc_seg: 52.7252, loss: 1.0652
2021-08-14 11:00:02,853 - mmseg - INFO - Iter [21950/160000]	lr: 8.769e-03, eta: 2 days, 3:23:35, time: 1.215, data_time: 0.014, memory: 9759, decode.loss_seg: 1.1222, decode.acc_seg: 51.0265, loss: 1.1222
2021-08-14 11:01:06,773 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 11:01:06,773 - mmseg - INFO - Iter [22000/160000]	lr: 8.766e-03, eta: 2 days, 3:22:08, time: 1.278, data_time: 0.014, memory: 9759, decode.loss_seg: 1.0948, decode.acc_seg: 51.8341, loss: 1.0948
2021-08-14 11:02:09,477 - mmseg - INFO - Iter [22050/160000]	lr: 8.763e-03, eta: 2 days, 3:20:35, time: 1.255, data_time: 0.016, memory: 9759, decode.loss_seg: 1.1512, decode.acc_seg: 51.6123, loss: 1.1512
2021-08-14 11:03:49,917 - mmseg - INFO - Iter [22100/160000]	lr: 8.760e-03, eta: 2 days, 3:22:56, time: 2.008, data_time: 0.692, memory: 9759, decode.loss_seg: 1.1034, decode.acc_seg: 50.9485, loss: 1.1034
2021-08-14 11:04:52,976 - mmseg - INFO - Iter [22150/160000]	lr: 8.758e-03, eta: 2 days, 3:21:24, time: 1.262, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0773, decode.acc_seg: 51.3721, loss: 1.0773
2021-08-14 11:05:54,765 - mmseg - INFO - Iter [22200/160000]	lr: 8.755e-03, eta: 2 days, 3:19:44, time: 1.235, data_time: 0.014, memory: 9759, decode.loss_seg: 1.0867, decode.acc_seg: 52.6376, loss: 1.0867
2021-08-14 11:06:57,639 - mmseg - INFO - Iter [22250/160000]	lr: 8.752e-03, eta: 2 days, 3:18:11, time: 1.257, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0482, decode.acc_seg: 51.9579, loss: 1.0482
2021-08-14 11:08:02,663 - mmseg - INFO - Iter [22300/160000]	lr: 8.749e-03, eta: 2 days, 3:16:52, time: 1.300, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0885, decode.acc_seg: 51.6077, loss: 1.0885
2021-08-14 11:09:07,778 - mmseg - INFO - Iter [22350/160000]	lr: 8.746e-03, eta: 2 days, 3:15:33, time: 1.304, data_time: 0.016, memory: 9759, decode.loss_seg: 1.0410, decode.acc_seg: 51.7285, loss: 1.0410
2021-08-14 11:10:11,122 - mmseg - INFO - Iter [22400/160000]	lr: 8.743e-03, eta: 2 days, 3:14:04, time: 1.267, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0827, decode.acc_seg: 52.0847, loss: 1.0827
2021-08-14 11:11:13,052 - mmseg - INFO - Iter [22450/160000]	lr: 8.741e-03, eta: 2 days, 3:12:25, time: 1.239, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0741, decode.acc_seg: 52.0971, loss: 1.0741
2021-08-14 11:12:14,693 - mmseg - INFO - Iter [22500/160000]	lr: 8.738e-03, eta: 2 days, 3:10:45, time: 1.233, data_time: 0.014, memory: 9759, decode.loss_seg: 1.1023, decode.acc_seg: 51.5376, loss: 1.1023
2021-08-14 11:13:17,220 - mmseg - INFO - Iter [22550/160000]	lr: 8.735e-03, eta: 2 days, 3:09:11, time: 1.250, data_time: 0.015, memory: 9759, decode.loss_seg: 1.1213, decode.acc_seg: 51.3662, loss: 1.1213
2021-08-14 11:14:19,521 - mmseg - INFO - Iter [22600/160000]	lr: 8.732e-03, eta: 2 days, 3:07:36, time: 1.246, data_time: 0.014, memory: 9759, decode.loss_seg: 1.1301, decode.acc_seg: 51.9956, loss: 1.1301
2021-08-14 11:15:23,210 - mmseg - INFO - Iter [22650/160000]	lr: 8.729e-03, eta: 2 days, 3:06:09, time: 1.274, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0838, decode.acc_seg: 52.1150, loss: 1.0838
2021-08-14 11:16:25,737 - mmseg - INFO - Iter [22700/160000]	lr: 8.726e-03, eta: 2 days, 3:04:35, time: 1.250, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0867, decode.acc_seg: 50.4106, loss: 1.0867
2021-08-14 11:18:04,780 - mmseg - INFO - Iter [22750/160000]	lr: 8.724e-03, eta: 2 days, 3:06:41, time: 1.980, data_time: 0.730, memory: 9759, decode.loss_seg: 1.0775, decode.acc_seg: 51.3166, loss: 1.0775
2021-08-14 11:19:09,443 - mmseg - INFO - Iter [22800/160000]	lr: 8.721e-03, eta: 2 days, 3:05:20, time: 1.293, data_time: 0.017, memory: 9759, decode.loss_seg: 1.0494, decode.acc_seg: 51.5603, loss: 1.0494
2021-08-14 11:20:12,977 - mmseg - INFO - Iter [22850/160000]	lr: 8.718e-03, eta: 2 days, 3:03:52, time: 1.272, data_time: 0.016, memory: 9759, decode.loss_seg: 1.1095, decode.acc_seg: 51.4303, loss: 1.1095
2021-08-14 11:21:15,842 - mmseg - INFO - Iter [22900/160000]	lr: 8.715e-03, eta: 2 days, 3:02:20, time: 1.257, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0814, decode.acc_seg: 52.7366, loss: 1.0814
2021-08-14 11:22:19,672 - mmseg - INFO - Iter [22950/160000]	lr: 8.712e-03, eta: 2 days, 3:00:54, time: 1.276, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0783, decode.acc_seg: 50.1746, loss: 1.0783
2021-08-14 11:23:24,901 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 11:23:24,902 - mmseg - INFO - Iter [23000/160000]	lr: 8.710e-03, eta: 2 days, 2:59:37, time: 1.305, data_time: 0.016, memory: 9759, decode.loss_seg: 1.0831, decode.acc_seg: 51.8075, loss: 1.0831
2021-08-14 11:24:29,898 - mmseg - INFO - Iter [23050/160000]	lr: 8.707e-03, eta: 2 days, 2:58:18, time: 1.300, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0708, decode.acc_seg: 53.4382, loss: 1.0708
2021-08-14 11:25:34,175 - mmseg - INFO - Iter [23100/160000]	lr: 8.704e-03, eta: 2 days, 2:56:55, time: 1.285, data_time: 0.014, memory: 9759, decode.loss_seg: 1.0679, decode.acc_seg: 51.5339, loss: 1.0679
2021-08-14 11:26:34,990 - mmseg - INFO - Iter [23150/160000]	lr: 8.701e-03, eta: 2 days, 2:55:11, time: 1.217, data_time: 0.016, memory: 9759, decode.loss_seg: 1.0727, decode.acc_seg: 51.8127, loss: 1.0727
2021-08-14 11:27:39,090 - mmseg - INFO - Iter [23200/160000]	lr: 8.698e-03, eta: 2 days, 2:53:47, time: 1.282, data_time: 0.015, memory: 9759, decode.loss_seg: 1.1006, decode.acc_seg: 51.0507, loss: 1.1006
2021-08-14 11:28:45,716 - mmseg - INFO - Iter [23250/160000]	lr: 8.695e-03, eta: 2 days, 2:52:38, time: 1.332, data_time: 0.016, memory: 9759, decode.loss_seg: 1.0875, decode.acc_seg: 51.5816, loss: 1.0875
2021-08-14 11:29:49,751 - mmseg - INFO - Iter [23300/160000]	lr: 8.693e-03, eta: 2 days, 2:51:14, time: 1.282, data_time: 0.015, memory: 9759, decode.loss_seg: 1.1121, decode.acc_seg: 51.5692, loss: 1.1121
2021-08-14 11:31:28,189 - mmseg - INFO - Iter [23350/160000]	lr: 8.690e-03, eta: 2 days, 2:53:11, time: 1.968, data_time: 0.721, memory: 9759, decode.loss_seg: 1.1074, decode.acc_seg: 51.1964, loss: 1.1074
2021-08-14 11:32:32,248 - mmseg - INFO - Iter [23400/160000]	lr: 8.687e-03, eta: 2 days, 2:51:47, time: 1.282, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0860, decode.acc_seg: 52.0920, loss: 1.0860
2021-08-14 11:33:34,911 - mmseg - INFO - Iter [23450/160000]	lr: 8.684e-03, eta: 2 days, 2:50:15, time: 1.254, data_time: 0.017, memory: 9759, decode.loss_seg: 1.1181, decode.acc_seg: 51.9153, loss: 1.1181
2021-08-14 11:34:38,714 - mmseg - INFO - Iter [23500/160000]	lr: 8.681e-03, eta: 2 days, 2:48:49, time: 1.275, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0845, decode.acc_seg: 52.5870, loss: 1.0845
2021-08-14 11:35:41,567 - mmseg - INFO - Iter [23550/160000]	lr: 8.678e-03, eta: 2 days, 2:47:18, time: 1.257, data_time: 0.014, memory: 9759, decode.loss_seg: 1.0582, decode.acc_seg: 50.8478, loss: 1.0582
2021-08-14 11:36:45,853 - mmseg - INFO - Iter [23600/160000]	lr: 8.676e-03, eta: 2 days, 2:45:55, time: 1.286, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0931, decode.acc_seg: 51.7689, loss: 1.0931
2021-08-14 11:37:48,882 - mmseg - INFO - Iter [23650/160000]	lr: 8.673e-03, eta: 2 days, 2:44:25, time: 1.261, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0781, decode.acc_seg: 51.4133, loss: 1.0781
2021-08-14 11:38:50,375 - mmseg - INFO - Iter [23700/160000]	lr: 8.670e-03, eta: 2 days, 2:42:47, time: 1.229, data_time: 0.014, memory: 9759, decode.loss_seg: 1.0543, decode.acc_seg: 52.4283, loss: 1.0543
2021-08-14 11:39:54,320 - mmseg - INFO - Iter [23750/160000]	lr: 8.667e-03, eta: 2 days, 2:41:22, time: 1.279, data_time: 0.014, memory: 9759, decode.loss_seg: 1.0482, decode.acc_seg: 52.3262, loss: 1.0482
2021-08-14 11:40:58,466 - mmseg - INFO - Iter [23800/160000]	lr: 8.664e-03, eta: 2 days, 2:39:59, time: 1.283, data_time: 0.015, memory: 9759, decode.loss_seg: 1.1124, decode.acc_seg: 51.4686, loss: 1.1124
2021-08-14 11:42:02,033 - mmseg - INFO - Iter [23850/160000]	lr: 8.661e-03, eta: 2 days, 2:38:33, time: 1.272, data_time: 0.015, memory: 9759, decode.loss_seg: 1.1088, decode.acc_seg: 52.2417, loss: 1.1088
2021-08-14 11:43:06,390 - mmseg - INFO - Iter [23900/160000]	lr: 8.659e-03, eta: 2 days, 2:37:11, time: 1.287, data_time: 0.014, memory: 9759, decode.loss_seg: 1.0877, decode.acc_seg: 51.5615, loss: 1.0877
2021-08-14 11:44:08,274 - mmseg - INFO - Iter [23950/160000]	lr: 8.656e-03, eta: 2 days, 2:35:36, time: 1.238, data_time: 0.013, memory: 9759, decode.loss_seg: 1.1107, decode.acc_seg: 51.8560, loss: 1.1107
2021-08-14 11:45:46,924 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 11:45:46,928 - mmseg - INFO - Iter [24000/160000]	lr: 8.653e-03, eta: 2 days, 2:37:28, time: 1.972, data_time: 0.709, memory: 9759, decode.loss_seg: 1.0796, decode.acc_seg: 51.9630, loss: 1.0796
2021-08-14 11:46:49,980 - mmseg - INFO - Iter [24050/160000]	lr: 8.650e-03, eta: 2 days, 2:35:59, time: 1.262, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0708, decode.acc_seg: 52.1148, loss: 1.0708
2021-08-14 11:47:52,913 - mmseg - INFO - Iter [24100/160000]	lr: 8.647e-03, eta: 2 days, 2:34:29, time: 1.259, data_time: 0.014, memory: 9759, decode.loss_seg: 1.0700, decode.acc_seg: 51.4921, loss: 1.0700
2021-08-14 11:48:55,140 - mmseg - INFO - Iter [24150/160000]	lr: 8.644e-03, eta: 2 days, 2:32:55, time: 1.244, data_time: 0.014, memory: 9759, decode.loss_seg: 1.0594, decode.acc_seg: 52.1685, loss: 1.0594
2021-08-14 11:50:00,006 - mmseg - INFO - Iter [24200/160000]	lr: 8.642e-03, eta: 2 days, 2:31:36, time: 1.298, data_time: 0.014, memory: 9759, decode.loss_seg: 1.0751, decode.acc_seg: 52.4758, loss: 1.0751
2021-08-14 11:51:01,975 - mmseg - INFO - Iter [24250/160000]	lr: 8.639e-03, eta: 2 days, 2:30:01, time: 1.239, data_time: 0.014, memory: 9759, decode.loss_seg: 1.0658, decode.acc_seg: 52.3488, loss: 1.0658
2021-08-14 11:52:04,089 - mmseg - INFO - Iter [24300/160000]	lr: 8.636e-03, eta: 2 days, 2:28:27, time: 1.242, data_time: 0.014, memory: 9759, decode.loss_seg: 1.0883, decode.acc_seg: 50.5923, loss: 1.0883
2021-08-14 11:53:05,609 - mmseg - INFO - Iter [24350/160000]	lr: 8.633e-03, eta: 2 days, 2:26:50, time: 1.231, data_time: 0.014, memory: 9759, decode.loss_seg: 1.0931, decode.acc_seg: 51.9200, loss: 1.0931
2021-08-14 11:54:09,582 - mmseg - INFO - Iter [24400/160000]	lr: 8.630e-03, eta: 2 days, 2:25:26, time: 1.278, data_time: 0.014, memory: 9759, decode.loss_seg: 1.0550, decode.acc_seg: 52.1926, loss: 1.0550
2021-08-14 11:55:13,048 - mmseg - INFO - Iter [24450/160000]	lr: 8.627e-03, eta: 2 days, 2:24:01, time: 1.271, data_time: 0.015, memory: 9759, decode.loss_seg: 1.1150, decode.acc_seg: 51.1249, loss: 1.1150
2021-08-14 11:56:15,611 - mmseg - INFO - Iter [24500/160000]	lr: 8.625e-03, eta: 2 days, 2:22:29, time: 1.251, data_time: 0.013, memory: 9759, decode.loss_seg: 1.0864, decode.acc_seg: 51.7924, loss: 1.0864
2021-08-14 11:57:18,743 - mmseg - INFO - Iter [24550/160000]	lr: 8.622e-03, eta: 2 days, 2:21:02, time: 1.262, data_time: 0.015, memory: 9759, decode.loss_seg: 1.1004, decode.acc_seg: 52.0709, loss: 1.1004
2021-08-14 11:58:21,725 - mmseg - INFO - Iter [24600/160000]	lr: 8.619e-03, eta: 2 days, 2:19:33, time: 1.260, data_time: 0.014, memory: 9759, decode.loss_seg: 1.1036, decode.acc_seg: 51.4023, loss: 1.1036
2021-08-14 11:59:59,224 - mmseg - INFO - Iter [24650/160000]	lr: 8.616e-03, eta: 2 days, 2:21:14, time: 1.950, data_time: 0.694, memory: 9759, decode.loss_seg: 1.0859, decode.acc_seg: 52.2081, loss: 1.0859
2021-08-14 12:01:04,848 - mmseg - INFO - Iter [24700/160000]	lr: 8.613e-03, eta: 2 days, 2:20:00, time: 1.313, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0639, decode.acc_seg: 51.3478, loss: 1.0639
2021-08-14 12:02:08,418 - mmseg - INFO - Iter [24750/160000]	lr: 8.610e-03, eta: 2 days, 2:18:34, time: 1.271, data_time: 0.013, memory: 9759, decode.loss_seg: 1.0571, decode.acc_seg: 52.3484, loss: 1.0571
2021-08-14 12:03:11,682 - mmseg - INFO - Iter [24800/160000]	lr: 8.608e-03, eta: 2 days, 2:17:07, time: 1.265, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0525, decode.acc_seg: 52.7758, loss: 1.0525
2021-08-14 12:04:16,951 - mmseg - INFO - Iter [24850/160000]	lr: 8.605e-03, eta: 2 days, 2:15:51, time: 1.305, data_time: 0.014, memory: 9759, decode.loss_seg: 1.0614, decode.acc_seg: 52.1419, loss: 1.0614
2021-08-14 12:05:19,624 - mmseg - INFO - Iter [24900/160000]	lr: 8.602e-03, eta: 2 days, 2:14:21, time: 1.253, data_time: 0.014, memory: 9759, decode.loss_seg: 1.0809, decode.acc_seg: 51.4515, loss: 1.0809
2021-08-14 12:06:24,872 - mmseg - INFO - Iter [24950/160000]	lr: 8.599e-03, eta: 2 days, 2:13:05, time: 1.304, data_time: 0.014, memory: 9759, decode.loss_seg: 1.0607, decode.acc_seg: 53.1111, loss: 1.0607
2021-08-14 12:07:32,325 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 12:07:32,325 - mmseg - INFO - Iter [25000/160000]	lr: 8.596e-03, eta: 2 days, 2:12:01, time: 1.349, data_time: 0.014, memory: 9759, decode.loss_seg: 1.1012, decode.acc_seg: 51.8351, loss: 1.1012
2021-08-14 12:08:40,217 - mmseg - INFO - Iter [25050/160000]	lr: 8.593e-03, eta: 2 days, 2:10:59, time: 1.358, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0927, decode.acc_seg: 51.1908, loss: 1.0927
2021-08-14 12:09:44,398 - mmseg - INFO - Iter [25100/160000]	lr: 8.591e-03, eta: 2 days, 2:09:37, time: 1.284, data_time: 0.016, memory: 9759, decode.loss_seg: 1.0795, decode.acc_seg: 52.7409, loss: 1.0795
2021-08-14 12:10:50,112 - mmseg - INFO - Iter [25150/160000]	lr: 8.588e-03, eta: 2 days, 2:08:24, time: 1.314, data_time: 0.014, memory: 9759, decode.loss_seg: 1.0603, decode.acc_seg: 51.8578, loss: 1.0603
2021-08-14 12:11:54,443 - mmseg - INFO - Iter [25200/160000]	lr: 8.585e-03, eta: 2 days, 2:07:03, time: 1.286, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0848, decode.acc_seg: 51.6982, loss: 1.0848
2021-08-14 12:13:45,809 - mmseg - INFO - Iter [25250/160000]	lr: 8.582e-03, eta: 2 days, 2:09:53, time: 2.228, data_time: 0.991, memory: 9759, decode.loss_seg: 1.0734, decode.acc_seg: 52.6139, loss: 1.0734
2021-08-14 12:14:48,077 - mmseg - INFO - Iter [25300/160000]	lr: 8.579e-03, eta: 2 days, 2:08:21, time: 1.246, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0389, decode.acc_seg: 52.8754, loss: 1.0389
2021-08-14 12:15:50,402 - mmseg - INFO - Iter [25350/160000]	lr: 8.576e-03, eta: 2 days, 2:06:49, time: 1.246, data_time: 0.014, memory: 9759, decode.loss_seg: 1.0583, decode.acc_seg: 52.0561, loss: 1.0583
2021-08-14 12:16:53,578 - mmseg - INFO - Iter [25400/160000]	lr: 8.574e-03, eta: 2 days, 2:05:22, time: 1.263, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0629, decode.acc_seg: 52.6028, loss: 1.0629
2021-08-14 12:17:55,678 - mmseg - INFO - Iter [25450/160000]	lr: 8.571e-03, eta: 2 days, 2:03:49, time: 1.243, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0913, decode.acc_seg: 52.2720, loss: 1.0913
2021-08-14 12:18:58,259 - mmseg - INFO - Iter [25500/160000]	lr: 8.568e-03, eta: 2 days, 2:02:19, time: 1.251, data_time: 0.017, memory: 9759, decode.loss_seg: 1.0909, decode.acc_seg: 52.9596, loss: 1.0909
2021-08-14 12:20:00,760 - mmseg - INFO - Iter [25550/160000]	lr: 8.565e-03, eta: 2 days, 2:00:49, time: 1.250, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0740, decode.acc_seg: 51.1593, loss: 1.0740
2021-08-14 12:21:05,675 - mmseg - INFO - Iter [25600/160000]	lr: 8.562e-03, eta: 2 days, 1:59:31, time: 1.298, data_time: 0.015, memory: 9759, decode.loss_seg: 1.1210, decode.acc_seg: 50.3727, loss: 1.1210
2021-08-14 12:22:09,129 - mmseg - INFO - Iter [25650/160000]	lr: 8.559e-03, eta: 2 days, 1:58:06, time: 1.270, data_time: 0.016, memory: 9759, decode.loss_seg: 1.0570, decode.acc_seg: 52.7158, loss: 1.0570
2021-08-14 12:23:12,982 - mmseg - INFO - Iter [25700/160000]	lr: 8.557e-03, eta: 2 days, 1:56:43, time: 1.277, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0652, decode.acc_seg: 51.5019, loss: 1.0652
2021-08-14 12:24:15,481 - mmseg - INFO - Iter [25750/160000]	lr: 8.554e-03, eta: 2 days, 1:55:12, time: 1.249, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0878, decode.acc_seg: 51.5310, loss: 1.0878
2021-08-14 12:25:17,744 - mmseg - INFO - Iter [25800/160000]	lr: 8.551e-03, eta: 2 days, 1:53:41, time: 1.246, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0677, decode.acc_seg: 51.9132, loss: 1.0677
2021-08-14 12:26:20,594 - mmseg - INFO - Iter [25850/160000]	lr: 8.548e-03, eta: 2 days, 1:52:13, time: 1.256, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0752, decode.acc_seg: 52.5988, loss: 1.0752
2021-08-14 12:27:59,498 - mmseg - INFO - Iter [25900/160000]	lr: 8.545e-03, eta: 2 days, 1:53:52, time: 1.978, data_time: 0.723, memory: 9759, decode.loss_seg: 1.0419, decode.acc_seg: 52.5601, loss: 1.0419
2021-08-14 12:29:01,894 - mmseg - INFO - Iter [25950/160000]	lr: 8.542e-03, eta: 2 days, 1:52:21, time: 1.248, data_time: 0.016, memory: 9759, decode.loss_seg: 1.0311, decode.acc_seg: 52.4843, loss: 1.0311
2021-08-14 12:30:05,348 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 12:30:05,349 - mmseg - INFO - Iter [26000/160000]	lr: 8.540e-03, eta: 2 days, 1:50:56, time: 1.269, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0255, decode.acc_seg: 52.6882, loss: 1.0255
2021-08-14 12:31:08,418 - mmseg - INFO - Iter [26050/160000]	lr: 8.537e-03, eta: 2 days, 1:49:29, time: 1.260, data_time: 0.016, memory: 9759, decode.loss_seg: 1.0568, decode.acc_seg: 52.3617, loss: 1.0568
2021-08-14 12:32:12,010 - mmseg - INFO - Iter [26100/160000]	lr: 8.534e-03, eta: 2 days, 1:48:05, time: 1.273, data_time: 0.016, memory: 9759, decode.loss_seg: 1.0340, decode.acc_seg: 52.8018, loss: 1.0340
2021-08-14 12:33:15,865 - mmseg - INFO - Iter [26150/160000]	lr: 8.531e-03, eta: 2 days, 1:46:42, time: 1.277, data_time: 0.014, memory: 9759, decode.loss_seg: 1.0737, decode.acc_seg: 51.4834, loss: 1.0737
2021-08-14 12:34:19,647 - mmseg - INFO - Iter [26200/160000]	lr: 8.528e-03, eta: 2 days, 1:45:19, time: 1.275, data_time: 0.014, memory: 9759, decode.loss_seg: 1.0792, decode.acc_seg: 52.3275, loss: 1.0792
2021-08-14 12:35:22,879 - mmseg - INFO - Iter [26250/160000]	lr: 8.525e-03, eta: 2 days, 1:43:53, time: 1.265, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0558, decode.acc_seg: 51.5319, loss: 1.0558
2021-08-14 12:36:24,079 - mmseg - INFO - Iter [26300/160000]	lr: 8.523e-03, eta: 2 days, 1:42:17, time: 1.223, data_time: 0.013, memory: 9759, decode.loss_seg: 1.0755, decode.acc_seg: 51.2320, loss: 1.0755
2021-08-14 12:37:25,806 - mmseg - INFO - Iter [26350/160000]	lr: 8.520e-03, eta: 2 days, 1:40:44, time: 1.235, data_time: 0.016, memory: 9759, decode.loss_seg: 1.0915, decode.acc_seg: 52.3395, loss: 1.0915
2021-08-14 12:38:29,259 - mmseg - INFO - Iter [26400/160000]	lr: 8.517e-03, eta: 2 days, 1:39:20, time: 1.269, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0814, decode.acc_seg: 53.1950, loss: 1.0814
2021-08-14 12:39:30,874 - mmseg - INFO - Iter [26450/160000]	lr: 8.514e-03, eta: 2 days, 1:37:46, time: 1.232, data_time: 0.014, memory: 9759, decode.loss_seg: 1.0786, decode.acc_seg: 51.9533, loss: 1.0786
2021-08-14 12:40:32,720 - mmseg - INFO - Iter [26500/160000]	lr: 8.511e-03, eta: 2 days, 1:36:14, time: 1.237, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0523, decode.acc_seg: 52.5670, loss: 1.0523
2021-08-14 12:42:10,360 - mmseg - INFO - Iter [26550/160000]	lr: 8.508e-03, eta: 2 days, 1:37:41, time: 1.952, data_time: 0.708, memory: 9759, decode.loss_seg: 1.0075, decode.acc_seg: 53.2061, loss: 1.0075
2021-08-14 12:43:13,533 - mmseg - INFO - Iter [26600/160000]	lr: 8.506e-03, eta: 2 days, 1:36:15, time: 1.264, data_time: 0.016, memory: 9759, decode.loss_seg: 1.0765, decode.acc_seg: 51.2536, loss: 1.0765
2021-08-14 12:44:16,512 - mmseg - INFO - Iter [26650/160000]	lr: 8.503e-03, eta: 2 days, 1:34:49, time: 1.259, data_time: 0.014, memory: 9759, decode.loss_seg: 1.0700, decode.acc_seg: 51.4774, loss: 1.0700
2021-08-14 12:45:20,073 - mmseg - INFO - Iter [26700/160000]	lr: 8.500e-03, eta: 2 days, 1:33:25, time: 1.272, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0655, decode.acc_seg: 51.6472, loss: 1.0655
2021-08-14 12:46:21,455 - mmseg - INFO - Iter [26750/160000]	lr: 8.497e-03, eta: 2 days, 1:31:50, time: 1.227, data_time: 0.014, memory: 9759, decode.loss_seg: 1.0195, decode.acc_seg: 53.1670, loss: 1.0195
2021-08-14 12:47:23,975 - mmseg - INFO - Iter [26800/160000]	lr: 8.494e-03, eta: 2 days, 1:30:22, time: 1.251, data_time: 0.014, memory: 9759, decode.loss_seg: 1.0604, decode.acc_seg: 51.8175, loss: 1.0604
2021-08-14 12:48:26,135 - mmseg - INFO - Iter [26850/160000]	lr: 8.491e-03, eta: 2 days, 1:28:51, time: 1.243, data_time: 0.013, memory: 9759, decode.loss_seg: 1.0687, decode.acc_seg: 51.6227, loss: 1.0687
2021-08-14 12:49:31,701 - mmseg - INFO - Iter [26900/160000]	lr: 8.489e-03, eta: 2 days, 1:27:38, time: 1.310, data_time: 0.013, memory: 9759, decode.loss_seg: 1.0584, decode.acc_seg: 52.1514, loss: 1.0584
2021-08-14 12:50:37,465 - mmseg - INFO - Iter [26950/160000]	lr: 8.486e-03, eta: 2 days, 1:26:26, time: 1.317, data_time: 0.014, memory: 9759, decode.loss_seg: 1.0323, decode.acc_seg: 52.9749, loss: 1.0323
2021-08-14 12:51:40,812 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 12:51:40,813 - mmseg - INFO - Iter [27000/160000]	lr: 8.483e-03, eta: 2 days, 1:25:01, time: 1.266, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0673, decode.acc_seg: 52.7275, loss: 1.0673
2021-08-14 12:52:45,726 - mmseg - INFO - Iter [27050/160000]	lr: 8.480e-03, eta: 2 days, 1:23:45, time: 1.299, data_time: 0.014, memory: 9759, decode.loss_seg: 1.0636, decode.acc_seg: 52.0623, loss: 1.0636
2021-08-14 12:53:47,466 - mmseg - INFO - Iter [27100/160000]	lr: 8.477e-03, eta: 2 days, 1:22:13, time: 1.235, data_time: 0.014, memory: 9759, decode.loss_seg: 1.0809, decode.acc_seg: 52.2399, loss: 1.0809
2021-08-14 12:55:25,414 - mmseg - INFO - Iter [27150/160000]	lr: 8.474e-03, eta: 2 days, 1:23:38, time: 1.959, data_time: 0.690, memory: 9759, decode.loss_seg: 1.0677, decode.acc_seg: 52.9270, loss: 1.0677
2021-08-14 12:56:27,556 - mmseg - INFO - Iter [27200/160000]	lr: 8.472e-03, eta: 2 days, 1:22:07, time: 1.242, data_time: 0.014, memory: 9759, decode.loss_seg: 1.0810, decode.acc_seg: 51.1500, loss: 1.0810
2021-08-14 12:57:31,061 - mmseg - INFO - Iter [27250/160000]	lr: 8.469e-03, eta: 2 days, 1:20:44, time: 1.271, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0461, decode.acc_seg: 52.7689, loss: 1.0461
2021-08-14 12:58:33,320 - mmseg - INFO - Iter [27300/160000]	lr: 8.466e-03, eta: 2 days, 1:19:14, time: 1.245, data_time: 0.014, memory: 9759, decode.loss_seg: 1.0453, decode.acc_seg: 53.6321, loss: 1.0453
2021-08-14 12:59:36,574 - mmseg - INFO - Iter [27350/160000]	lr: 8.463e-03, eta: 2 days, 1:17:50, time: 1.266, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0301, decode.acc_seg: 52.6258, loss: 1.0301
2021-08-14 13:00:40,235 - mmseg - INFO - Iter [27400/160000]	lr: 8.460e-03, eta: 2 days, 1:16:27, time: 1.273, data_time: 0.016, memory: 9759, decode.loss_seg: 1.0871, decode.acc_seg: 51.5370, loss: 1.0871
2021-08-14 13:01:43,302 - mmseg - INFO - Iter [27450/160000]	lr: 8.457e-03, eta: 2 days, 1:15:02, time: 1.260, data_time: 0.014, memory: 9759, decode.loss_seg: 1.0590, decode.acc_seg: 52.6266, loss: 1.0590
2021-08-14 13:02:47,568 - mmseg - INFO - Iter [27500/160000]	lr: 8.455e-03, eta: 2 days, 1:13:43, time: 1.286, data_time: 0.014, memory: 9759, decode.loss_seg: 1.0414, decode.acc_seg: 53.3771, loss: 1.0414
2021-08-14 13:03:50,599 - mmseg - INFO - Iter [27550/160000]	lr: 8.452e-03, eta: 2 days, 1:12:17, time: 1.260, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0842, decode.acc_seg: 51.6892, loss: 1.0842
2021-08-14 13:04:52,342 - mmseg - INFO - Iter [27600/160000]	lr: 8.449e-03, eta: 2 days, 1:10:46, time: 1.236, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0641, decode.acc_seg: 52.6200, loss: 1.0641
2021-08-14 13:05:54,021 - mmseg - INFO - Iter [27650/160000]	lr: 8.446e-03, eta: 2 days, 1:09:14, time: 1.234, data_time: 0.014, memory: 9759, decode.loss_seg: 1.0555, decode.acc_seg: 52.4534, loss: 1.0555
2021-08-14 13:06:55,842 - mmseg - INFO - Iter [27700/160000]	lr: 8.443e-03, eta: 2 days, 1:07:43, time: 1.236, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0374, decode.acc_seg: 53.3540, loss: 1.0374
2021-08-14 13:07:58,135 - mmseg - INFO - Iter [27750/160000]	lr: 8.440e-03, eta: 2 days, 1:06:15, time: 1.245, data_time: 0.014, memory: 9759, decode.loss_seg: 1.0779, decode.acc_seg: 51.6565, loss: 1.0779
2021-08-14 13:09:36,767 - mmseg - INFO - Iter [27800/160000]	lr: 8.438e-03, eta: 2 days, 1:07:39, time: 1.973, data_time: 0.711, memory: 9759, decode.loss_seg: 1.0778, decode.acc_seg: 52.1437, loss: 1.0778
2021-08-14 13:10:40,501 - mmseg - INFO - Iter [27850/160000]	lr: 8.435e-03, eta: 2 days, 1:06:17, time: 1.274, data_time: 0.014, memory: 9759, decode.loss_seg: 1.0109, decode.acc_seg: 53.4934, loss: 1.0109
2021-08-14 13:11:42,545 - mmseg - INFO - Iter [27900/160000]	lr: 8.432e-03, eta: 2 days, 1:04:47, time: 1.241, data_time: 0.014, memory: 9759, decode.loss_seg: 1.0379, decode.acc_seg: 52.7151, loss: 1.0379
2021-08-14 13:12:47,961 - mmseg - INFO - Iter [27950/160000]	lr: 8.429e-03, eta: 2 days, 1:03:34, time: 1.309, data_time: 0.014, memory: 9759, decode.loss_seg: 1.0421, decode.acc_seg: 52.8592, loss: 1.0421
2021-08-14 13:13:49,921 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 13:13:49,922 - mmseg - INFO - Iter [28000/160000]	lr: 8.426e-03, eta: 2 days, 1:02:03, time: 1.238, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0262, decode.acc_seg: 53.0922, loss: 1.0262
2021-08-14 13:14:51,748 - mmseg - INFO - Iter [28050/160000]	lr: 8.423e-03, eta: 2 days, 1:00:33, time: 1.237, data_time: 0.016, memory: 9759, decode.loss_seg: 1.0378, decode.acc_seg: 53.1589, loss: 1.0378
2021-08-14 13:15:55,433 - mmseg - INFO - Iter [28100/160000]	lr: 8.421e-03, eta: 2 days, 0:59:11, time: 1.273, data_time: 0.016, memory: 9759, decode.loss_seg: 1.0375, decode.acc_seg: 52.6673, loss: 1.0375
2021-08-14 13:16:58,569 - mmseg - INFO - Iter [28150/160000]	lr: 8.418e-03, eta: 2 days, 0:57:47, time: 1.263, data_time: 0.016, memory: 9759, decode.loss_seg: 1.0284, decode.acc_seg: 53.1662, loss: 1.0284
2021-08-14 13:18:00,923 - mmseg - INFO - Iter [28200/160000]	lr: 8.415e-03, eta: 2 days, 0:56:19, time: 1.248, data_time: 0.016, memory: 9759, decode.loss_seg: 1.0283, decode.acc_seg: 53.4562, loss: 1.0283
2021-08-14 13:19:02,850 - mmseg - INFO - Iter [28250/160000]	lr: 8.412e-03, eta: 2 days, 0:54:49, time: 1.239, data_time: 0.016, memory: 9759, decode.loss_seg: 1.0961, decode.acc_seg: 52.3688, loss: 1.0961
2021-08-14 13:20:05,819 - mmseg - INFO - Iter [28300/160000]	lr: 8.409e-03, eta: 2 days, 0:53:25, time: 1.259, data_time: 0.016, memory: 9759, decode.loss_seg: 1.0012, decode.acc_seg: 53.3574, loss: 1.0012
2021-08-14 13:21:07,812 - mmseg - INFO - Iter [28350/160000]	lr: 8.406e-03, eta: 2 days, 0:51:55, time: 1.240, data_time: 0.013, memory: 9759, decode.loss_seg: 1.0838, decode.acc_seg: 52.6856, loss: 1.0838
2021-08-14 13:22:45,420 - mmseg - INFO - Iter [28400/160000]	lr: 8.403e-03, eta: 2 days, 0:53:11, time: 1.952, data_time: 0.713, memory: 9759, decode.loss_seg: 1.0564, decode.acc_seg: 53.2282, loss: 1.0564
2021-08-14 13:23:48,533 - mmseg - INFO - Iter [28450/160000]	lr: 8.401e-03, eta: 2 days, 0:51:47, time: 1.262, data_time: 0.016, memory: 9759, decode.loss_seg: 1.0514, decode.acc_seg: 52.5434, loss: 1.0514
2021-08-14 13:24:52,326 - mmseg - INFO - Iter [28500/160000]	lr: 8.398e-03, eta: 2 days, 0:50:26, time: 1.275, data_time: 0.014, memory: 9759, decode.loss_seg: 1.0345, decode.acc_seg: 52.5963, loss: 1.0345
2021-08-14 13:25:55,243 - mmseg - INFO - Iter [28550/160000]	lr: 8.395e-03, eta: 2 days, 0:49:01, time: 1.259, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0464, decode.acc_seg: 52.2636, loss: 1.0464
2021-08-14 13:26:58,289 - mmseg - INFO - Iter [28600/160000]	lr: 8.392e-03, eta: 2 days, 0:47:37, time: 1.261, data_time: 0.016, memory: 9759, decode.loss_seg: 0.9984, decode.acc_seg: 53.3826, loss: 0.9984
2021-08-14 13:28:02,245 - mmseg - INFO - Iter [28650/160000]	lr: 8.389e-03, eta: 2 days, 0:46:17, time: 1.280, data_time: 0.017, memory: 9759, decode.loss_seg: 1.0341, decode.acc_seg: 53.2390, loss: 1.0341
2021-08-14 13:29:03,956 - mmseg - INFO - Iter [28700/160000]	lr: 8.386e-03, eta: 2 days, 0:44:46, time: 1.234, data_time: 0.014, memory: 9759, decode.loss_seg: 1.0582, decode.acc_seg: 52.5162, loss: 1.0582
2021-08-14 13:30:06,931 - mmseg - INFO - Iter [28750/160000]	lr: 8.384e-03, eta: 2 days, 0:43:22, time: 1.259, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0148, decode.acc_seg: 53.1663, loss: 1.0148
2021-08-14 13:31:09,145 - mmseg - INFO - Iter [28800/160000]	lr: 8.381e-03, eta: 2 days, 0:41:54, time: 1.244, data_time: 0.016, memory: 9759, decode.loss_seg: 1.0208, decode.acc_seg: 51.8067, loss: 1.0208
2021-08-14 13:32:11,132 - mmseg - INFO - Iter [28850/160000]	lr: 8.378e-03, eta: 2 days, 0:40:26, time: 1.240, data_time: 0.016, memory: 9759, decode.loss_seg: 1.0448, decode.acc_seg: 53.1005, loss: 1.0448
2021-08-14 13:33:13,735 - mmseg - INFO - Iter [28900/160000]	lr: 8.375e-03, eta: 2 days, 0:39:00, time: 1.252, data_time: 0.017, memory: 9759, decode.loss_seg: 1.0634, decode.acc_seg: 51.9299, loss: 1.0634
2021-08-14 13:34:16,741 - mmseg - INFO - Iter [28950/160000]	lr: 8.372e-03, eta: 2 days, 0:37:36, time: 1.260, data_time: 0.016, memory: 9759, decode.loss_seg: 1.0374, decode.acc_seg: 52.5003, loss: 1.0374
2021-08-14 13:35:19,936 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 13:35:19,936 - mmseg - INFO - Iter [29000/160000]	lr: 8.369e-03, eta: 2 days, 0:36:12, time: 1.263, data_time: 0.014, memory: 9759, decode.loss_seg: 1.0476, decode.acc_seg: 52.2070, loss: 1.0476
2021-08-14 13:36:57,018 - mmseg - INFO - Iter [29050/160000]	lr: 8.367e-03, eta: 2 days, 0:37:22, time: 1.942, data_time: 0.714, memory: 9759, decode.loss_seg: 1.0737, decode.acc_seg: 52.2780, loss: 1.0737
2021-08-14 13:38:02,600 - mmseg - INFO - Iter [29100/160000]	lr: 8.364e-03, eta: 2 days, 0:36:10, time: 1.311, data_time: 0.013, memory: 9759, decode.loss_seg: 1.0189, decode.acc_seg: 52.2431, loss: 1.0189
2021-08-14 13:39:04,546 - mmseg - INFO - Iter [29150/160000]	lr: 8.361e-03, eta: 2 days, 0:34:41, time: 1.240, data_time: 0.014, memory: 9759, decode.loss_seg: 1.0190, decode.acc_seg: 53.4475, loss: 1.0190
2021-08-14 13:40:07,326 - mmseg - INFO - Iter [29200/160000]	lr: 8.358e-03, eta: 2 days, 0:33:16, time: 1.255, data_time: 0.016, memory: 9759, decode.loss_seg: 1.0413, decode.acc_seg: 52.7919, loss: 1.0413
2021-08-14 13:41:10,152 - mmseg - INFO - Iter [29250/160000]	lr: 8.355e-03, eta: 2 days, 0:31:51, time: 1.256, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0258, decode.acc_seg: 52.7464, loss: 1.0258
2021-08-14 13:42:12,432 - mmseg - INFO - Iter [29300/160000]	lr: 8.352e-03, eta: 2 days, 0:30:25, time: 1.246, data_time: 0.016, memory: 9759, decode.loss_seg: 1.0069, decode.acc_seg: 53.2978, loss: 1.0069
2021-08-14 13:43:14,040 - mmseg - INFO - Iter [29350/160000]	lr: 8.350e-03, eta: 2 days, 0:28:55, time: 1.232, data_time: 0.014, memory: 9759, decode.loss_seg: 1.0370, decode.acc_seg: 52.8129, loss: 1.0370
2021-08-14 13:44:18,294 - mmseg - INFO - Iter [29400/160000]	lr: 8.347e-03, eta: 2 days, 0:27:36, time: 1.284, data_time: 0.012, memory: 9759, decode.loss_seg: 1.0421, decode.acc_seg: 53.0326, loss: 1.0421
2021-08-14 13:45:23,802 - mmseg - INFO - Iter [29450/160000]	lr: 8.344e-03, eta: 2 days, 0:26:24, time: 1.311, data_time: 0.014, memory: 9759, decode.loss_seg: 1.0604, decode.acc_seg: 52.4575, loss: 1.0604
2021-08-14 13:46:25,500 - mmseg - INFO - Iter [29500/160000]	lr: 8.341e-03, eta: 2 days, 0:24:55, time: 1.233, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0569, decode.acc_seg: 52.9993, loss: 1.0569
2021-08-14 13:47:27,659 - mmseg - INFO - Iter [29550/160000]	lr: 8.338e-03, eta: 2 days, 0:23:27, time: 1.243, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0613, decode.acc_seg: 52.8076, loss: 1.0613
2021-08-14 13:48:29,708 - mmseg - INFO - Iter [29600/160000]	lr: 8.335e-03, eta: 2 days, 0:22:00, time: 1.241, data_time: 0.016, memory: 9759, decode.loss_seg: 1.0588, decode.acc_seg: 52.1064, loss: 1.0588
2021-08-14 13:49:32,510 - mmseg - INFO - Iter [29650/160000]	lr: 8.332e-03, eta: 2 days, 0:20:36, time: 1.256, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0118, decode.acc_seg: 52.9284, loss: 1.0118
2021-08-14 13:51:08,665 - mmseg - INFO - Iter [29700/160000]	lr: 8.330e-03, eta: 2 days, 0:21:38, time: 1.923, data_time: 0.674, memory: 9759, decode.loss_seg: 0.9894, decode.acc_seg: 52.6972, loss: 0.9894
2021-08-14 13:52:12,389 - mmseg - INFO - Iter [29750/160000]	lr: 8.327e-03, eta: 2 days, 0:20:18, time: 1.275, data_time: 0.014, memory: 9759, decode.loss_seg: 1.0082, decode.acc_seg: 53.5700, loss: 1.0082
2021-08-14 13:53:15,544 - mmseg - INFO - Iter [29800/160000]	lr: 8.324e-03, eta: 2 days, 0:18:55, time: 1.263, data_time: 0.014, memory: 9759, decode.loss_seg: 1.0185, decode.acc_seg: 53.4497, loss: 1.0185
2021-08-14 13:54:18,162 - mmseg - INFO - Iter [29850/160000]	lr: 8.321e-03, eta: 2 days, 0:17:30, time: 1.252, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0840, decode.acc_seg: 52.6046, loss: 1.0840
2021-08-14 13:55:20,856 - mmseg - INFO - Iter [29900/160000]	lr: 8.318e-03, eta: 2 days, 0:16:05, time: 1.254, data_time: 0.014, memory: 9759, decode.loss_seg: 1.0218, decode.acc_seg: 52.8885, loss: 1.0218
2021-08-14 13:56:22,632 - mmseg - INFO - Iter [29950/160000]	lr: 8.315e-03, eta: 2 days, 0:14:37, time: 1.235, data_time: 0.014, memory: 9759, decode.loss_seg: 1.0084, decode.acc_seg: 53.4828, loss: 1.0084
2021-08-14 13:57:25,508 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 13:57:25,508 - mmseg - INFO - Iter [30000/160000]	lr: 8.313e-03, eta: 2 days, 0:13:13, time: 1.258, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0378, decode.acc_seg: 52.5973, loss: 1.0378
2021-08-14 13:58:30,033 - mmseg - INFO - Iter [30050/160000]	lr: 8.310e-03, eta: 2 days, 0:11:56, time: 1.289, data_time: 0.014, memory: 9759, decode.loss_seg: 1.0258, decode.acc_seg: 53.4025, loss: 1.0258
2021-08-14 13:59:37,632 - mmseg - INFO - Iter [30100/160000]	lr: 8.307e-03, eta: 2 days, 0:10:53, time: 1.352, data_time: 0.014, memory: 9759, decode.loss_seg: 1.0276, decode.acc_seg: 52.8130, loss: 1.0276
2021-08-14 14:00:45,246 - mmseg - INFO - Iter [30150/160000]	lr: 8.304e-03, eta: 2 days, 0:09:50, time: 1.353, data_time: 0.014, memory: 9759, decode.loss_seg: 1.0319, decode.acc_seg: 53.7367, loss: 1.0319
2021-08-14 14:01:47,638 - mmseg - INFO - Iter [30200/160000]	lr: 8.301e-03, eta: 2 days, 0:08:25, time: 1.249, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0445, decode.acc_seg: 52.1267, loss: 1.0445
2021-08-14 14:02:53,562 - mmseg - INFO - Iter [30250/160000]	lr: 8.298e-03, eta: 2 days, 0:07:14, time: 1.317, data_time: 0.014, memory: 9759, decode.loss_seg: 1.0446, decode.acc_seg: 53.5307, loss: 1.0446
2021-08-14 14:04:34,977 - mmseg - INFO - Iter [30300/160000]	lr: 8.296e-03, eta: 2 days, 0:08:36, time: 2.030, data_time: 0.713, memory: 9759, decode.loss_seg: 1.0800, decode.acc_seg: 51.3140, loss: 1.0800
2021-08-14 14:05:39,468 - mmseg - INFO - Iter [30350/160000]	lr: 8.293e-03, eta: 2 days, 0:07:19, time: 1.290, data_time: 0.014, memory: 9759, decode.loss_seg: 1.0241, decode.acc_seg: 52.5673, loss: 1.0241
2021-08-14 14:06:40,752 - mmseg - INFO - Iter [30400/160000]	lr: 8.290e-03, eta: 2 days, 0:05:49, time: 1.225, data_time: 0.014, memory: 9759, decode.loss_seg: 1.0294, decode.acc_seg: 53.6332, loss: 1.0294
2021-08-14 14:07:45,566 - mmseg - INFO - Iter [30450/160000]	lr: 8.287e-03, eta: 2 days, 0:04:33, time: 1.295, data_time: 0.013, memory: 9759, decode.loss_seg: 1.0478, decode.acc_seg: 53.1218, loss: 1.0478
2021-08-14 14:08:48,840 - mmseg - INFO - Iter [30500/160000]	lr: 8.284e-03, eta: 2 days, 0:03:12, time: 1.266, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0166, decode.acc_seg: 52.9371, loss: 1.0166
2021-08-14 14:09:51,668 - mmseg - INFO - Iter [30550/160000]	lr: 8.281e-03, eta: 2 days, 0:01:48, time: 1.257, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0008, decode.acc_seg: 52.4706, loss: 1.0008
2021-08-14 14:10:55,768 - mmseg - INFO - Iter [30600/160000]	lr: 8.278e-03, eta: 2 days, 0:00:30, time: 1.282, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0014, decode.acc_seg: 53.0711, loss: 1.0014
2021-08-14 14:12:00,115 - mmseg - INFO - Iter [30650/160000]	lr: 8.276e-03, eta: 1 day, 23:59:13, time: 1.286, data_time: 0.014, memory: 9759, decode.loss_seg: 1.0285, decode.acc_seg: 53.3881, loss: 1.0285
2021-08-14 14:13:03,697 - mmseg - INFO - Iter [30700/160000]	lr: 8.273e-03, eta: 1 day, 23:57:53, time: 1.272, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0312, decode.acc_seg: 53.1175, loss: 1.0312
2021-08-14 14:14:06,154 - mmseg - INFO - Iter [30750/160000]	lr: 8.270e-03, eta: 1 day, 23:56:28, time: 1.249, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0765, decode.acc_seg: 51.5845, loss: 1.0765
2021-08-14 14:15:07,666 - mmseg - INFO - Iter [30800/160000]	lr: 8.267e-03, eta: 1 day, 23:54:59, time: 1.230, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0260, decode.acc_seg: 52.9684, loss: 1.0260
2021-08-14 14:16:11,572 - mmseg - INFO - Iter [30850/160000]	lr: 8.264e-03, eta: 1 day, 23:53:40, time: 1.278, data_time: 0.016, memory: 9759, decode.loss_seg: 1.0122, decode.acc_seg: 53.4532, loss: 1.0122
2021-08-14 14:17:16,683 - mmseg - INFO - Iter [30900/160000]	lr: 8.261e-03, eta: 1 day, 23:52:27, time: 1.302, data_time: 0.017, memory: 9759, decode.loss_seg: 1.0683, decode.acc_seg: 52.6570, loss: 1.0683
2021-08-14 14:18:56,283 - mmseg - INFO - Iter [30950/160000]	lr: 8.259e-03, eta: 1 day, 23:53:37, time: 1.992, data_time: 0.686, memory: 9759, decode.loss_seg: 1.0233, decode.acc_seg: 53.1266, loss: 1.0233
2021-08-14 14:20:02,286 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 14:20:02,286 - mmseg - INFO - Iter [31000/160000]	lr: 8.256e-03, eta: 1 day, 23:52:27, time: 1.320, data_time: 0.016, memory: 9759, decode.loss_seg: 0.9984, decode.acc_seg: 53.8100, loss: 0.9984
2021-08-14 14:21:05,870 - mmseg - INFO - Iter [31050/160000]	lr: 8.253e-03, eta: 1 day, 23:51:07, time: 1.272, data_time: 0.014, memory: 9759, decode.loss_seg: 1.0217, decode.acc_seg: 53.1270, loss: 1.0217
2021-08-14 14:22:07,163 - mmseg - INFO - Iter [31100/160000]	lr: 8.250e-03, eta: 1 day, 23:49:37, time: 1.226, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9916, decode.acc_seg: 53.3347, loss: 0.9916
2021-08-14 14:23:09,386 - mmseg - INFO - Iter [31150/160000]	lr: 8.247e-03, eta: 1 day, 23:48:12, time: 1.244, data_time: 0.016, memory: 9759, decode.loss_seg: 1.0249, decode.acc_seg: 52.7332, loss: 1.0249
2021-08-14 14:24:13,140 - mmseg - INFO - Iter [31200/160000]	lr: 8.244e-03, eta: 1 day, 23:46:52, time: 1.274, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0536, decode.acc_seg: 52.3842, loss: 1.0536
2021-08-14 14:25:15,058 - mmseg - INFO - Iter [31250/160000]	lr: 8.241e-03, eta: 1 day, 23:45:25, time: 1.239, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0344, decode.acc_seg: 53.2785, loss: 1.0344
2021-08-14 14:26:17,397 - mmseg - INFO - Iter [31300/160000]	lr: 8.239e-03, eta: 1 day, 23:44:00, time: 1.247, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0172, decode.acc_seg: 53.3763, loss: 1.0172
2021-08-14 14:27:19,931 - mmseg - INFO - Iter [31350/160000]	lr: 8.236e-03, eta: 1 day, 23:42:36, time: 1.251, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0530, decode.acc_seg: 53.2202, loss: 1.0530
2021-08-14 14:28:25,252 - mmseg - INFO - Iter [31400/160000]	lr: 8.233e-03, eta: 1 day, 23:41:24, time: 1.306, data_time: 0.016, memory: 9759, decode.loss_seg: 1.0519, decode.acc_seg: 53.2279, loss: 1.0519
2021-08-14 14:29:30,251 - mmseg - INFO - Iter [31450/160000]	lr: 8.230e-03, eta: 1 day, 23:40:10, time: 1.301, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0257, decode.acc_seg: 52.6649, loss: 1.0257
2021-08-14 14:30:33,927 - mmseg - INFO - Iter [31500/160000]	lr: 8.227e-03, eta: 1 day, 23:38:50, time: 1.273, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0412, decode.acc_seg: 52.0794, loss: 1.0412
2021-08-14 14:31:35,774 - mmseg - INFO - Iter [31550/160000]	lr: 8.224e-03, eta: 1 day, 23:37:24, time: 1.238, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0315, decode.acc_seg: 52.8640, loss: 1.0315
2021-08-14 14:33:14,299 - mmseg - INFO - Iter [31600/160000]	lr: 8.222e-03, eta: 1 day, 23:38:26, time: 1.970, data_time: 0.719, memory: 9759, decode.loss_seg: 0.9926, decode.acc_seg: 53.7211, loss: 0.9926
2021-08-14 14:34:19,456 - mmseg - INFO - Iter [31650/160000]	lr: 8.219e-03, eta: 1 day, 23:37:13, time: 1.303, data_time: 0.016, memory: 9759, decode.loss_seg: 1.0007, decode.acc_seg: 54.3266, loss: 1.0007
2021-08-14 14:35:25,484 - mmseg - INFO - Iter [31700/160000]	lr: 8.216e-03, eta: 1 day, 23:36:03, time: 1.320, data_time: 0.016, memory: 9759, decode.loss_seg: 1.0148, decode.acc_seg: 53.5104, loss: 1.0148
2021-08-14 14:36:28,854 - mmseg - INFO - Iter [31750/160000]	lr: 8.213e-03, eta: 1 day, 23:34:42, time: 1.268, data_time: 0.016, memory: 9759, decode.loss_seg: 0.9993, decode.acc_seg: 53.3252, loss: 0.9993
2021-08-14 14:37:32,144 - mmseg - INFO - Iter [31800/160000]	lr: 8.210e-03, eta: 1 day, 23:33:22, time: 1.266, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0279, decode.acc_seg: 53.0553, loss: 1.0279
2021-08-14 14:38:33,897 - mmseg - INFO - Iter [31850/160000]	lr: 8.207e-03, eta: 1 day, 23:31:55, time: 1.235, data_time: 0.014, memory: 9759, decode.loss_seg: 1.0194, decode.acc_seg: 52.0360, loss: 1.0194
2021-08-14 14:39:36,499 - mmseg - INFO - Iter [31900/160000]	lr: 8.204e-03, eta: 1 day, 23:30:31, time: 1.252, data_time: 0.014, memory: 9759, decode.loss_seg: 1.0452, decode.acc_seg: 52.4847, loss: 1.0452
2021-08-14 14:40:38,696 - mmseg - INFO - Iter [31950/160000]	lr: 8.202e-03, eta: 1 day, 23:29:06, time: 1.244, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0030, decode.acc_seg: 53.5598, loss: 1.0030
2021-08-14 14:41:43,823 - mmseg - INFO - Saving checkpoint at 32000 iterations
2021-08-14 14:41:44,236 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 14:41:44,239 - mmseg - INFO - Iter [32000/160000]	lr: 8.199e-03, eta: 1 day, 23:27:55, time: 1.312, data_time: 0.014, memory: 9759, decode.loss_seg: 1.0509, decode.acc_seg: 53.0259, loss: 1.0509
2021-08-14 14:43:31,074 - mmseg - INFO - per class results:
2021-08-14 14:43:31,093 - mmseg - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        | 56.06 | 81.57 |
|       building      | 68.69 | 81.61 |
|         sky         | 89.64 | 93.73 |
|        floor        | 59.23 | 82.03 |
|         tree        | 57.43 | 84.68 |
|       ceiling       | 68.36 | 80.48 |
|         road        | 65.44 | 88.98 |
|         bed         |  59.8 | 83.54 |
|      windowpane     | 40.96 | 58.72 |
|        grass        | 53.77 | 61.69 |
|       cabinet       | 35.23 | 70.05 |
|       sidewalk      | 30.48 | 37.66 |
|        person       | 46.11 | 57.65 |
|        earth        | 22.93 | 35.82 |
|         door        | 14.81 | 18.96 |
|        table        | 30.18 | 42.97 |
|       mountain      |  33.1 | 57.69 |
|        plant        | 28.13 | 35.19 |
|       curtain       |  36.6 | 61.81 |
|        chair        | 25.29 | 34.03 |
|         car         | 55.01 | 78.75 |
|        water        | 31.28 | 53.59 |
|       painting      | 46.87 | 59.72 |
|         sofa        | 32.11 | 41.44 |
|        shelf        | 19.87 | 28.93 |
|        house        | 36.34 | 55.34 |
|         sea         | 34.75 |  77.9 |
|        mirror       | 10.57 | 11.26 |
|         rug         | 25.03 | 28.18 |
|        field        |  22.6 |  51.8 |
|       armchair      |  7.64 |  8.85 |
|         seat        |  22.6 | 30.81 |
|        fence        | 14.11 | 17.74 |
|         desk        | 13.69 | 17.18 |
|         rock        | 10.46 | 16.78 |
|       wardrobe      | 14.15 | 16.49 |
|         lamp        | 26.38 | 32.51 |
|       bathtub       | 18.36 | 19.84 |
|       railing       | 11.09 | 12.96 |
|       cushion       | 19.98 | 27.18 |
|         base        |  1.05 |  1.15 |
|         box         |  1.16 |  1.24 |
|        column       |  5.06 |  5.22 |
|      signboard      |  9.9  | 11.79 |
|   chest of drawers  | 24.02 | 26.85 |
|       counter       |  10.8 | 11.79 |
|         sand        |  7.49 | 11.41 |
|         sink        | 23.62 | 34.46 |
|      skyscraper     |  36.1 | 71.87 |
|      fireplace      |  43.2 | 50.09 |
|     refrigerator    | 18.25 | 22.42 |
|      grandstand     | 20.42 | 39.76 |
|         path        |  4.69 |  5.4  |
|        stairs       |  3.85 |  3.91 |
|        runway       | 40.29 | 51.49 |
|         case        | 14.13 |  17.0 |
|      pool table     | 60.53 | 73.72 |
|        pillow       | 26.69 | 33.62 |
|     screen door     |  4.06 |  4.17 |
|       stairway      |  5.88 |  7.27 |
|        river        |  1.9  |  2.02 |
|        bridge       | 11.22 | 21.65 |
|       bookcase      |  17.5 |  22.3 |
|        blind        |  0.62 |  0.63 |
|     coffee table    | 29.18 | 42.94 |
|        toilet       | 39.84 | 50.68 |
|        flower       |  8.11 |  9.54 |
|         book        |  9.7  | 11.04 |
|         hill        |  2.17 |  3.29 |
|        bench        | 10.46 | 11.36 |
|      countertop     |  13.4 |  15.0 |
|        stove        | 27.47 | 41.84 |
|         palm        | 14.81 | 16.44 |
|    kitchen island   | 13.71 | 19.42 |
|       computer      | 19.96 | 21.77 |
|     swivel chair    | 16.81 | 18.29 |
|         boat        | 12.41 | 18.06 |
|         bar         | 10.37 | 11.62 |
|    arcade machine   |  2.25 |  2.95 |
|        hovel        |  6.19 |  8.83 |
|         bus         | 34.15 | 38.81 |
|        towel        |  5.7  |  5.97 |
|        light        | 16.84 | 18.26 |
|        truck        |  1.11 |  1.45 |
|        tower        | 20.03 | 22.41 |
|      chandelier     |  35.8 | 57.39 |
|        awning       | 11.29 |  16.8 |
|     streetlight     |  1.91 |  1.99 |
|        booth        |  0.0  |  0.0  |
| television receiver | 21.12 | 22.92 |
|       airplane      | 23.41 | 37.64 |
|      dirt track     |  0.0  |  0.0  |
|       apparel       |  3.15 |  4.57 |
|         pole        |  1.44 |  1.61 |
|         land        |  0.0  |  0.0  |
|      bannister      |  0.0  |  0.0  |
|      escalator      |  1.07 |  1.53 |
|       ottoman       |  4.41 |  4.52 |
|        bottle       |  0.65 |  0.72 |
|        buffet       |  0.0  |  0.0  |
|        poster       |  0.0  |  0.0  |
|        stage        |  0.42 |  0.51 |
|         van         |  0.0  |  0.0  |
|         ship        |  0.0  |  0.0  |
|       fountain      |  1.08 |  1.11 |
|    conveyer belt    |  8.65 |  8.92 |
|        canopy       |  0.0  |  0.0  |
|        washer       | 31.02 | 35.99 |
|      plaything      |  0.0  |  0.0  |
|    swimming pool    |  5.72 |  8.25 |
|        stool        |  0.0  |  0.0  |
|        barrel       |  0.0  |  0.0  |
|        basket       |  0.0  |  0.0  |
|      waterfall      | 34.13 | 51.75 |
|         tent        | 44.53 | 75.08 |
|         bag         |  0.0  |  0.0  |
|       minibike      | 14.75 | 15.09 |
|        cradle       | 49.67 | 70.91 |
|         oven        |  0.41 |  0.42 |
|         ball        | 13.97 |  33.9 |
|         food        | 10.04 | 11.19 |
|         step        |  0.0  |  0.0  |
|         tank        |  0.0  |  0.0  |
|      trade name     |  12.0 | 14.06 |
|      microwave      |  8.59 |  9.08 |
|         pot         |  0.87 |  0.87 |
|        animal       |  1.1  |  1.1  |
|       bicycle       | 10.92 | 11.57 |
|         lake        |  0.0  |  0.0  |
|      dishwasher     | 10.09 | 12.73 |
|        screen       | 34.67 | 47.46 |
|       blanket       |  0.0  |  0.0  |
|      sculpture      |  0.0  |  0.0  |
|         hood        |  7.95 |  8.09 |
|        sconce       |  0.0  |  0.0  |
|         vase        |  3.82 |  4.25 |
|    traffic light    |  0.0  |  0.0  |
|         tray        |  0.0  |  0.0  |
|        ashcan       |  0.0  |  0.0  |
|         fan         |  0.01 |  0.01 |
|         pier        |  0.0  |  0.0  |
|      crt screen     |  0.0  |  0.0  |
|        plate        |  0.37 |  0.37 |
|       monitor       |  3.6  |  3.69 |
|    bulletin board   |  0.0  |  0.0  |
|        shower       |  0.0  |  0.0  |
|       radiator      |  0.0  |  0.0  |
|        glass        |  0.0  |  0.0  |
|        clock        |  0.0  |  0.0  |
|         flag        |  0.0  |  0.0  |
+---------------------+-------+-------+
2021-08-14 14:43:31,093 - mmseg - INFO - Summary:
2021-08-14 14:43:31,094 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 66.57 | 16.77 | 22.89 |
+-------+-------+-------+
2021-08-14 14:43:31,220 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 14:43:31,221 - mmseg - INFO - Iter(val) [250]	aAcc: 0.6657, mIoU: 0.1677, mAcc: 0.2289, IoU.wall: 0.5606, IoU.building: 0.6869, IoU.sky: 0.8964, IoU.floor: 0.5923, IoU.tree: 0.5743, IoU.ceiling: 0.6836, IoU.road: 0.6544, IoU.bed : 0.5980, IoU.windowpane: 0.4096, IoU.grass: 0.5377, IoU.cabinet: 0.3523, IoU.sidewalk: 0.3048, IoU.person: 0.4611, IoU.earth: 0.2293, IoU.door: 0.1481, IoU.table: 0.3018, IoU.mountain: 0.3310, IoU.plant: 0.2813, IoU.curtain: 0.3660, IoU.chair: 0.2529, IoU.car: 0.5501, IoU.water: 0.3128, IoU.painting: 0.4687, IoU.sofa: 0.3211, IoU.shelf: 0.1987, IoU.house: 0.3634, IoU.sea: 0.3475, IoU.mirror: 0.1057, IoU.rug: 0.2503, IoU.field: 0.2260, IoU.armchair: 0.0764, IoU.seat: 0.2260, IoU.fence: 0.1411, IoU.desk: 0.1369, IoU.rock: 0.1046, IoU.wardrobe: 0.1415, IoU.lamp: 0.2638, IoU.bathtub: 0.1836, IoU.railing: 0.1109, IoU.cushion: 0.1998, IoU.base: 0.0105, IoU.box: 0.0116, IoU.column: 0.0506, IoU.signboard: 0.0990, IoU.chest of drawers: 0.2402, IoU.counter: 0.1080, IoU.sand: 0.0749, IoU.sink: 0.2362, IoU.skyscraper: 0.3610, IoU.fireplace: 0.4320, IoU.refrigerator: 0.1825, IoU.grandstand: 0.2042, IoU.path: 0.0469, IoU.stairs: 0.0385, IoU.runway: 0.4029, IoU.case: 0.1413, IoU.pool table: 0.6053, IoU.pillow: 0.2669, IoU.screen door: 0.0406, IoU.stairway: 0.0588, IoU.river: 0.0190, IoU.bridge: 0.1122, IoU.bookcase: 0.1750, IoU.blind: 0.0062, IoU.coffee table: 0.2918, IoU.toilet: 0.3984, IoU.flower: 0.0811, IoU.book: 0.0970, IoU.hill: 0.0217, IoU.bench: 0.1046, IoU.countertop: 0.1340, IoU.stove: 0.2747, IoU.palm: 0.1481, IoU.kitchen island: 0.1371, IoU.computer: 0.1996, IoU.swivel chair: 0.1681, IoU.boat: 0.1241, IoU.bar: 0.1037, IoU.arcade machine: 0.0225, IoU.hovel: 0.0619, IoU.bus: 0.3415, IoU.towel: 0.0570, IoU.light: 0.1684, IoU.truck: 0.0111, IoU.tower: 0.2003, IoU.chandelier: 0.3580, IoU.awning: 0.1129, IoU.streetlight: 0.0191, IoU.booth: 0.0000, IoU.television receiver: 0.2112, IoU.airplane: 0.2341, IoU.dirt track: 0.0000, IoU.apparel: 0.0315, IoU.pole: 0.0144, IoU.land: 0.0000, IoU.bannister: 0.0000, IoU.escalator: 0.0107, IoU.ottoman: 0.0441, IoU.bottle: 0.0065, IoU.buffet: 0.0000, IoU.poster: 0.0000, IoU.stage: 0.0042, IoU.van: 0.0000, IoU.ship: 0.0000, IoU.fountain: 0.0108, IoU.conveyer belt: 0.0865, IoU.canopy: 0.0000, IoU.washer: 0.3102, IoU.plaything: 0.0000, IoU.swimming pool: 0.0572, IoU.stool: 0.0000, IoU.barrel: 0.0000, IoU.basket: 0.0000, IoU.waterfall: 0.3413, IoU.tent: 0.4453, IoU.bag: 0.0000, IoU.minibike: 0.1475, IoU.cradle: 0.4967, IoU.oven: 0.0041, IoU.ball: 0.1397, IoU.food: 0.1004, IoU.step: 0.0000, IoU.tank: 0.0000, IoU.trade name: 0.1200, IoU.microwave: 0.0859, IoU.pot: 0.0087, IoU.animal: 0.0110, IoU.bicycle: 0.1092, IoU.lake: 0.0000, IoU.dishwasher: 0.1009, IoU.screen: 0.3467, IoU.blanket: 0.0000, IoU.sculpture: 0.0000, IoU.hood: 0.0795, IoU.sconce: 0.0000, IoU.vase: 0.0382, IoU.traffic light: 0.0000, IoU.tray: 0.0000, IoU.ashcan: 0.0000, IoU.fan: 0.0001, IoU.pier: 0.0000, IoU.crt screen: 0.0000, IoU.plate: 0.0037, IoU.monitor: 0.0360, IoU.bulletin board: 0.0000, IoU.shower: 0.0000, IoU.radiator: 0.0000, IoU.glass: 0.0000, IoU.clock: 0.0000, IoU.flag: 0.0000, Acc.wall: 0.8157, Acc.building: 0.8161, Acc.sky: 0.9373, Acc.floor: 0.8203, Acc.tree: 0.8468, Acc.ceiling: 0.8048, Acc.road: 0.8898, Acc.bed : 0.8354, Acc.windowpane: 0.5872, Acc.grass: 0.6169, Acc.cabinet: 0.7005, Acc.sidewalk: 0.3766, Acc.person: 0.5765, Acc.earth: 0.3582, Acc.door: 0.1896, Acc.table: 0.4297, Acc.mountain: 0.5769, Acc.plant: 0.3519, Acc.curtain: 0.6181, Acc.chair: 0.3403, Acc.car: 0.7875, Acc.water: 0.5359, Acc.painting: 0.5972, Acc.sofa: 0.4144, Acc.shelf: 0.2893, Acc.house: 0.5534, Acc.sea: 0.7790, Acc.mirror: 0.1126, Acc.rug: 0.2818, Acc.field: 0.5180, Acc.armchair: 0.0885, Acc.seat: 0.3081, Acc.fence: 0.1774, Acc.desk: 0.1718, Acc.rock: 0.1678, Acc.wardrobe: 0.1649, Acc.lamp: 0.3251, Acc.bathtub: 0.1984, Acc.railing: 0.1296, Acc.cushion: 0.2718, Acc.base: 0.0115, Acc.box: 0.0124, Acc.column: 0.0522, Acc.signboard: 0.1179, Acc.chest of drawers: 0.2685, Acc.counter: 0.1179, Acc.sand: 0.1141, Acc.sink: 0.3446, Acc.skyscraper: 0.7187, Acc.fireplace: 0.5009, Acc.refrigerator: 0.2242, Acc.grandstand: 0.3976, Acc.path: 0.0540, Acc.stairs: 0.0391, Acc.runway: 0.5149, Acc.case: 0.1700, Acc.pool table: 0.7372, Acc.pillow: 0.3362, Acc.screen door: 0.0417, Acc.stairway: 0.0727, Acc.river: 0.0202, Acc.bridge: 0.2165, Acc.bookcase: 0.2230, Acc.blind: 0.0063, Acc.coffee table: 0.4294, Acc.toilet: 0.5068, Acc.flower: 0.0954, Acc.book: 0.1104, Acc.hill: 0.0329, Acc.bench: 0.1136, Acc.countertop: 0.1500, Acc.stove: 0.4184, Acc.palm: 0.1644, Acc.kitchen island: 0.1942, Acc.computer: 0.2177, Acc.swivel chair: 0.1829, Acc.boat: 0.1806, Acc.bar: 0.1162, Acc.arcade machine: 0.0295, Acc.hovel: 0.0883, Acc.bus: 0.3881, Acc.towel: 0.0597, Acc.light: 0.1826, Acc.truck: 0.0145, Acc.tower: 0.2241, Acc.chandelier: 0.5739, Acc.awning: 0.1680, Acc.streetlight: 0.0199, Acc.booth: 0.0000, Acc.television receiver: 0.2292, Acc.airplane: 0.3764, Acc.dirt track: 0.0000, Acc.apparel: 0.0457, Acc.pole: 0.0161, Acc.land: 0.0000, Acc.bannister: 0.0000, Acc.escalator: 0.0153, Acc.ottoman: 0.0452, Acc.bottle: 0.0072, Acc.buffet: 0.0000, Acc.poster: 0.0000, Acc.stage: 0.0051, Acc.van: 0.0000, Acc.ship: 0.0000, Acc.fountain: 0.0111, Acc.conveyer belt: 0.0892, Acc.canopy: 0.0000, Acc.washer: 0.3599, Acc.plaything: 0.0000, Acc.swimming pool: 0.0825, Acc.stool: 0.0000, Acc.barrel: 0.0000, Acc.basket: 0.0000, Acc.waterfall: 0.5175, Acc.tent: 0.7508, Acc.bag: 0.0000, Acc.minibike: 0.1509, Acc.cradle: 0.7091, Acc.oven: 0.0042, Acc.ball: 0.3390, Acc.food: 0.1119, Acc.step: 0.0000, Acc.tank: 0.0000, Acc.trade name: 0.1406, Acc.microwave: 0.0908, Acc.pot: 0.0087, Acc.animal: 0.0110, Acc.bicycle: 0.1157, Acc.lake: 0.0000, Acc.dishwasher: 0.1273, Acc.screen: 0.4746, Acc.blanket: 0.0000, Acc.sculpture: 0.0000, Acc.hood: 0.0809, Acc.sconce: 0.0000, Acc.vase: 0.0425, Acc.traffic light: 0.0000, Acc.tray: 0.0000, Acc.ashcan: 0.0000, Acc.fan: 0.0001, Acc.pier: 0.0000, Acc.crt screen: 0.0000, Acc.plate: 0.0037, Acc.monitor: 0.0369, Acc.bulletin board: 0.0000, Acc.shower: 0.0000, Acc.radiator: 0.0000, Acc.glass: 0.0000, Acc.clock: 0.0000, Acc.flag: 0.0000
2021-08-14 14:44:33,615 - mmseg - INFO - Iter [32050/160000]	lr: 8.196e-03, eta: 1 day, 23:33:37, time: 3.387, data_time: 2.155, memory: 9759, decode.loss_seg: 1.0257, decode.acc_seg: 53.1754, loss: 1.0257
2021-08-14 14:45:36,841 - mmseg - INFO - Iter [32100/160000]	lr: 8.193e-03, eta: 1 day, 23:32:16, time: 1.265, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0228, decode.acc_seg: 52.9690, loss: 1.0228
2021-08-14 14:46:39,791 - mmseg - INFO - Iter [32150/160000]	lr: 8.190e-03, eta: 1 day, 23:30:53, time: 1.258, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0490, decode.acc_seg: 53.1737, loss: 1.0490
2021-08-14 14:48:17,824 - mmseg - INFO - Iter [32200/160000]	lr: 8.187e-03, eta: 1 day, 23:31:50, time: 1.961, data_time: 0.672, memory: 9759, decode.loss_seg: 0.9964, decode.acc_seg: 52.9443, loss: 0.9964
2021-08-14 14:49:22,500 - mmseg - INFO - Iter [32250/160000]	lr: 8.185e-03, eta: 1 day, 23:30:34, time: 1.293, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9898, decode.acc_seg: 54.3829, loss: 0.9898
2021-08-14 14:50:26,395 - mmseg - INFO - Iter [32300/160000]	lr: 8.182e-03, eta: 1 day, 23:29:15, time: 1.278, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0422, decode.acc_seg: 53.7096, loss: 1.0422
2021-08-14 14:51:30,410 - mmseg - INFO - Iter [32350/160000]	lr: 8.179e-03, eta: 1 day, 23:27:56, time: 1.280, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9964, decode.acc_seg: 53.1802, loss: 0.9964
2021-08-14 14:52:37,013 - mmseg - INFO - Iter [32400/160000]	lr: 8.176e-03, eta: 1 day, 23:26:48, time: 1.333, data_time: 0.014, memory: 9759, decode.loss_seg: 1.0236, decode.acc_seg: 52.6753, loss: 1.0236
2021-08-14 14:53:39,995 - mmseg - INFO - Iter [32450/160000]	lr: 8.173e-03, eta: 1 day, 23:25:26, time: 1.260, data_time: 0.013, memory: 9759, decode.loss_seg: 0.9880, decode.acc_seg: 54.1949, loss: 0.9880
2021-08-14 14:54:42,216 - mmseg - INFO - Iter [32500/160000]	lr: 8.170e-03, eta: 1 day, 23:24:01, time: 1.244, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0166, decode.acc_seg: 52.5863, loss: 1.0166
2021-08-14 14:55:44,311 - mmseg - INFO - Iter [32550/160000]	lr: 8.167e-03, eta: 1 day, 23:22:35, time: 1.242, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0287, decode.acc_seg: 53.7802, loss: 1.0287
2021-08-14 14:56:45,315 - mmseg - INFO - Iter [32600/160000]	lr: 8.165e-03, eta: 1 day, 23:21:05, time: 1.220, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0001, decode.acc_seg: 52.9967, loss: 1.0001
2021-08-14 14:57:49,164 - mmseg - INFO - Iter [32650/160000]	lr: 8.162e-03, eta: 1 day, 23:19:46, time: 1.277, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0243, decode.acc_seg: 53.0923, loss: 1.0243
2021-08-14 14:58:51,852 - mmseg - INFO - Iter [32700/160000]	lr: 8.159e-03, eta: 1 day, 23:18:23, time: 1.253, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0119, decode.acc_seg: 54.0731, loss: 1.0119
2021-08-14 14:59:55,264 - mmseg - INFO - Iter [32750/160000]	lr: 8.156e-03, eta: 1 day, 23:17:02, time: 1.268, data_time: 0.016, memory: 9759, decode.loss_seg: 1.0130, decode.acc_seg: 52.6784, loss: 1.0130
2021-08-14 15:01:00,401 - mmseg - INFO - Iter [32800/160000]	lr: 8.153e-03, eta: 1 day, 23:15:49, time: 1.303, data_time: 0.016, memory: 9759, decode.loss_seg: 1.0241, decode.acc_seg: 53.2132, loss: 1.0241
2021-08-14 15:02:39,941 - mmseg - INFO - Iter [32850/160000]	lr: 8.150e-03, eta: 1 day, 23:16:48, time: 1.991, data_time: 0.702, memory: 9759, decode.loss_seg: 1.0091, decode.acc_seg: 53.4154, loss: 1.0091
2021-08-14 15:03:43,845 - mmseg - INFO - Iter [32900/160000]	lr: 8.148e-03, eta: 1 day, 23:15:30, time: 1.278, data_time: 0.014, memory: 9759, decode.loss_seg: 0.9963, decode.acc_seg: 53.2337, loss: 0.9963
2021-08-14 15:04:48,584 - mmseg - INFO - Iter [32950/160000]	lr: 8.145e-03, eta: 1 day, 23:14:14, time: 1.294, data_time: 0.013, memory: 9759, decode.loss_seg: 1.0226, decode.acc_seg: 52.6375, loss: 1.0226
2021-08-14 15:05:50,949 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 15:05:50,950 - mmseg - INFO - Iter [33000/160000]	lr: 8.142e-03, eta: 1 day, 23:12:49, time: 1.247, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0254, decode.acc_seg: 53.2020, loss: 1.0254
2021-08-14 15:06:53,740 - mmseg - INFO - Iter [33050/160000]	lr: 8.139e-03, eta: 1 day, 23:11:27, time: 1.257, data_time: 0.016, memory: 9759, decode.loss_seg: 1.0116, decode.acc_seg: 52.2638, loss: 1.0116
2021-08-14 15:07:56,617 - mmseg - INFO - Iter [33100/160000]	lr: 8.136e-03, eta: 1 day, 23:10:04, time: 1.257, data_time: 0.014, memory: 9759, decode.loss_seg: 0.9844, decode.acc_seg: 54.4173, loss: 0.9844
2021-08-14 15:09:00,596 - mmseg - INFO - Iter [33150/160000]	lr: 8.133e-03, eta: 1 day, 23:08:46, time: 1.280, data_time: 0.016, memory: 9759, decode.loss_seg: 1.0096, decode.acc_seg: 53.7151, loss: 1.0096
2021-08-14 15:10:04,551 - mmseg - INFO - Iter [33200/160000]	lr: 8.130e-03, eta: 1 day, 23:07:28, time: 1.279, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9942, decode.acc_seg: 53.5474, loss: 0.9942
2021-08-14 15:11:07,689 - mmseg - INFO - Iter [33250/160000]	lr: 8.128e-03, eta: 1 day, 23:06:07, time: 1.264, data_time: 0.016, memory: 9759, decode.loss_seg: 1.0215, decode.acc_seg: 52.9513, loss: 1.0215
2021-08-14 15:12:08,683 - mmseg - INFO - Iter [33300/160000]	lr: 8.125e-03, eta: 1 day, 23:04:38, time: 1.220, data_time: 0.014, memory: 9759, decode.loss_seg: 1.0640, decode.acc_seg: 52.2566, loss: 1.0640
2021-08-14 15:13:10,532 - mmseg - INFO - Iter [33350/160000]	lr: 8.122e-03, eta: 1 day, 23:03:11, time: 1.236, data_time: 0.012, memory: 9759, decode.loss_seg: 1.0442, decode.acc_seg: 52.7396, loss: 1.0442
2021-08-14 15:14:13,983 - mmseg - INFO - Iter [33400/160000]	lr: 8.119e-03, eta: 1 day, 23:01:52, time: 1.270, data_time: 0.014, memory: 9759, decode.loss_seg: 1.0060, decode.acc_seg: 53.8376, loss: 1.0060
2021-08-14 15:15:52,754 - mmseg - INFO - Iter [33450/160000]	lr: 8.116e-03, eta: 1 day, 23:02:46, time: 1.975, data_time: 0.727, memory: 9759, decode.loss_seg: 1.0240, decode.acc_seg: 53.7347, loss: 1.0240
2021-08-14 15:16:55,270 - mmseg - INFO - Iter [33500/160000]	lr: 8.113e-03, eta: 1 day, 23:01:22, time: 1.251, data_time: 0.017, memory: 9759, decode.loss_seg: 0.9862, decode.acc_seg: 53.0778, loss: 0.9862
2021-08-14 15:17:58,539 - mmseg - INFO - Iter [33550/160000]	lr: 8.110e-03, eta: 1 day, 23:00:01, time: 1.266, data_time: 0.014, memory: 9759, decode.loss_seg: 1.0108, decode.acc_seg: 54.2097, loss: 1.0108
2021-08-14 15:19:00,834 - mmseg - INFO - Iter [33600/160000]	lr: 8.108e-03, eta: 1 day, 22:58:37, time: 1.245, data_time: 0.017, memory: 9759, decode.loss_seg: 1.0421, decode.acc_seg: 53.3292, loss: 1.0421
2021-08-14 15:20:03,359 - mmseg - INFO - Iter [33650/160000]	lr: 8.105e-03, eta: 1 day, 22:57:14, time: 1.251, data_time: 0.016, memory: 9759, decode.loss_seg: 1.0101, decode.acc_seg: 53.3099, loss: 1.0101
2021-08-14 15:21:05,276 - mmseg - INFO - Iter [33700/160000]	lr: 8.102e-03, eta: 1 day, 22:55:48, time: 1.238, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9860, decode.acc_seg: 53.2796, loss: 0.9860
2021-08-14 15:22:06,528 - mmseg - INFO - Iter [33750/160000]	lr: 8.099e-03, eta: 1 day, 22:54:20, time: 1.225, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0295, decode.acc_seg: 52.9300, loss: 1.0295
2021-08-14 15:23:10,134 - mmseg - INFO - Iter [33800/160000]	lr: 8.096e-03, eta: 1 day, 22:53:01, time: 1.271, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9986, decode.acc_seg: 54.0891, loss: 0.9986
2021-08-14 15:24:12,846 - mmseg - INFO - Iter [33850/160000]	lr: 8.093e-03, eta: 1 day, 22:51:39, time: 1.255, data_time: 0.016, memory: 9759, decode.loss_seg: 1.0364, decode.acc_seg: 52.6096, loss: 1.0364
2021-08-14 15:25:15,943 - mmseg - INFO - Iter [33900/160000]	lr: 8.090e-03, eta: 1 day, 22:50:18, time: 1.262, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0315, decode.acc_seg: 53.7602, loss: 1.0315
2021-08-14 15:26:19,632 - mmseg - INFO - Iter [33950/160000]	lr: 8.088e-03, eta: 1 day, 22:48:59, time: 1.274, data_time: 0.014, memory: 9759, decode.loss_seg: 1.0457, decode.acc_seg: 53.2645, loss: 1.0457
2021-08-14 15:27:21,834 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 15:27:21,834 - mmseg - INFO - Iter [34000/160000]	lr: 8.085e-03, eta: 1 day, 22:47:35, time: 1.244, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0171, decode.acc_seg: 52.8466, loss: 1.0171
2021-08-14 15:28:23,425 - mmseg - INFO - Iter [34050/160000]	lr: 8.082e-03, eta: 1 day, 22:46:09, time: 1.232, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9833, decode.acc_seg: 54.0758, loss: 0.9833
2021-08-14 15:29:58,534 - mmseg - INFO - Iter [34100/160000]	lr: 8.079e-03, eta: 1 day, 22:46:46, time: 1.901, data_time: 0.707, memory: 9759, decode.loss_seg: 1.0213, decode.acc_seg: 52.4373, loss: 1.0213
2021-08-14 15:31:00,926 - mmseg - INFO - Iter [34150/160000]	lr: 8.076e-03, eta: 1 day, 22:45:23, time: 1.248, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9905, decode.acc_seg: 52.5016, loss: 0.9905
2021-08-14 15:32:04,305 - mmseg - INFO - Iter [34200/160000]	lr: 8.073e-03, eta: 1 day, 22:44:03, time: 1.268, data_time: 0.014, memory: 9759, decode.loss_seg: 0.9861, decode.acc_seg: 53.8693, loss: 0.9861
2021-08-14 15:33:07,706 - mmseg - INFO - Iter [34250/160000]	lr: 8.071e-03, eta: 1 day, 22:42:44, time: 1.267, data_time: 0.014, memory: 9759, decode.loss_seg: 1.0059, decode.acc_seg: 53.2994, loss: 1.0059
2021-08-14 15:34:13,847 - mmseg - INFO - Iter [34300/160000]	lr: 8.068e-03, eta: 1 day, 22:41:34, time: 1.323, data_time: 0.014, memory: 9759, decode.loss_seg: 0.9853, decode.acc_seg: 54.3120, loss: 0.9853
2021-08-14 15:35:20,049 - mmseg - INFO - Iter [34350/160000]	lr: 8.065e-03, eta: 1 day, 22:40:25, time: 1.325, data_time: 0.014, memory: 9759, decode.loss_seg: 1.0188, decode.acc_seg: 53.0067, loss: 1.0188
2021-08-14 15:36:22,413 - mmseg - INFO - Iter [34400/160000]	lr: 8.062e-03, eta: 1 day, 22:39:02, time: 1.247, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0028, decode.acc_seg: 53.8280, loss: 1.0028
2021-08-14 15:37:26,294 - mmseg - INFO - Iter [34450/160000]	lr: 8.059e-03, eta: 1 day, 22:37:44, time: 1.278, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0007, decode.acc_seg: 53.1882, loss: 1.0007
2021-08-14 15:38:30,297 - mmseg - INFO - Iter [34500/160000]	lr: 8.056e-03, eta: 1 day, 22:36:27, time: 1.280, data_time: 0.014, memory: 9759, decode.loss_seg: 1.0383, decode.acc_seg: 53.0454, loss: 1.0383
2021-08-14 15:39:34,875 - mmseg - INFO - Iter [34550/160000]	lr: 8.053e-03, eta: 1 day, 22:35:12, time: 1.291, data_time: 0.014, memory: 9759, decode.loss_seg: 1.0262, decode.acc_seg: 53.1924, loss: 1.0262
2021-08-14 15:40:37,144 - mmseg - INFO - Iter [34600/160000]	lr: 8.051e-03, eta: 1 day, 22:33:48, time: 1.246, data_time: 0.017, memory: 9759, decode.loss_seg: 1.0082, decode.acc_seg: 53.7560, loss: 1.0082
2021-08-14 15:41:39,293 - mmseg - INFO - Iter [34650/160000]	lr: 8.048e-03, eta: 1 day, 22:32:25, time: 1.243, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9388, decode.acc_seg: 54.6440, loss: 0.9388
2021-08-14 15:42:41,907 - mmseg - INFO - Iter [34700/160000]	lr: 8.045e-03, eta: 1 day, 22:31:02, time: 1.252, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0399, decode.acc_seg: 52.9499, loss: 1.0399
2021-08-14 15:44:21,987 - mmseg - INFO - Iter [34750/160000]	lr: 8.042e-03, eta: 1 day, 22:31:55, time: 2.001, data_time: 0.677, memory: 9759, decode.loss_seg: 0.9759, decode.acc_seg: 53.5153, loss: 0.9759
2021-08-14 15:45:25,223 - mmseg - INFO - Iter [34800/160000]	lr: 8.039e-03, eta: 1 day, 22:30:35, time: 1.266, data_time: 0.016, memory: 9759, decode.loss_seg: 0.9992, decode.acc_seg: 54.1906, loss: 0.9992
2021-08-14 15:46:27,442 - mmseg - INFO - Iter [34850/160000]	lr: 8.036e-03, eta: 1 day, 22:29:12, time: 1.244, data_time: 0.016, memory: 9759, decode.loss_seg: 0.9864, decode.acc_seg: 52.8429, loss: 0.9864
2021-08-14 15:47:31,325 - mmseg - INFO - Iter [34900/160000]	lr: 8.033e-03, eta: 1 day, 22:27:54, time: 1.278, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0117, decode.acc_seg: 54.1902, loss: 1.0117
2021-08-14 15:48:35,267 - mmseg - INFO - Iter [34950/160000]	lr: 8.031e-03, eta: 1 day, 22:26:37, time: 1.279, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9833, decode.acc_seg: 53.9842, loss: 0.9833
2021-08-14 15:49:41,387 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 15:49:41,387 - mmseg - INFO - Iter [35000/160000]	lr: 8.028e-03, eta: 1 day, 22:25:27, time: 1.322, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0025, decode.acc_seg: 53.9861, loss: 1.0025
2021-08-14 15:50:45,065 - mmseg - INFO - Iter [35050/160000]	lr: 8.025e-03, eta: 1 day, 22:24:09, time: 1.275, data_time: 0.016, memory: 9759, decode.loss_seg: 1.0107, decode.acc_seg: 52.2908, loss: 1.0107
2021-08-14 15:51:48,728 - mmseg - INFO - Iter [35100/160000]	lr: 8.022e-03, eta: 1 day, 22:22:51, time: 1.273, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9922, decode.acc_seg: 53.5749, loss: 0.9922
2021-08-14 15:52:49,459 - mmseg - INFO - Iter [35150/160000]	lr: 8.019e-03, eta: 1 day, 22:21:23, time: 1.215, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0300, decode.acc_seg: 53.5538, loss: 1.0300
2021-08-14 15:53:52,000 - mmseg - INFO - Iter [35200/160000]	lr: 8.016e-03, eta: 1 day, 22:20:01, time: 1.251, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0275, decode.acc_seg: 53.8559, loss: 1.0275
2021-08-14 15:54:55,578 - mmseg - INFO - Iter [35250/160000]	lr: 8.013e-03, eta: 1 day, 22:18:42, time: 1.270, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0056, decode.acc_seg: 53.8747, loss: 1.0056
2021-08-14 15:56:02,041 - mmseg - INFO - Iter [35300/160000]	lr: 8.011e-03, eta: 1 day, 22:17:34, time: 1.330, data_time: 0.016, memory: 9759, decode.loss_seg: 1.0088, decode.acc_seg: 52.8915, loss: 1.0088
2021-08-14 15:57:38,487 - mmseg - INFO - Iter [35350/160000]	lr: 8.008e-03, eta: 1 day, 22:18:12, time: 1.930, data_time: 0.695, memory: 9759, decode.loss_seg: 1.0242, decode.acc_seg: 52.9883, loss: 1.0242
2021-08-14 15:58:42,420 - mmseg - INFO - Iter [35400/160000]	lr: 8.005e-03, eta: 1 day, 22:16:55, time: 1.279, data_time: 0.014, memory: 9759, decode.loss_seg: 0.9931, decode.acc_seg: 54.1815, loss: 0.9931
2021-08-14 15:59:46,060 - mmseg - INFO - Iter [35450/160000]	lr: 8.002e-03, eta: 1 day, 22:15:36, time: 1.272, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0316, decode.acc_seg: 52.4373, loss: 1.0316
2021-08-14 16:00:54,245 - mmseg - INFO - Iter [35500/160000]	lr: 7.999e-03, eta: 1 day, 22:14:34, time: 1.363, data_time: 0.014, memory: 9759, decode.loss_seg: 1.0094, decode.acc_seg: 53.8092, loss: 1.0094
2021-08-14 16:02:02,290 - mmseg - INFO - Iter [35550/160000]	lr: 7.996e-03, eta: 1 day, 22:13:31, time: 1.361, data_time: 0.014, memory: 9759, decode.loss_seg: 0.9723, decode.acc_seg: 53.4973, loss: 0.9723
2021-08-14 16:03:09,341 - mmseg - INFO - Iter [35600/160000]	lr: 7.993e-03, eta: 1 day, 22:12:25, time: 1.341, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0284, decode.acc_seg: 52.5338, loss: 1.0284
2021-08-14 16:04:13,695 - mmseg - INFO - Iter [35650/160000]	lr: 7.991e-03, eta: 1 day, 22:11:10, time: 1.288, data_time: 0.014, memory: 9759, decode.loss_seg: 1.0186, decode.acc_seg: 52.9961, loss: 1.0186
2021-08-14 16:05:15,629 - mmseg - INFO - Iter [35700/160000]	lr: 7.988e-03, eta: 1 day, 22:09:46, time: 1.240, data_time: 0.014, memory: 9759, decode.loss_seg: 0.9739, decode.acc_seg: 54.3636, loss: 0.9739
2021-08-14 16:06:20,189 - mmseg - INFO - Iter [35750/160000]	lr: 7.985e-03, eta: 1 day, 22:08:31, time: 1.291, data_time: 0.014, memory: 9759, decode.loss_seg: 1.0014, decode.acc_seg: 52.9897, loss: 1.0014
2021-08-14 16:07:23,308 - mmseg - INFO - Iter [35800/160000]	lr: 7.982e-03, eta: 1 day, 22:07:11, time: 1.262, data_time: 0.014, memory: 9759, decode.loss_seg: 1.0141, decode.acc_seg: 53.8071, loss: 1.0141
2021-08-14 16:08:27,338 - mmseg - INFO - Iter [35850/160000]	lr: 7.979e-03, eta: 1 day, 22:05:55, time: 1.281, data_time: 0.014, memory: 9759, decode.loss_seg: 0.9967, decode.acc_seg: 54.0057, loss: 0.9967
2021-08-14 16:09:28,498 - mmseg - INFO - Iter [35900/160000]	lr: 7.976e-03, eta: 1 day, 22:04:28, time: 1.223, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0107, decode.acc_seg: 53.2997, loss: 1.0107
2021-08-14 16:10:31,607 - mmseg - INFO - Iter [35950/160000]	lr: 7.973e-03, eta: 1 day, 22:03:09, time: 1.262, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0122, decode.acc_seg: 53.1620, loss: 1.0122
2021-08-14 16:12:09,732 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 16:12:09,736 - mmseg - INFO - Iter [36000/160000]	lr: 7.971e-03, eta: 1 day, 22:03:50, time: 1.963, data_time: 0.737, memory: 9759, decode.loss_seg: 0.9866, decode.acc_seg: 52.9225, loss: 0.9866
2021-08-14 16:13:13,721 - mmseg - INFO - Iter [36050/160000]	lr: 7.968e-03, eta: 1 day, 22:02:33, time: 1.279, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0315, decode.acc_seg: 53.6808, loss: 1.0315
2021-08-14 16:14:17,510 - mmseg - INFO - Iter [36100/160000]	lr: 7.965e-03, eta: 1 day, 22:01:15, time: 1.276, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9667, decode.acc_seg: 55.0221, loss: 0.9667
2021-08-14 16:15:21,534 - mmseg - INFO - Iter [36150/160000]	lr: 7.962e-03, eta: 1 day, 21:59:59, time: 1.280, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9667, decode.acc_seg: 54.1298, loss: 0.9667
2021-08-14 16:16:24,545 - mmseg - INFO - Iter [36200/160000]	lr: 7.959e-03, eta: 1 day, 21:58:39, time: 1.260, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9625, decode.acc_seg: 53.8165, loss: 0.9625
2021-08-14 16:17:27,770 - mmseg - INFO - Iter [36250/160000]	lr: 7.956e-03, eta: 1 day, 21:57:20, time: 1.265, data_time: 0.017, memory: 9759, decode.loss_seg: 0.9885, decode.acc_seg: 53.6045, loss: 0.9885
2021-08-14 16:18:31,319 - mmseg - INFO - Iter [36300/160000]	lr: 7.953e-03, eta: 1 day, 21:56:01, time: 1.270, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0631, decode.acc_seg: 53.1548, loss: 1.0631
2021-08-14 16:19:35,202 - mmseg - INFO - Iter [36350/160000]	lr: 7.951e-03, eta: 1 day, 21:54:45, time: 1.278, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0123, decode.acc_seg: 53.8060, loss: 1.0123
2021-08-14 16:20:39,092 - mmseg - INFO - Iter [36400/160000]	lr: 7.948e-03, eta: 1 day, 21:53:28, time: 1.277, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9680, decode.acc_seg: 53.3991, loss: 0.9680
2021-08-14 16:21:43,956 - mmseg - INFO - Iter [36450/160000]	lr: 7.945e-03, eta: 1 day, 21:52:14, time: 1.297, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9922, decode.acc_seg: 53.2366, loss: 0.9922
2021-08-14 16:22:47,237 - mmseg - INFO - Iter [36500/160000]	lr: 7.942e-03, eta: 1 day, 21:50:55, time: 1.266, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0092, decode.acc_seg: 53.3464, loss: 1.0092
2021-08-14 16:23:50,131 - mmseg - INFO - Iter [36550/160000]	lr: 7.939e-03, eta: 1 day, 21:49:35, time: 1.258, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0044, decode.acc_seg: 53.4863, loss: 1.0044
2021-08-14 16:25:27,651 - mmseg - INFO - Iter [36600/160000]	lr: 7.936e-03, eta: 1 day, 21:50:12, time: 1.951, data_time: 0.727, memory: 9759, decode.loss_seg: 1.0161, decode.acc_seg: 53.5368, loss: 1.0161
2021-08-14 16:26:30,786 - mmseg - INFO - Iter [36650/160000]	lr: 7.933e-03, eta: 1 day, 21:48:53, time: 1.263, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9912, decode.acc_seg: 53.6606, loss: 0.9912
2021-08-14 16:27:33,869 - mmseg - INFO - Iter [36700/160000]	lr: 7.931e-03, eta: 1 day, 21:47:33, time: 1.261, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9845, decode.acc_seg: 54.5454, loss: 0.9845
2021-08-14 16:28:38,097 - mmseg - INFO - Iter [36750/160000]	lr: 7.928e-03, eta: 1 day, 21:46:17, time: 1.285, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9559, decode.acc_seg: 54.3000, loss: 0.9559
2021-08-14 16:29:41,740 - mmseg - INFO - Iter [36800/160000]	lr: 7.925e-03, eta: 1 day, 21:45:00, time: 1.273, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0337, decode.acc_seg: 53.9506, loss: 1.0337
2021-08-14 16:30:44,961 - mmseg - INFO - Iter [36850/160000]	lr: 7.922e-03, eta: 1 day, 21:43:41, time: 1.265, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0249, decode.acc_seg: 53.1528, loss: 1.0249
2021-08-14 16:31:49,002 - mmseg - INFO - Iter [36900/160000]	lr: 7.919e-03, eta: 1 day, 21:42:25, time: 1.281, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0093, decode.acc_seg: 53.3681, loss: 1.0093
2021-08-14 16:32:53,652 - mmseg - INFO - Iter [36950/160000]	lr: 7.916e-03, eta: 1 day, 21:41:11, time: 1.293, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9855, decode.acc_seg: 54.4227, loss: 0.9855
2021-08-14 16:33:59,484 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 16:33:59,485 - mmseg - INFO - Iter [37000/160000]	lr: 7.913e-03, eta: 1 day, 21:40:00, time: 1.316, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9850, decode.acc_seg: 53.7764, loss: 0.9850
2021-08-14 16:35:04,074 - mmseg - INFO - Iter [37050/160000]	lr: 7.911e-03, eta: 1 day, 21:38:46, time: 1.293, data_time: 0.017, memory: 9759, decode.loss_seg: 1.0125, decode.acc_seg: 52.9356, loss: 1.0125
2021-08-14 16:36:05,972 - mmseg - INFO - Iter [37100/160000]	lr: 7.908e-03, eta: 1 day, 21:37:23, time: 1.238, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9896, decode.acc_seg: 54.2909, loss: 0.9896
2021-08-14 16:37:10,179 - mmseg - INFO - Iter [37150/160000]	lr: 7.905e-03, eta: 1 day, 21:36:07, time: 1.283, data_time: 0.014, memory: 9759, decode.loss_seg: 0.9866, decode.acc_seg: 52.4960, loss: 0.9866
2021-08-14 16:38:17,433 - mmseg - INFO - Iter [37200/160000]	lr: 7.902e-03, eta: 1 day, 21:35:02, time: 1.345, data_time: 0.014, memory: 9759, decode.loss_seg: 1.0390, decode.acc_seg: 53.5012, loss: 1.0390
2021-08-14 16:39:58,952 - mmseg - INFO - Iter [37250/160000]	lr: 7.899e-03, eta: 1 day, 21:35:50, time: 2.031, data_time: 0.736, memory: 9759, decode.loss_seg: 0.9812, decode.acc_seg: 53.4234, loss: 0.9812
2021-08-14 16:41:01,624 - mmseg - INFO - Iter [37300/160000]	lr: 7.896e-03, eta: 1 day, 21:34:29, time: 1.254, data_time: 0.016, memory: 9759, decode.loss_seg: 0.9746, decode.acc_seg: 53.7505, loss: 0.9746
2021-08-14 16:42:03,869 - mmseg - INFO - Iter [37350/160000]	lr: 7.893e-03, eta: 1 day, 21:33:07, time: 1.245, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9796, decode.acc_seg: 54.0871, loss: 0.9796
2021-08-14 16:43:06,972 - mmseg - INFO - Iter [37400/160000]	lr: 7.891e-03, eta: 1 day, 21:31:48, time: 1.262, data_time: 0.016, memory: 9759, decode.loss_seg: 0.9959, decode.acc_seg: 54.8369, loss: 0.9959
2021-08-14 16:44:10,690 - mmseg - INFO - Iter [37450/160000]	lr: 7.888e-03, eta: 1 day, 21:30:31, time: 1.274, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0163, decode.acc_seg: 54.1390, loss: 1.0163
2021-08-14 16:45:12,457 - mmseg - INFO - Iter [37500/160000]	lr: 7.885e-03, eta: 1 day, 21:29:07, time: 1.235, data_time: 0.014, memory: 9759, decode.loss_seg: 0.9842, decode.acc_seg: 53.6999, loss: 0.9842
2021-08-14 16:46:14,466 - mmseg - INFO - Iter [37550/160000]	lr: 7.882e-03, eta: 1 day, 21:27:45, time: 1.240, data_time: 0.014, memory: 9759, decode.loss_seg: 0.9590, decode.acc_seg: 54.5706, loss: 0.9590
2021-08-14 16:47:18,259 - mmseg - INFO - Iter [37600/160000]	lr: 7.879e-03, eta: 1 day, 21:26:28, time: 1.276, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9907, decode.acc_seg: 53.6814, loss: 0.9907
2021-08-14 16:48:24,377 - mmseg - INFO - Iter [37650/160000]	lr: 7.876e-03, eta: 1 day, 21:25:19, time: 1.322, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9877, decode.acc_seg: 53.4990, loss: 0.9877
2021-08-14 16:49:27,848 - mmseg - INFO - Iter [37700/160000]	lr: 7.873e-03, eta: 1 day, 21:24:01, time: 1.270, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9864, decode.acc_seg: 53.6973, loss: 0.9864
2021-08-14 16:50:32,104 - mmseg - INFO - Iter [37750/160000]	lr: 7.871e-03, eta: 1 day, 21:22:46, time: 1.285, data_time: 0.014, memory: 9759, decode.loss_seg: 1.0064, decode.acc_seg: 53.9638, loss: 1.0064
2021-08-14 16:51:36,033 - mmseg - INFO - Iter [37800/160000]	lr: 7.868e-03, eta: 1 day, 21:21:30, time: 1.278, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9849, decode.acc_seg: 54.7058, loss: 0.9849
2021-08-14 16:52:37,565 - mmseg - INFO - Iter [37850/160000]	lr: 7.865e-03, eta: 1 day, 21:20:06, time: 1.231, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0120, decode.acc_seg: 52.9373, loss: 1.0120
2021-08-14 16:54:15,545 - mmseg - INFO - Iter [37900/160000]	lr: 7.862e-03, eta: 1 day, 21:20:40, time: 1.959, data_time: 0.725, memory: 9759, decode.loss_seg: 0.9547, decode.acc_seg: 53.8376, loss: 0.9547
2021-08-14 16:55:21,582 - mmseg - INFO - Iter [37950/160000]	lr: 7.859e-03, eta: 1 day, 21:19:30, time: 1.321, data_time: 0.016, memory: 9759, decode.loss_seg: 0.9666, decode.acc_seg: 53.5604, loss: 0.9666
2021-08-14 16:56:25,731 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 16:56:25,732 - mmseg - INFO - Iter [38000/160000]	lr: 7.856e-03, eta: 1 day, 21:18:15, time: 1.283, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9947, decode.acc_seg: 53.9811, loss: 0.9947
2021-08-14 16:57:29,384 - mmseg - INFO - Iter [38050/160000]	lr: 7.853e-03, eta: 1 day, 21:16:58, time: 1.273, data_time: 0.016, memory: 9759, decode.loss_seg: 0.9876, decode.acc_seg: 54.8615, loss: 0.9876
2021-08-14 16:58:31,327 - mmseg - INFO - Iter [38100/160000]	lr: 7.851e-03, eta: 1 day, 21:15:35, time: 1.239, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9705, decode.acc_seg: 54.5497, loss: 0.9705
2021-08-14 16:59:34,413 - mmseg - INFO - Iter [38150/160000]	lr: 7.848e-03, eta: 1 day, 21:14:16, time: 1.262, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9775, decode.acc_seg: 54.8992, loss: 0.9775
2021-08-14 17:00:36,718 - mmseg - INFO - Iter [38200/160000]	lr: 7.845e-03, eta: 1 day, 21:12:55, time: 1.247, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0098, decode.acc_seg: 53.5163, loss: 1.0098
2021-08-14 17:01:43,348 - mmseg - INFO - Iter [38250/160000]	lr: 7.842e-03, eta: 1 day, 21:11:48, time: 1.331, data_time: 0.014, memory: 9759, decode.loss_seg: 0.9841, decode.acc_seg: 52.8401, loss: 0.9841
2021-08-14 17:02:48,454 - mmseg - INFO - Iter [38300/160000]	lr: 7.839e-03, eta: 1 day, 21:10:36, time: 1.303, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9805, decode.acc_seg: 54.4951, loss: 0.9805
2021-08-14 17:03:52,509 - mmseg - INFO - Iter [38350/160000]	lr: 7.836e-03, eta: 1 day, 21:09:20, time: 1.281, data_time: 0.016, memory: 9759, decode.loss_seg: 1.0025, decode.acc_seg: 54.1326, loss: 1.0025
2021-08-14 17:04:56,883 - mmseg - INFO - Iter [38400/160000]	lr: 7.833e-03, eta: 1 day, 21:08:05, time: 1.286, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0026, decode.acc_seg: 53.7633, loss: 1.0026
2021-08-14 17:05:59,666 - mmseg - INFO - Iter [38450/160000]	lr: 7.831e-03, eta: 1 day, 21:06:46, time: 1.257, data_time: 0.016, memory: 9759, decode.loss_seg: 0.9858, decode.acc_seg: 54.6642, loss: 0.9858
2021-08-14 17:07:37,300 - mmseg - INFO - Iter [38500/160000]	lr: 7.828e-03, eta: 1 day, 21:07:16, time: 1.952, data_time: 0.716, memory: 9759, decode.loss_seg: 1.0310, decode.acc_seg: 52.1362, loss: 1.0310
2021-08-14 17:08:43,241 - mmseg - INFO - Iter [38550/160000]	lr: 7.825e-03, eta: 1 day, 21:06:07, time: 1.319, data_time: 0.016, memory: 9759, decode.loss_seg: 0.9294, decode.acc_seg: 54.2928, loss: 0.9294
2021-08-14 17:09:45,495 - mmseg - INFO - Iter [38600/160000]	lr: 7.822e-03, eta: 1 day, 21:04:45, time: 1.246, data_time: 0.014, memory: 9759, decode.loss_seg: 0.9613, decode.acc_seg: 53.6593, loss: 0.9613
2021-08-14 17:10:49,617 - mmseg - INFO - Iter [38650/160000]	lr: 7.819e-03, eta: 1 day, 21:03:30, time: 1.282, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9369, decode.acc_seg: 54.2979, loss: 0.9369
2021-08-14 17:11:52,916 - mmseg - INFO - Iter [38700/160000]	lr: 7.816e-03, eta: 1 day, 21:02:12, time: 1.267, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0038, decode.acc_seg: 53.7786, loss: 1.0038
2021-08-14 17:12:56,685 - mmseg - INFO - Iter [38750/160000]	lr: 7.813e-03, eta: 1 day, 21:00:56, time: 1.275, data_time: 0.014, memory: 9759, decode.loss_seg: 0.9830, decode.acc_seg: 54.0099, loss: 0.9830
2021-08-14 17:14:01,434 - mmseg - INFO - Iter [38800/160000]	lr: 7.811e-03, eta: 1 day, 20:59:42, time: 1.296, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0120, decode.acc_seg: 54.0183, loss: 1.0120
2021-08-14 17:15:04,140 - mmseg - INFO - Iter [38850/160000]	lr: 7.808e-03, eta: 1 day, 20:58:23, time: 1.254, data_time: 0.014, memory: 9759, decode.loss_seg: 1.0038, decode.acc_seg: 53.9775, loss: 1.0038
2021-08-14 17:16:06,462 - mmseg - INFO - Iter [38900/160000]	lr: 7.805e-03, eta: 1 day, 20:57:02, time: 1.246, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0018, decode.acc_seg: 53.3099, loss: 1.0018
2021-08-14 17:17:11,368 - mmseg - INFO - Iter [38950/160000]	lr: 7.802e-03, eta: 1 day, 20:55:49, time: 1.297, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0275, decode.acc_seg: 52.4883, loss: 1.0275
2021-08-14 17:18:16,269 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 17:18:16,270 - mmseg - INFO - Iter [39000/160000]	lr: 7.799e-03, eta: 1 day, 20:54:36, time: 1.298, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9889, decode.acc_seg: 53.2702, loss: 0.9889
2021-08-14 17:19:19,790 - mmseg - INFO - Iter [39050/160000]	lr: 7.796e-03, eta: 1 day, 20:53:19, time: 1.270, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9740, decode.acc_seg: 53.0206, loss: 0.9740
2021-08-14 17:20:24,598 - mmseg - INFO - Iter [39100/160000]	lr: 7.793e-03, eta: 1 day, 20:52:06, time: 1.297, data_time: 0.014, memory: 9759, decode.loss_seg: 0.9939, decode.acc_seg: 53.1947, loss: 0.9939
2021-08-14 17:22:02,687 - mmseg - INFO - Iter [39150/160000]	lr: 7.790e-03, eta: 1 day, 20:52:36, time: 1.962, data_time: 0.714, memory: 9759, decode.loss_seg: 0.9863, decode.acc_seg: 53.0532, loss: 0.9863
2021-08-14 17:23:06,374 - mmseg - INFO - Iter [39200/160000]	lr: 7.788e-03, eta: 1 day, 20:51:20, time: 1.274, data_time: 0.016, memory: 9759, decode.loss_seg: 1.0077, decode.acc_seg: 53.8918, loss: 1.0077
2021-08-14 17:24:10,510 - mmseg - INFO - Iter [39250/160000]	lr: 7.785e-03, eta: 1 day, 20:50:04, time: 1.282, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9526, decode.acc_seg: 54.7925, loss: 0.9526
2021-08-14 17:25:15,109 - mmseg - INFO - Iter [39300/160000]	lr: 7.782e-03, eta: 1 day, 20:48:51, time: 1.292, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9702, decode.acc_seg: 54.3925, loss: 0.9702
2021-08-14 17:26:20,859 - mmseg - INFO - Iter [39350/160000]	lr: 7.779e-03, eta: 1 day, 20:47:40, time: 1.314, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9765, decode.acc_seg: 53.8696, loss: 0.9765
2021-08-14 17:27:25,665 - mmseg - INFO - Iter [39400/160000]	lr: 7.776e-03, eta: 1 day, 20:46:27, time: 1.297, data_time: 0.016, memory: 9759, decode.loss_seg: 0.9829, decode.acc_seg: 54.5363, loss: 0.9829
2021-08-14 17:28:30,944 - mmseg - INFO - Iter [39450/160000]	lr: 7.773e-03, eta: 1 day, 20:45:16, time: 1.305, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9906, decode.acc_seg: 54.5896, loss: 0.9906
2021-08-14 17:29:35,896 - mmseg - INFO - Iter [39500/160000]	lr: 7.770e-03, eta: 1 day, 20:44:03, time: 1.299, data_time: 0.016, memory: 9759, decode.loss_seg: 0.9935, decode.acc_seg: 52.9267, loss: 0.9935
2021-08-14 17:30:39,133 - mmseg - INFO - Iter [39550/160000]	lr: 7.768e-03, eta: 1 day, 20:42:46, time: 1.265, data_time: 0.014, memory: 9759, decode.loss_seg: 1.0060, decode.acc_seg: 53.2447, loss: 1.0060
2021-08-14 17:31:43,739 - mmseg - INFO - Iter [39600/160000]	lr: 7.765e-03, eta: 1 day, 20:41:32, time: 1.292, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9700, decode.acc_seg: 54.4444, loss: 0.9700
2021-08-14 17:32:45,927 - mmseg - INFO - Iter [39650/160000]	lr: 7.762e-03, eta: 1 day, 20:40:11, time: 1.244, data_time: 0.014, memory: 9759, decode.loss_seg: 0.9801, decode.acc_seg: 54.2392, loss: 0.9801
2021-08-14 17:33:48,801 - mmseg - INFO - Iter [39700/160000]	lr: 7.759e-03, eta: 1 day, 20:38:53, time: 1.258, data_time: 0.016, memory: 9759, decode.loss_seg: 1.0180, decode.acc_seg: 53.3916, loss: 1.0180
2021-08-14 17:34:50,438 - mmseg - INFO - Iter [39750/160000]	lr: 7.756e-03, eta: 1 day, 20:37:30, time: 1.232, data_time: 0.014, memory: 9759, decode.loss_seg: 0.9958, decode.acc_seg: 53.0102, loss: 0.9958
2021-08-14 17:36:29,022 - mmseg - INFO - Iter [39800/160000]	lr: 7.753e-03, eta: 1 day, 20:37:59, time: 1.972, data_time: 0.715, memory: 9759, decode.loss_seg: 0.9410, decode.acc_seg: 54.8587, loss: 0.9410
2021-08-14 17:37:33,622 - mmseg - INFO - Iter [39850/160000]	lr: 7.750e-03, eta: 1 day, 20:36:46, time: 1.291, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9950, decode.acc_seg: 53.4754, loss: 0.9950
2021-08-14 17:38:35,175 - mmseg - INFO - Iter [39900/160000]	lr: 7.747e-03, eta: 1 day, 20:35:23, time: 1.231, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0044, decode.acc_seg: 54.1344, loss: 1.0044
2021-08-14 17:39:37,720 - mmseg - INFO - Iter [39950/160000]	lr: 7.745e-03, eta: 1 day, 20:34:03, time: 1.252, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9860, decode.acc_seg: 54.1867, loss: 0.9860
2021-08-14 17:40:40,978 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 17:40:40,979 - mmseg - INFO - Iter [40000/160000]	lr: 7.742e-03, eta: 1 day, 20:32:46, time: 1.265, data_time: 0.014, memory: 9759, decode.loss_seg: 0.9895, decode.acc_seg: 54.1050, loss: 0.9895
2021-08-14 17:41:43,435 - mmseg - INFO - Iter [40050/160000]	lr: 7.739e-03, eta: 1 day, 20:31:26, time: 1.250, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9758, decode.acc_seg: 54.7538, loss: 0.9758
2021-08-14 17:42:45,990 - mmseg - INFO - Iter [40100/160000]	lr: 7.736e-03, eta: 1 day, 20:30:06, time: 1.250, data_time: 0.014, memory: 9759, decode.loss_seg: 0.9868, decode.acc_seg: 53.6325, loss: 0.9868
2021-08-14 17:43:49,631 - mmseg - INFO - Iter [40150/160000]	lr: 7.733e-03, eta: 1 day, 20:28:50, time: 1.272, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0040, decode.acc_seg: 53.8059, loss: 1.0040
2021-08-14 17:44:53,480 - mmseg - INFO - Iter [40200/160000]	lr: 7.730e-03, eta: 1 day, 20:27:34, time: 1.278, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9417, decode.acc_seg: 54.3204, loss: 0.9417
2021-08-14 17:45:55,542 - mmseg - INFO - Iter [40250/160000]	lr: 7.727e-03, eta: 1 day, 20:26:13, time: 1.241, data_time: 0.016, memory: 9759, decode.loss_seg: 0.9904, decode.acc_seg: 54.1867, loss: 0.9904
2021-08-14 17:47:00,493 - mmseg - INFO - Iter [40300/160000]	lr: 7.725e-03, eta: 1 day, 20:25:01, time: 1.299, data_time: 0.014, memory: 9759, decode.loss_seg: 1.0035, decode.acc_seg: 53.7866, loss: 1.0035
2021-08-14 17:48:03,923 - mmseg - INFO - Iter [40350/160000]	lr: 7.722e-03, eta: 1 day, 20:23:44, time: 1.269, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9619, decode.acc_seg: 54.1285, loss: 0.9619
2021-08-14 17:49:40,951 - mmseg - INFO - Iter [40400/160000]	lr: 7.719e-03, eta: 1 day, 20:24:07, time: 1.941, data_time: 0.705, memory: 9759, decode.loss_seg: 0.9836, decode.acc_seg: 53.1107, loss: 0.9836
2021-08-14 17:50:43,569 - mmseg - INFO - Iter [40450/160000]	lr: 7.716e-03, eta: 1 day, 20:22:48, time: 1.251, data_time: 0.016, memory: 9759, decode.loss_seg: 0.9882, decode.acc_seg: 53.9738, loss: 0.9882
2021-08-14 17:51:47,624 - mmseg - INFO - Iter [40500/160000]	lr: 7.713e-03, eta: 1 day, 20:21:33, time: 1.282, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9567, decode.acc_seg: 54.6144, loss: 0.9567
2021-08-14 17:52:49,878 - mmseg - INFO - Iter [40550/160000]	lr: 7.710e-03, eta: 1 day, 20:20:13, time: 1.246, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9932, decode.acc_seg: 54.1763, loss: 0.9932
2021-08-14 17:53:54,587 - mmseg - INFO - Iter [40600/160000]	lr: 7.707e-03, eta: 1 day, 20:19:00, time: 1.294, data_time: 0.014, memory: 9759, decode.loss_seg: 0.9714, decode.acc_seg: 53.7152, loss: 0.9714
2021-08-14 17:55:02,078 - mmseg - INFO - Iter [40650/160000]	lr: 7.705e-03, eta: 1 day, 20:17:55, time: 1.349, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9794, decode.acc_seg: 53.6515, loss: 0.9794
2021-08-14 17:56:08,958 - mmseg - INFO - Iter [40700/160000]	lr: 7.702e-03, eta: 1 day, 20:16:48, time: 1.338, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9704, decode.acc_seg: 53.8741, loss: 0.9704
2021-08-14 17:57:11,009 - mmseg - INFO - Iter [40750/160000]	lr: 7.699e-03, eta: 1 day, 20:15:28, time: 1.242, data_time: 0.016, memory: 9759, decode.loss_seg: 0.9766, decode.acc_seg: 54.4617, loss: 0.9766
2021-08-14 17:58:12,414 - mmseg - INFO - Iter [40800/160000]	lr: 7.696e-03, eta: 1 day, 20:14:05, time: 1.228, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9966, decode.acc_seg: 53.7481, loss: 0.9966
2021-08-14 17:59:17,445 - mmseg - INFO - Iter [40850/160000]	lr: 7.693e-03, eta: 1 day, 20:12:53, time: 1.300, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9941, decode.acc_seg: 53.6803, loss: 0.9941
2021-08-14 18:00:21,725 - mmseg - INFO - Iter [40900/160000]	lr: 7.690e-03, eta: 1 day, 20:11:39, time: 1.286, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0205, decode.acc_seg: 54.0103, loss: 1.0205
2021-08-14 18:01:24,843 - mmseg - INFO - Iter [40950/160000]	lr: 7.687e-03, eta: 1 day, 20:10:21, time: 1.263, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9875, decode.acc_seg: 54.6617, loss: 0.9875
2021-08-14 18:02:26,639 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 18:02:26,640 - mmseg - INFO - Iter [41000/160000]	lr: 7.684e-03, eta: 1 day, 20:09:00, time: 1.235, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9614, decode.acc_seg: 54.3509, loss: 0.9614
2021-08-14 18:04:08,063 - mmseg - INFO - Iter [41050/160000]	lr: 7.682e-03, eta: 1 day, 20:09:34, time: 2.029, data_time: 0.760, memory: 9759, decode.loss_seg: 0.9533, decode.acc_seg: 55.5954, loss: 0.9533
2021-08-14 18:05:10,841 - mmseg - INFO - Iter [41100/160000]	lr: 7.679e-03, eta: 1 day, 20:08:15, time: 1.256, data_time: 0.013, memory: 9759, decode.loss_seg: 0.9375, decode.acc_seg: 54.6776, loss: 0.9375
2021-08-14 18:06:12,388 - mmseg - INFO - Iter [41150/160000]	lr: 7.676e-03, eta: 1 day, 20:06:53, time: 1.231, data_time: 0.013, memory: 9759, decode.loss_seg: 0.9944, decode.acc_seg: 54.2505, loss: 0.9944
2021-08-14 18:07:14,239 - mmseg - INFO - Iter [41200/160000]	lr: 7.673e-03, eta: 1 day, 20:05:32, time: 1.237, data_time: 0.014, memory: 9759, decode.loss_seg: 0.9721, decode.acc_seg: 54.9994, loss: 0.9721
2021-08-14 18:08:16,474 - mmseg - INFO - Iter [41250/160000]	lr: 7.670e-03, eta: 1 day, 20:04:12, time: 1.245, data_time: 0.013, memory: 9759, decode.loss_seg: 0.9861, decode.acc_seg: 54.4700, loss: 0.9861
2021-08-14 18:09:19,351 - mmseg - INFO - Iter [41300/160000]	lr: 7.667e-03, eta: 1 day, 20:02:54, time: 1.258, data_time: 0.013, memory: 9759, decode.loss_seg: 0.9535, decode.acc_seg: 54.2229, loss: 0.9535
2021-08-14 18:10:20,394 - mmseg - INFO - Iter [41350/160000]	lr: 7.664e-03, eta: 1 day, 20:01:31, time: 1.221, data_time: 0.013, memory: 9759, decode.loss_seg: 0.9687, decode.acc_seg: 54.5507, loss: 0.9687
2021-08-14 18:11:22,703 - mmseg - INFO - Iter [41400/160000]	lr: 7.661e-03, eta: 1 day, 20:00:11, time: 1.246, data_time: 0.014, memory: 9759, decode.loss_seg: 0.9965, decode.acc_seg: 53.4549, loss: 0.9965
2021-08-14 18:12:25,368 - mmseg - INFO - Iter [41450/160000]	lr: 7.659e-03, eta: 1 day, 19:58:52, time: 1.254, data_time: 0.014, memory: 9759, decode.loss_seg: 0.9986, decode.acc_seg: 53.1872, loss: 0.9986
2021-08-14 18:13:29,319 - mmseg - INFO - Iter [41500/160000]	lr: 7.656e-03, eta: 1 day, 19:57:38, time: 1.279, data_time: 0.014, memory: 9759, decode.loss_seg: 0.9964, decode.acc_seg: 53.9489, loss: 0.9964
2021-08-14 18:14:31,496 - mmseg - INFO - Iter [41550/160000]	lr: 7.653e-03, eta: 1 day, 19:56:18, time: 1.244, data_time: 0.014, memory: 9759, decode.loss_seg: 0.9606, decode.acc_seg: 53.7450, loss: 0.9606
2021-08-14 18:15:32,138 - mmseg - INFO - Iter [41600/160000]	lr: 7.650e-03, eta: 1 day, 19:54:54, time: 1.213, data_time: 0.014, memory: 9759, decode.loss_seg: 0.9912, decode.acc_seg: 54.3374, loss: 0.9912
2021-08-14 18:17:10,797 - mmseg - INFO - Iter [41650/160000]	lr: 7.647e-03, eta: 1 day, 19:55:17, time: 1.973, data_time: 0.694, memory: 9759, decode.loss_seg: 0.9802, decode.acc_seg: 54.0382, loss: 0.9802
2021-08-14 18:18:14,157 - mmseg - INFO - Iter [41700/160000]	lr: 7.644e-03, eta: 1 day, 19:54:01, time: 1.268, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9287, decode.acc_seg: 54.2619, loss: 0.9287
2021-08-14 18:19:15,977 - mmseg - INFO - Iter [41750/160000]	lr: 7.641e-03, eta: 1 day, 19:52:40, time: 1.236, data_time: 0.014, memory: 9759, decode.loss_seg: 0.9488, decode.acc_seg: 55.6646, loss: 0.9488
2021-08-14 18:20:21,037 - mmseg - INFO - Iter [41800/160000]	lr: 7.639e-03, eta: 1 day, 19:51:28, time: 1.301, data_time: 0.014, memory: 9759, decode.loss_seg: 0.9292, decode.acc_seg: 55.1319, loss: 0.9292
2021-08-14 18:21:23,602 - mmseg - INFO - Iter [41850/160000]	lr: 7.636e-03, eta: 1 day, 19:50:09, time: 1.251, data_time: 0.014, memory: 9759, decode.loss_seg: 1.0057, decode.acc_seg: 53.9508, loss: 1.0057
2021-08-14 18:22:28,628 - mmseg - INFO - Iter [41900/160000]	lr: 7.633e-03, eta: 1 day, 19:48:58, time: 1.300, data_time: 0.014, memory: 9759, decode.loss_seg: 0.9811, decode.acc_seg: 53.3299, loss: 0.9811
2021-08-14 18:23:32,753 - mmseg - INFO - Iter [41950/160000]	lr: 7.630e-03, eta: 1 day, 19:47:43, time: 1.283, data_time: 0.014, memory: 9759, decode.loss_seg: 1.0074, decode.acc_seg: 53.3986, loss: 1.0074
2021-08-14 18:24:34,994 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 18:24:34,994 - mmseg - INFO - Iter [42000/160000]	lr: 7.627e-03, eta: 1 day, 19:46:24, time: 1.245, data_time: 0.014, memory: 9759, decode.loss_seg: 0.9660, decode.acc_seg: 53.6898, loss: 0.9660
2021-08-14 18:25:38,517 - mmseg - INFO - Iter [42050/160000]	lr: 7.624e-03, eta: 1 day, 19:45:08, time: 1.271, data_time: 0.014, memory: 9759, decode.loss_seg: 0.9426, decode.acc_seg: 53.8016, loss: 0.9426
2021-08-14 18:26:42,249 - mmseg - INFO - Iter [42100/160000]	lr: 7.621e-03, eta: 1 day, 19:43:53, time: 1.274, data_time: 0.014, memory: 9759, decode.loss_seg: 0.9749, decode.acc_seg: 53.5798, loss: 0.9749
2021-08-14 18:27:43,936 - mmseg - INFO - Iter [42150/160000]	lr: 7.618e-03, eta: 1 day, 19:42:32, time: 1.234, data_time: 0.014, memory: 9759, decode.loss_seg: 0.9688, decode.acc_seg: 54.1394, loss: 0.9688
2021-08-14 18:28:47,045 - mmseg - INFO - Iter [42200/160000]	lr: 7.616e-03, eta: 1 day, 19:41:15, time: 1.262, data_time: 0.014, memory: 9759, decode.loss_seg: 0.9843, decode.acc_seg: 53.5072, loss: 0.9843
2021-08-14 18:29:51,894 - mmseg - INFO - Iter [42250/160000]	lr: 7.613e-03, eta: 1 day, 19:40:03, time: 1.297, data_time: 0.013, memory: 9759, decode.loss_seg: 1.0169, decode.acc_seg: 53.1312, loss: 1.0169
2021-08-14 18:31:28,447 - mmseg - INFO - Iter [42300/160000]	lr: 7.610e-03, eta: 1 day, 19:40:19, time: 1.931, data_time: 0.670, memory: 9759, decode.loss_seg: 0.9658, decode.acc_seg: 53.9242, loss: 0.9658
2021-08-14 18:32:31,295 - mmseg - INFO - Iter [42350/160000]	lr: 7.607e-03, eta: 1 day, 19:39:01, time: 1.257, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9299, decode.acc_seg: 54.4778, loss: 0.9299
2021-08-14 18:33:37,700 - mmseg - INFO - Iter [42400/160000]	lr: 7.604e-03, eta: 1 day, 19:37:53, time: 1.328, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9624, decode.acc_seg: 53.8612, loss: 0.9624
2021-08-14 18:34:41,182 - mmseg - INFO - Iter [42450/160000]	lr: 7.601e-03, eta: 1 day, 19:36:38, time: 1.270, data_time: 0.016, memory: 9759, decode.loss_seg: 0.9897, decode.acc_seg: 53.2526, loss: 0.9897
2021-08-14 18:35:42,880 - mmseg - INFO - Iter [42500/160000]	lr: 7.598e-03, eta: 1 day, 19:35:17, time: 1.233, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9606, decode.acc_seg: 55.1716, loss: 0.9606
2021-08-14 18:36:44,836 - mmseg - INFO - Iter [42550/160000]	lr: 7.595e-03, eta: 1 day, 19:33:56, time: 1.239, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9602, decode.acc_seg: 54.3646, loss: 0.9602
2021-08-14 18:37:50,164 - mmseg - INFO - Iter [42600/160000]	lr: 7.593e-03, eta: 1 day, 19:32:46, time: 1.307, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9809, decode.acc_seg: 54.6057, loss: 0.9809
2021-08-14 18:38:51,878 - mmseg - INFO - Iter [42650/160000]	lr: 7.590e-03, eta: 1 day, 19:31:25, time: 1.234, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9749, decode.acc_seg: 53.9353, loss: 0.9749
2021-08-14 18:39:55,695 - mmseg - INFO - Iter [42700/160000]	lr: 7.587e-03, eta: 1 day, 19:30:10, time: 1.276, data_time: 0.014, memory: 9759, decode.loss_seg: 0.9651, decode.acc_seg: 54.1398, loss: 0.9651
2021-08-14 18:40:58,700 - mmseg - INFO - Iter [42750/160000]	lr: 7.584e-03, eta: 1 day, 19:28:53, time: 1.260, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9708, decode.acc_seg: 54.6789, loss: 0.9708
2021-08-14 18:42:01,583 - mmseg - INFO - Iter [42800/160000]	lr: 7.581e-03, eta: 1 day, 19:27:36, time: 1.257, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9249, decode.acc_seg: 56.5014, loss: 0.9249
2021-08-14 18:43:03,931 - mmseg - INFO - Iter [42850/160000]	lr: 7.578e-03, eta: 1 day, 19:26:17, time: 1.248, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9912, decode.acc_seg: 54.1620, loss: 0.9912
2021-08-14 18:44:05,743 - mmseg - INFO - Iter [42900/160000]	lr: 7.575e-03, eta: 1 day, 19:24:57, time: 1.236, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9792, decode.acc_seg: 53.7624, loss: 0.9792
2021-08-14 18:45:43,472 - mmseg - INFO - Iter [42950/160000]	lr: 7.572e-03, eta: 1 day, 19:25:15, time: 1.954, data_time: 0.711, memory: 9759, decode.loss_seg: 0.9345, decode.acc_seg: 54.0417, loss: 0.9345
2021-08-14 18:46:45,849 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 18:46:45,850 - mmseg - INFO - Iter [43000/160000]	lr: 7.570e-03, eta: 1 day, 19:23:56, time: 1.246, data_time: 0.016, memory: 9759, decode.loss_seg: 0.9129, decode.acc_seg: 55.6304, loss: 0.9129
2021-08-14 18:47:52,258 - mmseg - INFO - Iter [43050/160000]	lr: 7.567e-03, eta: 1 day, 19:22:48, time: 1.329, data_time: 0.016, memory: 9759, decode.loss_seg: 0.9595, decode.acc_seg: 55.0496, loss: 0.9595
2021-08-14 18:48:54,261 - mmseg - INFO - Iter [43100/160000]	lr: 7.564e-03, eta: 1 day, 19:21:29, time: 1.240, data_time: 0.016, memory: 9759, decode.loss_seg: 0.9788, decode.acc_seg: 53.6226, loss: 0.9788
2021-08-14 18:49:55,871 - mmseg - INFO - Iter [43150/160000]	lr: 7.561e-03, eta: 1 day, 19:20:08, time: 1.232, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9288, decode.acc_seg: 55.3345, loss: 0.9288
2021-08-14 18:51:00,391 - mmseg - INFO - Iter [43200/160000]	lr: 7.558e-03, eta: 1 day, 19:18:55, time: 1.291, data_time: 0.017, memory: 9759, decode.loss_seg: 0.9599, decode.acc_seg: 55.2605, loss: 0.9599
2021-08-14 18:52:03,415 - mmseg - INFO - Iter [43250/160000]	lr: 7.555e-03, eta: 1 day, 19:17:38, time: 1.260, data_time: 0.016, memory: 9759, decode.loss_seg: 1.0132, decode.acc_seg: 53.0297, loss: 1.0132
2021-08-14 18:53:05,775 - mmseg - INFO - Iter [43300/160000]	lr: 7.552e-03, eta: 1 day, 19:16:20, time: 1.247, data_time: 0.016, memory: 9759, decode.loss_seg: 0.9886, decode.acc_seg: 54.4416, loss: 0.9886
2021-08-14 18:54:10,664 - mmseg - INFO - Iter [43350/160000]	lr: 7.549e-03, eta: 1 day, 19:15:08, time: 1.298, data_time: 0.016, memory: 9759, decode.loss_seg: 0.9725, decode.acc_seg: 54.0850, loss: 0.9725
2021-08-14 18:55:13,641 - mmseg - INFO - Iter [43400/160000]	lr: 7.547e-03, eta: 1 day, 19:13:51, time: 1.258, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0120, decode.acc_seg: 53.5030, loss: 1.0120
2021-08-14 18:56:17,065 - mmseg - INFO - Iter [43450/160000]	lr: 7.544e-03, eta: 1 day, 19:12:35, time: 1.269, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9736, decode.acc_seg: 54.2815, loss: 0.9736
2021-08-14 18:57:22,821 - mmseg - INFO - Iter [43500/160000]	lr: 7.541e-03, eta: 1 day, 19:11:26, time: 1.314, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9564, decode.acc_seg: 55.3991, loss: 0.9564
2021-08-14 18:59:01,001 - mmseg - INFO - Iter [43550/160000]	lr: 7.538e-03, eta: 1 day, 19:11:43, time: 1.964, data_time: 0.729, memory: 9759, decode.loss_seg: 0.9674, decode.acc_seg: 54.6682, loss: 0.9674
2021-08-14 19:00:04,407 - mmseg - INFO - Iter [43600/160000]	lr: 7.535e-03, eta: 1 day, 19:10:28, time: 1.268, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9147, decode.acc_seg: 54.8414, loss: 0.9147
2021-08-14 19:01:05,875 - mmseg - INFO - Iter [43650/160000]	lr: 7.532e-03, eta: 1 day, 19:09:07, time: 1.229, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9662, decode.acc_seg: 54.0787, loss: 0.9662
2021-08-14 19:02:07,814 - mmseg - INFO - Iter [43700/160000]	lr: 7.529e-03, eta: 1 day, 19:07:47, time: 1.238, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9336, decode.acc_seg: 55.2842, loss: 0.9336
2021-08-14 19:03:10,025 - mmseg - INFO - Iter [43750/160000]	lr: 7.527e-03, eta: 1 day, 19:06:28, time: 1.245, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9494, decode.acc_seg: 55.3371, loss: 0.9494
2021-08-14 19:04:12,623 - mmseg - INFO - Iter [43800/160000]	lr: 7.524e-03, eta: 1 day, 19:05:11, time: 1.252, data_time: 0.016, memory: 9759, decode.loss_seg: 0.9960, decode.acc_seg: 53.3302, loss: 0.9960
2021-08-14 19:05:15,121 - mmseg - INFO - Iter [43850/160000]	lr: 7.521e-03, eta: 1 day, 19:03:53, time: 1.251, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9202, decode.acc_seg: 55.7410, loss: 0.9202
2021-08-14 19:06:17,376 - mmseg - INFO - Iter [43900/160000]	lr: 7.518e-03, eta: 1 day, 19:02:34, time: 1.244, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9549, decode.acc_seg: 54.5736, loss: 0.9549
2021-08-14 19:07:20,403 - mmseg - INFO - Iter [43950/160000]	lr: 7.515e-03, eta: 1 day, 19:01:17, time: 1.261, data_time: 0.014, memory: 9759, decode.loss_seg: 1.0346, decode.acc_seg: 53.5724, loss: 1.0346
2021-08-14 19:08:22,666 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 19:08:22,666 - mmseg - INFO - Iter [44000/160000]	lr: 7.512e-03, eta: 1 day, 18:59:59, time: 1.246, data_time: 0.014, memory: 9759, decode.loss_seg: 0.9526, decode.acc_seg: 54.0383, loss: 0.9526
2021-08-14 19:09:24,903 - mmseg - INFO - Iter [44050/160000]	lr: 7.509e-03, eta: 1 day, 18:58:40, time: 1.244, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9623, decode.acc_seg: 54.1547, loss: 0.9623
2021-08-14 19:10:29,740 - mmseg - INFO - Iter [44100/160000]	lr: 7.506e-03, eta: 1 day, 18:57:29, time: 1.297, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9954, decode.acc_seg: 53.6096, loss: 0.9954
2021-08-14 19:11:32,579 - mmseg - INFO - Iter [44150/160000]	lr: 7.503e-03, eta: 1 day, 18:56:12, time: 1.257, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9555, decode.acc_seg: 54.9681, loss: 0.9555
2021-08-14 19:13:12,876 - mmseg - INFO - Iter [44200/160000]	lr: 7.501e-03, eta: 1 day, 18:56:33, time: 2.006, data_time: 0.705, memory: 9759, decode.loss_seg: 0.9492, decode.acc_seg: 55.1970, loss: 0.9492
2021-08-14 19:14:19,401 - mmseg - INFO - Iter [44250/160000]	lr: 7.498e-03, eta: 1 day, 18:55:26, time: 1.330, data_time: 0.016, memory: 9759, decode.loss_seg: 0.9383, decode.acc_seg: 54.8391, loss: 0.9383
2021-08-14 19:15:22,691 - mmseg - INFO - Iter [44300/160000]	lr: 7.495e-03, eta: 1 day, 18:54:10, time: 1.266, data_time: 0.016, memory: 9759, decode.loss_seg: 1.0154, decode.acc_seg: 54.7826, loss: 1.0154
2021-08-14 19:16:25,754 - mmseg - INFO - Iter [44350/160000]	lr: 7.492e-03, eta: 1 day, 18:52:54, time: 1.261, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9571, decode.acc_seg: 54.6963, loss: 0.9571
2021-08-14 19:17:28,841 - mmseg - INFO - Iter [44400/160000]	lr: 7.489e-03, eta: 1 day, 18:51:37, time: 1.262, data_time: 0.014, memory: 9759, decode.loss_seg: 0.9783, decode.acc_seg: 54.1079, loss: 0.9783
2021-08-14 19:18:32,567 - mmseg - INFO - Iter [44450/160000]	lr: 7.486e-03, eta: 1 day, 18:50:23, time: 1.274, data_time: 0.016, memory: 9759, decode.loss_seg: 0.9722, decode.acc_seg: 53.8490, loss: 0.9722
2021-08-14 19:19:35,537 - mmseg - INFO - Iter [44500/160000]	lr: 7.483e-03, eta: 1 day, 18:49:06, time: 1.259, data_time: 0.016, memory: 9759, decode.loss_seg: 0.9597, decode.acc_seg: 54.7907, loss: 0.9597
2021-08-14 19:20:39,712 - mmseg - INFO - Iter [44550/160000]	lr: 7.480e-03, eta: 1 day, 18:47:53, time: 1.284, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9261, decode.acc_seg: 54.8982, loss: 0.9261
2021-08-14 19:21:45,654 - mmseg - INFO - Iter [44600/160000]	lr: 7.478e-03, eta: 1 day, 18:46:44, time: 1.318, data_time: 0.014, memory: 9759, decode.loss_seg: 0.9650, decode.acc_seg: 54.2597, loss: 0.9650
2021-08-14 19:22:53,637 - mmseg - INFO - Iter [44650/160000]	lr: 7.475e-03, eta: 1 day, 18:45:41, time: 1.359, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9837, decode.acc_seg: 54.3143, loss: 0.9837
2021-08-14 19:24:00,990 - mmseg - INFO - Iter [44700/160000]	lr: 7.472e-03, eta: 1 day, 18:44:36, time: 1.349, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9639, decode.acc_seg: 55.2458, loss: 0.9639
2021-08-14 19:25:02,998 - mmseg - INFO - Iter [44750/160000]	lr: 7.469e-03, eta: 1 day, 18:43:17, time: 1.240, data_time: 0.014, memory: 9759, decode.loss_seg: 0.9904, decode.acc_seg: 54.0607, loss: 0.9904
2021-08-14 19:26:04,555 - mmseg - INFO - Iter [44800/160000]	lr: 7.466e-03, eta: 1 day, 18:41:57, time: 1.231, data_time: 0.014, memory: 9759, decode.loss_seg: 0.9666, decode.acc_seg: 54.3296, loss: 0.9666
2021-08-14 19:27:42,488 - mmseg - INFO - Iter [44850/160000]	lr: 7.463e-03, eta: 1 day, 18:42:10, time: 1.959, data_time: 0.716, memory: 9759, decode.loss_seg: 0.9359, decode.acc_seg: 54.6886, loss: 0.9359
2021-08-14 19:28:45,466 - mmseg - INFO - Iter [44900/160000]	lr: 7.460e-03, eta: 1 day, 18:40:54, time: 1.259, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9505, decode.acc_seg: 55.0362, loss: 0.9505
2021-08-14 19:29:48,017 - mmseg - INFO - Iter [44950/160000]	lr: 7.457e-03, eta: 1 day, 18:39:36, time: 1.251, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9504, decode.acc_seg: 54.9527, loss: 0.9504
2021-08-14 19:30:52,689 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 19:30:52,690 - mmseg - INFO - Iter [45000/160000]	lr: 7.455e-03, eta: 1 day, 18:38:24, time: 1.294, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9517, decode.acc_seg: 54.9511, loss: 0.9517
2021-08-14 19:31:56,778 - mmseg - INFO - Iter [45050/160000]	lr: 7.452e-03, eta: 1 day, 18:37:11, time: 1.281, data_time: 0.014, memory: 9759, decode.loss_seg: 0.9526, decode.acc_seg: 53.7448, loss: 0.9526
2021-08-14 19:33:01,193 - mmseg - INFO - Iter [45100/160000]	lr: 7.449e-03, eta: 1 day, 18:35:58, time: 1.288, data_time: 0.017, memory: 9759, decode.loss_seg: 0.9455, decode.acc_seg: 54.3537, loss: 0.9455
2021-08-14 19:34:04,857 - mmseg - INFO - Iter [45150/160000]	lr: 7.446e-03, eta: 1 day, 18:34:43, time: 1.274, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9436, decode.acc_seg: 54.4244, loss: 0.9436
2021-08-14 19:35:06,997 - mmseg - INFO - Iter [45200/160000]	lr: 7.443e-03, eta: 1 day, 18:33:25, time: 1.243, data_time: 0.016, memory: 9759, decode.loss_seg: 0.9542, decode.acc_seg: 54.1079, loss: 0.9542
2021-08-14 19:36:09,578 - mmseg - INFO - Iter [45250/160000]	lr: 7.440e-03, eta: 1 day, 18:32:08, time: 1.252, data_time: 0.014, memory: 9759, decode.loss_seg: 0.9908, decode.acc_seg: 53.9111, loss: 0.9908
2021-08-14 19:37:12,688 - mmseg - INFO - Iter [45300/160000]	lr: 7.437e-03, eta: 1 day, 18:30:52, time: 1.263, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9911, decode.acc_seg: 54.1846, loss: 0.9911
2021-08-14 19:38:18,621 - mmseg - INFO - Iter [45350/160000]	lr: 7.434e-03, eta: 1 day, 18:29:43, time: 1.318, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9747, decode.acc_seg: 53.7818, loss: 0.9747
2021-08-14 19:39:23,295 - mmseg - INFO - Iter [45400/160000]	lr: 7.432e-03, eta: 1 day, 18:28:31, time: 1.294, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9600, decode.acc_seg: 54.9751, loss: 0.9600
2021-08-14 19:41:02,796 - mmseg - INFO - Iter [45450/160000]	lr: 7.429e-03, eta: 1 day, 18:28:47, time: 1.989, data_time: 0.743, memory: 9759, decode.loss_seg: 0.9726, decode.acc_seg: 54.5685, loss: 0.9726
2021-08-14 19:42:08,553 - mmseg - INFO - Iter [45500/160000]	lr: 7.426e-03, eta: 1 day, 18:27:38, time: 1.316, data_time: 0.016, memory: 9759, decode.loss_seg: 0.9219, decode.acc_seg: 54.4557, loss: 0.9219
2021-08-14 19:43:13,526 - mmseg - INFO - Iter [45550/160000]	lr: 7.423e-03, eta: 1 day, 18:26:27, time: 1.299, data_time: 0.014, memory: 9759, decode.loss_seg: 0.9404, decode.acc_seg: 55.1784, loss: 0.9404
2021-08-14 19:44:16,830 - mmseg - INFO - Iter [45600/160000]	lr: 7.420e-03, eta: 1 day, 18:25:11, time: 1.267, data_time: 0.016, memory: 9759, decode.loss_seg: 0.9697, decode.acc_seg: 54.7921, loss: 0.9697
2021-08-14 19:45:20,711 - mmseg - INFO - Iter [45650/160000]	lr: 7.417e-03, eta: 1 day, 18:23:58, time: 1.277, data_time: 0.016, memory: 9759, decode.loss_seg: 0.9475, decode.acc_seg: 54.5869, loss: 0.9475
2021-08-14 19:46:21,722 - mmseg - INFO - Iter [45700/160000]	lr: 7.414e-03, eta: 1 day, 18:22:36, time: 1.220, data_time: 0.014, memory: 9759, decode.loss_seg: 0.9563, decode.acc_seg: 54.7648, loss: 0.9563
2021-08-14 19:47:24,515 - mmseg - INFO - Iter [45750/160000]	lr: 7.411e-03, eta: 1 day, 18:21:20, time: 1.256, data_time: 0.014, memory: 9759, decode.loss_seg: 0.9889, decode.acc_seg: 54.1847, loss: 0.9889
2021-08-14 19:48:28,245 - mmseg - INFO - Iter [45800/160000]	lr: 7.409e-03, eta: 1 day, 18:20:06, time: 1.274, data_time: 0.014, memory: 9759, decode.loss_seg: 0.9477, decode.acc_seg: 54.9578, loss: 0.9477
2021-08-14 19:49:30,192 - mmseg - INFO - Iter [45850/160000]	lr: 7.406e-03, eta: 1 day, 18:18:47, time: 1.240, data_time: 0.014, memory: 9759, decode.loss_seg: 0.9726, decode.acc_seg: 54.4533, loss: 0.9726
2021-08-14 19:50:31,650 - mmseg - INFO - Iter [45900/160000]	lr: 7.403e-03, eta: 1 day, 18:17:27, time: 1.229, data_time: 0.014, memory: 9759, decode.loss_seg: 0.9644, decode.acc_seg: 54.3944, loss: 0.9644
2021-08-14 19:51:37,242 - mmseg - INFO - Iter [45950/160000]	lr: 7.400e-03, eta: 1 day, 18:16:18, time: 1.311, data_time: 0.014, memory: 9759, decode.loss_seg: 0.9445, decode.acc_seg: 54.9864, loss: 0.9445
2021-08-14 19:52:41,401 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 19:52:41,403 - mmseg - INFO - Iter [46000/160000]	lr: 7.397e-03, eta: 1 day, 18:15:05, time: 1.283, data_time: 0.014, memory: 9759, decode.loss_seg: 0.9808, decode.acc_seg: 54.9559, loss: 0.9808
2021-08-14 19:53:42,424 - mmseg - INFO - Iter [46050/160000]	lr: 7.394e-03, eta: 1 day, 18:13:44, time: 1.220, data_time: 0.013, memory: 9759, decode.loss_seg: 0.9545, decode.acc_seg: 54.3083, loss: 0.9545
2021-08-14 19:55:21,599 - mmseg - INFO - Iter [46100/160000]	lr: 7.391e-03, eta: 1 day, 18:13:57, time: 1.984, data_time: 0.717, memory: 9759, decode.loss_seg: 0.9408, decode.acc_seg: 54.7896, loss: 0.9408
2021-08-14 19:56:25,346 - mmseg - INFO - Iter [46150/160000]	lr: 7.388e-03, eta: 1 day, 18:12:43, time: 1.274, data_time: 0.016, memory: 9759, decode.loss_seg: 0.9492, decode.acc_seg: 54.8862, loss: 0.9492
2021-08-14 19:57:26,680 - mmseg - INFO - Iter [46200/160000]	lr: 7.385e-03, eta: 1 day, 18:11:23, time: 1.227, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9659, decode.acc_seg: 54.7930, loss: 0.9659
2021-08-14 19:58:31,310 - mmseg - INFO - Iter [46250/160000]	lr: 7.383e-03, eta: 1 day, 18:10:11, time: 1.292, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9532, decode.acc_seg: 54.7755, loss: 0.9532
2021-08-14 19:59:34,496 - mmseg - INFO - Iter [46300/160000]	lr: 7.380e-03, eta: 1 day, 18:08:56, time: 1.264, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9399, decode.acc_seg: 54.2098, loss: 0.9399
2021-08-14 20:00:39,318 - mmseg - INFO - Iter [46350/160000]	lr: 7.377e-03, eta: 1 day, 18:07:44, time: 1.296, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9589, decode.acc_seg: 53.6338, loss: 0.9589
2021-08-14 20:01:44,920 - mmseg - INFO - Iter [46400/160000]	lr: 7.374e-03, eta: 1 day, 18:06:35, time: 1.312, data_time: 0.014, memory: 9759, decode.loss_seg: 0.9623, decode.acc_seg: 53.9378, loss: 0.9623
2021-08-14 20:02:49,463 - mmseg - INFO - Iter [46450/160000]	lr: 7.371e-03, eta: 1 day, 18:05:23, time: 1.291, data_time: 0.014, memory: 9759, decode.loss_seg: 0.9496, decode.acc_seg: 55.1997, loss: 0.9496
2021-08-14 20:03:53,449 - mmseg - INFO - Iter [46500/160000]	lr: 7.368e-03, eta: 1 day, 18:04:09, time: 1.280, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9450, decode.acc_seg: 54.7493, loss: 0.9450
2021-08-14 20:04:56,097 - mmseg - INFO - Iter [46550/160000]	lr: 7.365e-03, eta: 1 day, 18:02:53, time: 1.252, data_time: 0.014, memory: 9759, decode.loss_seg: 0.9352, decode.acc_seg: 55.3104, loss: 0.9352
2021-08-14 20:06:00,716 - mmseg - INFO - Iter [46600/160000]	lr: 7.362e-03, eta: 1 day, 18:01:41, time: 1.293, data_time: 0.016, memory: 9759, decode.loss_seg: 0.9581, decode.acc_seg: 54.4945, loss: 0.9581
2021-08-14 20:07:04,640 - mmseg - INFO - Iter [46650/160000]	lr: 7.360e-03, eta: 1 day, 18:00:28, time: 1.279, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9744, decode.acc_seg: 54.6434, loss: 0.9744
2021-08-14 20:08:45,112 - mmseg - INFO - Iter [46700/160000]	lr: 7.357e-03, eta: 1 day, 18:00:43, time: 2.009, data_time: 0.747, memory: 9759, decode.loss_seg: 0.9695, decode.acc_seg: 54.8265, loss: 0.9695
2021-08-14 20:09:49,015 - mmseg - INFO - Iter [46750/160000]	lr: 7.354e-03, eta: 1 day, 17:59:29, time: 1.278, data_time: 0.017, memory: 9759, decode.loss_seg: 0.9446, decode.acc_seg: 54.8838, loss: 0.9446
2021-08-14 20:10:51,528 - mmseg - INFO - Iter [46800/160000]	lr: 7.351e-03, eta: 1 day, 17:58:12, time: 1.251, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9300, decode.acc_seg: 54.4395, loss: 0.9300
2021-08-14 20:11:54,446 - mmseg - INFO - Iter [46850/160000]	lr: 7.348e-03, eta: 1 day, 17:56:56, time: 1.259, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9050, decode.acc_seg: 55.0676, loss: 0.9050
2021-08-14 20:12:57,004 - mmseg - INFO - Iter [46900/160000]	lr: 7.345e-03, eta: 1 day, 17:55:39, time: 1.251, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9565, decode.acc_seg: 55.1251, loss: 0.9565
2021-08-14 20:14:00,862 - mmseg - INFO - Iter [46950/160000]	lr: 7.342e-03, eta: 1 day, 17:54:26, time: 1.277, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9396, decode.acc_seg: 56.0296, loss: 0.9396
2021-08-14 20:15:03,283 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 20:15:03,284 - mmseg - INFO - Iter [47000/160000]	lr: 7.339e-03, eta: 1 day, 17:53:09, time: 1.248, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9291, decode.acc_seg: 55.4950, loss: 0.9291
2021-08-14 20:16:05,845 - mmseg - INFO - Iter [47050/160000]	lr: 7.336e-03, eta: 1 day, 17:51:52, time: 1.251, data_time: 0.014, memory: 9759, decode.loss_seg: 0.9579, decode.acc_seg: 54.5073, loss: 0.9579
2021-08-14 20:17:08,053 - mmseg - INFO - Iter [47100/160000]	lr: 7.334e-03, eta: 1 day, 17:50:34, time: 1.244, data_time: 0.016, memory: 9759, decode.loss_seg: 0.9203, decode.acc_seg: 54.7910, loss: 0.9203
2021-08-14 20:18:12,190 - mmseg - INFO - Iter [47150/160000]	lr: 7.331e-03, eta: 1 day, 17:49:22, time: 1.282, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9446, decode.acc_seg: 55.4454, loss: 0.9446
2021-08-14 20:19:16,211 - mmseg - INFO - Iter [47200/160000]	lr: 7.328e-03, eta: 1 day, 17:48:08, time: 1.281, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9838, decode.acc_seg: 54.3438, loss: 0.9838
2021-08-14 20:20:19,354 - mmseg - INFO - Iter [47250/160000]	lr: 7.325e-03, eta: 1 day, 17:46:53, time: 1.263, data_time: 0.016, memory: 9759, decode.loss_seg: 0.9763, decode.acc_seg: 54.0417, loss: 0.9763
2021-08-14 20:21:21,353 - mmseg - INFO - Iter [47300/160000]	lr: 7.322e-03, eta: 1 day, 17:45:35, time: 1.241, data_time: 0.015, memory: 9759, decode.loss_seg: 1.0132, decode.acc_seg: 53.8926, loss: 1.0132
2021-08-14 20:23:00,542 - mmseg - INFO - Iter [47350/160000]	lr: 7.319e-03, eta: 1 day, 17:45:46, time: 1.983, data_time: 0.735, memory: 9759, decode.loss_seg: 0.9412, decode.acc_seg: 54.7120, loss: 0.9412
2021-08-14 20:24:04,151 - mmseg - INFO - Iter [47400/160000]	lr: 7.316e-03, eta: 1 day, 17:44:32, time: 1.273, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9507, decode.acc_seg: 53.3424, loss: 0.9507
2021-08-14 20:25:06,487 - mmseg - INFO - Iter [47450/160000]	lr: 7.313e-03, eta: 1 day, 17:43:15, time: 1.246, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9540, decode.acc_seg: 54.5717, loss: 0.9540
2021-08-14 20:26:10,809 - mmseg - INFO - Iter [47500/160000]	lr: 7.311e-03, eta: 1 day, 17:42:02, time: 1.287, data_time: 0.016, memory: 9759, decode.loss_seg: 0.9485, decode.acc_seg: 55.2626, loss: 0.9485
2021-08-14 20:27:15,289 - mmseg - INFO - Iter [47550/160000]	lr: 7.308e-03, eta: 1 day, 17:40:50, time: 1.289, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9580, decode.acc_seg: 54.1451, loss: 0.9580
2021-08-14 20:28:18,846 - mmseg - INFO - Iter [47600/160000]	lr: 7.305e-03, eta: 1 day, 17:39:36, time: 1.271, data_time: 0.016, memory: 9759, decode.loss_seg: 0.9233, decode.acc_seg: 55.3143, loss: 0.9233
2021-08-14 20:29:22,281 - mmseg - INFO - Iter [47650/160000]	lr: 7.302e-03, eta: 1 day, 17:38:22, time: 1.269, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9838, decode.acc_seg: 55.1470, loss: 0.9838
2021-08-14 20:30:26,820 - mmseg - INFO - Iter [47700/160000]	lr: 7.299e-03, eta: 1 day, 17:37:10, time: 1.291, data_time: 0.014, memory: 9759, decode.loss_seg: 0.9258, decode.acc_seg: 56.5228, loss: 0.9258
2021-08-14 20:31:29,771 - mmseg - INFO - Iter [47750/160000]	lr: 7.296e-03, eta: 1 day, 17:35:54, time: 1.259, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9834, decode.acc_seg: 53.3648, loss: 0.9834
2021-08-14 20:32:32,600 - mmseg - INFO - Iter [47800/160000]	lr: 7.293e-03, eta: 1 day, 17:34:38, time: 1.256, data_time: 0.016, memory: 9759, decode.loss_seg: 0.9339, decode.acc_seg: 55.2998, loss: 0.9339
2021-08-14 20:33:36,491 - mmseg - INFO - Iter [47850/160000]	lr: 7.290e-03, eta: 1 day, 17:33:25, time: 1.278, data_time: 0.016, memory: 9759, decode.loss_seg: 0.9635, decode.acc_seg: 55.0293, loss: 0.9635
2021-08-14 20:34:39,143 - mmseg - INFO - Iter [47900/160000]	lr: 7.287e-03, eta: 1 day, 17:32:09, time: 1.254, data_time: 0.015, memory: 9759, decode.loss_seg: 0.9411, decode.acc_seg: 55.1757, loss: 0.9411
2021-08-14 20:35:41,748 - mmseg - INFO - Iter [47950/160000]	lr: 7.285e-03, eta: 1 day, 17:30:53, time: 1.252, data_time: 0.014, memory: 9759, decode.loss_seg: 0.9636, decode.acc_seg: 55.4676, loss: 0.9636
2021-08-14 20:37:21,105 - mmseg - INFO - Saving checkpoint at 48000 iterations
2021-08-14 20:37:21,454 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 20:37:21,454 - mmseg - INFO - Iter [48000/160000]	lr: 7.282e-03, eta: 1 day, 17:31:03, time: 1.995, data_time: 0.706, memory: 9759, decode.loss_seg: 0.9083, decode.acc_seg: 55.2339, loss: 0.9083
