2021-08-13 11:11:15,925 - mmseg - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.7.6 (default, Jan  8 2020, 19:59:22) [GCC 7.3.0]
CUDA available: True
GPU 0,1,2,3,4,5,6,7: TITAN Xp
CUDA_HOME: /mnt/lustre/share/polaris/dep/cuda-9.0-cudnn7.6.5
NVCC: Cuda compilation tools, release 9.0, V9.0.176
GCC: gcc (GCC) 5.4.0
PyTorch: 1.5.0
PyTorch compiling details: PyTorch built with:
  - GCC 5.4
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.1 Product Build 20200208 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v0.21.1 (Git Hash 912ce228837d1ce28e1a61806118835de03f5751)
  - OpenMP 201307 (a.k.a. OpenMP 4.0)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 9.0
  - NVCC architecture flags: -gencode;arch=compute_52,code=sm_52;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_70,code=compute_70
  - CuDNN 7.6.5
  - Magma 2.5.0
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_INTERNAL_THREADPOOL_IMPL -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=ON, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

TorchVision: 0.6.0
OpenCV: 4.2.0
MMCV: 1.3.11
MMCV Compiler: n/a
MMCV CUDA Compiler: n/a
MMSegmentation: 0.16.0+2bb6f37
------------------------------------------------------------

2021-08-13 11:11:15,927 - mmseg - INFO - Distributed training: True
2021-08-13 11:11:16,315 - mmseg - INFO - Config:
norm_cfg = dict(type='SyncBN', requires_grad=True)
model = dict(
    type='EncoderDecoder',
    backbone=dict(
        type='LiteHRNet',
        norm_cfg=dict(type='SyncBN', requires_grad=True),
        norm_eval=False,
        extra=dict(
            stem=dict(stem_channels=32, out_channels=32, expand_ratio=1),
            num_stages=3,
            stages_spec=dict(
                num_modules=(3, 8, 3),
                num_branches=(2, 3, 4),
                num_blocks=(2, 2, 2),
                module_type=('LITE', 'LITE', 'LITE'),
                with_fuse=(True, True, True),
                reduce_ratios=(8, 8, 8),
                num_channels=((40, 80), (40, 80, 160), (40, 80, 160, 320))),
            with_head=False)),
    decode_head=dict(
        type='FCNHead',
        in_channels=[40, 80, 160, 320],
        in_index=(0, 1, 2, 3),
        channels=600,
        input_transform='resize_concat',
        kernel_size=1,
        num_convs=1,
        concat_input=False,
        dropout_ratio=-1,
        num_classes=150,
        norm_cfg=dict(type='SyncBN', requires_grad=True),
        align_corners=False,
        loss_decode=dict(
            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0)),
    train_cfg=dict(),
    test_cfg=dict(mode='whole'))
dataset_type = 'ADE20KDataset'
data_root = 'data/ade/ADEChallengeData2016'
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
crop_size = (512, 512)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations', reduce_zero_label=True),
    dict(type='Resize', img_scale=(2048, 512), ratio_range=(0.5, 2.0)),
    dict(type='RandomCrop', crop_size=(512, 512), cat_max_ratio=0.75),
    dict(type='RandomFlip', prob=0.5),
    dict(type='PhotoMetricDistortion'),
    dict(
        type='Normalize',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='Pad', size=(512, 512), pad_val=0, seg_pad_val=255),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_semantic_seg'])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(2048, 512),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
data = dict(
    samples_per_gpu=4,
    workers_per_gpu=4,
    train=dict(
        type='ADE20KDataset',
        data_root='data/ade/ADEChallengeData2016',
        img_dir='images/training',
        ann_dir='annotations/training',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations', reduce_zero_label=True),
            dict(type='Resize', img_scale=(2048, 512), ratio_range=(0.5, 2.0)),
            dict(type='RandomCrop', crop_size=(512, 512), cat_max_ratio=0.75),
            dict(type='RandomFlip', prob=0.5),
            dict(type='PhotoMetricDistortion'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='Pad', size=(512, 512), pad_val=0, seg_pad_val=255),
            dict(type='DefaultFormatBundle'),
            dict(type='Collect', keys=['img', 'gt_semantic_seg'])
        ]),
    val=dict(
        type='ADE20KDataset',
        data_root='data/ade/ADEChallengeData2016',
        img_dir='images/validation',
        ann_dir='annotations/validation',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(2048, 512),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]),
    test=dict(
        type='ADE20KDataset',
        data_root='data/ade/ADEChallengeData2016',
        img_dir='images/validation',
        ann_dir='annotations/validation',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(2048, 512),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]))
log_config = dict(
    interval=50, hooks=[dict(type='TextLoggerHook', by_epoch=False)])
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]
cudnn_benchmark = True
optimizer = dict(type='SGD', lr=0.01, momentum=0.9, weight_decay=0.0005)
optimizer_config = dict()
lr_config = dict(policy='poly', power=0.9, min_lr=0.0001, by_epoch=False)
runner = dict(type='IterBasedRunner', max_iters=160000)
checkpoint_config = dict(by_epoch=False, interval=16000)
evaluation = dict(interval=16000, metric='mIoU')
work_dir = './work_dirs/fcn-resize-concat_litehr30-without-head_512x512_160k_ade20k'
gpu_ids = range(0, 1)

2021-08-13 11:11:16,315 - mmseg - INFO - Set random seed to 0, deterministic: False
2021-08-13 11:11:16,652 - mmseg - INFO - initialize LiteHRNet with init_cfg [{'type': 'Normal', 'std': 0.001, 'layer': 'Conv2d'}, {'type': 'Constant', 'val': 1, 'layer': ['_BatchNorm', 'GroupNorm']}]
2021-08-13 11:11:17,032 - mmseg - INFO - initialize FCNHead with init_cfg {'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
Name of parameter - Initialization information

backbone.stem.conv1.conv.weight - torch.Size([32, 3, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.stem.conv1.bn.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stem.conv1.bn.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stem.branch1.0.conv.weight - torch.Size([16, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stem.branch1.0.bn.weight - torch.Size([16]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stem.branch1.0.bn.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stem.branch1.1.conv.weight - torch.Size([16, 16, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stem.branch1.1.bn.weight - torch.Size([16]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stem.branch1.1.bn.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stem.expand_conv.conv.weight - torch.Size([32, 16, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.stem.expand_conv.bn.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stem.expand_conv.bn.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stem.depthwise_conv.conv.weight - torch.Size([32, 1, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.stem.depthwise_conv.bn.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stem.depthwise_conv.bn.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stem.linear_conv.conv.weight - torch.Size([16, 32, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.stem.linear_conv.bn.weight - torch.Size([16]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stem.linear_conv.bn.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.transition0.0.0.weight - torch.Size([32, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.transition0.0.1.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.transition0.0.1.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.transition0.0.2.weight - torch.Size([40, 32, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.transition0.0.3.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.transition0.0.3.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.transition0.1.0.0.weight - torch.Size([32, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.transition0.1.0.1.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.transition0.1.0.1.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.transition0.1.0.2.weight - torch.Size([80, 32, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.transition0.1.0.3.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.transition0.1.0.3.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.0.cross_resolution_weighting.conv1.conv.weight - torch.Size([7, 60, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.layers.0.cross_resolution_weighting.conv1.bn.weight - torch.Size([7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.0.cross_resolution_weighting.conv1.bn.bias - torch.Size([7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.0.cross_resolution_weighting.conv2.conv.weight - torch.Size([60, 7, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.layers.0.cross_resolution_weighting.conv2.bn.weight - torch.Size([60]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.0.cross_resolution_weighting.conv2.bn.bias - torch.Size([60]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.0.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.layers.0.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.0.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.0.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.layers.0.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.0.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.0.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.layers.0.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.0.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.layers.0.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.0.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.layers.0.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.0.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.layers.0.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.1.cross_resolution_weighting.conv1.conv.weight - torch.Size([7, 60, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.layers.1.cross_resolution_weighting.conv1.bn.weight - torch.Size([7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.1.cross_resolution_weighting.conv1.bn.bias - torch.Size([7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.1.cross_resolution_weighting.conv2.conv.weight - torch.Size([60, 7, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.layers.1.cross_resolution_weighting.conv2.bn.weight - torch.Size([60]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.1.cross_resolution_weighting.conv2.bn.bias - torch.Size([60]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.1.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.layers.1.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.1.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.1.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.layers.1.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.1.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.1.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.layers.1.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.1.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.layers.1.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.1.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.layers.1.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.1.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.layers.1.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.fuse_layers.0.1.0.weight - torch.Size([40, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.fuse_layers.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.fuse_layers.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.fuse_layers.1.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.fuse_layers.1.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.fuse_layers.1.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.fuse_layers.1.0.0.2.weight - torch.Size([80, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.fuse_layers.1.0.0.3.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.fuse_layers.1.0.0.3.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.0.cross_resolution_weighting.conv1.conv.weight - torch.Size([7, 60, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.layers.0.cross_resolution_weighting.conv1.bn.weight - torch.Size([7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.0.cross_resolution_weighting.conv1.bn.bias - torch.Size([7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.0.cross_resolution_weighting.conv2.conv.weight - torch.Size([60, 7, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.layers.0.cross_resolution_weighting.conv2.bn.weight - torch.Size([60]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.0.cross_resolution_weighting.conv2.bn.bias - torch.Size([60]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.0.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.layers.0.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.0.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.0.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.layers.0.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.0.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.0.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.layers.0.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.0.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.layers.0.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.0.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.layers.0.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.0.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.layers.0.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.1.cross_resolution_weighting.conv1.conv.weight - torch.Size([7, 60, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.layers.1.cross_resolution_weighting.conv1.bn.weight - torch.Size([7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.1.cross_resolution_weighting.conv1.bn.bias - torch.Size([7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.1.cross_resolution_weighting.conv2.conv.weight - torch.Size([60, 7, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.layers.1.cross_resolution_weighting.conv2.bn.weight - torch.Size([60]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.1.cross_resolution_weighting.conv2.bn.bias - torch.Size([60]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.1.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.layers.1.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.1.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.1.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.layers.1.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.1.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.1.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.layers.1.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.1.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.layers.1.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.1.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.layers.1.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.1.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.layers.1.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.fuse_layers.0.1.0.weight - torch.Size([40, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.fuse_layers.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.fuse_layers.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.fuse_layers.1.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.fuse_layers.1.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.fuse_layers.1.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.fuse_layers.1.0.0.2.weight - torch.Size([80, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.fuse_layers.1.0.0.3.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.fuse_layers.1.0.0.3.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.0.cross_resolution_weighting.conv1.conv.weight - torch.Size([7, 60, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.2.layers.0.cross_resolution_weighting.conv1.bn.weight - torch.Size([7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.0.cross_resolution_weighting.conv1.bn.bias - torch.Size([7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.0.cross_resolution_weighting.conv2.conv.weight - torch.Size([60, 7, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.2.layers.0.cross_resolution_weighting.conv2.bn.weight - torch.Size([60]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.0.cross_resolution_weighting.conv2.bn.bias - torch.Size([60]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.0.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.2.layers.0.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.0.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.0.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.2.layers.0.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.0.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.0.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.2.layers.0.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.0.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.2.layers.0.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.0.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.2.layers.0.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.0.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.2.layers.0.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.1.cross_resolution_weighting.conv1.conv.weight - torch.Size([7, 60, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.2.layers.1.cross_resolution_weighting.conv1.bn.weight - torch.Size([7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.1.cross_resolution_weighting.conv1.bn.bias - torch.Size([7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.1.cross_resolution_weighting.conv2.conv.weight - torch.Size([60, 7, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.2.layers.1.cross_resolution_weighting.conv2.bn.weight - torch.Size([60]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.1.cross_resolution_weighting.conv2.bn.bias - torch.Size([60]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.1.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.2.layers.1.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.1.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.1.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.2.layers.1.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.1.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.1.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.2.layers.1.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.1.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.2.layers.1.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.1.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.2.layers.1.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.1.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.2.layers.1.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.fuse_layers.0.1.0.weight - torch.Size([40, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.2.fuse_layers.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.fuse_layers.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.fuse_layers.1.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.2.fuse_layers.1.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.fuse_layers.1.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.fuse_layers.1.0.0.2.weight - torch.Size([80, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.2.fuse_layers.1.0.0.3.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.fuse_layers.1.0.0.3.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.transition1.2.0.0.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.transition1.2.0.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.transition1.2.0.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.transition1.2.0.2.weight - torch.Size([160, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.transition1.2.0.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.transition1.2.0.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.0.cross_resolution_weighting.conv1.conv.weight - torch.Size([17, 140, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.0.cross_resolution_weighting.conv1.bn.weight - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.0.cross_resolution_weighting.conv1.bn.bias - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.0.cross_resolution_weighting.conv2.conv.weight - torch.Size([140, 17, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.0.cross_resolution_weighting.conv2.bn.weight - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.0.cross_resolution_weighting.conv2.bn.bias - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.0.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.0.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.0.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.0.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.0.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.0.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.0.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.0.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.0.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.0.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.0.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.0.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.0.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.0.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.0.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.0.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.0.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.0.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.0.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.0.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.0.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.1.cross_resolution_weighting.conv1.conv.weight - torch.Size([17, 140, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.1.cross_resolution_weighting.conv1.bn.weight - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.1.cross_resolution_weighting.conv1.bn.bias - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.1.cross_resolution_weighting.conv2.conv.weight - torch.Size([140, 17, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.1.cross_resolution_weighting.conv2.bn.weight - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.1.cross_resolution_weighting.conv2.bn.bias - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.1.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.1.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.1.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.1.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.1.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.1.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.1.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.1.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.1.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.1.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.1.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.1.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.1.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.1.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.1.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.1.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.1.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.1.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.1.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.1.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.1.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.0.1.0.weight - torch.Size([40, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.fuse_layers.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.0.2.0.weight - torch.Size([40, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.fuse_layers.0.2.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.0.2.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.1.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.fuse_layers.1.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.1.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.1.0.0.2.weight - torch.Size([80, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.fuse_layers.1.0.0.3.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.1.0.0.3.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.1.2.0.weight - torch.Size([80, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.fuse_layers.1.2.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.1.2.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.2.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.fuse_layers.2.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.2.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.2.0.0.2.weight - torch.Size([40, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.fuse_layers.2.0.0.3.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.2.0.0.3.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.2.0.1.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.fuse_layers.2.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.2.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.2.0.1.2.weight - torch.Size([160, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.fuse_layers.2.0.1.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.2.0.1.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.2.1.0.0.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.fuse_layers.2.1.0.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.2.1.0.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.2.1.0.2.weight - torch.Size([160, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.fuse_layers.2.1.0.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.2.1.0.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.0.cross_resolution_weighting.conv1.conv.weight - torch.Size([17, 140, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.0.cross_resolution_weighting.conv1.bn.weight - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.0.cross_resolution_weighting.conv1.bn.bias - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.0.cross_resolution_weighting.conv2.conv.weight - torch.Size([140, 17, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.0.cross_resolution_weighting.conv2.bn.weight - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.0.cross_resolution_weighting.conv2.bn.bias - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.0.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.0.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.0.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.0.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.0.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.0.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.0.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.0.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.0.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.0.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.0.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.0.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.0.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.0.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.0.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.0.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.0.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.0.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.0.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.0.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.0.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.1.cross_resolution_weighting.conv1.conv.weight - torch.Size([17, 140, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.1.cross_resolution_weighting.conv1.bn.weight - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.1.cross_resolution_weighting.conv1.bn.bias - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.1.cross_resolution_weighting.conv2.conv.weight - torch.Size([140, 17, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.1.cross_resolution_weighting.conv2.bn.weight - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.1.cross_resolution_weighting.conv2.bn.bias - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.1.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.1.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.1.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.1.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.1.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.1.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.1.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.1.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.1.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.1.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.1.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.1.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.1.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.1.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.1.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.1.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.1.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.1.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.1.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.1.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.1.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.0.1.0.weight - torch.Size([40, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.fuse_layers.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.0.2.0.weight - torch.Size([40, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.fuse_layers.0.2.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.0.2.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.1.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.fuse_layers.1.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.1.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.1.0.0.2.weight - torch.Size([80, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.fuse_layers.1.0.0.3.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.1.0.0.3.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.1.2.0.weight - torch.Size([80, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.fuse_layers.1.2.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.1.2.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.2.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.fuse_layers.2.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.2.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.2.0.0.2.weight - torch.Size([40, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.fuse_layers.2.0.0.3.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.2.0.0.3.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.2.0.1.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.fuse_layers.2.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.2.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.2.0.1.2.weight - torch.Size([160, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.fuse_layers.2.0.1.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.2.0.1.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.2.1.0.0.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.fuse_layers.2.1.0.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.2.1.0.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.2.1.0.2.weight - torch.Size([160, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.fuse_layers.2.1.0.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.2.1.0.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.0.cross_resolution_weighting.conv1.conv.weight - torch.Size([17, 140, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.0.cross_resolution_weighting.conv1.bn.weight - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.0.cross_resolution_weighting.conv1.bn.bias - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.0.cross_resolution_weighting.conv2.conv.weight - torch.Size([140, 17, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.0.cross_resolution_weighting.conv2.bn.weight - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.0.cross_resolution_weighting.conv2.bn.bias - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.0.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.0.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.0.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.0.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.0.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.0.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.0.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.0.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.0.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.0.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.0.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.0.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.0.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.0.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.0.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.0.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.0.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.0.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.0.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.0.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.0.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.1.cross_resolution_weighting.conv1.conv.weight - torch.Size([17, 140, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.1.cross_resolution_weighting.conv1.bn.weight - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.1.cross_resolution_weighting.conv1.bn.bias - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.1.cross_resolution_weighting.conv2.conv.weight - torch.Size([140, 17, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.1.cross_resolution_weighting.conv2.bn.weight - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.1.cross_resolution_weighting.conv2.bn.bias - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.1.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.1.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.1.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.1.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.1.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.1.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.1.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.1.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.1.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.1.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.1.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.1.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.1.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.1.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.1.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.1.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.1.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.1.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.1.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.1.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.1.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.0.1.0.weight - torch.Size([40, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.fuse_layers.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.0.2.0.weight - torch.Size([40, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.fuse_layers.0.2.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.0.2.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.1.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.fuse_layers.1.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.1.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.1.0.0.2.weight - torch.Size([80, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.fuse_layers.1.0.0.3.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.1.0.0.3.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.1.2.0.weight - torch.Size([80, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.fuse_layers.1.2.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.1.2.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.2.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.fuse_layers.2.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.2.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.2.0.0.2.weight - torch.Size([40, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.fuse_layers.2.0.0.3.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.2.0.0.3.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.2.0.1.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.fuse_layers.2.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.2.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.2.0.1.2.weight - torch.Size([160, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.fuse_layers.2.0.1.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.2.0.1.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.2.1.0.0.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.fuse_layers.2.1.0.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.2.1.0.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.2.1.0.2.weight - torch.Size([160, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.fuse_layers.2.1.0.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.2.1.0.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.0.cross_resolution_weighting.conv1.conv.weight - torch.Size([17, 140, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.0.cross_resolution_weighting.conv1.bn.weight - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.0.cross_resolution_weighting.conv1.bn.bias - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.0.cross_resolution_weighting.conv2.conv.weight - torch.Size([140, 17, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.0.cross_resolution_weighting.conv2.bn.weight - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.0.cross_resolution_weighting.conv2.bn.bias - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.0.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.0.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.0.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.0.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.0.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.0.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.0.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.0.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.0.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.0.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.0.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.0.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.0.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.0.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.0.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.0.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.0.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.0.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.0.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.0.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.0.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.1.cross_resolution_weighting.conv1.conv.weight - torch.Size([17, 140, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.1.cross_resolution_weighting.conv1.bn.weight - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.1.cross_resolution_weighting.conv1.bn.bias - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.1.cross_resolution_weighting.conv2.conv.weight - torch.Size([140, 17, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.1.cross_resolution_weighting.conv2.bn.weight - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.1.cross_resolution_weighting.conv2.bn.bias - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.1.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.1.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.1.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.1.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.1.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.1.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.1.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.1.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.1.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.1.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.1.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.1.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.1.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.1.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.1.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.1.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.1.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.1.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.1.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.1.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.1.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.0.1.0.weight - torch.Size([40, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.fuse_layers.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.0.2.0.weight - torch.Size([40, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.fuse_layers.0.2.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.0.2.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.1.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.fuse_layers.1.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.1.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.1.0.0.2.weight - torch.Size([80, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.fuse_layers.1.0.0.3.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.1.0.0.3.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.1.2.0.weight - torch.Size([80, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.fuse_layers.1.2.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.1.2.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.2.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.fuse_layers.2.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.2.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.2.0.0.2.weight - torch.Size([40, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.fuse_layers.2.0.0.3.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.2.0.0.3.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.2.0.1.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.fuse_layers.2.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.2.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.2.0.1.2.weight - torch.Size([160, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.fuse_layers.2.0.1.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.2.0.1.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.2.1.0.0.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.fuse_layers.2.1.0.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.2.1.0.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.2.1.0.2.weight - torch.Size([160, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.fuse_layers.2.1.0.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.2.1.0.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.0.cross_resolution_weighting.conv1.conv.weight - torch.Size([17, 140, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.layers.0.cross_resolution_weighting.conv1.bn.weight - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.0.cross_resolution_weighting.conv1.bn.bias - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.0.cross_resolution_weighting.conv2.conv.weight - torch.Size([140, 17, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.layers.0.cross_resolution_weighting.conv2.bn.weight - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.0.cross_resolution_weighting.conv2.bn.bias - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.0.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.layers.0.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.0.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.0.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.layers.0.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.0.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.0.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.layers.0.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.0.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.0.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.layers.0.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.0.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.layers.0.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.0.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.layers.0.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.0.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.layers.0.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.0.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.layers.0.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.0.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.layers.0.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.1.cross_resolution_weighting.conv1.conv.weight - torch.Size([17, 140, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.layers.1.cross_resolution_weighting.conv1.bn.weight - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.1.cross_resolution_weighting.conv1.bn.bias - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.1.cross_resolution_weighting.conv2.conv.weight - torch.Size([140, 17, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.layers.1.cross_resolution_weighting.conv2.bn.weight - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.1.cross_resolution_weighting.conv2.bn.bias - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.1.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.layers.1.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.1.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.1.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.layers.1.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.1.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.1.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.layers.1.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.1.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.1.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.layers.1.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.1.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.layers.1.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.1.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.layers.1.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.1.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.layers.1.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.1.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.layers.1.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.1.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.layers.1.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.fuse_layers.0.1.0.weight - torch.Size([40, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.fuse_layers.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.fuse_layers.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.fuse_layers.0.2.0.weight - torch.Size([40, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.fuse_layers.0.2.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.fuse_layers.0.2.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.fuse_layers.1.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.fuse_layers.1.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.fuse_layers.1.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.fuse_layers.1.0.0.2.weight - torch.Size([80, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.fuse_layers.1.0.0.3.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.fuse_layers.1.0.0.3.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.fuse_layers.1.2.0.weight - torch.Size([80, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.fuse_layers.1.2.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.fuse_layers.1.2.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.fuse_layers.2.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.fuse_layers.2.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.fuse_layers.2.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.fuse_layers.2.0.0.2.weight - torch.Size([40, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.fuse_layers.2.0.0.3.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.fuse_layers.2.0.0.3.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.fuse_layers.2.0.1.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.fuse_layers.2.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.fuse_layers.2.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.fuse_layers.2.0.1.2.weight - torch.Size([160, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.fuse_layers.2.0.1.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.fuse_layers.2.0.1.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.fuse_layers.2.1.0.0.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.fuse_layers.2.1.0.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.fuse_layers.2.1.0.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.fuse_layers.2.1.0.2.weight - torch.Size([160, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.fuse_layers.2.1.0.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.fuse_layers.2.1.0.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.0.cross_resolution_weighting.conv1.conv.weight - torch.Size([17, 140, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.layers.0.cross_resolution_weighting.conv1.bn.weight - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.0.cross_resolution_weighting.conv1.bn.bias - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.0.cross_resolution_weighting.conv2.conv.weight - torch.Size([140, 17, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.layers.0.cross_resolution_weighting.conv2.bn.weight - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.0.cross_resolution_weighting.conv2.bn.bias - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.0.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.layers.0.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.0.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.0.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.layers.0.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.0.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.0.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.layers.0.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.0.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.0.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.layers.0.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.0.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.layers.0.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.0.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.layers.0.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.0.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.layers.0.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.0.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.layers.0.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.0.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.layers.0.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.1.cross_resolution_weighting.conv1.conv.weight - torch.Size([17, 140, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.layers.1.cross_resolution_weighting.conv1.bn.weight - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.1.cross_resolution_weighting.conv1.bn.bias - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.1.cross_resolution_weighting.conv2.conv.weight - torch.Size([140, 17, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.layers.1.cross_resolution_weighting.conv2.bn.weight - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.1.cross_resolution_weighting.conv2.bn.bias - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.1.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.layers.1.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.1.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.1.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.layers.1.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.1.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.1.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.layers.1.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.1.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.1.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.layers.1.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.1.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.layers.1.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.1.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.layers.1.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.1.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.layers.1.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.1.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.layers.1.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.1.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.layers.1.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.fuse_layers.0.1.0.weight - torch.Size([40, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.fuse_layers.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.fuse_layers.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.fuse_layers.0.2.0.weight - torch.Size([40, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.fuse_layers.0.2.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.fuse_layers.0.2.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.fuse_layers.1.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.fuse_layers.1.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.fuse_layers.1.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.fuse_layers.1.0.0.2.weight - torch.Size([80, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.fuse_layers.1.0.0.3.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.fuse_layers.1.0.0.3.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.fuse_layers.1.2.0.weight - torch.Size([80, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.fuse_layers.1.2.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.fuse_layers.1.2.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.fuse_layers.2.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.fuse_layers.2.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.fuse_layers.2.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.fuse_layers.2.0.0.2.weight - torch.Size([40, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.fuse_layers.2.0.0.3.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.fuse_layers.2.0.0.3.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.fuse_layers.2.0.1.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.fuse_layers.2.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.fuse_layers.2.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.fuse_layers.2.0.1.2.weight - torch.Size([160, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.fuse_layers.2.0.1.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.fuse_layers.2.0.1.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.fuse_layers.2.1.0.0.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.fuse_layers.2.1.0.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.fuse_layers.2.1.0.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.fuse_layers.2.1.0.2.weight - torch.Size([160, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.fuse_layers.2.1.0.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.fuse_layers.2.1.0.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.0.cross_resolution_weighting.conv1.conv.weight - torch.Size([17, 140, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.layers.0.cross_resolution_weighting.conv1.bn.weight - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.0.cross_resolution_weighting.conv1.bn.bias - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.0.cross_resolution_weighting.conv2.conv.weight - torch.Size([140, 17, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.layers.0.cross_resolution_weighting.conv2.bn.weight - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.0.cross_resolution_weighting.conv2.bn.bias - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.0.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.layers.0.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.0.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.0.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.layers.0.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.0.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.0.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.layers.0.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.0.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.0.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.layers.0.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.0.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.layers.0.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.0.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.layers.0.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.0.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.layers.0.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.0.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.layers.0.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.0.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.layers.0.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.1.cross_resolution_weighting.conv1.conv.weight - torch.Size([17, 140, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.layers.1.cross_resolution_weighting.conv1.bn.weight - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.1.cross_resolution_weighting.conv1.bn.bias - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.1.cross_resolution_weighting.conv2.conv.weight - torch.Size([140, 17, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.layers.1.cross_resolution_weighting.conv2.bn.weight - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.1.cross_resolution_weighting.conv2.bn.bias - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.1.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.layers.1.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.1.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.1.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.layers.1.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.1.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.1.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.layers.1.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.1.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.1.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.layers.1.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.1.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.layers.1.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.1.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.layers.1.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.1.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.layers.1.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.1.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.layers.1.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.1.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.layers.1.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.fuse_layers.0.1.0.weight - torch.Size([40, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.fuse_layers.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.fuse_layers.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.fuse_layers.0.2.0.weight - torch.Size([40, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.fuse_layers.0.2.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.fuse_layers.0.2.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.fuse_layers.1.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.fuse_layers.1.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.fuse_layers.1.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.fuse_layers.1.0.0.2.weight - torch.Size([80, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.fuse_layers.1.0.0.3.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.fuse_layers.1.0.0.3.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.fuse_layers.1.2.0.weight - torch.Size([80, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.fuse_layers.1.2.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.fuse_layers.1.2.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.fuse_layers.2.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.fuse_layers.2.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.fuse_layers.2.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.fuse_layers.2.0.0.2.weight - torch.Size([40, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.fuse_layers.2.0.0.3.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.fuse_layers.2.0.0.3.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.fuse_layers.2.0.1.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.fuse_layers.2.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.fuse_layers.2.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.fuse_layers.2.0.1.2.weight - torch.Size([160, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.fuse_layers.2.0.1.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.fuse_layers.2.0.1.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.fuse_layers.2.1.0.0.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.fuse_layers.2.1.0.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.fuse_layers.2.1.0.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.fuse_layers.2.1.0.2.weight - torch.Size([160, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.fuse_layers.2.1.0.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.fuse_layers.2.1.0.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.0.cross_resolution_weighting.conv1.conv.weight - torch.Size([17, 140, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.layers.0.cross_resolution_weighting.conv1.bn.weight - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.0.cross_resolution_weighting.conv1.bn.bias - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.0.cross_resolution_weighting.conv2.conv.weight - torch.Size([140, 17, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.layers.0.cross_resolution_weighting.conv2.bn.weight - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.0.cross_resolution_weighting.conv2.bn.bias - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.0.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.layers.0.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.0.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.0.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.layers.0.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.0.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.0.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.layers.0.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.0.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.0.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.layers.0.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.0.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.layers.0.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.0.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.layers.0.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.0.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.layers.0.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.0.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.layers.0.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.0.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.layers.0.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.1.cross_resolution_weighting.conv1.conv.weight - torch.Size([17, 140, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.layers.1.cross_resolution_weighting.conv1.bn.weight - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.1.cross_resolution_weighting.conv1.bn.bias - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.1.cross_resolution_weighting.conv2.conv.weight - torch.Size([140, 17, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.layers.1.cross_resolution_weighting.conv2.bn.weight - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.1.cross_resolution_weighting.conv2.bn.bias - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.1.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.layers.1.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.1.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.1.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.layers.1.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.1.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.1.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.layers.1.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.1.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.1.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.layers.1.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.1.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.layers.1.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.1.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.layers.1.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.1.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.layers.1.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.1.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.layers.1.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.1.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.layers.1.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.fuse_layers.0.1.0.weight - torch.Size([40, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.fuse_layers.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.fuse_layers.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.fuse_layers.0.2.0.weight - torch.Size([40, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.fuse_layers.0.2.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.fuse_layers.0.2.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.fuse_layers.1.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.fuse_layers.1.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.fuse_layers.1.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.fuse_layers.1.0.0.2.weight - torch.Size([80, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.fuse_layers.1.0.0.3.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.fuse_layers.1.0.0.3.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.fuse_layers.1.2.0.weight - torch.Size([80, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.fuse_layers.1.2.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.fuse_layers.1.2.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.fuse_layers.2.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.fuse_layers.2.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.fuse_layers.2.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.fuse_layers.2.0.0.2.weight - torch.Size([40, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.fuse_layers.2.0.0.3.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.fuse_layers.2.0.0.3.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.fuse_layers.2.0.1.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.fuse_layers.2.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.fuse_layers.2.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.fuse_layers.2.0.1.2.weight - torch.Size([160, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.fuse_layers.2.0.1.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.fuse_layers.2.0.1.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.fuse_layers.2.1.0.0.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.fuse_layers.2.1.0.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.fuse_layers.2.1.0.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.fuse_layers.2.1.0.2.weight - torch.Size([160, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.fuse_layers.2.1.0.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.fuse_layers.2.1.0.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.transition2.3.0.0.weight - torch.Size([160, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.transition2.3.0.1.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.transition2.3.0.1.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.transition2.3.0.2.weight - torch.Size([320, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.transition2.3.0.3.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.transition2.3.0.3.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.cross_resolution_weighting.conv1.conv.weight - torch.Size([37, 300, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.0.cross_resolution_weighting.conv1.bn.weight - torch.Size([37]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.cross_resolution_weighting.conv1.bn.bias - torch.Size([37]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.cross_resolution_weighting.conv2.conv.weight - torch.Size([300, 37, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.0.cross_resolution_weighting.conv2.bn.weight - torch.Size([300]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.cross_resolution_weighting.conv2.bn.bias - torch.Size([300]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.0.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.0.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.0.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.depthwise_convs.3.conv.weight - torch.Size([160, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.0.depthwise_convs.3.bn.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.depthwise_convs.3.bn.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.0.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.0.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.0.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.0.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.0.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.0.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.spatial_weighting.3.conv1.conv.weight - torch.Size([40, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.0.spatial_weighting.3.conv1.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.spatial_weighting.3.conv2.conv.weight - torch.Size([160, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.0.spatial_weighting.3.conv2.conv.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.cross_resolution_weighting.conv1.conv.weight - torch.Size([37, 300, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.1.cross_resolution_weighting.conv1.bn.weight - torch.Size([37]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.cross_resolution_weighting.conv1.bn.bias - torch.Size([37]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.cross_resolution_weighting.conv2.conv.weight - torch.Size([300, 37, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.1.cross_resolution_weighting.conv2.bn.weight - torch.Size([300]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.cross_resolution_weighting.conv2.bn.bias - torch.Size([300]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.1.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.1.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.1.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.depthwise_convs.3.conv.weight - torch.Size([160, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.1.depthwise_convs.3.bn.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.depthwise_convs.3.bn.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.1.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.1.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.1.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.1.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.1.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.1.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.spatial_weighting.3.conv1.conv.weight - torch.Size([40, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.1.spatial_weighting.3.conv1.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.spatial_weighting.3.conv2.conv.weight - torch.Size([160, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.1.spatial_weighting.3.conv2.conv.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.0.1.0.weight - torch.Size([40, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.0.2.0.weight - torch.Size([40, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.0.2.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.0.2.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.0.3.0.weight - torch.Size([40, 320, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.0.3.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.0.3.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.1.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.1.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.1.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.1.0.0.2.weight - torch.Size([80, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.1.0.0.3.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.1.0.0.3.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.1.2.0.weight - torch.Size([80, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.1.2.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.1.2.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.1.3.0.weight - torch.Size([80, 320, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.1.3.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.1.3.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.2.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.2.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.2.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.2.0.0.2.weight - torch.Size([40, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.2.0.0.3.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.2.0.0.3.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.2.0.1.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.2.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.2.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.2.0.1.2.weight - torch.Size([160, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.2.0.1.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.2.0.1.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.2.1.0.0.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.2.1.0.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.2.1.0.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.2.1.0.2.weight - torch.Size([160, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.2.1.0.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.2.1.0.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.2.3.0.weight - torch.Size([160, 320, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.2.3.1.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.2.3.1.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.3.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.0.0.2.weight - torch.Size([40, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.3.0.0.3.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.0.0.3.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.0.1.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.3.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.0.1.2.weight - torch.Size([40, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.3.0.1.3.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.0.1.3.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.0.2.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.3.0.2.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.0.2.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.0.2.2.weight - torch.Size([320, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.3.0.2.3.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.0.2.3.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.1.0.0.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.3.1.0.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.1.0.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.1.0.2.weight - torch.Size([80, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.3.1.0.3.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.1.0.3.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.1.1.0.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.3.1.1.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.1.1.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.1.1.2.weight - torch.Size([320, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.3.1.1.3.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.1.1.3.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.2.0.0.weight - torch.Size([160, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.3.2.0.1.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.2.0.1.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.2.0.2.weight - torch.Size([320, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.3.2.0.3.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.2.0.3.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.cross_resolution_weighting.conv1.conv.weight - torch.Size([37, 300, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.0.cross_resolution_weighting.conv1.bn.weight - torch.Size([37]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.cross_resolution_weighting.conv1.bn.bias - torch.Size([37]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.cross_resolution_weighting.conv2.conv.weight - torch.Size([300, 37, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.0.cross_resolution_weighting.conv2.bn.weight - torch.Size([300]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.cross_resolution_weighting.conv2.bn.bias - torch.Size([300]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.0.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.0.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.0.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.depthwise_convs.3.conv.weight - torch.Size([160, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.0.depthwise_convs.3.bn.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.depthwise_convs.3.bn.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.0.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.0.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.0.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.0.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.0.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.0.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.spatial_weighting.3.conv1.conv.weight - torch.Size([40, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.0.spatial_weighting.3.conv1.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.spatial_weighting.3.conv2.conv.weight - torch.Size([160, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.0.spatial_weighting.3.conv2.conv.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.cross_resolution_weighting.conv1.conv.weight - torch.Size([37, 300, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.1.cross_resolution_weighting.conv1.bn.weight - torch.Size([37]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.cross_resolution_weighting.conv1.bn.bias - torch.Size([37]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.cross_resolution_weighting.conv2.conv.weight - torch.Size([300, 37, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.1.cross_resolution_weighting.conv2.bn.weight - torch.Size([300]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.cross_resolution_weighting.conv2.bn.bias - torch.Size([300]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.1.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.1.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.1.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.depthwise_convs.3.conv.weight - torch.Size([160, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.1.depthwise_convs.3.bn.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.depthwise_convs.3.bn.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.1.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.1.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.1.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.1.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.1.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.1.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.spatial_weighting.3.conv1.conv.weight - torch.Size([40, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.1.spatial_weighting.3.conv1.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.spatial_weighting.3.conv2.conv.weight - torch.Size([160, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.1.spatial_weighting.3.conv2.conv.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.0.1.0.weight - torch.Size([40, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.0.2.0.weight - torch.Size([40, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.0.2.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.0.2.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.0.3.0.weight - torch.Size([40, 320, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.0.3.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.0.3.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.1.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.1.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.1.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.1.0.0.2.weight - torch.Size([80, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.1.0.0.3.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.1.0.0.3.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.1.2.0.weight - torch.Size([80, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.1.2.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.1.2.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.1.3.0.weight - torch.Size([80, 320, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.1.3.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.1.3.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.2.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.2.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.2.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.2.0.0.2.weight - torch.Size([40, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.2.0.0.3.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.2.0.0.3.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.2.0.1.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.2.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.2.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.2.0.1.2.weight - torch.Size([160, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.2.0.1.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.2.0.1.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.2.1.0.0.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.2.1.0.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.2.1.0.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.2.1.0.2.weight - torch.Size([160, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.2.1.0.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.2.1.0.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.2.3.0.weight - torch.Size([160, 320, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.2.3.1.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.2.3.1.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.3.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.0.0.2.weight - torch.Size([40, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.3.0.0.3.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.0.0.3.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.0.1.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.3.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.0.1.2.weight - torch.Size([40, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.3.0.1.3.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.0.1.3.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.0.2.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.3.0.2.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.0.2.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.0.2.2.weight - torch.Size([320, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.3.0.2.3.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.0.2.3.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.1.0.0.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.3.1.0.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.1.0.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.1.0.2.weight - torch.Size([80, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.3.1.0.3.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.1.0.3.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.1.1.0.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.3.1.1.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.1.1.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.1.1.2.weight - torch.Size([320, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.3.1.1.3.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.1.1.3.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.2.0.0.weight - torch.Size([160, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.3.2.0.1.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.2.0.1.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.2.0.2.weight - torch.Size([320, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.3.2.0.3.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.2.0.3.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.0.cross_resolution_weighting.conv1.conv.weight - torch.Size([37, 300, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.0.cross_resolution_weighting.conv1.bn.weight - torch.Size([37]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.0.cross_resolution_weighting.conv1.bn.bias - torch.Size([37]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.0.cross_resolution_weighting.conv2.conv.weight - torch.Size([300, 37, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.0.cross_resolution_weighting.conv2.bn.weight - torch.Size([300]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.0.cross_resolution_weighting.conv2.bn.bias - torch.Size([300]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.0.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.0.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.0.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.0.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.0.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.0.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.0.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.0.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.0.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.0.depthwise_convs.3.conv.weight - torch.Size([160, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.0.depthwise_convs.3.bn.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.0.depthwise_convs.3.bn.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.0.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.0.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.0.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.0.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.0.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.0.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.0.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.0.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.0.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.0.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.0.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.0.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.0.spatial_weighting.3.conv1.conv.weight - torch.Size([40, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.0.spatial_weighting.3.conv1.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.0.spatial_weighting.3.conv2.conv.weight - torch.Size([160, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.0.spatial_weighting.3.conv2.conv.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.1.cross_resolution_weighting.conv1.conv.weight - torch.Size([37, 300, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.1.cross_resolution_weighting.conv1.bn.weight - torch.Size([37]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.1.cross_resolution_weighting.conv1.bn.bias - torch.Size([37]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.1.cross_resolution_weighting.conv2.conv.weight - torch.Size([300, 37, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.1.cross_resolution_weighting.conv2.bn.weight - torch.Size([300]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.1.cross_resolution_weighting.conv2.bn.bias - torch.Size([300]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.1.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.1.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.1.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.1.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.1.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.1.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.1.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.1.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.1.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.1.depthwise_convs.3.conv.weight - torch.Size([160, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.1.depthwise_convs.3.bn.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.1.depthwise_convs.3.bn.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.1.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.1.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.1.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.1.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.1.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.1.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.1.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.1.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.1.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.1.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.1.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.1.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.1.spatial_weighting.3.conv1.conv.weight - torch.Size([40, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.1.spatial_weighting.3.conv1.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.1.spatial_weighting.3.conv2.conv.weight - torch.Size([160, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.1.spatial_weighting.3.conv2.conv.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.0.1.0.weight - torch.Size([40, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.0.2.0.weight - torch.Size([40, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.0.2.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.0.2.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.0.3.0.weight - torch.Size([40, 320, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.0.3.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.0.3.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.1.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.1.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.1.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.1.0.0.2.weight - torch.Size([80, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.1.0.0.3.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.1.0.0.3.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.1.2.0.weight - torch.Size([80, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.1.2.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.1.2.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.1.3.0.weight - torch.Size([80, 320, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.1.3.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.1.3.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.2.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.2.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.2.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.2.0.0.2.weight - torch.Size([40, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.2.0.0.3.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.2.0.0.3.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.2.0.1.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.2.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.2.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.2.0.1.2.weight - torch.Size([160, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.2.0.1.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.2.0.1.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.2.1.0.0.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.2.1.0.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.2.1.0.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.2.1.0.2.weight - torch.Size([160, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.2.1.0.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.2.1.0.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.2.3.0.weight - torch.Size([160, 320, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.2.3.1.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.2.3.1.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.3.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.0.0.2.weight - torch.Size([40, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.3.0.0.3.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.0.0.3.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.0.1.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.3.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.0.1.2.weight - torch.Size([40, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.3.0.1.3.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.0.1.3.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.0.2.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.3.0.2.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.0.2.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.0.2.2.weight - torch.Size([320, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.3.0.2.3.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.0.2.3.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.1.0.0.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.3.1.0.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.1.0.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.1.0.2.weight - torch.Size([80, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.3.1.0.3.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.1.0.3.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.1.1.0.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.3.1.1.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.1.1.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.1.1.2.weight - torch.Size([320, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.3.1.1.3.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.1.1.3.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.2.0.0.weight - torch.Size([160, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.3.2.0.1.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.2.0.1.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.2.0.2.weight - torch.Size([320, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.3.2.0.3.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.2.0.3.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.conv_seg.weight - torch.Size([150, 600, 1, 1]): 
NormalInit: mean=0, std=0.01, bias=0 

decode_head.conv_seg.bias - torch.Size([150]): 
NormalInit: mean=0, std=0.01, bias=0 

decode_head.convs.0.conv.weight - torch.Size([600, 600, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.convs.0.bn.weight - torch.Size([600]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.convs.0.bn.bias - torch.Size([600]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  
2021-08-13 11:11:17,124 - mmseg - INFO - EncoderDecoder(
  (backbone): LiteHRNet(
    (stem): Stem(
      (conv1): ConvModule(
        (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (branch1): Sequential(
        (0): ConvModule(
          (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)
          (bn): SyncBatchNorm(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): ConvModule(
          (conv): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): SyncBatchNorm(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (expand_conv): ConvModule(
        (conv): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (depthwise_conv): ConvModule(
        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)
        (bn): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (linear_conv): ConvModule(
        (conv): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): SyncBatchNorm(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (transition0): ModuleList(
      (0): Sequential(
        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
        (1): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Conv2d(32, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (3): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (4): ReLU()
      )
      (1): Sequential(
        (0): Sequential(
          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)
          (1): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Conv2d(32, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU()
        )
      )
    )
    (stage0): Sequential(
      (0): LiteHRModule(
        (layers): Sequential(
          (0): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(60, 7, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(7, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
          (1): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(60, 7, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(7, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
        )
        (fuse_layers): ModuleList(
          (0): ModuleList(
            (0): None
            (1): Sequential(
              (0): Conv2d(80, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
          )
          (1): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): None
          )
        )
        (relu): ReLU()
      )
      (1): LiteHRModule(
        (layers): Sequential(
          (0): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(60, 7, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(7, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
          (1): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(60, 7, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(7, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
        )
        (fuse_layers): ModuleList(
          (0): ModuleList(
            (0): None
            (1): Sequential(
              (0): Conv2d(80, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
          )
          (1): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): None
          )
        )
        (relu): ReLU()
      )
      (2): LiteHRModule(
        (layers): Sequential(
          (0): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(60, 7, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(7, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
          (1): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(60, 7, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(7, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
        )
        (fuse_layers): ModuleList(
          (0): ModuleList(
            (0): None
            (1): Sequential(
              (0): Conv2d(80, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
          )
          (1): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): None
          )
        )
        (relu): ReLU()
      )
    )
    (transition1): ModuleList(
      (0): None
      (1): None
      (2): Sequential(
        (0): Sequential(
          (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=80, bias=False)
          (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Conv2d(80, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU()
        )
      )
    )
    (stage1): Sequential(
      (0): LiteHRModule(
        (layers): Sequential(
          (0): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(140, 17, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(17, 140, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
          (1): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(140, 17, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(17, 140, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
        )
        (fuse_layers): ModuleList(
          (0): ModuleList(
            (0): None
            (1): Sequential(
              (0): Conv2d(80, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
            (2): Sequential(
              (0): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=4.0, mode=nearest)
            )
          )
          (1): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): None
            (2): Sequential(
              (0): Conv2d(160, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
          )
          (2): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (1): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=80, bias=False)
                (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(80, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): None
          )
        )
        (relu): ReLU()
      )
      (1): LiteHRModule(
        (layers): Sequential(
          (0): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(140, 17, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(17, 140, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
          (1): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(140, 17, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(17, 140, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
        )
        (fuse_layers): ModuleList(
          (0): ModuleList(
            (0): None
            (1): Sequential(
              (0): Conv2d(80, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
            (2): Sequential(
              (0): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=4.0, mode=nearest)
            )
          )
          (1): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): None
            (2): Sequential(
              (0): Conv2d(160, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
          )
          (2): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (1): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=80, bias=False)
                (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(80, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): None
          )
        )
        (relu): ReLU()
      )
      (2): LiteHRModule(
        (layers): Sequential(
          (0): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(140, 17, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(17, 140, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
          (1): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(140, 17, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(17, 140, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
        )
        (fuse_layers): ModuleList(
          (0): ModuleList(
            (0): None
            (1): Sequential(
              (0): Conv2d(80, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
            (2): Sequential(
              (0): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=4.0, mode=nearest)
            )
          )
          (1): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): None
            (2): Sequential(
              (0): Conv2d(160, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
          )
          (2): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (1): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=80, bias=False)
                (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(80, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): None
          )
        )
        (relu): ReLU()
      )
      (3): LiteHRModule(
        (layers): Sequential(
          (0): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(140, 17, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(17, 140, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
          (1): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(140, 17, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(17, 140, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
        )
        (fuse_layers): ModuleList(
          (0): ModuleList(
            (0): None
            (1): Sequential(
              (0): Conv2d(80, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
            (2): Sequential(
              (0): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=4.0, mode=nearest)
            )
          )
          (1): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): None
            (2): Sequential(
              (0): Conv2d(160, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
          )
          (2): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (1): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=80, bias=False)
                (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(80, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): None
          )
        )
        (relu): ReLU()
      )
      (4): LiteHRModule(
        (layers): Sequential(
          (0): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(140, 17, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(17, 140, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
          (1): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(140, 17, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(17, 140, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
        )
        (fuse_layers): ModuleList(
          (0): ModuleList(
            (0): None
            (1): Sequential(
              (0): Conv2d(80, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
            (2): Sequential(
              (0): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=4.0, mode=nearest)
            )
          )
          (1): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): None
            (2): Sequential(
              (0): Conv2d(160, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
          )
          (2): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (1): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=80, bias=False)
                (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(80, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): None
          )
        )
        (relu): ReLU()
      )
      (5): LiteHRModule(
        (layers): Sequential(
          (0): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(140, 17, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(17, 140, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
          (1): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(140, 17, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(17, 140, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
        )
        (fuse_layers): ModuleList(
          (0): ModuleList(
            (0): None
            (1): Sequential(
              (0): Conv2d(80, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
            (2): Sequential(
              (0): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=4.0, mode=nearest)
            )
          )
          (1): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): None
            (2): Sequential(
              (0): Conv2d(160, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
          )
          (2): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (1): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=80, bias=False)
                (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(80, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): None
          )
        )
        (relu): ReLU()
      )
      (6): LiteHRModule(
        (layers): Sequential(
          (0): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(140, 17, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(17, 140, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
          (1): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(140, 17, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(17, 140, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
        )
        (fuse_layers): ModuleList(
          (0): ModuleList(
            (0): None
            (1): Sequential(
              (0): Conv2d(80, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
            (2): Sequential(
              (0): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=4.0, mode=nearest)
            )
          )
          (1): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): None
            (2): Sequential(
              (0): Conv2d(160, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
          )
          (2): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (1): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=80, bias=False)
                (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(80, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): None
          )
        )
        (relu): ReLU()
      )
      (7): LiteHRModule(
        (layers): Sequential(
          (0): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(140, 17, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(17, 140, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
          (1): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(140, 17, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(17, 140, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
        )
        (fuse_layers): ModuleList(
          (0): ModuleList(
            (0): None
            (1): Sequential(
              (0): Conv2d(80, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
            (2): Sequential(
              (0): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=4.0, mode=nearest)
            )
          )
          (1): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): None
            (2): Sequential(
              (0): Conv2d(160, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
          )
          (2): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (1): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=80, bias=False)
                (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(80, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): None
          )
        )
        (relu): ReLU()
      )
    )
    (transition2): ModuleList(
      (0): None
      (1): None
      (2): None
      (3): Sequential(
        (0): Sequential(
          (0): Conv2d(160, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=160, bias=False)
          (1): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Conv2d(160, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): SyncBatchNorm(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU()
        )
      )
    )
    (stage2): Sequential(
      (0): LiteHRModule(
        (layers): Sequential(
          (0): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(300, 37, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(37, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(37, 300, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): ConvModule(
                (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (3): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
          (1): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(300, 37, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(37, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(37, 300, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): ConvModule(
                (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (3): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
        )
        (fuse_layers): ModuleList(
          (0): ModuleList(
            (0): None
            (1): Sequential(
              (0): Conv2d(80, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
            (2): Sequential(
              (0): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=4.0, mode=nearest)
            )
            (3): Sequential(
              (0): Conv2d(320, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=8.0, mode=nearest)
            )
          )
          (1): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): None
            (2): Sequential(
              (0): Conv2d(160, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
            (3): Sequential(
              (0): Conv2d(320, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=4.0, mode=nearest)
            )
          )
          (2): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (1): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=80, bias=False)
                (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(80, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): None
            (3): Sequential(
              (0): Conv2d(320, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
          )
          (3): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (1): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (2): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=80, bias=False)
                (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (1): Sequential(
                (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=80, bias=False)
                (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(80, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): Sequential(
              (0): Sequential(
                (0): Conv2d(160, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=160, bias=False)
                (1): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(160, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): None
          )
        )
        (relu): ReLU()
      )
      (1): LiteHRModule(
        (layers): Sequential(
          (0): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(300, 37, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(37, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(37, 300, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): ConvModule(
                (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (3): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
          (1): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(300, 37, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(37, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(37, 300, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): ConvModule(
                (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (3): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
        )
        (fuse_layers): ModuleList(
          (0): ModuleList(
            (0): None
            (1): Sequential(
              (0): Conv2d(80, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
            (2): Sequential(
              (0): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=4.0, mode=nearest)
            )
            (3): Sequential(
              (0): Conv2d(320, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=8.0, mode=nearest)
            )
          )
          (1): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): None
            (2): Sequential(
              (0): Conv2d(160, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
            (3): Sequential(
              (0): Conv2d(320, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=4.0, mode=nearest)
            )
          )
          (2): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (1): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=80, bias=False)
                (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(80, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): None
            (3): Sequential(
              (0): Conv2d(320, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
          )
          (3): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (1): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (2): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=80, bias=False)
                (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (1): Sequential(
                (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=80, bias=False)
                (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(80, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): Sequential(
              (0): Sequential(
                (0): Conv2d(160, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=160, bias=False)
                (1): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(160, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): None
          )
        )
        (relu): ReLU()
      )
      (2): LiteHRModule(
        (layers): Sequential(
          (0): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(300, 37, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(37, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(37, 300, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): ConvModule(
                (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (3): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
          (1): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(300, 37, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(37, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(37, 300, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): ConvModule(
                (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (3): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
        )
        (fuse_layers): ModuleList(
          (0): ModuleList(
            (0): None
            (1): Sequential(
              (0): Conv2d(80, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
            (2): Sequential(
              (0): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=4.0, mode=nearest)
            )
            (3): Sequential(
              (0): Conv2d(320, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=8.0, mode=nearest)
            )
          )
          (1): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): None
            (2): Sequential(
              (0): Conv2d(160, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
            (3): Sequential(
              (0): Conv2d(320, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=4.0, mode=nearest)
            )
          )
          (2): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (1): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=80, bias=False)
                (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(80, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): None
            (3): Sequential(
              (0): Conv2d(320, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
          )
          (3): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (1): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (2): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=80, bias=False)
                (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (1): Sequential(
                (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=80, bias=False)
                (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(80, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): Sequential(
              (0): Sequential(
                (0): Conv2d(160, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=160, bias=False)
                (1): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(160, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): None
          )
        )
        (relu): ReLU()
      )
    )
  )
  init_cfg=[{'type': 'Normal', 'std': 0.001, 'layer': 'Conv2d'}, {'type': 'Constant', 'val': 1, 'layer': ['_BatchNorm', 'GroupNorm']}]
  (decode_head): FCNHead(
    input_transform=resize_concat, ignore_index=255, align_corners=False
    (loss_decode): CrossEntropyLoss()
    (conv_seg): Conv2d(600, 150, kernel_size=(1, 1), stride=(1, 1))
    (convs): Sequential(
      (0): ConvModule(
        (conv): Conv2d(600, 600, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): SyncBatchNorm(600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
)
2021-08-13 11:11:17,857 - mmseg - INFO - Loaded 20210 images
2021-08-13 11:11:22,991 - mmseg - INFO - Loaded 2000 images
2021-08-13 11:11:22,992 - mmseg - INFO - Start running, host: hejunjun@SH-IDC2-172-20-20-71, work_dir: /mnt/lustrenew/hejunjun/mmseg_dev/lite_hrnet/mmsegmentation/work_dirs/fcn-resize-concat_litehr30-without-head_512x512_160k_ade20k
2021-08-13 11:11:22,992 - mmseg - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(NORMAL      ) CheckpointHook                     
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
2021-08-13 11:11:22,993 - mmseg - INFO - workflow: [('train', 1)], max: 160000 iters
2021-08-13 11:13:06,403 - mmseg - INFO - Iter [50/160000]	lr: 9.997e-03, eta: 2 days, 13:55:43, time: 1.394, data_time: 0.017, memory: 6002, decode.loss_seg: 3.0787, decode.acc_seg: 12.5744, loss: 3.0787
2021-08-13 11:14:13,494 - mmseg - INFO - Iter [100/160000]	lr: 9.994e-03, eta: 2 days, 12:45:14, time: 1.342, data_time: 0.013, memory: 6002, decode.loss_seg: 2.8284, decode.acc_seg: 14.4842, loss: 2.8284
2021-08-13 11:15:19,499 - mmseg - INFO - Iter [150/160000]	lr: 9.992e-03, eta: 2 days, 12:00:34, time: 1.319, data_time: 0.013, memory: 6002, decode.loss_seg: 2.8517, decode.acc_seg: 14.1476, loss: 2.8517
2021-08-13 11:16:25,536 - mmseg - INFO - Iter [200/160000]	lr: 9.989e-03, eta: 2 days, 11:39:00, time: 1.321, data_time: 0.015, memory: 6002, decode.loss_seg: 2.8051, decode.acc_seg: 15.2508, loss: 2.8051
2021-08-13 11:17:30,087 - mmseg - INFO - Iter [250/160000]	lr: 9.986e-03, eta: 2 days, 11:10:03, time: 1.292, data_time: 0.013, memory: 6002, decode.loss_seg: 2.7715, decode.acc_seg: 16.2216, loss: 2.7715
2021-08-13 11:18:35,600 - mmseg - INFO - Iter [300/160000]	lr: 9.983e-03, eta: 2 days, 10:58:59, time: 1.311, data_time: 0.014, memory: 6002, decode.loss_seg: 2.7545, decode.acc_seg: 15.5048, loss: 2.7545
2021-08-13 11:19:40,955 - mmseg - INFO - Iter [350/160000]	lr: 9.981e-03, eta: 2 days, 10:49:04, time: 1.306, data_time: 0.012, memory: 6002, decode.loss_seg: 2.7568, decode.acc_seg: 16.3024, loss: 2.7568
2021-08-13 11:20:46,511 - mmseg - INFO - Iter [400/160000]	lr: 9.978e-03, eta: 2 days, 10:43:08, time: 1.312, data_time: 0.013, memory: 6002, decode.loss_seg: 2.7474, decode.acc_seg: 16.3433, loss: 2.7474
2021-08-13 11:21:55,557 - mmseg - INFO - Iter [450/160000]	lr: 9.975e-03, eta: 2 days, 10:58:42, time: 1.381, data_time: 0.013, memory: 6002, decode.loss_seg: 2.6909, decode.acc_seg: 17.0384, loss: 2.6909
2021-08-13 11:23:01,543 - mmseg - INFO - Iter [500/160000]	lr: 9.972e-03, eta: 2 days, 10:54:39, time: 1.320, data_time: 0.013, memory: 6002, decode.loss_seg: 2.6860, decode.acc_seg: 19.9886, loss: 2.6860
2021-08-13 11:24:05,853 - mmseg - INFO - Iter [550/160000]	lr: 9.969e-03, eta: 2 days, 10:42:51, time: 1.285, data_time: 0.013, memory: 6002, decode.loss_seg: 2.6047, decode.acc_seg: 21.6907, loss: 2.6047
2021-08-13 11:25:11,850 - mmseg - INFO - Iter [600/160000]	lr: 9.967e-03, eta: 2 days, 10:40:34, time: 1.320, data_time: 0.013, memory: 6002, decode.loss_seg: 2.5700, decode.acc_seg: 23.9081, loss: 2.5700
2021-08-13 11:26:51,122 - mmseg - INFO - Iter [650/160000]	lr: 9.964e-03, eta: 2 days, 12:54:19, time: 1.985, data_time: 0.747, memory: 6002, decode.loss_seg: 2.4838, decode.acc_seg: 25.1961, loss: 2.4838
2021-08-13 11:27:55,075 - mmseg - INFO - Iter [700/160000]	lr: 9.961e-03, eta: 2 days, 12:34:49, time: 1.279, data_time: 0.014, memory: 6002, decode.loss_seg: 2.4429, decode.acc_seg: 25.2260, loss: 2.4429
2021-08-13 11:29:00,615 - mmseg - INFO - Iter [750/160000]	lr: 9.958e-03, eta: 2 days, 12:23:18, time: 1.310, data_time: 0.013, memory: 6002, decode.loss_seg: 2.4254, decode.acc_seg: 26.6811, loss: 2.4254
2021-08-13 11:30:06,454 - mmseg - INFO - Iter [800/160000]	lr: 9.955e-03, eta: 2 days, 12:14:15, time: 1.317, data_time: 0.013, memory: 6002, decode.loss_seg: 2.3319, decode.acc_seg: 28.6223, loss: 2.3319
2021-08-13 11:31:11,088 - mmseg - INFO - Iter [850/160000]	lr: 9.953e-03, eta: 2 days, 12:02:09, time: 1.292, data_time: 0.014, memory: 6002, decode.loss_seg: 2.2919, decode.acc_seg: 27.2293, loss: 2.2919
2021-08-13 11:32:14,106 - mmseg - INFO - Iter [900/160000]	lr: 9.950e-03, eta: 2 days, 11:46:46, time: 1.261, data_time: 0.014, memory: 6002, decode.loss_seg: 2.2636, decode.acc_seg: 28.5470, loss: 2.2636
2021-08-13 11:33:18,703 - mmseg - INFO - Iter [950/160000]	lr: 9.947e-03, eta: 2 days, 11:37:02, time: 1.291, data_time: 0.013, memory: 6002, decode.loss_seg: 2.1812, decode.acc_seg: 29.5101, loss: 2.1812
2021-08-13 11:34:27,456 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-without-head_512x512_160k_ade20k.py
2021-08-13 11:34:27,456 - mmseg - INFO - Iter [1000/160000]	lr: 9.944e-03, eta: 2 days, 11:39:10, time: 1.374, data_time: 0.013, memory: 6002, decode.loss_seg: 2.2016, decode.acc_seg: 30.4270, loss: 2.2016
2021-08-13 11:35:37,256 - mmseg - INFO - Iter [1050/160000]	lr: 9.942e-03, eta: 2 days, 11:43:49, time: 1.396, data_time: 0.014, memory: 6002, decode.loss_seg: 2.1704, decode.acc_seg: 29.5157, loss: 2.1704
2021-08-13 11:36:46,958 - mmseg - INFO - Iter [1100/160000]	lr: 9.939e-03, eta: 2 days, 11:47:39, time: 1.394, data_time: 0.014, memory: 6002, decode.loss_seg: 2.1192, decode.acc_seg: 31.1190, loss: 2.1192
2021-08-13 11:37:54,163 - mmseg - INFO - Iter [1150/160000]	lr: 9.936e-03, eta: 2 days, 11:45:29, time: 1.346, data_time: 0.015, memory: 6002, decode.loss_seg: 2.1084, decode.acc_seg: 31.3251, loss: 2.1084
2021-08-13 11:38:59,712 - mmseg - INFO - Iter [1200/160000]	lr: 9.933e-03, eta: 2 days, 11:39:35, time: 1.311, data_time: 0.013, memory: 6002, decode.loss_seg: 2.0582, decode.acc_seg: 32.2607, loss: 2.0582
2021-08-13 11:40:05,702 - mmseg - INFO - Iter [1250/160000]	lr: 9.930e-03, eta: 2 days, 11:34:54, time: 1.319, data_time: 0.012, memory: 6002, decode.loss_seg: 2.0139, decode.acc_seg: 33.3244, loss: 2.0139
2021-08-13 11:41:45,457 - mmseg - INFO - Iter [1300/160000]	lr: 9.928e-03, eta: 2 days, 12:39:22, time: 1.996, data_time: 0.698, memory: 6002, decode.loss_seg: 2.0796, decode.acc_seg: 31.9923, loss: 2.0796
2021-08-13 11:42:50,401 - mmseg - INFO - Iter [1350/160000]	lr: 9.925e-03, eta: 2 days, 12:30:37, time: 1.298, data_time: 0.016, memory: 6002, decode.loss_seg: 1.9839, decode.acc_seg: 33.9420, loss: 1.9839
2021-08-13 11:43:56,497 - mmseg - INFO - Iter [1400/160000]	lr: 9.922e-03, eta: 2 days, 12:24:34, time: 1.321, data_time: 0.013, memory: 6002, decode.loss_seg: 2.0190, decode.acc_seg: 32.4093, loss: 2.0190
2021-08-13 11:45:01,732 - mmseg - INFO - Iter [1450/160000]	lr: 9.919e-03, eta: 2 days, 12:17:29, time: 1.306, data_time: 0.015, memory: 6002, decode.loss_seg: 1.9543, decode.acc_seg: 33.4892, loss: 1.9543
2021-08-13 11:46:07,184 - mmseg - INFO - Iter [1500/160000]	lr: 9.916e-03, eta: 2 days, 12:10:59, time: 1.308, data_time: 0.014, memory: 6002, decode.loss_seg: 1.9754, decode.acc_seg: 33.4395, loss: 1.9754
2021-08-13 11:47:11,234 - mmseg - INFO - Iter [1550/160000]	lr: 9.914e-03, eta: 2 days, 12:02:33, time: 1.281, data_time: 0.015, memory: 6002, decode.loss_seg: 1.8931, decode.acc_seg: 34.9656, loss: 1.8931
2021-08-13 11:48:13,853 - mmseg - INFO - Iter [1600/160000]	lr: 9.911e-03, eta: 2 days, 11:52:13, time: 1.253, data_time: 0.014, memory: 6002, decode.loss_seg: 1.9574, decode.acc_seg: 33.2011, loss: 1.9574
2021-08-13 11:49:17,135 - mmseg - INFO - Iter [1650/160000]	lr: 9.908e-03, eta: 2 days, 11:43:28, time: 1.265, data_time: 0.014, memory: 6002, decode.loss_seg: 1.8686, decode.acc_seg: 35.1241, loss: 1.8686
2021-08-13 11:50:18,547 - mmseg - INFO - Iter [1700/160000]	lr: 9.905e-03, eta: 2 days, 11:32:17, time: 1.228, data_time: 0.014, memory: 6002, decode.loss_seg: 1.9257, decode.acc_seg: 35.1291, loss: 1.9257
2021-08-13 11:51:21,212 - mmseg - INFO - Iter [1750/160000]	lr: 9.903e-03, eta: 2 days, 11:23:36, time: 1.254, data_time: 0.016, memory: 6002, decode.loss_seg: 1.8973, decode.acc_seg: 35.8512, loss: 1.8973
2021-08-13 11:52:24,501 - mmseg - INFO - Iter [1800/160000]	lr: 9.900e-03, eta: 2 days, 11:16:13, time: 1.266, data_time: 0.013, memory: 6002, decode.loss_seg: 1.8727, decode.acc_seg: 35.9369, loss: 1.8727
2021-08-13 11:53:27,369 - mmseg - INFO - Iter [1850/160000]	lr: 9.897e-03, eta: 2 days, 11:08:31, time: 1.256, data_time: 0.014, memory: 6002, decode.loss_seg: 1.8709, decode.acc_seg: 35.5055, loss: 1.8709
2021-08-13 11:55:08,063 - mmseg - INFO - Iter [1900/160000]	lr: 9.894e-03, eta: 2 days, 11:53:41, time: 2.014, data_time: 0.736, memory: 6002, decode.loss_seg: 1.8904, decode.acc_seg: 36.1651, loss: 1.8904
2021-08-13 11:56:13,172 - mmseg - INFO - Iter [1950/160000]	lr: 9.891e-03, eta: 2 days, 11:48:24, time: 1.302, data_time: 0.016, memory: 6002, decode.loss_seg: 1.8224, decode.acc_seg: 34.8322, loss: 1.8224
2021-08-13 11:57:17,832 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-without-head_512x512_160k_ade20k.py
2021-08-13 11:57:17,832 - mmseg - INFO - Iter [2000/160000]	lr: 9.889e-03, eta: 2 days, 11:42:46, time: 1.294, data_time: 0.015, memory: 6002, decode.loss_seg: 1.8802, decode.acc_seg: 35.4860, loss: 1.8802
2021-08-13 11:58:20,444 - mmseg - INFO - Iter [2050/160000]	lr: 9.886e-03, eta: 2 days, 11:34:40, time: 1.252, data_time: 0.014, memory: 6002, decode.loss_seg: 1.7878, decode.acc_seg: 37.5061, loss: 1.7878
2021-08-13 11:59:25,489 - mmseg - INFO - Iter [2100/160000]	lr: 9.883e-03, eta: 2 days, 11:29:54, time: 1.300, data_time: 0.014, memory: 6002, decode.loss_seg: 1.8393, decode.acc_seg: 36.7408, loss: 1.8393
2021-08-13 12:00:31,588 - mmseg - INFO - Iter [2150/160000]	lr: 9.880e-03, eta: 2 days, 11:26:44, time: 1.323, data_time: 0.014, memory: 6002, decode.loss_seg: 1.8464, decode.acc_seg: 35.5242, loss: 1.8464
2021-08-13 12:01:35,595 - mmseg - INFO - Iter [2200/160000]	lr: 9.877e-03, eta: 2 days, 11:21:02, time: 1.279, data_time: 0.013, memory: 6002, decode.loss_seg: 1.7826, decode.acc_seg: 36.4394, loss: 1.7826
2021-08-13 12:02:39,731 - mmseg - INFO - Iter [2250/160000]	lr: 9.875e-03, eta: 2 days, 11:15:45, time: 1.283, data_time: 0.014, memory: 6002, decode.loss_seg: 1.7864, decode.acc_seg: 37.0760, loss: 1.7864
2021-08-13 12:03:44,475 - mmseg - INFO - Iter [2300/160000]	lr: 9.872e-03, eta: 2 days, 11:11:18, time: 1.294, data_time: 0.014, memory: 6002, decode.loss_seg: 1.8102, decode.acc_seg: 36.8078, loss: 1.8102
2021-08-13 12:04:48,927 - mmseg - INFO - Iter [2350/160000]	lr: 9.869e-03, eta: 2 days, 11:06:45, time: 1.290, data_time: 0.015, memory: 6002, decode.loss_seg: 1.7941, decode.acc_seg: 37.1740, loss: 1.7941
2021-08-13 12:05:52,783 - mmseg - INFO - Iter [2400/160000]	lr: 9.866e-03, eta: 2 days, 11:01:40, time: 1.277, data_time: 0.015, memory: 6002, decode.loss_seg: 1.7325, decode.acc_seg: 39.2974, loss: 1.7325
2021-08-13 12:06:57,383 - mmseg - INFO - Iter [2450/160000]	lr: 9.864e-03, eta: 2 days, 10:57:28, time: 1.291, data_time: 0.014, memory: 6002, decode.loss_seg: 1.7170, decode.acc_seg: 38.8864, loss: 1.7170
2021-08-13 12:08:00,553 - mmseg - INFO - Iter [2500/160000]	lr: 9.861e-03, eta: 2 days, 10:51:58, time: 1.264, data_time: 0.015, memory: 6002, decode.loss_seg: 1.7870, decode.acc_seg: 37.8369, loss: 1.7870
2021-08-13 12:10:09,030 - mmseg - INFO - Iter [2550/160000]	lr: 9.858e-03, eta: 2 days, 11:53:51, time: 2.570, data_time: 1.288, memory: 6002, decode.loss_seg: 1.7193, decode.acc_seg: 38.7214, loss: 1.7193
2021-08-13 12:11:11,194 - mmseg - INFO - Iter [2600/160000]	lr: 9.855e-03, eta: 2 days, 11:46:18, time: 1.243, data_time: 0.014, memory: 6002, decode.loss_seg: 1.6607, decode.acc_seg: 39.2898, loss: 1.6607
2021-08-13 12:12:14,715 - mmseg - INFO - Iter [2650/160000]	lr: 9.852e-03, eta: 2 days, 11:40:22, time: 1.270, data_time: 0.014, memory: 6002, decode.loss_seg: 1.7524, decode.acc_seg: 38.8773, loss: 1.7524
2021-08-13 12:13:19,029 - mmseg - INFO - Iter [2700/160000]	lr: 9.850e-03, eta: 2 days, 11:35:25, time: 1.287, data_time: 0.015, memory: 6002, decode.loss_seg: 1.7450, decode.acc_seg: 38.6577, loss: 1.7450
2021-08-13 12:14:22,378 - mmseg - INFO - Iter [2750/160000]	lr: 9.847e-03, eta: 2 days, 11:29:41, time: 1.267, data_time: 0.014, memory: 6002, decode.loss_seg: 1.7388, decode.acc_seg: 37.9056, loss: 1.7388
2021-08-13 12:15:24,020 - mmseg - INFO - Iter [2800/160000]	lr: 9.844e-03, eta: 2 days, 11:22:31, time: 1.233, data_time: 0.014, memory: 6002, decode.loss_seg: 1.6233, decode.acc_seg: 39.6682, loss: 1.6233
2021-08-13 12:16:31,415 - mmseg - INFO - Iter [2850/160000]	lr: 9.841e-03, eta: 2 days, 11:20:47, time: 1.347, data_time: 0.014, memory: 6002, decode.loss_seg: 1.7027, decode.acc_seg: 38.6426, loss: 1.7027
2021-08-13 12:17:34,938 - mmseg - INFO - Iter [2900/160000]	lr: 9.838e-03, eta: 2 days, 11:15:39, time: 1.271, data_time: 0.016, memory: 6002, decode.loss_seg: 1.6521, decode.acc_seg: 39.8213, loss: 1.6521
2021-08-13 12:18:41,906 - mmseg - INFO - Iter [2950/160000]	lr: 9.836e-03, eta: 2 days, 11:13:43, time: 1.340, data_time: 0.015, memory: 6002, decode.loss_seg: 1.6536, decode.acc_seg: 40.0527, loss: 1.6536
2021-08-13 12:19:47,853 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-without-head_512x512_160k_ade20k.py
2021-08-13 12:19:47,853 - mmseg - INFO - Iter [3000/160000]	lr: 9.833e-03, eta: 2 days, 11:10:53, time: 1.318, data_time: 0.015, memory: 6002, decode.loss_seg: 1.7021, decode.acc_seg: 38.9954, loss: 1.7021
2021-08-13 12:20:51,880 - mmseg - INFO - Iter [3050/160000]	lr: 9.830e-03, eta: 2 days, 11:06:27, time: 1.280, data_time: 0.015, memory: 6002, decode.loss_seg: 1.6990, decode.acc_seg: 39.7086, loss: 1.6990
2021-08-13 12:21:54,777 - mmseg - INFO - Iter [3100/160000]	lr: 9.827e-03, eta: 2 days, 11:01:13, time: 1.258, data_time: 0.014, memory: 6002, decode.loss_seg: 1.6688, decode.acc_seg: 39.8945, loss: 1.6688
2021-08-13 12:22:59,339 - mmseg - INFO - Iter [3150/160000]	lr: 9.824e-03, eta: 2 days, 10:57:28, time: 1.291, data_time: 0.013, memory: 6002, decode.loss_seg: 1.6527, decode.acc_seg: 40.5888, loss: 1.6527
2021-08-13 12:24:37,807 - mmseg - INFO - Iter [3200/160000]	lr: 9.822e-03, eta: 2 days, 11:21:31, time: 1.970, data_time: 0.709, memory: 6002, decode.loss_seg: 1.6764, decode.acc_seg: 39.0755, loss: 1.6764
2021-08-13 12:25:41,482 - mmseg - INFO - Iter [3250/160000]	lr: 9.819e-03, eta: 2 days, 11:16:48, time: 1.274, data_time: 0.014, memory: 6002, decode.loss_seg: 1.6885, decode.acc_seg: 40.7588, loss: 1.6885
2021-08-13 12:26:44,660 - mmseg - INFO - Iter [3300/160000]	lr: 9.816e-03, eta: 2 days, 11:11:46, time: 1.263, data_time: 0.014, memory: 6002, decode.loss_seg: 1.6601, decode.acc_seg: 40.2193, loss: 1.6601
2021-08-13 12:27:48,151 - mmseg - INFO - Iter [3350/160000]	lr: 9.813e-03, eta: 2 days, 11:07:06, time: 1.269, data_time: 0.014, memory: 6002, decode.loss_seg: 1.6392, decode.acc_seg: 40.5700, loss: 1.6392
2021-08-13 12:28:50,994 - mmseg - INFO - Iter [3400/160000]	lr: 9.811e-03, eta: 2 days, 11:02:05, time: 1.257, data_time: 0.015, memory: 6002, decode.loss_seg: 1.6140, decode.acc_seg: 41.2173, loss: 1.6140
2021-08-13 12:29:56,102 - mmseg - INFO - Iter [3450/160000]	lr: 9.808e-03, eta: 2 days, 10:58:52, time: 1.302, data_time: 0.014, memory: 6002, decode.loss_seg: 1.6385, decode.acc_seg: 40.2160, loss: 1.6385
2021-08-13 12:31:00,997 - mmseg - INFO - Iter [3500/160000]	lr: 9.805e-03, eta: 2 days, 10:55:34, time: 1.298, data_time: 0.014, memory: 6002, decode.loss_seg: 1.6205, decode.acc_seg: 40.6088, loss: 1.6205
2021-08-13 12:32:04,665 - mmseg - INFO - Iter [3550/160000]	lr: 9.802e-03, eta: 2 days, 10:51:25, time: 1.273, data_time: 0.015, memory: 6002, decode.loss_seg: 1.5988, decode.acc_seg: 40.0578, loss: 1.5988
2021-08-13 12:33:08,121 - mmseg - INFO - Iter [3600/160000]	lr: 9.799e-03, eta: 2 days, 10:47:13, time: 1.270, data_time: 0.015, memory: 6002, decode.loss_seg: 1.6062, decode.acc_seg: 41.3896, loss: 1.6062
2021-08-13 12:34:13,311 - mmseg - INFO - Iter [3650/160000]	lr: 9.797e-03, eta: 2 days, 10:44:18, time: 1.303, data_time: 0.014, memory: 6002, decode.loss_seg: 1.5977, decode.acc_seg: 41.2350, loss: 1.5977
2021-08-13 12:35:18,519 - mmseg - INFO - Iter [3700/160000]	lr: 9.794e-03, eta: 2 days, 10:41:30, time: 1.305, data_time: 0.014, memory: 6002, decode.loss_seg: 1.5867, decode.acc_seg: 41.5128, loss: 1.5867
2021-08-13 12:36:20,740 - mmseg - INFO - Iter [3750/160000]	lr: 9.791e-03, eta: 2 days, 10:36:39, time: 1.245, data_time: 0.016, memory: 6002, decode.loss_seg: 1.5721, decode.acc_seg: 41.4237, loss: 1.5721
2021-08-13 12:38:00,119 - mmseg - INFO - Iter [3800/160000]	lr: 9.788e-03, eta: 2 days, 10:57:21, time: 1.988, data_time: 0.708, memory: 6002, decode.loss_seg: 1.6327, decode.acc_seg: 41.0606, loss: 1.6327
2021-08-13 12:39:05,002 - mmseg - INFO - Iter [3850/160000]	lr: 9.785e-03, eta: 2 days, 10:54:09, time: 1.298, data_time: 0.015, memory: 6002, decode.loss_seg: 1.5831, decode.acc_seg: 41.2504, loss: 1.5831
2021-08-13 12:40:09,576 - mmseg - INFO - Iter [3900/160000]	lr: 9.783e-03, eta: 2 days, 10:50:48, time: 1.292, data_time: 0.016, memory: 6002, decode.loss_seg: 1.5248, decode.acc_seg: 42.1708, loss: 1.5248
2021-08-13 12:41:12,900 - mmseg - INFO - Iter [3950/160000]	lr: 9.780e-03, eta: 2 days, 10:46:40, time: 1.266, data_time: 0.014, memory: 6002, decode.loss_seg: 1.6119, decode.acc_seg: 41.2835, loss: 1.6119
2021-08-13 12:42:17,164 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-without-head_512x512_160k_ade20k.py
2021-08-13 12:42:17,165 - mmseg - INFO - Iter [4000/160000]	lr: 9.777e-03, eta: 2 days, 10:43:13, time: 1.285, data_time: 0.014, memory: 6002, decode.loss_seg: 1.5388, decode.acc_seg: 42.2062, loss: 1.5388
2021-08-13 12:43:19,997 - mmseg - INFO - Iter [4050/160000]	lr: 9.774e-03, eta: 2 days, 10:38:57, time: 1.258, data_time: 0.016, memory: 6002, decode.loss_seg: 1.5791, decode.acc_seg: 41.5679, loss: 1.5791
2021-08-13 12:44:27,208 - mmseg - INFO - Iter [4100/160000]	lr: 9.771e-03, eta: 2 days, 10:37:31, time: 1.344, data_time: 0.013, memory: 6002, decode.loss_seg: 1.5701, decode.acc_seg: 41.3913, loss: 1.5701
2021-08-13 12:45:32,275 - mmseg - INFO - Iter [4150/160000]	lr: 9.769e-03, eta: 2 days, 10:34:44, time: 1.301, data_time: 0.014, memory: 6002, decode.loss_seg: 1.5753, decode.acc_seg: 41.1110, loss: 1.5753
2021-08-13 12:46:38,121 - mmseg - INFO - Iter [4200/160000]	lr: 9.766e-03, eta: 2 days, 10:32:30, time: 1.317, data_time: 0.013, memory: 6002, decode.loss_seg: 1.5702, decode.acc_seg: 41.0018, loss: 1.5702
2021-08-13 12:47:42,307 - mmseg - INFO - Iter [4250/160000]	lr: 9.763e-03, eta: 2 days, 10:29:17, time: 1.284, data_time: 0.014, memory: 6002, decode.loss_seg: 1.5380, decode.acc_seg: 42.4579, loss: 1.5380
2021-08-13 12:48:47,082 - mmseg - INFO - Iter [4300/160000]	lr: 9.760e-03, eta: 2 days, 10:26:27, time: 1.295, data_time: 0.013, memory: 6002, decode.loss_seg: 1.5329, decode.acc_seg: 42.0845, loss: 1.5329
2021-08-13 12:49:53,676 - mmseg - INFO - Iter [4350/160000]	lr: 9.757e-03, eta: 2 days, 10:24:44, time: 1.332, data_time: 0.014, memory: 6002, decode.loss_seg: 1.5566, decode.acc_seg: 41.9272, loss: 1.5566
2021-08-13 12:50:58,386 - mmseg - INFO - Iter [4400/160000]	lr: 9.755e-03, eta: 2 days, 10:21:57, time: 1.295, data_time: 0.015, memory: 6002, decode.loss_seg: 1.5340, decode.acc_seg: 42.0651, loss: 1.5340
2021-08-13 12:52:36,721 - mmseg - INFO - Iter [4450/160000]	lr: 9.752e-03, eta: 2 days, 10:38:46, time: 1.966, data_time: 0.693, memory: 6002, decode.loss_seg: 1.5157, decode.acc_seg: 42.8559, loss: 1.5157
2021-08-13 12:53:41,763 - mmseg - INFO - Iter [4500/160000]	lr: 9.749e-03, eta: 2 days, 10:36:00, time: 1.301, data_time: 0.015, memory: 6002, decode.loss_seg: 1.5185, decode.acc_seg: 41.5781, loss: 1.5185
2021-08-13 12:54:45,071 - mmseg - INFO - Iter [4550/160000]	lr: 9.746e-03, eta: 2 days, 10:32:18, time: 1.266, data_time: 0.015, memory: 6002, decode.loss_seg: 1.5715, decode.acc_seg: 41.3297, loss: 1.5715
2021-08-13 12:55:49,768 - mmseg - INFO - Iter [4600/160000]	lr: 9.744e-03, eta: 2 days, 10:29:26, time: 1.294, data_time: 0.016, memory: 6002, decode.loss_seg: 1.5660, decode.acc_seg: 42.3622, loss: 1.5660
2021-08-13 12:56:53,427 - mmseg - INFO - Iter [4650/160000]	lr: 9.741e-03, eta: 2 days, 10:26:02, time: 1.273, data_time: 0.014, memory: 6002, decode.loss_seg: 1.4542, decode.acc_seg: 43.5591, loss: 1.4542
2021-08-13 12:57:57,247 - mmseg - INFO - Iter [4700/160000]	lr: 9.738e-03, eta: 2 days, 10:22:46, time: 1.277, data_time: 0.016, memory: 6002, decode.loss_seg: 1.4870, decode.acc_seg: 42.9414, loss: 1.4870
2021-08-13 12:58:59,986 - mmseg - INFO - Iter [4750/160000]	lr: 9.735e-03, eta: 2 days, 10:18:56, time: 1.254, data_time: 0.013, memory: 6002, decode.loss_seg: 1.5148, decode.acc_seg: 42.1737, loss: 1.5148
2021-08-13 13:00:02,593 - mmseg - INFO - Iter [4800/160000]	lr: 9.732e-03, eta: 2 days, 10:15:08, time: 1.253, data_time: 0.013, memory: 6002, decode.loss_seg: 1.4919, decode.acc_seg: 43.1954, loss: 1.4919
2021-08-13 13:01:06,334 - mmseg - INFO - Iter [4850/160000]	lr: 9.730e-03, eta: 2 days, 10:11:57, time: 1.274, data_time: 0.013, memory: 6002, decode.loss_seg: 1.5308, decode.acc_seg: 42.7699, loss: 1.5308
2021-08-13 13:02:10,573 - mmseg - INFO - Iter [4900/160000]	lr: 9.727e-03, eta: 2 days, 10:09:05, time: 1.284, data_time: 0.015, memory: 6002, decode.loss_seg: 1.4775, decode.acc_seg: 44.4298, loss: 1.4775
2021-08-13 13:03:13,632 - mmseg - INFO - Iter [4950/160000]	lr: 9.724e-03, eta: 2 days, 10:05:40, time: 1.262, data_time: 0.017, memory: 6002, decode.loss_seg: 1.5537, decode.acc_seg: 41.8040, loss: 1.5537
2021-08-13 13:04:17,224 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-without-head_512x512_160k_ade20k.py
2021-08-13 13:04:17,225 - mmseg - INFO - Iter [5000/160000]	lr: 9.721e-03, eta: 2 days, 10:02:34, time: 1.272, data_time: 0.014, memory: 6002, decode.loss_seg: 1.4930, decode.acc_seg: 43.4681, loss: 1.4930
2021-08-13 13:05:57,045 - mmseg - INFO - Iter [5050/160000]	lr: 9.718e-03, eta: 2 days, 10:18:01, time: 1.996, data_time: 0.739, memory: 6002, decode.loss_seg: 1.5100, decode.acc_seg: 42.7578, loss: 1.5100
2021-08-13 13:07:00,478 - mmseg - INFO - Iter [5100/160000]	lr: 9.716e-03, eta: 2 days, 10:14:43, time: 1.269, data_time: 0.014, memory: 6002, decode.loss_seg: 1.3997, decode.acc_seg: 44.0432, loss: 1.3997
2021-08-13 13:08:06,728 - mmseg - INFO - Iter [5150/160000]	lr: 9.713e-03, eta: 2 days, 10:12:51, time: 1.324, data_time: 0.014, memory: 6002, decode.loss_seg: 1.5046, decode.acc_seg: 42.1563, loss: 1.5046
2021-08-13 13:09:11,243 - mmseg - INFO - Iter [5200/160000]	lr: 9.710e-03, eta: 2 days, 10:10:10, time: 1.291, data_time: 0.015, memory: 6002, decode.loss_seg: 1.4896, decode.acc_seg: 43.7229, loss: 1.4896
2021-08-13 13:10:15,104 - mmseg - INFO - Iter [5250/160000]	lr: 9.707e-03, eta: 2 days, 10:07:10, time: 1.276, data_time: 0.014, memory: 6002, decode.loss_seg: 1.4475, decode.acc_seg: 44.5419, loss: 1.4475
2021-08-13 13:11:24,546 - mmseg - INFO - Iter [5300/160000]	lr: 9.704e-03, eta: 2 days, 10:06:55, time: 1.388, data_time: 0.015, memory: 6002, decode.loss_seg: 1.4988, decode.acc_seg: 43.5614, loss: 1.4988
2021-08-13 13:12:32,480 - mmseg - INFO - Iter [5350/160000]	lr: 9.702e-03, eta: 2 days, 10:05:58, time: 1.360, data_time: 0.015, memory: 6002, decode.loss_seg: 1.5277, decode.acc_seg: 42.8987, loss: 1.5277
2021-08-13 13:13:40,106 - mmseg - INFO - Iter [5400/160000]	lr: 9.699e-03, eta: 2 days, 10:04:49, time: 1.351, data_time: 0.013, memory: 6002, decode.loss_seg: 1.4909, decode.acc_seg: 44.8142, loss: 1.4909
2021-08-13 13:14:44,029 - mmseg - INFO - Iter [5450/160000]	lr: 9.696e-03, eta: 2 days, 10:01:58, time: 1.279, data_time: 0.015, memory: 6002, decode.loss_seg: 1.4446, decode.acc_seg: 44.0117, loss: 1.4446
2021-08-13 13:15:47,697 - mmseg - INFO - Iter [5500/160000]	lr: 9.693e-03, eta: 2 days, 9:59:00, time: 1.273, data_time: 0.013, memory: 6002, decode.loss_seg: 1.4032, decode.acc_seg: 44.4505, loss: 1.4032
2021-08-13 13:16:51,449 - mmseg - INFO - Iter [5550/160000]	lr: 9.690e-03, eta: 2 days, 9:56:06, time: 1.275, data_time: 0.015, memory: 6002, decode.loss_seg: 1.4874, decode.acc_seg: 43.9272, loss: 1.4874
2021-08-13 13:17:56,485 - mmseg - INFO - Iter [5600/160000]	lr: 9.688e-03, eta: 2 days, 9:53:52, time: 1.302, data_time: 0.014, memory: 6002, decode.loss_seg: 1.4187, decode.acc_seg: 43.3859, loss: 1.4187
2021-08-13 13:19:01,963 - mmseg - INFO - Iter [5650/160000]	lr: 9.685e-03, eta: 2 days, 9:51:47, time: 1.308, data_time: 0.014, memory: 6002, decode.loss_seg: 1.4230, decode.acc_seg: 44.0770, loss: 1.4230
2021-08-13 13:20:44,884 - mmseg - INFO - Iter [5700/160000]	lr: 9.682e-03, eta: 2 days, 10:06:39, time: 2.058, data_time: 0.655, memory: 6002, decode.loss_seg: 1.4590, decode.acc_seg: 43.3866, loss: 1.4590
2021-08-13 13:21:51,710 - mmseg - INFO - Iter [5750/160000]	lr: 9.679e-03, eta: 2 days, 10:05:06, time: 1.337, data_time: 0.014, memory: 6002, decode.loss_seg: 1.4421, decode.acc_seg: 42.8475, loss: 1.4421
2021-08-13 13:22:57,637 - mmseg - INFO - Iter [5800/160000]	lr: 9.676e-03, eta: 2 days, 10:03:10, time: 1.320, data_time: 0.014, memory: 6002, decode.loss_seg: 1.4719, decode.acc_seg: 44.1649, loss: 1.4719
2021-08-13 13:24:01,778 - mmseg - INFO - Iter [5850/160000]	lr: 9.674e-03, eta: 2 days, 10:00:26, time: 1.282, data_time: 0.015, memory: 6002, decode.loss_seg: 1.4464, decode.acc_seg: 43.6431, loss: 1.4464
2021-08-13 13:25:06,488 - mmseg - INFO - Iter [5900/160000]	lr: 9.671e-03, eta: 2 days, 9:57:58, time: 1.294, data_time: 0.013, memory: 6002, decode.loss_seg: 1.4501, decode.acc_seg: 43.9855, loss: 1.4501
2021-08-13 13:26:11,168 - mmseg - INFO - Iter [5950/160000]	lr: 9.668e-03, eta: 2 days, 9:55:33, time: 1.294, data_time: 0.015, memory: 6002, decode.loss_seg: 1.4709, decode.acc_seg: 42.5888, loss: 1.4709
2021-08-13 13:27:16,935 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-without-head_512x512_160k_ade20k.py
2021-08-13 13:27:16,936 - mmseg - INFO - Iter [6000/160000]	lr: 9.665e-03, eta: 2 days, 9:53:37, time: 1.316, data_time: 0.013, memory: 6002, decode.loss_seg: 1.3989, decode.acc_seg: 44.0358, loss: 1.3989
2021-08-13 13:28:23,224 - mmseg - INFO - Iter [6050/160000]	lr: 9.663e-03, eta: 2 days, 9:51:53, time: 1.325, data_time: 0.012, memory: 6002, decode.loss_seg: 1.4255, decode.acc_seg: 44.7300, loss: 1.4255
2021-08-13 13:29:27,706 - mmseg - INFO - Iter [6100/160000]	lr: 9.660e-03, eta: 2 days, 9:49:25, time: 1.290, data_time: 0.013, memory: 6002, decode.loss_seg: 1.4488, decode.acc_seg: 43.8050, loss: 1.4488
2021-08-13 13:30:29,879 - mmseg - INFO - Iter [6150/160000]	lr: 9.657e-03, eta: 2 days, 9:46:02, time: 1.244, data_time: 0.013, memory: 6002, decode.loss_seg: 1.4353, decode.acc_seg: 45.9429, loss: 1.4353
2021-08-13 13:31:33,023 - mmseg - INFO - Iter [6200/160000]	lr: 9.654e-03, eta: 2 days, 9:43:04, time: 1.263, data_time: 0.013, memory: 6002, decode.loss_seg: 1.4077, decode.acc_seg: 45.6605, loss: 1.4077
2021-08-13 13:32:34,890 - mmseg - INFO - Iter [6250/160000]	lr: 9.651e-03, eta: 2 days, 9:39:37, time: 1.237, data_time: 0.014, memory: 6002, decode.loss_seg: 1.4443, decode.acc_seg: 44.0076, loss: 1.4443
2021-08-13 13:33:39,410 - mmseg - INFO - Iter [6300/160000]	lr: 9.649e-03, eta: 2 days, 9:37:16, time: 1.290, data_time: 0.013, memory: 6002, decode.loss_seg: 1.4895, decode.acc_seg: 43.8134, loss: 1.4895
2021-08-13 13:35:21,589 - mmseg - INFO - Iter [6350/160000]	lr: 9.646e-03, eta: 2 days, 9:50:09, time: 2.044, data_time: 0.681, memory: 6002, decode.loss_seg: 1.4606, decode.acc_seg: 45.1077, loss: 1.4606
2021-08-13 13:36:26,805 - mmseg - INFO - Iter [6400/160000]	lr: 9.643e-03, eta: 2 days, 9:47:59, time: 1.303, data_time: 0.015, memory: 6002, decode.loss_seg: 1.4032, decode.acc_seg: 45.0530, loss: 1.4032
2021-08-13 13:37:30,970 - mmseg - INFO - Iter [6450/160000]	lr: 9.640e-03, eta: 2 days, 9:45:26, time: 1.284, data_time: 0.017, memory: 6002, decode.loss_seg: 1.4063, decode.acc_seg: 44.0225, loss: 1.4063
2021-08-13 13:38:35,382 - mmseg - INFO - Iter [6500/160000]	lr: 9.637e-03, eta: 2 days, 9:43:01, time: 1.288, data_time: 0.015, memory: 6002, decode.loss_seg: 1.4638, decode.acc_seg: 43.5312, loss: 1.4638
2021-08-13 13:39:39,675 - mmseg - INFO - Iter [6550/160000]	lr: 9.635e-03, eta: 2 days, 9:40:33, time: 1.286, data_time: 0.014, memory: 6002, decode.loss_seg: 1.4199, decode.acc_seg: 43.7642, loss: 1.4199
2021-08-13 13:40:44,322 - mmseg - INFO - Iter [6600/160000]	lr: 9.632e-03, eta: 2 days, 9:38:16, time: 1.293, data_time: 0.016, memory: 6002, decode.loss_seg: 1.3951, decode.acc_seg: 44.7233, loss: 1.3951
2021-08-13 13:41:52,386 - mmseg - INFO - Iter [6650/160000]	lr: 9.629e-03, eta: 2 days, 9:37:18, time: 1.361, data_time: 0.014, memory: 6002, decode.loss_seg: 1.4109, decode.acc_seg: 44.9561, loss: 1.4109
2021-08-13 13:42:58,270 - mmseg - INFO - Iter [6700/160000]	lr: 9.626e-03, eta: 2 days, 9:35:31, time: 1.318, data_time: 0.015, memory: 6002, decode.loss_seg: 1.3832, decode.acc_seg: 46.2042, loss: 1.3832
2021-08-13 13:44:02,728 - mmseg - INFO - Iter [6750/160000]	lr: 9.623e-03, eta: 2 days, 9:33:11, time: 1.289, data_time: 0.016, memory: 6002, decode.loss_seg: 1.3972, decode.acc_seg: 44.5697, loss: 1.3972
2021-08-13 13:45:06,475 - mmseg - INFO - Iter [6800/160000]	lr: 9.621e-03, eta: 2 days, 9:30:37, time: 1.275, data_time: 0.015, memory: 6002, decode.loss_seg: 1.4376, decode.acc_seg: 45.0813, loss: 1.4376
2021-08-13 13:46:11,520 - mmseg - INFO - Iter [6850/160000]	lr: 9.618e-03, eta: 2 days, 9:28:33, time: 1.301, data_time: 0.015, memory: 6002, decode.loss_seg: 1.4350, decode.acc_seg: 44.6994, loss: 1.4350
2021-08-13 13:47:14,659 - mmseg - INFO - Iter [6900/160000]	lr: 9.615e-03, eta: 2 days, 9:25:48, time: 1.263, data_time: 0.014, memory: 6002, decode.loss_seg: 1.4197, decode.acc_seg: 45.7602, loss: 1.4197
2021-08-13 13:48:56,030 - mmseg - INFO - Iter [6950/160000]	lr: 9.612e-03, eta: 2 days, 9:37:06, time: 2.028, data_time: 0.736, memory: 6002, decode.loss_seg: 1.3740, decode.acc_seg: 44.7692, loss: 1.3740
2021-08-13 13:49:59,565 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-without-head_512x512_160k_ade20k.py
2021-08-13 13:49:59,565 - mmseg - INFO - Iter [7000/160000]	lr: 9.609e-03, eta: 2 days, 9:34:26, time: 1.271, data_time: 0.013, memory: 6002, decode.loss_seg: 1.3964, decode.acc_seg: 44.9579, loss: 1.3964
2021-08-13 13:51:03,548 - mmseg - INFO - Iter [7050/160000]	lr: 9.607e-03, eta: 2 days, 9:31:57, time: 1.280, data_time: 0.012, memory: 6002, decode.loss_seg: 1.4164, decode.acc_seg: 45.0452, loss: 1.4164
2021-08-13 13:52:07,272 - mmseg - INFO - Iter [7100/160000]	lr: 9.604e-03, eta: 2 days, 9:29:23, time: 1.274, data_time: 0.012, memory: 6002, decode.loss_seg: 1.4061, decode.acc_seg: 44.2360, loss: 1.4061
2021-08-13 13:53:09,769 - mmseg - INFO - Iter [7150/160000]	lr: 9.601e-03, eta: 2 days, 9:26:25, time: 1.251, data_time: 0.013, memory: 6002, decode.loss_seg: 1.3942, decode.acc_seg: 45.4632, loss: 1.3942
2021-08-13 13:54:13,288 - mmseg - INFO - Iter [7200/160000]	lr: 9.598e-03, eta: 2 days, 9:23:49, time: 1.270, data_time: 0.012, memory: 6002, decode.loss_seg: 1.3368, decode.acc_seg: 45.4063, loss: 1.3368
2021-08-13 13:55:17,259 - mmseg - INFO - Iter [7250/160000]	lr: 9.595e-03, eta: 2 days, 9:21:25, time: 1.279, data_time: 0.013, memory: 6002, decode.loss_seg: 1.3838, decode.acc_seg: 45.7734, loss: 1.3838
2021-08-13 13:56:22,649 - mmseg - INFO - Iter [7300/160000]	lr: 9.593e-03, eta: 2 days, 9:19:32, time: 1.308, data_time: 0.015, memory: 6002, decode.loss_seg: 1.4006, decode.acc_seg: 45.5208, loss: 1.4006
2021-08-13 13:57:25,395 - mmseg - INFO - Iter [7350/160000]	lr: 9.590e-03, eta: 2 days, 9:16:43, time: 1.254, data_time: 0.013, memory: 6002, decode.loss_seg: 1.3853, decode.acc_seg: 45.4874, loss: 1.3853
2021-08-13 13:58:31,064 - mmseg - INFO - Iter [7400/160000]	lr: 9.587e-03, eta: 2 days, 9:14:57, time: 1.313, data_time: 0.013, memory: 6002, decode.loss_seg: 1.3452, decode.acc_seg: 45.6553, loss: 1.3452
2021-08-13 13:59:35,082 - mmseg - INFO - Iter [7450/160000]	lr: 9.584e-03, eta: 2 days, 9:12:38, time: 1.281, data_time: 0.012, memory: 6002, decode.loss_seg: 1.4065, decode.acc_seg: 46.1087, loss: 1.4065
2021-08-13 14:00:37,734 - mmseg - INFO - Iter [7500/160000]	lr: 9.581e-03, eta: 2 days, 9:09:51, time: 1.252, data_time: 0.013, memory: 6002, decode.loss_seg: 1.4471, decode.acc_seg: 44.8934, loss: 1.4471
2021-08-13 14:01:42,908 - mmseg - INFO - Iter [7550/160000]	lr: 9.579e-03, eta: 2 days, 9:07:58, time: 1.304, data_time: 0.014, memory: 6002, decode.loss_seg: 1.3762, decode.acc_seg: 45.7048, loss: 1.3762
2021-08-13 14:03:23,686 - mmseg - INFO - Iter [7600/160000]	lr: 9.576e-03, eta: 2 days, 9:17:58, time: 2.015, data_time: 0.724, memory: 6002, decode.loss_seg: 1.3327, decode.acc_seg: 45.9485, loss: 1.3327
2021-08-13 14:04:30,141 - mmseg - INFO - Iter [7650/160000]	lr: 9.573e-03, eta: 2 days, 9:16:25, time: 1.329, data_time: 0.014, memory: 6002, decode.loss_seg: 1.3652, decode.acc_seg: 45.6311, loss: 1.3652
2021-08-13 14:05:34,155 - mmseg - INFO - Iter [7700/160000]	lr: 9.570e-03, eta: 2 days, 9:14:06, time: 1.281, data_time: 0.013, memory: 6002, decode.loss_seg: 1.3363, decode.acc_seg: 46.8437, loss: 1.3363
2021-08-13 14:06:37,696 - mmseg - INFO - Iter [7750/160000]	lr: 9.567e-03, eta: 2 days, 9:11:37, time: 1.271, data_time: 0.013, memory: 6002, decode.loss_seg: 1.3595, decode.acc_seg: 45.5707, loss: 1.3595
2021-08-13 14:07:41,344 - mmseg - INFO - Iter [7800/160000]	lr: 9.565e-03, eta: 2 days, 9:09:13, time: 1.274, data_time: 0.014, memory: 6002, decode.loss_seg: 1.3934, decode.acc_seg: 44.6485, loss: 1.3934
2021-08-13 14:08:44,030 - mmseg - INFO - Iter [7850/160000]	lr: 9.562e-03, eta: 2 days, 9:06:31, time: 1.254, data_time: 0.013, memory: 6002, decode.loss_seg: 1.3402, decode.acc_seg: 46.0379, loss: 1.3402
2021-08-13 14:09:47,216 - mmseg - INFO - Iter [7900/160000]	lr: 9.559e-03, eta: 2 days, 9:03:58, time: 1.263, data_time: 0.012, memory: 6002, decode.loss_seg: 1.3826, decode.acc_seg: 45.2597, loss: 1.3826
2021-08-13 14:10:50,124 - mmseg - INFO - Iter [7950/160000]	lr: 9.556e-03, eta: 2 days, 9:01:23, time: 1.259, data_time: 0.013, memory: 6002, decode.loss_seg: 1.3589, decode.acc_seg: 46.0952, loss: 1.3589
2021-08-13 14:11:55,404 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-without-head_512x512_160k_ade20k.py
2021-08-13 14:11:55,405 - mmseg - INFO - Iter [8000/160000]	lr: 9.553e-03, eta: 2 days, 8:59:33, time: 1.305, data_time: 0.015, memory: 6002, decode.loss_seg: 1.3707, decode.acc_seg: 45.5750, loss: 1.3707
2021-08-13 14:13:00,076 - mmseg - INFO - Iter [8050/160000]	lr: 9.551e-03, eta: 2 days, 8:57:32, time: 1.294, data_time: 0.014, memory: 6002, decode.loss_seg: 1.3357, decode.acc_seg: 45.9762, loss: 1.3357
2021-08-13 14:14:05,619 - mmseg - INFO - Iter [8100/160000]	lr: 9.548e-03, eta: 2 days, 8:55:48, time: 1.310, data_time: 0.014, memory: 6002, decode.loss_seg: 1.3734, decode.acc_seg: 46.2530, loss: 1.3734
2021-08-13 14:15:11,693 - mmseg - INFO - Iter [8150/160000]	lr: 9.545e-03, eta: 2 days, 8:54:15, time: 1.322, data_time: 0.016, memory: 6002, decode.loss_seg: 1.3752, decode.acc_seg: 46.0440, loss: 1.3752
2021-08-13 14:16:16,865 - mmseg - INFO - Iter [8200/160000]	lr: 9.542e-03, eta: 2 days, 8:52:25, time: 1.303, data_time: 0.013, memory: 6002, decode.loss_seg: 1.3643, decode.acc_seg: 45.1896, loss: 1.3643
2021-08-13 14:17:57,392 - mmseg - INFO - Iter [8250/160000]	lr: 9.539e-03, eta: 2 days, 9:01:26, time: 2.011, data_time: 0.716, memory: 6002, decode.loss_seg: 1.3083, decode.acc_seg: 46.4720, loss: 1.3083
2021-08-13 14:19:05,894 - mmseg - INFO - Iter [8300/160000]	lr: 9.537e-03, eta: 2 days, 9:00:34, time: 1.370, data_time: 0.013, memory: 6002, decode.loss_seg: 1.3702, decode.acc_seg: 45.9892, loss: 1.3702
2021-08-13 14:20:09,678 - mmseg - INFO - Iter [8350/160000]	lr: 9.534e-03, eta: 2 days, 8:58:17, time: 1.276, data_time: 0.014, memory: 6002, decode.loss_seg: 1.3670, decode.acc_seg: 46.4544, loss: 1.3670
2021-08-13 14:21:13,647 - mmseg - INFO - Iter [8400/160000]	lr: 9.531e-03, eta: 2 days, 8:56:04, time: 1.280, data_time: 0.016, memory: 6002, decode.loss_seg: 1.3236, decode.acc_seg: 46.3832, loss: 1.3236
2021-08-13 14:22:20,909 - mmseg - INFO - Iter [8450/160000]	lr: 9.528e-03, eta: 2 days, 8:54:50, time: 1.345, data_time: 0.015, memory: 6002, decode.loss_seg: 1.3335, decode.acc_seg: 46.0690, loss: 1.3335
2021-08-13 14:23:26,036 - mmseg - INFO - Iter [8500/160000]	lr: 9.525e-03, eta: 2 days, 8:52:58, time: 1.302, data_time: 0.014, memory: 6002, decode.loss_seg: 1.3454, decode.acc_seg: 45.7205, loss: 1.3454
2021-08-13 14:24:31,765 - mmseg - INFO - Iter [8550/160000]	lr: 9.523e-03, eta: 2 days, 8:51:17, time: 1.315, data_time: 0.016, memory: 6002, decode.loss_seg: 1.3745, decode.acc_seg: 45.4621, loss: 1.3745
2021-08-13 14:25:35,561 - mmseg - INFO - Iter [8600/160000]	lr: 9.520e-03, eta: 2 days, 8:49:02, time: 1.275, data_time: 0.014, memory: 6002, decode.loss_seg: 1.3407, decode.acc_seg: 46.5361, loss: 1.3407
2021-08-13 14:26:39,662 - mmseg - INFO - Iter [8650/160000]	lr: 9.517e-03, eta: 2 days, 8:46:55, time: 1.283, data_time: 0.016, memory: 6002, decode.loss_seg: 1.3554, decode.acc_seg: 46.3531, loss: 1.3554
2021-08-13 14:27:45,897 - mmseg - INFO - Iter [8700/160000]	lr: 9.514e-03, eta: 2 days, 8:45:26, time: 1.325, data_time: 0.015, memory: 6002, decode.loss_seg: 1.3281, decode.acc_seg: 46.7073, loss: 1.3281
2021-08-13 14:28:48,991 - mmseg - INFO - Iter [8750/160000]	lr: 9.511e-03, eta: 2 days, 8:43:02, time: 1.262, data_time: 0.013, memory: 6002, decode.loss_seg: 1.3274, decode.acc_seg: 46.3000, loss: 1.3274
2021-08-13 14:29:58,605 - mmseg - INFO - Iter [8800/160000]	lr: 9.509e-03, eta: 2 days, 8:42:30, time: 1.392, data_time: 0.014, memory: 6002, decode.loss_seg: 1.3187, decode.acc_seg: 46.3157, loss: 1.3187
2021-08-13 14:31:37,823 - mmseg - INFO - Iter [8850/160000]	lr: 9.506e-03, eta: 2 days, 8:50:23, time: 1.983, data_time: 0.688, memory: 6002, decode.loss_seg: 1.3578, decode.acc_seg: 45.8376, loss: 1.3578
2021-08-13 14:32:43,356 - mmseg - INFO - Iter [8900/160000]	lr: 9.503e-03, eta: 2 days, 8:48:40, time: 1.311, data_time: 0.014, memory: 6002, decode.loss_seg: 1.3071, decode.acc_seg: 46.7470, loss: 1.3071
2021-08-13 14:33:48,707 - mmseg - INFO - Iter [8950/160000]	lr: 9.500e-03, eta: 2 days, 8:46:53, time: 1.307, data_time: 0.013, memory: 6002, decode.loss_seg: 1.3137, decode.acc_seg: 46.6327, loss: 1.3137
2021-08-13 14:34:51,279 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-without-head_512x512_160k_ade20k.py
2021-08-13 14:34:51,280 - mmseg - INFO - Iter [9000/160000]	lr: 9.497e-03, eta: 2 days, 8:44:20, time: 1.251, data_time: 0.014, memory: 6002, decode.loss_seg: 1.3480, decode.acc_seg: 46.0883, loss: 1.3480
2021-08-13 14:35:53,992 - mmseg - INFO - Iter [9050/160000]	lr: 9.495e-03, eta: 2 days, 8:41:50, time: 1.255, data_time: 0.015, memory: 6002, decode.loss_seg: 1.3209, decode.acc_seg: 46.7209, loss: 1.3209
2021-08-13 14:36:58,409 - mmseg - INFO - Iter [9100/160000]	lr: 9.492e-03, eta: 2 days, 8:39:50, time: 1.289, data_time: 0.015, memory: 6002, decode.loss_seg: 1.3033, decode.acc_seg: 46.5126, loss: 1.3033
2021-08-13 14:38:01,848 - mmseg - INFO - Iter [9150/160000]	lr: 9.489e-03, eta: 2 days, 8:37:34, time: 1.269, data_time: 0.014, memory: 6002, decode.loss_seg: 1.3436, decode.acc_seg: 46.8393, loss: 1.3436
2021-08-13 14:39:06,764 - mmseg - INFO - Iter [9200/160000]	lr: 9.486e-03, eta: 2 days, 8:35:42, time: 1.298, data_time: 0.015, memory: 6002, decode.loss_seg: 1.3391, decode.acc_seg: 45.8689, loss: 1.3391
2021-08-13 14:40:11,270 - mmseg - INFO - Iter [9250/160000]	lr: 9.483e-03, eta: 2 days, 8:33:45, time: 1.291, data_time: 0.015, memory: 6002, decode.loss_seg: 1.2759, decode.acc_seg: 46.5974, loss: 1.2759
2021-08-13 14:41:14,189 - mmseg - INFO - Iter [9300/160000]	lr: 9.481e-03, eta: 2 days, 8:31:22, time: 1.258, data_time: 0.013, memory: 6002, decode.loss_seg: 1.3207, decode.acc_seg: 46.4777, loss: 1.3207
2021-08-13 14:42:18,294 - mmseg - INFO - Iter [9350/160000]	lr: 9.478e-03, eta: 2 days, 8:29:20, time: 1.282, data_time: 0.015, memory: 6002, decode.loss_seg: 1.3738, decode.acc_seg: 46.5082, loss: 1.3738
2021-08-13 14:43:21,633 - mmseg - INFO - Iter [9400/160000]	lr: 9.475e-03, eta: 2 days, 8:27:06, time: 1.267, data_time: 0.016, memory: 6002, decode.loss_seg: 1.3081, decode.acc_seg: 46.5103, loss: 1.3081
2021-08-13 14:44:26,672 - mmseg - INFO - Iter [9450/160000]	lr: 9.472e-03, eta: 2 days, 8:25:20, time: 1.301, data_time: 0.016, memory: 6002, decode.loss_seg: 1.3459, decode.acc_seg: 45.3870, loss: 1.3459
2021-08-13 14:46:05,089 - mmseg - INFO - Iter [9500/160000]	lr: 9.469e-03, eta: 2 days, 8:32:23, time: 1.969, data_time: 0.665, memory: 6002, decode.loss_seg: 1.2621, decode.acc_seg: 48.5542, loss: 1.2621
2021-08-13 14:47:09,695 - mmseg - INFO - Iter [9550/160000]	lr: 9.467e-03, eta: 2 days, 8:30:28, time: 1.292, data_time: 0.015, memory: 6002, decode.loss_seg: 1.3133, decode.acc_seg: 46.1915, loss: 1.3133
2021-08-13 14:48:13,088 - mmseg - INFO - Iter [9600/160000]	lr: 9.464e-03, eta: 2 days, 8:28:14, time: 1.268, data_time: 0.013, memory: 6002, decode.loss_seg: 1.3344, decode.acc_seg: 46.6183, loss: 1.3344
2021-08-13 14:49:20,117 - mmseg - INFO - Iter [9650/160000]	lr: 9.461e-03, eta: 2 days, 8:26:58, time: 1.340, data_time: 0.015, memory: 6002, decode.loss_seg: 1.3330, decode.acc_seg: 46.6206, loss: 1.3330
2021-08-13 14:50:24,576 - mmseg - INFO - Iter [9700/160000]	lr: 9.458e-03, eta: 2 days, 8:25:02, time: 1.289, data_time: 0.013, memory: 6002, decode.loss_seg: 1.3057, decode.acc_seg: 46.5182, loss: 1.3057
2021-08-13 14:51:28,922 - mmseg - INFO - Iter [9750/160000]	lr: 9.455e-03, eta: 2 days, 8:23:05, time: 1.287, data_time: 0.015, memory: 6002, decode.loss_seg: 1.2592, decode.acc_seg: 48.7231, loss: 1.2592
2021-08-13 14:52:35,664 - mmseg - INFO - Iter [9800/160000]	lr: 9.453e-03, eta: 2 days, 8:21:45, time: 1.335, data_time: 0.015, memory: 6002, decode.loss_seg: 1.3054, decode.acc_seg: 46.9541, loss: 1.3054
2021-08-13 14:53:44,014 - mmseg - INFO - Iter [9850/160000]	lr: 9.450e-03, eta: 2 days, 8:20:50, time: 1.367, data_time: 0.016, memory: 6002, decode.loss_seg: 1.2927, decode.acc_seg: 47.3793, loss: 1.2927
2021-08-13 14:54:48,764 - mmseg - INFO - Iter [9900/160000]	lr: 9.447e-03, eta: 2 days, 8:19:00, time: 1.295, data_time: 0.014, memory: 6002, decode.loss_seg: 1.3009, decode.acc_seg: 48.4201, loss: 1.3009
2021-08-13 14:55:55,276 - mmseg - INFO - Iter [9950/160000]	lr: 9.444e-03, eta: 2 days, 8:17:37, time: 1.331, data_time: 0.016, memory: 6002, decode.loss_seg: 1.2878, decode.acc_seg: 46.2686, loss: 1.2878
2021-08-13 14:56:59,493 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-without-head_512x512_160k_ade20k.py
2021-08-13 14:56:59,493 - mmseg - INFO - Iter [10000/160000]	lr: 9.441e-03, eta: 2 days, 8:15:39, time: 1.283, data_time: 0.014, memory: 6002, decode.loss_seg: 1.3116, decode.acc_seg: 47.2853, loss: 1.3116
2021-08-13 14:58:03,714 - mmseg - INFO - Iter [10050/160000]	lr: 9.439e-03, eta: 2 days, 8:13:43, time: 1.285, data_time: 0.016, memory: 6002, decode.loss_seg: 1.2907, decode.acc_seg: 47.3344, loss: 1.2907
2021-08-13 14:59:42,491 - mmseg - INFO - Iter [10100/160000]	lr: 9.436e-03, eta: 2 days, 8:20:19, time: 1.975, data_time: 0.702, memory: 6002, decode.loss_seg: 1.3157, decode.acc_seg: 46.6829, loss: 1.3157
2021-08-13 15:00:48,599 - mmseg - INFO - Iter [10150/160000]	lr: 9.433e-03, eta: 2 days, 8:18:48, time: 1.322, data_time: 0.013, memory: 6002, decode.loss_seg: 1.2488, decode.acc_seg: 48.1745, loss: 1.2488
2021-08-13 15:01:52,290 - mmseg - INFO - Iter [10200/160000]	lr: 9.430e-03, eta: 2 days, 8:16:43, time: 1.274, data_time: 0.013, memory: 6002, decode.loss_seg: 1.2529, decode.acc_seg: 48.7554, loss: 1.2529
2021-08-13 15:02:57,130 - mmseg - INFO - Iter [10250/160000]	lr: 9.427e-03, eta: 2 days, 8:14:55, time: 1.297, data_time: 0.014, memory: 6002, decode.loss_seg: 1.2980, decode.acc_seg: 47.3478, loss: 1.2980
2021-08-13 15:03:59,751 - mmseg - INFO - Iter [10300/160000]	lr: 9.425e-03, eta: 2 days, 8:12:35, time: 1.253, data_time: 0.013, memory: 6002, decode.loss_seg: 1.2776, decode.acc_seg: 47.4105, loss: 1.2776
2021-08-13 15:05:02,491 - mmseg - INFO - Iter [10350/160000]	lr: 9.422e-03, eta: 2 days, 8:10:17, time: 1.255, data_time: 0.013, memory: 6002, decode.loss_seg: 1.3089, decode.acc_seg: 46.8440, loss: 1.3089
2021-08-13 15:06:05,924 - mmseg - INFO - Iter [10400/160000]	lr: 9.419e-03, eta: 2 days, 8:08:10, time: 1.268, data_time: 0.014, memory: 6002, decode.loss_seg: 1.2928, decode.acc_seg: 47.4491, loss: 1.2928
2021-08-13 15:07:09,854 - mmseg - INFO - Iter [10450/160000]	lr: 9.416e-03, eta: 2 days, 8:06:11, time: 1.279, data_time: 0.014, memory: 6002, decode.loss_seg: 1.3129, decode.acc_seg: 46.7413, loss: 1.3129
2021-08-13 15:08:14,358 - mmseg - INFO - Iter [10500/160000]	lr: 9.413e-03, eta: 2 days, 8:04:21, time: 1.291, data_time: 0.012, memory: 6002, decode.loss_seg: 1.2816, decode.acc_seg: 47.0430, loss: 1.2816
2021-08-13 15:09:18,239 - mmseg - INFO - Iter [10550/160000]	lr: 9.411e-03, eta: 2 days, 8:02:21, time: 1.277, data_time: 0.014, memory: 6002, decode.loss_seg: 1.2902, decode.acc_seg: 46.7808, loss: 1.2902
2021-08-13 15:10:22,803 - mmseg - INFO - Iter [10600/160000]	lr: 9.408e-03, eta: 2 days, 8:00:32, time: 1.291, data_time: 0.014, memory: 6002, decode.loss_seg: 1.2596, decode.acc_seg: 48.8545, loss: 1.2596
2021-08-13 15:11:29,129 - mmseg - INFO - Iter [10650/160000]	lr: 9.405e-03, eta: 2 days, 7:59:08, time: 1.326, data_time: 0.014, memory: 6002, decode.loss_seg: 1.2533, decode.acc_seg: 47.5721, loss: 1.2533
2021-08-13 15:12:33,539 - mmseg - INFO - Iter [10700/160000]	lr: 9.402e-03, eta: 2 days, 7:57:19, time: 1.289, data_time: 0.013, memory: 6002, decode.loss_seg: 1.3201, decode.acc_seg: 46.9341, loss: 1.3201
2021-08-13 15:14:12,805 - mmseg - INFO - Iter [10750/160000]	lr: 9.399e-03, eta: 2 days, 8:03:32, time: 1.985, data_time: 0.726, memory: 6002, decode.loss_seg: 1.2825, decode.acc_seg: 46.8419, loss: 1.2825
2021-08-13 15:15:18,024 - mmseg - INFO - Iter [10800/160000]	lr: 9.397e-03, eta: 2 days, 8:01:52, time: 1.304, data_time: 0.016, memory: 6002, decode.loss_seg: 1.2438, decode.acc_seg: 47.7695, loss: 1.2438
2021-08-13 15:16:23,011 - mmseg - INFO - Iter [10850/160000]	lr: 9.394e-03, eta: 2 days, 8:00:08, time: 1.300, data_time: 0.013, memory: 6002, decode.loss_seg: 1.2858, decode.acc_seg: 47.6651, loss: 1.2858
2021-08-13 15:17:27,619 - mmseg - INFO - Iter [10900/160000]	lr: 9.391e-03, eta: 2 days, 7:58:20, time: 1.293, data_time: 0.015, memory: 6002, decode.loss_seg: 1.2890, decode.acc_seg: 47.7374, loss: 1.2890
2021-08-13 15:18:33,223 - mmseg - INFO - Iter [10950/160000]	lr: 9.388e-03, eta: 2 days, 7:56:45, time: 1.311, data_time: 0.013, memory: 6002, decode.loss_seg: 1.2567, decode.acc_seg: 46.6296, loss: 1.2567
2021-08-13 15:19:38,492 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-without-head_512x512_160k_ade20k.py
2021-08-13 15:19:38,493 - mmseg - INFO - Iter [11000/160000]	lr: 9.385e-03, eta: 2 days, 7:55:07, time: 1.305, data_time: 0.014, memory: 6002, decode.loss_seg: 1.2878, decode.acc_seg: 48.0465, loss: 1.2878
2021-08-13 15:20:44,190 - mmseg - INFO - Iter [11050/160000]	lr: 9.383e-03, eta: 2 days, 7:53:35, time: 1.315, data_time: 0.015, memory: 6002, decode.loss_seg: 1.2833, decode.acc_seg: 47.4400, loss: 1.2833
2021-08-13 15:21:49,260 - mmseg - INFO - Iter [11100/160000]	lr: 9.380e-03, eta: 2 days, 7:51:54, time: 1.301, data_time: 0.014, memory: 6002, decode.loss_seg: 1.2762, decode.acc_seg: 47.1379, loss: 1.2762
2021-08-13 15:22:52,164 - mmseg - INFO - Iter [11150/160000]	lr: 9.377e-03, eta: 2 days, 7:49:45, time: 1.258, data_time: 0.015, memory: 6002, decode.loss_seg: 1.2995, decode.acc_seg: 46.6177, loss: 1.2995
2021-08-13 15:23:57,634 - mmseg - INFO - Iter [11200/160000]	lr: 9.374e-03, eta: 2 days, 7:48:10, time: 1.309, data_time: 0.013, memory: 6002, decode.loss_seg: 1.2441, decode.acc_seg: 48.4004, loss: 1.2441
2021-08-13 15:25:01,856 - mmseg - INFO - Iter [11250/160000]	lr: 9.371e-03, eta: 2 days, 7:46:19, time: 1.285, data_time: 0.014, memory: 6002, decode.loss_seg: 1.2838, decode.acc_seg: 47.0036, loss: 1.2838
2021-08-13 15:26:04,372 - mmseg - INFO - Iter [11300/160000]	lr: 9.369e-03, eta: 2 days, 7:44:06, time: 1.249, data_time: 0.013, memory: 6002, decode.loss_seg: 1.2963, decode.acc_seg: 47.4794, loss: 1.2963
2021-08-13 15:27:07,298 - mmseg - INFO - Iter [11350/160000]	lr: 9.366e-03, eta: 2 days, 7:41:59, time: 1.260, data_time: 0.014, memory: 6002, decode.loss_seg: 1.2492, decode.acc_seg: 48.4582, loss: 1.2492
2021-08-13 15:28:46,152 - mmseg - INFO - Iter [11400/160000]	lr: 9.363e-03, eta: 2 days, 7:47:41, time: 1.977, data_time: 0.697, memory: 6002, decode.loss_seg: 1.2493, decode.acc_seg: 47.6627, loss: 1.2493
2021-08-13 15:29:49,236 - mmseg - INFO - Iter [11450/160000]	lr: 9.360e-03, eta: 2 days, 7:45:35, time: 1.261, data_time: 0.013, memory: 6002, decode.loss_seg: 1.3050, decode.acc_seg: 47.7632, loss: 1.3050
2021-08-13 15:30:53,804 - mmseg - INFO - Iter [11500/160000]	lr: 9.357e-03, eta: 2 days, 7:43:49, time: 1.292, data_time: 0.013, memory: 6002, decode.loss_seg: 1.2856, decode.acc_seg: 47.1879, loss: 1.2856
2021-08-13 15:31:59,163 - mmseg - INFO - Iter [11550/160000]	lr: 9.354e-03, eta: 2 days, 7:42:13, time: 1.307, data_time: 0.014, memory: 6002, decode.loss_seg: 1.2751, decode.acc_seg: 48.5028, loss: 1.2751
2021-08-13 15:33:01,640 - mmseg - INFO - Iter [11600/160000]	lr: 9.352e-03, eta: 2 days, 7:40:01, time: 1.249, data_time: 0.013, memory: 6002, decode.loss_seg: 1.2603, decode.acc_seg: 47.6543, loss: 1.2603
2021-08-13 15:34:04,214 - mmseg - INFO - Iter [11650/160000]	lr: 9.349e-03, eta: 2 days, 7:37:50, time: 1.251, data_time: 0.013, memory: 6002, decode.loss_seg: 1.2740, decode.acc_seg: 48.1715, loss: 1.2740
2021-08-13 15:35:10,034 - mmseg - INFO - Iter [11700/160000]	lr: 9.346e-03, eta: 2 days, 7:36:21, time: 1.316, data_time: 0.015, memory: 6002, decode.loss_seg: 1.2358, decode.acc_seg: 48.9243, loss: 1.2358
2021-08-13 15:36:17,685 - mmseg - INFO - Iter [11750/160000]	lr: 9.343e-03, eta: 2 days, 7:35:16, time: 1.354, data_time: 0.016, memory: 6002, decode.loss_seg: 1.2381, decode.acc_seg: 48.4717, loss: 1.2381
2021-08-13 15:37:23,234 - mmseg - INFO - Iter [11800/160000]	lr: 9.340e-03, eta: 2 days, 7:33:44, time: 1.310, data_time: 0.013, memory: 6002, decode.loss_seg: 1.2784, decode.acc_seg: 47.9016, loss: 1.2784
2021-08-13 15:38:31,977 - mmseg - INFO - Iter [11850/160000]	lr: 9.338e-03, eta: 2 days, 7:32:52, time: 1.375, data_time: 0.014, memory: 6002, decode.loss_seg: 1.2793, decode.acc_seg: 47.2531, loss: 1.2793
2021-08-13 15:39:36,742 - mmseg - INFO - Iter [11900/160000]	lr: 9.335e-03, eta: 2 days, 7:31:11, time: 1.295, data_time: 0.014, memory: 6002, decode.loss_seg: 1.2409, decode.acc_seg: 47.2514, loss: 1.2409
2021-08-13 15:40:40,041 - mmseg - INFO - Iter [11950/160000]	lr: 9.332e-03, eta: 2 days, 7:29:11, time: 1.266, data_time: 0.015, memory: 6002, decode.loss_seg: 1.2600, decode.acc_seg: 48.6287, loss: 1.2600
2021-08-13 15:42:18,527 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-without-head_512x512_160k_ade20k.py
2021-08-13 15:42:18,531 - mmseg - INFO - Iter [12000/160000]	lr: 9.329e-03, eta: 2 days, 7:34:27, time: 1.970, data_time: 0.736, memory: 6002, decode.loss_seg: 1.2639, decode.acc_seg: 47.8787, loss: 1.2639
2021-08-13 15:43:23,210 - mmseg - INFO - Iter [12050/160000]	lr: 9.326e-03, eta: 2 days, 7:32:43, time: 1.293, data_time: 0.013, memory: 6002, decode.loss_seg: 1.2510, decode.acc_seg: 47.9591, loss: 1.2510
2021-08-13 15:44:27,078 - mmseg - INFO - Iter [12100/160000]	lr: 9.324e-03, eta: 2 days, 7:30:51, time: 1.278, data_time: 0.013, memory: 6002, decode.loss_seg: 1.2415, decode.acc_seg: 48.5530, loss: 1.2415
2021-08-13 15:45:31,814 - mmseg - INFO - Iter [12150/160000]	lr: 9.321e-03, eta: 2 days, 7:29:08, time: 1.294, data_time: 0.012, memory: 6002, decode.loss_seg: 1.2528, decode.acc_seg: 48.1902, loss: 1.2528
2021-08-13 15:46:34,951 - mmseg - INFO - Iter [12200/160000]	lr: 9.318e-03, eta: 2 days, 7:27:07, time: 1.263, data_time: 0.014, memory: 6002, decode.loss_seg: 1.2702, decode.acc_seg: 47.3539, loss: 1.2702
2021-08-13 15:47:38,019 - mmseg - INFO - Iter [12250/160000]	lr: 9.315e-03, eta: 2 days, 7:25:06, time: 1.262, data_time: 0.014, memory: 6002, decode.loss_seg: 1.2404, decode.acc_seg: 49.1780, loss: 1.2404
2021-08-13 15:48:42,093 - mmseg - INFO - Iter [12300/160000]	lr: 9.312e-03, eta: 2 days, 7:23:18, time: 1.282, data_time: 0.013, memory: 6002, decode.loss_seg: 1.2394, decode.acc_seg: 48.5601, loss: 1.2394
2021-08-13 15:49:45,457 - mmseg - INFO - Iter [12350/160000]	lr: 9.310e-03, eta: 2 days, 7:21:20, time: 1.267, data_time: 0.012, memory: 6002, decode.loss_seg: 1.2340, decode.acc_seg: 48.5585, loss: 1.2340
2021-08-13 15:50:47,749 - mmseg - INFO - Iter [12400/160000]	lr: 9.307e-03, eta: 2 days, 7:19:11, time: 1.245, data_time: 0.012, memory: 6002, decode.loss_seg: 1.2287, decode.acc_seg: 47.9964, loss: 1.2287
2021-08-13 15:51:52,502 - mmseg - INFO - Iter [12450/160000]	lr: 9.304e-03, eta: 2 days, 7:17:31, time: 1.295, data_time: 0.014, memory: 6002, decode.loss_seg: 1.2595, decode.acc_seg: 47.9688, loss: 1.2595
2021-08-13 15:52:55,989 - mmseg - INFO - Iter [12500/160000]	lr: 9.301e-03, eta: 2 days, 7:15:37, time: 1.270, data_time: 0.013, memory: 6002, decode.loss_seg: 1.2523, decode.acc_seg: 49.0675, loss: 1.2523
2021-08-13 15:54:00,143 - mmseg - INFO - Iter [12550/160000]	lr: 9.298e-03, eta: 2 days, 7:13:51, time: 1.283, data_time: 0.014, memory: 6002, decode.loss_seg: 1.2506, decode.acc_seg: 47.6277, loss: 1.2506
2021-08-13 15:55:03,036 - mmseg - INFO - Iter [12600/160000]	lr: 9.296e-03, eta: 2 days, 7:11:50, time: 1.257, data_time: 0.012, memory: 6002, decode.loss_seg: 1.2333, decode.acc_seg: 48.7167, loss: 1.2333
2021-08-13 15:56:43,287 - mmseg - INFO - Iter [12650/160000]	lr: 9.293e-03, eta: 2 days, 7:17:06, time: 2.006, data_time: 0.722, memory: 6002, decode.loss_seg: 1.2179, decode.acc_seg: 48.5547, loss: 1.2179
2021-08-13 15:57:47,431 - mmseg - INFO - Iter [12700/160000]	lr: 9.290e-03, eta: 2 days, 7:15:19, time: 1.282, data_time: 0.012, memory: 6002, decode.loss_seg: 1.2098, decode.acc_seg: 48.9267, loss: 1.2098
2021-08-13 15:58:52,568 - mmseg - INFO - Iter [12750/160000]	lr: 9.287e-03, eta: 2 days, 7:13:44, time: 1.303, data_time: 0.012, memory: 6002, decode.loss_seg: 1.2043, decode.acc_seg: 49.2367, loss: 1.2043
2021-08-13 15:59:59,248 - mmseg - INFO - Iter [12800/160000]	lr: 9.284e-03, eta: 2 days, 7:12:26, time: 1.333, data_time: 0.013, memory: 6002, decode.loss_seg: 1.2273, decode.acc_seg: 48.8336, loss: 1.2273
2021-08-13 16:01:06,668 - mmseg - INFO - Iter [12850/160000]	lr: 9.282e-03, eta: 2 days, 7:11:18, time: 1.348, data_time: 0.014, memory: 6002, decode.loss_seg: 1.2162, decode.acc_seg: 48.6989, loss: 1.2162
2021-08-13 16:02:13,837 - mmseg - INFO - Iter [12900/160000]	lr: 9.279e-03, eta: 2 days, 7:10:06, time: 1.343, data_time: 0.013, memory: 6002, decode.loss_seg: 1.2144, decode.acc_seg: 48.3138, loss: 1.2144
2021-08-13 16:03:20,639 - mmseg - INFO - Iter [12950/160000]	lr: 9.276e-03, eta: 2 days, 7:08:51, time: 1.337, data_time: 0.014, memory: 6002, decode.loss_seg: 1.2331, decode.acc_seg: 49.1017, loss: 1.2331
2021-08-13 16:04:24,728 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-without-head_512x512_160k_ade20k.py
2021-08-13 16:04:24,728 - mmseg - INFO - Iter [13000/160000]	lr: 9.273e-03, eta: 2 days, 7:07:05, time: 1.282, data_time: 0.013, memory: 6002, decode.loss_seg: 1.2381, decode.acc_seg: 49.3727, loss: 1.2381
2021-08-13 16:05:27,320 - mmseg - INFO - Iter [13050/160000]	lr: 9.270e-03, eta: 2 days, 7:05:02, time: 1.251, data_time: 0.012, memory: 6002, decode.loss_seg: 1.2363, decode.acc_seg: 48.8409, loss: 1.2363
2021-08-13 16:06:31,006 - mmseg - INFO - Iter [13100/160000]	lr: 9.267e-03, eta: 2 days, 7:03:13, time: 1.274, data_time: 0.013, memory: 6002, decode.loss_seg: 1.1992, decode.acc_seg: 47.7609, loss: 1.1992
2021-08-13 16:07:33,635 - mmseg - INFO - Iter [13150/160000]	lr: 9.265e-03, eta: 2 days, 7:01:11, time: 1.252, data_time: 0.013, memory: 6002, decode.loss_seg: 1.2661, decode.acc_seg: 47.3827, loss: 1.2661
2021-08-13 16:08:35,580 - mmseg - INFO - Iter [13200/160000]	lr: 9.262e-03, eta: 2 days, 6:59:03, time: 1.240, data_time: 0.013, memory: 6002, decode.loss_seg: 1.2251, decode.acc_seg: 48.7492, loss: 1.2251
2021-08-13 16:09:39,474 - mmseg - INFO - Iter [13250/160000]	lr: 9.259e-03, eta: 2 days, 6:57:16, time: 1.278, data_time: 0.014, memory: 6002, decode.loss_seg: 1.2424, decode.acc_seg: 47.9032, loss: 1.2424
2021-08-13 16:11:20,735 - mmseg - INFO - Iter [13300/160000]	lr: 9.256e-03, eta: 2 days, 7:02:22, time: 2.025, data_time: 0.728, memory: 6002, decode.loss_seg: 1.2228, decode.acc_seg: 48.2383, loss: 1.2228
2021-08-13 16:12:23,765 - mmseg - INFO - Iter [13350/160000]	lr: 9.253e-03, eta: 2 days, 7:00:25, time: 1.260, data_time: 0.013, memory: 6002, decode.loss_seg: 1.1975, decode.acc_seg: 48.8741, loss: 1.1975
2021-08-13 16:13:27,678 - mmseg - INFO - Iter [13400/160000]	lr: 9.251e-03, eta: 2 days, 6:58:38, time: 1.279, data_time: 0.014, memory: 6002, decode.loss_seg: 1.1894, decode.acc_seg: 49.7217, loss: 1.1894
2021-08-13 16:14:31,065 - mmseg - INFO - Iter [13450/160000]	lr: 9.248e-03, eta: 2 days, 6:56:46, time: 1.268, data_time: 0.014, memory: 6002, decode.loss_seg: 1.2469, decode.acc_seg: 48.4159, loss: 1.2469
2021-08-13 16:15:35,750 - mmseg - INFO - Iter [13500/160000]	lr: 9.245e-03, eta: 2 days, 6:55:08, time: 1.295, data_time: 0.015, memory: 6002, decode.loss_seg: 1.2365, decode.acc_seg: 48.2198, loss: 1.2365
2021-08-13 16:16:40,572 - mmseg - INFO - Iter [13550/160000]	lr: 9.242e-03, eta: 2 days, 6:53:32, time: 1.296, data_time: 0.015, memory: 6002, decode.loss_seg: 1.1835, decode.acc_seg: 48.7752, loss: 1.1835
2021-08-13 16:17:44,825 - mmseg - INFO - Iter [13600/160000]	lr: 9.239e-03, eta: 2 days, 6:51:50, time: 1.284, data_time: 0.013, memory: 6002, decode.loss_seg: 1.2378, decode.acc_seg: 49.3164, loss: 1.2378
2021-08-13 16:18:48,060 - mmseg - INFO - Iter [13650/160000]	lr: 9.237e-03, eta: 2 days, 6:49:57, time: 1.265, data_time: 0.013, memory: 6002, decode.loss_seg: 1.1967, decode.acc_seg: 49.6131, loss: 1.1967
2021-08-13 16:19:51,601 - mmseg - INFO - Iter [13700/160000]	lr: 9.234e-03, eta: 2 days, 6:48:08, time: 1.271, data_time: 0.014, memory: 6002, decode.loss_seg: 1.2553, decode.acc_seg: 48.6383, loss: 1.2553
2021-08-13 16:20:54,144 - mmseg - INFO - Iter [13750/160000]	lr: 9.231e-03, eta: 2 days, 6:46:09, time: 1.250, data_time: 0.012, memory: 6002, decode.loss_seg: 1.2332, decode.acc_seg: 48.8419, loss: 1.2332
2021-08-13 16:21:57,448 - mmseg - INFO - Iter [13800/160000]	lr: 9.228e-03, eta: 2 days, 6:44:18, time: 1.266, data_time: 0.013, memory: 6002, decode.loss_seg: 1.2058, decode.acc_seg: 49.1083, loss: 1.2058
2021-08-13 16:23:02,892 - mmseg - INFO - Iter [13850/160000]	lr: 9.225e-03, eta: 2 days, 6:42:50, time: 1.310, data_time: 0.016, memory: 6002, decode.loss_seg: 1.2452, decode.acc_seg: 48.0972, loss: 1.2452
2021-08-13 16:24:42,797 - mmseg - INFO - Iter [13900/160000]	lr: 9.223e-03, eta: 2 days, 6:47:24, time: 1.997, data_time: 0.728, memory: 6002, decode.loss_seg: 1.2329, decode.acc_seg: 48.4752, loss: 1.2329
2021-08-13 16:25:48,850 - mmseg - INFO - Iter [13950/160000]	lr: 9.220e-03, eta: 2 days, 6:46:01, time: 1.321, data_time: 0.013, memory: 6002, decode.loss_seg: 1.2180, decode.acc_seg: 48.2018, loss: 1.2180
2021-08-13 16:26:53,586 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-without-head_512x512_160k_ade20k.py
2021-08-13 16:26:53,587 - mmseg - INFO - Iter [14000/160000]	lr: 9.217e-03, eta: 2 days, 6:44:25, time: 1.296, data_time: 0.014, memory: 6002, decode.loss_seg: 1.2347, decode.acc_seg: 49.1531, loss: 1.2347
2021-08-13 16:27:56,646 - mmseg - INFO - Iter [14050/160000]	lr: 9.214e-03, eta: 2 days, 6:42:32, time: 1.261, data_time: 0.013, memory: 6002, decode.loss_seg: 1.1727, decode.acc_seg: 49.1801, loss: 1.1727
2021-08-13 16:28:59,640 - mmseg - INFO - Iter [14100/160000]	lr: 9.211e-03, eta: 2 days, 6:40:38, time: 1.260, data_time: 0.013, memory: 6002, decode.loss_seg: 1.2304, decode.acc_seg: 47.9667, loss: 1.2304
2021-08-13 16:30:01,826 - mmseg - INFO - Iter [14150/160000]	lr: 9.208e-03, eta: 2 days, 6:38:36, time: 1.244, data_time: 0.013, memory: 6002, decode.loss_seg: 1.2242, decode.acc_seg: 48.2583, loss: 1.2242
2021-08-13 16:31:06,971 - mmseg - INFO - Iter [14200/160000]	lr: 9.206e-03, eta: 2 days, 6:37:05, time: 1.303, data_time: 0.015, memory: 6002, decode.loss_seg: 1.1998, decode.acc_seg: 49.6799, loss: 1.1998
2021-08-13 16:32:10,466 - mmseg - INFO - Iter [14250/160000]	lr: 9.203e-03, eta: 2 days, 6:35:17, time: 1.270, data_time: 0.016, memory: 6002, decode.loss_seg: 1.2091, decode.acc_seg: 49.1380, loss: 1.2091
2021-08-13 16:33:15,300 - mmseg - INFO - Iter [14300/160000]	lr: 9.200e-03, eta: 2 days, 6:33:44, time: 1.296, data_time: 0.012, memory: 6002, decode.loss_seg: 1.2105, decode.acc_seg: 48.0909, loss: 1.2105
2021-08-13 16:34:19,058 - mmseg - INFO - Iter [14350/160000]	lr: 9.197e-03, eta: 2 days, 6:31:59, time: 1.275, data_time: 0.013, memory: 6002, decode.loss_seg: 1.1840, decode.acc_seg: 49.8357, loss: 1.1840
2021-08-13 16:35:24,983 - mmseg - INFO - Iter [14400/160000]	lr: 9.194e-03, eta: 2 days, 6:30:37, time: 1.319, data_time: 0.014, memory: 6002, decode.loss_seg: 1.2211, decode.acc_seg: 49.4553, loss: 1.2211
2021-08-13 16:36:28,313 - mmseg - INFO - Iter [14450/160000]	lr: 9.192e-03, eta: 2 days, 6:28:48, time: 1.265, data_time: 0.012, memory: 6002, decode.loss_seg: 1.2037, decode.acc_seg: 49.2092, loss: 1.2037
2021-08-13 16:37:31,409 - mmseg - INFO - Iter [14500/160000]	lr: 9.189e-03, eta: 2 days, 6:26:58, time: 1.263, data_time: 0.014, memory: 6002, decode.loss_seg: 1.1679, decode.acc_seg: 50.7018, loss: 1.1679
2021-08-13 16:39:08,810 - mmseg - INFO - Iter [14550/160000]	lr: 9.186e-03, eta: 2 days, 6:30:51, time: 1.947, data_time: 0.689, memory: 6002, decode.loss_seg: 1.2324, decode.acc_seg: 47.9064, loss: 1.2324
2021-08-13 16:40:13,319 - mmseg - INFO - Iter [14600/160000]	lr: 9.183e-03, eta: 2 days, 6:29:14, time: 1.290, data_time: 0.013, memory: 6002, decode.loss_seg: 1.2113, decode.acc_seg: 48.8967, loss: 1.2113
2021-08-13 16:41:18,024 - mmseg - INFO - Iter [14650/160000]	lr: 9.180e-03, eta: 2 days, 6:27:39, time: 1.294, data_time: 0.013, memory: 6002, decode.loss_seg: 1.2074, decode.acc_seg: 48.9009, loss: 1.2074
2021-08-13 16:42:21,460 - mmseg - INFO - Iter [14700/160000]	lr: 9.178e-03, eta: 2 days, 6:25:52, time: 1.269, data_time: 0.013, memory: 6002, decode.loss_seg: 1.1937, decode.acc_seg: 48.7796, loss: 1.1937
2021-08-13 16:43:26,034 - mmseg - INFO - Iter [14750/160000]	lr: 9.175e-03, eta: 2 days, 6:24:17, time: 1.293, data_time: 0.017, memory: 6002, decode.loss_seg: 1.1823, decode.acc_seg: 48.9848, loss: 1.1823
2021-08-13 16:44:30,480 - mmseg - INFO - Iter [14800/160000]	lr: 9.172e-03, eta: 2 days, 6:22:40, time: 1.288, data_time: 0.012, memory: 6002, decode.loss_seg: 1.2352, decode.acc_seg: 49.2240, loss: 1.2352
2021-08-13 16:45:37,025 - mmseg - INFO - Iter [14850/160000]	lr: 9.169e-03, eta: 2 days, 6:21:25, time: 1.332, data_time: 0.015, memory: 6002, decode.loss_seg: 1.1912, decode.acc_seg: 49.7046, loss: 1.1912
2021-08-13 16:46:41,129 - mmseg - INFO - Iter [14900/160000]	lr: 9.166e-03, eta: 2 days, 6:19:45, time: 1.282, data_time: 0.014, memory: 6002, decode.loss_seg: 1.2031, decode.acc_seg: 49.3342, loss: 1.2031
2021-08-13 16:47:43,187 - mmseg - INFO - Iter [14950/160000]	lr: 9.163e-03, eta: 2 days, 6:17:46, time: 1.241, data_time: 0.014, memory: 6002, decode.loss_seg: 1.1920, decode.acc_seg: 49.4100, loss: 1.1920
2021-08-13 16:48:46,954 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-without-head_512x512_160k_ade20k.py
2021-08-13 16:48:46,954 - mmseg - INFO - Iter [15000/160000]	lr: 9.161e-03, eta: 2 days, 6:16:03, time: 1.275, data_time: 0.013, memory: 6002, decode.loss_seg: 1.2066, decode.acc_seg: 48.8063, loss: 1.2066
2021-08-13 16:49:50,884 - mmseg - INFO - Iter [15050/160000]	lr: 9.158e-03, eta: 2 days, 6:14:23, time: 1.280, data_time: 0.014, memory: 6002, decode.loss_seg: 1.1611, decode.acc_seg: 49.8535, loss: 1.1611
2021-08-13 16:50:53,722 - mmseg - INFO - Iter [15100/160000]	lr: 9.155e-03, eta: 2 days, 6:12:32, time: 1.256, data_time: 0.012, memory: 6002, decode.loss_seg: 1.1895, decode.acc_seg: 48.9940, loss: 1.1895
2021-08-13 16:52:31,909 - mmseg - INFO - Iter [15150/160000]	lr: 9.152e-03, eta: 2 days, 6:16:20, time: 1.964, data_time: 0.705, memory: 6002, decode.loss_seg: 1.1628, decode.acc_seg: 49.9537, loss: 1.1628
2021-08-13 16:53:36,415 - mmseg - INFO - Iter [15200/160000]	lr: 9.149e-03, eta: 2 days, 6:14:44, time: 1.290, data_time: 0.013, memory: 6002, decode.loss_seg: 1.1760, decode.acc_seg: 48.7231, loss: 1.1760
2021-08-13 16:54:39,651 - mmseg - INFO - Iter [15250/160000]	lr: 9.147e-03, eta: 2 days, 6:12:57, time: 1.264, data_time: 0.013, memory: 6002, decode.loss_seg: 1.1921, decode.acc_seg: 49.2423, loss: 1.1921
2021-08-13 16:55:44,107 - mmseg - INFO - Iter [15300/160000]	lr: 9.144e-03, eta: 2 days, 6:11:22, time: 1.290, data_time: 0.015, memory: 6002, decode.loss_seg: 1.2104, decode.acc_seg: 50.3567, loss: 1.2104
2021-08-13 16:56:46,996 - mmseg - INFO - Iter [15350/160000]	lr: 9.141e-03, eta: 2 days, 6:09:32, time: 1.258, data_time: 0.013, memory: 6002, decode.loss_seg: 1.1968, decode.acc_seg: 48.8779, loss: 1.1968
2021-08-13 16:57:49,338 - mmseg - INFO - Iter [15400/160000]	lr: 9.138e-03, eta: 2 days, 6:07:37, time: 1.246, data_time: 0.013, memory: 6002, decode.loss_seg: 1.2167, decode.acc_seg: 49.5686, loss: 1.2167
2021-08-13 16:58:53,864 - mmseg - INFO - Iter [15450/160000]	lr: 9.135e-03, eta: 2 days, 6:06:03, time: 1.290, data_time: 0.014, memory: 6002, decode.loss_seg: 1.2053, decode.acc_seg: 50.3187, loss: 1.2053
2021-08-13 16:59:57,785 - mmseg - INFO - Iter [15500/160000]	lr: 9.133e-03, eta: 2 days, 6:04:24, time: 1.279, data_time: 0.014, memory: 6002, decode.loss_seg: 1.1960, decode.acc_seg: 48.5492, loss: 1.1960
2021-08-13 17:01:00,839 - mmseg - INFO - Iter [15550/160000]	lr: 9.130e-03, eta: 2 days, 6:02:36, time: 1.260, data_time: 0.015, memory: 6002, decode.loss_seg: 1.1813, decode.acc_seg: 48.9164, loss: 1.1813
2021-08-13 17:02:04,913 - mmseg - INFO - Iter [15600/160000]	lr: 9.127e-03, eta: 2 days, 6:00:58, time: 1.282, data_time: 0.015, memory: 6002, decode.loss_seg: 1.1811, decode.acc_seg: 49.0139, loss: 1.1811
2021-08-13 17:03:07,612 - mmseg - INFO - Iter [15650/160000]	lr: 9.124e-03, eta: 2 days, 5:59:08, time: 1.254, data_time: 0.014, memory: 6002, decode.loss_seg: 1.1962, decode.acc_seg: 49.4188, loss: 1.1962
2021-08-13 17:04:13,245 - mmseg - INFO - Iter [15700/160000]	lr: 9.121e-03, eta: 2 days, 5:57:45, time: 1.311, data_time: 0.014, memory: 6002, decode.loss_seg: 1.1967, decode.acc_seg: 49.7024, loss: 1.1967
2021-08-13 17:05:19,778 - mmseg - INFO - Iter [15750/160000]	lr: 9.118e-03, eta: 2 days, 5:56:31, time: 1.331, data_time: 0.015, memory: 6002, decode.loss_seg: 1.1542, decode.acc_seg: 49.0673, loss: 1.1542
2021-08-13 17:06:58,451 - mmseg - INFO - Iter [15800/160000]	lr: 9.116e-03, eta: 2 days, 6:00:10, time: 1.974, data_time: 0.710, memory: 6002, decode.loss_seg: 1.1780, decode.acc_seg: 50.0914, loss: 1.1780
2021-08-13 17:08:02,811 - mmseg - INFO - Iter [15850/160000]	lr: 9.113e-03, eta: 2 days, 5:58:35, time: 1.287, data_time: 0.015, memory: 6002, decode.loss_seg: 1.1651, decode.acc_seg: 48.7810, loss: 1.1651
2021-08-13 17:09:05,586 - mmseg - INFO - Iter [15900/160000]	lr: 9.110e-03, eta: 2 days, 5:56:46, time: 1.256, data_time: 0.013, memory: 6002, decode.loss_seg: 1.1535, decode.acc_seg: 51.1760, loss: 1.1535
2021-08-13 17:10:07,917 - mmseg - INFO - Iter [15950/160000]	lr: 9.107e-03, eta: 2 days, 5:54:52, time: 1.246, data_time: 0.013, memory: 6002, decode.loss_seg: 1.1511, decode.acc_seg: 49.4071, loss: 1.1511
2021-08-13 17:11:10,784 - mmseg - INFO - Saving checkpoint at 16000 iterations
2021-08-13 17:11:11,151 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-without-head_512x512_160k_ade20k.py
2021-08-13 17:11:11,154 - mmseg - INFO - Iter [16000/160000]	lr: 9.104e-03, eta: 2 days, 5:53:08, time: 1.265, data_time: 0.014, memory: 6002, decode.loss_seg: 1.2284, decode.acc_seg: 49.1569, loss: 1.2284
2021-08-13 17:13:57,998 - mmseg - INFO - per class results:
2021-08-13 17:13:58,011 - mmseg - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        | 51.62 | 82.53 |
|       building      |  63.6 | 83.35 |
|         sky         | 86.58 | 94.28 |
|        floor        |  54.6 |  81.2 |
|         tree        | 54.35 |  72.7 |
|       ceiling       | 63.32 | 82.73 |
|         road        | 61.35 | 78.55 |
|         bed         | 52.68 | 71.43 |
|      windowpane     | 39.39 | 60.07 |
|        grass        | 54.84 | 77.11 |
|       cabinet       | 31.68 | 40.85 |
|       sidewalk      | 32.94 | 45.18 |
|        person       | 36.83 | 50.94 |
|        earth        | 23.11 | 38.33 |
|         door        |  10.3 | 13.43 |
|        table        | 20.12 | 26.47 |
|       mountain      | 27.44 | 48.59 |
|        plant        | 19.23 | 21.41 |
|       curtain       | 30.74 | 39.59 |
|        chair        | 17.13 | 24.53 |
|         car         | 50.49 | 67.33 |
|        water        | 14.32 | 18.62 |
|       painting      | 40.72 | 54.82 |
|         sofa        | 28.57 |  45.2 |
|        shelf        | 12.01 | 14.88 |
|        house        | 25.31 | 45.79 |
|         sea         | 25.22 | 67.05 |
|        mirror       | 16.43 | 19.96 |
|         rug         |  17.3 | 19.51 |
|        field        | 13.55 | 20.53 |
|       armchair      |  6.3  |  7.43 |
|         seat        | 16.89 | 18.98 |
|        fence        |  7.98 | 10.05 |
|         desk        |  5.04 |  5.33 |
|         rock        |  4.24 |  4.77 |
|       wardrobe      |  3.37 |  3.45 |
|         lamp        | 20.87 | 25.49 |
|       bathtub       | 14.13 | 16.18 |
|       railing       | 13.14 | 16.41 |
|       cushion       | 13.02 |  17.2 |
|         base        |  0.1  |  0.11 |
|         box         |  0.44 |  0.45 |
|        column       |  4.98 |  5.41 |
|      signboard      |  6.6  |  7.36 |
|   chest of drawers  |  17.0 | 22.75 |
|       counter       |  2.75 |  2.88 |
|         sand        | 12.39 | 24.41 |
|         sink        | 19.24 | 32.03 |
|      skyscraper     | 35.32 | 57.17 |
|      fireplace      | 43.15 | 51.97 |
|     refrigerator    |  5.3  |  5.45 |
|      grandstand     |  8.12 |  11.0 |
|         path        |  2.44 |  2.61 |
|        stairs       | 10.58 |  11.7 |
|        runway       | 37.05 | 65.29 |
|         case        |  9.69 | 14.92 |
|      pool table     | 29.95 |  78.3 |
|        pillow       | 22.15 | 26.59 |
|     screen door     |  0.69 |  0.7  |
|       stairway      |  4.89 |  6.91 |
|        river        |  6.83 | 11.97 |
|        bridge       |  3.34 |  5.02 |
|       bookcase      |  5.85 |  6.17 |
|        blind        |  0.56 |  0.57 |
|     coffee table    | 21.09 |  35.8 |
|        toilet       | 28.72 | 44.59 |
|        flower       |  4.82 |  5.32 |
|         book        | 16.62 | 19.02 |
|         hill        |  1.45 |  2.38 |
|        bench        |  8.87 | 10.78 |
|      countertop     |  7.65 |  9.1  |
|        stove        | 19.86 | 27.33 |
|         palm        |  1.9  |  1.9  |
|    kitchen island   | 20.08 | 22.04 |
|       computer      |  3.32 |  3.53 |
|     swivel chair    |  5.62 |  5.74 |
|         boat        |  1.5  |  1.66 |
|         bar         |  2.8  |  2.88 |
|    arcade machine   |  0.95 |  1.32 |
|        hovel        |  0.0  |  0.0  |
|         bus         | 10.78 | 12.61 |
|        towel        |  0.0  |  0.0  |
|        light        |  8.61 |  9.52 |
|        truck        |  0.55 |  0.57 |
|        tower        |  14.9 | 15.02 |
|      chandelier     | 26.81 | 35.64 |
|        awning       |  0.34 |  0.34 |
|     streetlight     |  0.63 |  0.64 |
|        booth        |  0.04 |  0.04 |
| television receiver |  18.1 | 21.12 |
|       airplane      |  9.62 | 17.16 |
|      dirt track     |  0.0  |  0.0  |
|       apparel       |  0.0  |  0.0  |
|         pole        |  0.66 |  0.7  |
|         land        |  0.0  |  0.0  |
|      bannister      |  0.0  |  0.0  |
|      escalator      |  0.25 |  0.27 |
|       ottoman       |  0.0  |  0.0  |
|        bottle       |  0.11 |  0.11 |
|        buffet       |  0.0  |  0.0  |
|        poster       |  0.0  |  0.0  |
|        stage        |  0.12 |  0.12 |
|         van         |  0.0  |  0.0  |
|         ship        |  0.0  |  0.0  |
|       fountain      |  0.0  |  0.0  |
|    conveyer belt    |  0.85 |  0.93 |
|        canopy       |  0.0  |  0.0  |
|        washer       | 17.19 | 18.88 |
|      plaything      |  0.0  |  0.0  |
|    swimming pool    |  8.99 | 15.54 |
|        stool        |  0.0  |  0.0  |
|        barrel       |  0.0  |  0.0  |
|        basket       |  0.0  |  0.0  |
|      waterfall      | 26.24 | 56.12 |
|         tent        | 11.97 | 18.41 |
|         bag         |  0.0  |  0.0  |
|       minibike      |  0.0  |  0.0  |
|        cradle       | 27.13 | 31.55 |
|         oven        |  0.0  |  0.0  |
|         ball        |  2.17 |  2.85 |
|         food        |  4.34 |  4.44 |
|         step        |  0.0  |  0.0  |
|         tank        |  0.0  |  0.0  |
|      trade name     |  3.2  |  3.26 |
|      microwave      |  9.62 |  9.97 |
|         pot         |  0.0  |  0.0  |
|        animal       |  0.0  |  0.0  |
|       bicycle       |  0.0  |  0.0  |
|         lake        |  0.0  |  0.0  |
|      dishwasher     |  2.75 |  2.77 |
|        screen       | 32.88 | 41.34 |
|       blanket       |  0.0  |  0.0  |
|      sculpture      |  0.0  |  0.0  |
|         hood        |  9.08 |  9.26 |
|        sconce       |  0.0  |  0.0  |
|         vase        |  0.24 |  0.24 |
|    traffic light    |  0.0  |  0.0  |
|         tray        |  0.0  |  0.0  |
|        ashcan       |  0.0  |  0.0  |
|         fan         |  0.21 |  0.21 |
|         pier        |  0.0  |  0.0  |
|      crt screen     |  0.0  |  0.0  |
|        plate        |  0.0  |  0.0  |
|       monitor       |  0.0  |  0.0  |
|    bulletin board   |  0.0  |  0.0  |
|        shower       |  0.0  |  0.0  |
|       radiator      |  0.0  |  0.0  |
|        glass        |  0.0  |  0.0  |
|        clock        |  0.0  |  0.0  |
|         flag        |  0.0  |  0.0  |
+---------------------+-------+-------+
2021-08-13 17:13:58,011 - mmseg - INFO - Summary:
2021-08-13 17:13:58,011 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 63.12 | 12.43 | 17.38 |
+-------+-------+-------+
2021-08-13 17:13:58,112 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-without-head_512x512_160k_ade20k.py
2021-08-13 17:13:58,113 - mmseg - INFO - Iter(val) [250]	aAcc: 0.6312, mIoU: 0.1243, mAcc: 0.1738, IoU.wall: 0.5162, IoU.building: 0.6360, IoU.sky: 0.8658, IoU.floor: 0.5460, IoU.tree: 0.5435, IoU.ceiling: 0.6332, IoU.road: 0.6135, IoU.bed : 0.5268, IoU.windowpane: 0.3939, IoU.grass: 0.5484, IoU.cabinet: 0.3168, IoU.sidewalk: 0.3294, IoU.person: 0.3683, IoU.earth: 0.2311, IoU.door: 0.1030, IoU.table: 0.2012, IoU.mountain: 0.2744, IoU.plant: 0.1923, IoU.curtain: 0.3074, IoU.chair: 0.1713, IoU.car: 0.5049, IoU.water: 0.1432, IoU.painting: 0.4072, IoU.sofa: 0.2857, IoU.shelf: 0.1201, IoU.house: 0.2531, IoU.sea: 0.2522, IoU.mirror: 0.1643, IoU.rug: 0.1730, IoU.field: 0.1355, IoU.armchair: 0.0630, IoU.seat: 0.1689, IoU.fence: 0.0798, IoU.desk: 0.0504, IoU.rock: 0.0424, IoU.wardrobe: 0.0337, IoU.lamp: 0.2087, IoU.bathtub: 0.1413, IoU.railing: 0.1314, IoU.cushion: 0.1302, IoU.base: 0.0010, IoU.box: 0.0044, IoU.column: 0.0498, IoU.signboard: 0.0660, IoU.chest of drawers: 0.1700, IoU.counter: 0.0275, IoU.sand: 0.1239, IoU.sink: 0.1924, IoU.skyscraper: 0.3532, IoU.fireplace: 0.4315, IoU.refrigerator: 0.0530, IoU.grandstand: 0.0812, IoU.path: 0.0244, IoU.stairs: 0.1058, IoU.runway: 0.3705, IoU.case: 0.0969, IoU.pool table: 0.2995, IoU.pillow: 0.2215, IoU.screen door: 0.0069, IoU.stairway: 0.0489, IoU.river: 0.0683, IoU.bridge: 0.0334, IoU.bookcase: 0.0585, IoU.blind: 0.0056, IoU.coffee table: 0.2109, IoU.toilet: 0.2872, IoU.flower: 0.0482, IoU.book: 0.1662, IoU.hill: 0.0145, IoU.bench: 0.0887, IoU.countertop: 0.0765, IoU.stove: 0.1986, IoU.palm: 0.0190, IoU.kitchen island: 0.2008, IoU.computer: 0.0332, IoU.swivel chair: 0.0562, IoU.boat: 0.0150, IoU.bar: 0.0280, IoU.arcade machine: 0.0095, IoU.hovel: 0.0000, IoU.bus: 0.1078, IoU.towel: 0.0000, IoU.light: 0.0861, IoU.truck: 0.0055, IoU.tower: 0.1490, IoU.chandelier: 0.2681, IoU.awning: 0.0034, IoU.streetlight: 0.0063, IoU.booth: 0.0004, IoU.television receiver: 0.1810, IoU.airplane: 0.0962, IoU.dirt track: 0.0000, IoU.apparel: 0.0000, IoU.pole: 0.0066, IoU.land: 0.0000, IoU.bannister: 0.0000, IoU.escalator: 0.0025, IoU.ottoman: 0.0000, IoU.bottle: 0.0011, IoU.buffet: 0.0000, IoU.poster: 0.0000, IoU.stage: 0.0012, IoU.van: 0.0000, IoU.ship: 0.0000, IoU.fountain: 0.0000, IoU.conveyer belt: 0.0085, IoU.canopy: 0.0000, IoU.washer: 0.1719, IoU.plaything: 0.0000, IoU.swimming pool: 0.0899, IoU.stool: 0.0000, IoU.barrel: 0.0000, IoU.basket: 0.0000, IoU.waterfall: 0.2624, IoU.tent: 0.1197, IoU.bag: 0.0000, IoU.minibike: 0.0000, IoU.cradle: 0.2713, IoU.oven: 0.0000, IoU.ball: 0.0217, IoU.food: 0.0434, IoU.step: 0.0000, IoU.tank: 0.0000, IoU.trade name: 0.0320, IoU.microwave: 0.0962, IoU.pot: 0.0000, IoU.animal: 0.0000, IoU.bicycle: 0.0000, IoU.lake: 0.0000, IoU.dishwasher: 0.0275, IoU.screen: 0.3288, IoU.blanket: 0.0000, IoU.sculpture: 0.0000, IoU.hood: 0.0908, IoU.sconce: 0.0000, IoU.vase: 0.0024, IoU.traffic light: 0.0000, IoU.tray: 0.0000, IoU.ashcan: 0.0000, IoU.fan: 0.0021, IoU.pier: 0.0000, IoU.crt screen: 0.0000, IoU.plate: 0.0000, IoU.monitor: 0.0000, IoU.bulletin board: 0.0000, IoU.shower: 0.0000, IoU.radiator: 0.0000, IoU.glass: 0.0000, IoU.clock: 0.0000, IoU.flag: 0.0000, Acc.wall: 0.8253, Acc.building: 0.8335, Acc.sky: 0.9428, Acc.floor: 0.8120, Acc.tree: 0.7270, Acc.ceiling: 0.8273, Acc.road: 0.7855, Acc.bed : 0.7143, Acc.windowpane: 0.6007, Acc.grass: 0.7711, Acc.cabinet: 0.4085, Acc.sidewalk: 0.4518, Acc.person: 0.5094, Acc.earth: 0.3833, Acc.door: 0.1343, Acc.table: 0.2647, Acc.mountain: 0.4859, Acc.plant: 0.2141, Acc.curtain: 0.3959, Acc.chair: 0.2453, Acc.car: 0.6733, Acc.water: 0.1862, Acc.painting: 0.5482, Acc.sofa: 0.4520, Acc.shelf: 0.1488, Acc.house: 0.4579, Acc.sea: 0.6705, Acc.mirror: 0.1996, Acc.rug: 0.1951, Acc.field: 0.2053, Acc.armchair: 0.0743, Acc.seat: 0.1898, Acc.fence: 0.1005, Acc.desk: 0.0533, Acc.rock: 0.0477, Acc.wardrobe: 0.0345, Acc.lamp: 0.2549, Acc.bathtub: 0.1618, Acc.railing: 0.1641, Acc.cushion: 0.1720, Acc.base: 0.0011, Acc.box: 0.0045, Acc.column: 0.0541, Acc.signboard: 0.0736, Acc.chest of drawers: 0.2275, Acc.counter: 0.0288, Acc.sand: 0.2441, Acc.sink: 0.3203, Acc.skyscraper: 0.5717, Acc.fireplace: 0.5197, Acc.refrigerator: 0.0545, Acc.grandstand: 0.1100, Acc.path: 0.0261, Acc.stairs: 0.1170, Acc.runway: 0.6529, Acc.case: 0.1492, Acc.pool table: 0.7830, Acc.pillow: 0.2659, Acc.screen door: 0.0070, Acc.stairway: 0.0691, Acc.river: 0.1197, Acc.bridge: 0.0502, Acc.bookcase: 0.0617, Acc.blind: 0.0057, Acc.coffee table: 0.3580, Acc.toilet: 0.4459, Acc.flower: 0.0532, Acc.book: 0.1902, Acc.hill: 0.0238, Acc.bench: 0.1078, Acc.countertop: 0.0910, Acc.stove: 0.2733, Acc.palm: 0.0190, Acc.kitchen island: 0.2204, Acc.computer: 0.0353, Acc.swivel chair: 0.0574, Acc.boat: 0.0166, Acc.bar: 0.0288, Acc.arcade machine: 0.0132, Acc.hovel: 0.0000, Acc.bus: 0.1261, Acc.towel: 0.0000, Acc.light: 0.0952, Acc.truck: 0.0057, Acc.tower: 0.1502, Acc.chandelier: 0.3564, Acc.awning: 0.0034, Acc.streetlight: 0.0064, Acc.booth: 0.0004, Acc.television receiver: 0.2112, Acc.airplane: 0.1716, Acc.dirt track: 0.0000, Acc.apparel: 0.0000, Acc.pole: 0.0070, Acc.land: 0.0000, Acc.bannister: 0.0000, Acc.escalator: 0.0027, Acc.ottoman: 0.0000, Acc.bottle: 0.0011, Acc.buffet: 0.0000, Acc.poster: 0.0000, Acc.stage: 0.0012, Acc.van: 0.0000, Acc.ship: 0.0000, Acc.fountain: 0.0000, Acc.conveyer belt: 0.0093, Acc.canopy: 0.0000, Acc.washer: 0.1888, Acc.plaything: 0.0000, Acc.swimming pool: 0.1554, Acc.stool: 0.0000, Acc.barrel: 0.0000, Acc.basket: 0.0000, Acc.waterfall: 0.5612, Acc.tent: 0.1841, Acc.bag: 0.0000, Acc.minibike: 0.0000, Acc.cradle: 0.3155, Acc.oven: 0.0000, Acc.ball: 0.0285, Acc.food: 0.0444, Acc.step: 0.0000, Acc.tank: 0.0000, Acc.trade name: 0.0326, Acc.microwave: 0.0997, Acc.pot: 0.0000, Acc.animal: 0.0000, Acc.bicycle: 0.0000, Acc.lake: 0.0000, Acc.dishwasher: 0.0277, Acc.screen: 0.4134, Acc.blanket: 0.0000, Acc.sculpture: 0.0000, Acc.hood: 0.0926, Acc.sconce: 0.0000, Acc.vase: 0.0024, Acc.traffic light: 0.0000, Acc.tray: 0.0000, Acc.ashcan: 0.0000, Acc.fan: 0.0021, Acc.pier: 0.0000, Acc.crt screen: 0.0000, Acc.plate: 0.0000, Acc.monitor: 0.0000, Acc.bulletin board: 0.0000, Acc.shower: 0.0000, Acc.radiator: 0.0000, Acc.glass: 0.0000, Acc.clock: 0.0000, Acc.flag: 0.0000
2021-08-13 17:15:05,461 - mmseg - INFO - Iter [16050/160000]	lr: 9.102e-03, eta: 2 days, 6:16:58, time: 4.685, data_time: 3.354, memory: 6005, decode.loss_seg: 1.1851, decode.acc_seg: 49.6393, loss: 1.1851
2021-08-13 17:16:10,522 - mmseg - INFO - Iter [16100/160000]	lr: 9.099e-03, eta: 2 days, 6:15:25, time: 1.302, data_time: 0.015, memory: 6005, decode.loss_seg: 1.2095, decode.acc_seg: 48.3597, loss: 1.2095
2021-08-13 17:17:15,994 - mmseg - INFO - Iter [16150/160000]	lr: 9.096e-03, eta: 2 days, 6:13:55, time: 1.308, data_time: 0.014, memory: 6005, decode.loss_seg: 1.1786, decode.acc_seg: 49.2209, loss: 1.1786
2021-08-13 17:18:20,679 - mmseg - INFO - Iter [16200/160000]	lr: 9.093e-03, eta: 2 days, 6:12:19, time: 1.295, data_time: 0.015, memory: 6005, decode.loss_seg: 1.2109, decode.acc_seg: 48.9133, loss: 1.2109
2021-08-13 17:19:25,745 - mmseg - INFO - Iter [16250/160000]	lr: 9.090e-03, eta: 2 days, 6:10:47, time: 1.302, data_time: 0.016, memory: 6005, decode.loss_seg: 1.2071, decode.acc_seg: 48.5939, loss: 1.2071
2021-08-13 17:20:31,915 - mmseg - INFO - Iter [16300/160000]	lr: 9.088e-03, eta: 2 days, 6:09:25, time: 1.324, data_time: 0.015, memory: 6005, decode.loss_seg: 1.1825, decode.acc_seg: 50.2215, loss: 1.1825
2021-08-13 17:21:34,973 - mmseg - INFO - Iter [16350/160000]	lr: 9.085e-03, eta: 2 days, 6:07:34, time: 1.260, data_time: 0.015, memory: 6005, decode.loss_seg: 1.1571, decode.acc_seg: 50.2821, loss: 1.1571
2021-08-13 17:22:37,342 - mmseg - INFO - Iter [16400/160000]	lr: 9.082e-03, eta: 2 days, 6:05:39, time: 1.248, data_time: 0.015, memory: 6005, decode.loss_seg: 1.1676, decode.acc_seg: 49.8065, loss: 1.1676
2021-08-13 17:24:17,557 - mmseg - INFO - Iter [16450/160000]	lr: 9.079e-03, eta: 2 days, 6:09:14, time: 2.003, data_time: 0.729, memory: 6005, decode.loss_seg: 1.1692, decode.acc_seg: 49.4390, loss: 1.1692
2021-08-13 17:25:21,595 - mmseg - INFO - Iter [16500/160000]	lr: 9.076e-03, eta: 2 days, 6:07:33, time: 1.282, data_time: 0.017, memory: 6005, decode.loss_seg: 1.1825, decode.acc_seg: 50.8576, loss: 1.1825
2021-08-13 17:26:27,183 - mmseg - INFO - Iter [16550/160000]	lr: 9.073e-03, eta: 2 days, 6:06:04, time: 1.311, data_time: 0.014, memory: 6005, decode.loss_seg: 1.1827, decode.acc_seg: 49.3936, loss: 1.1827
2021-08-13 17:27:33,574 - mmseg - INFO - Iter [16600/160000]	lr: 9.071e-03, eta: 2 days, 6:04:44, time: 1.329, data_time: 0.015, memory: 6005, decode.loss_seg: 1.1617, decode.acc_seg: 50.7076, loss: 1.1617
2021-08-13 17:28:37,363 - mmseg - INFO - Iter [16650/160000]	lr: 9.068e-03, eta: 2 days, 6:03:00, time: 1.275, data_time: 0.015, memory: 6005, decode.loss_seg: 1.1644, decode.acc_seg: 49.6897, loss: 1.1644
2021-08-13 17:29:39,997 - mmseg - INFO - Iter [16700/160000]	lr: 9.065e-03, eta: 2 days, 6:01:08, time: 1.253, data_time: 0.018, memory: 6005, decode.loss_seg: 1.1877, decode.acc_seg: 50.1171, loss: 1.1877
2021-08-13 17:30:44,380 - mmseg - INFO - Iter [16750/160000]	lr: 9.062e-03, eta: 2 days, 5:59:30, time: 1.288, data_time: 0.017, memory: 6005, decode.loss_seg: 1.1778, decode.acc_seg: 48.8884, loss: 1.1778
2021-08-13 17:31:47,331 - mmseg - INFO - Iter [16800/160000]	lr: 9.059e-03, eta: 2 days, 5:57:41, time: 1.259, data_time: 0.015, memory: 6005, decode.loss_seg: 1.1989, decode.acc_seg: 48.8216, loss: 1.1989
2021-08-13 17:32:50,707 - mmseg - INFO - Iter [16850/160000]	lr: 9.057e-03, eta: 2 days, 5:55:55, time: 1.268, data_time: 0.015, memory: 6005, decode.loss_seg: 1.1777, decode.acc_seg: 49.7707, loss: 1.1777
2021-08-13 17:33:54,817 - mmseg - INFO - Iter [16900/160000]	lr: 9.054e-03, eta: 2 days, 5:54:16, time: 1.282, data_time: 0.015, memory: 6005, decode.loss_seg: 1.1559, decode.acc_seg: 50.3061, loss: 1.1559
2021-08-13 17:34:59,035 - mmseg - INFO - Iter [16950/160000]	lr: 9.051e-03, eta: 2 days, 5:52:38, time: 1.284, data_time: 0.014, memory: 6005, decode.loss_seg: 1.1648, decode.acc_seg: 50.8048, loss: 1.1648
2021-08-13 17:36:05,099 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-without-head_512x512_160k_ade20k.py
2021-08-13 17:36:05,100 - mmseg - INFO - Iter [17000/160000]	lr: 9.048e-03, eta: 2 days, 5:51:15, time: 1.321, data_time: 0.018, memory: 6005, decode.loss_seg: 1.1544, decode.acc_seg: 50.9878, loss: 1.1544
2021-08-13 17:37:46,278 - mmseg - INFO - Iter [17050/160000]	lr: 9.045e-03, eta: 2 days, 5:54:48, time: 2.025, data_time: 0.730, memory: 6005, decode.loss_seg: 1.1697, decode.acc_seg: 50.0897, loss: 1.1697
2021-08-13 17:38:51,332 - mmseg - INFO - Iter [17100/160000]	lr: 9.043e-03, eta: 2 days, 5:53:16, time: 1.301, data_time: 0.015, memory: 6005, decode.loss_seg: 1.1546, decode.acc_seg: 49.6107, loss: 1.1546
2021-08-13 17:39:54,724 - mmseg - INFO - Iter [17150/160000]	lr: 9.040e-03, eta: 2 days, 5:51:31, time: 1.268, data_time: 0.014, memory: 6005, decode.loss_seg: 1.1519, decode.acc_seg: 49.8491, loss: 1.1519
2021-08-13 17:41:00,050 - mmseg - INFO - Iter [17200/160000]	lr: 9.037e-03, eta: 2 days, 5:50:01, time: 1.305, data_time: 0.014, memory: 6005, decode.loss_seg: 1.1814, decode.acc_seg: 50.0290, loss: 1.1814
2021-08-13 17:42:06,355 - mmseg - INFO - Iter [17250/160000]	lr: 9.034e-03, eta: 2 days, 5:48:41, time: 1.327, data_time: 0.014, memory: 6005, decode.loss_seg: 1.1435, decode.acc_seg: 50.5468, loss: 1.1435
2021-08-13 17:43:09,389 - mmseg - INFO - Iter [17300/160000]	lr: 9.031e-03, eta: 2 days, 5:46:53, time: 1.260, data_time: 0.015, memory: 6005, decode.loss_seg: 1.1445, decode.acc_seg: 49.8405, loss: 1.1445
2021-08-13 17:44:14,593 - mmseg - INFO - Iter [17350/160000]	lr: 9.028e-03, eta: 2 days, 5:45:24, time: 1.304, data_time: 0.014, memory: 6005, decode.loss_seg: 1.1607, decode.acc_seg: 49.9058, loss: 1.1607
2021-08-13 17:45:20,155 - mmseg - INFO - Iter [17400/160000]	lr: 9.026e-03, eta: 2 days, 5:43:57, time: 1.311, data_time: 0.016, memory: 6005, decode.loss_seg: 1.1664, decode.acc_seg: 49.7270, loss: 1.1664
2021-08-13 17:46:29,456 - mmseg - INFO - Iter [17450/160000]	lr: 9.023e-03, eta: 2 days, 5:43:01, time: 1.386, data_time: 0.016, memory: 6005, decode.loss_seg: 1.1358, decode.acc_seg: 50.2405, loss: 1.1358
2021-08-13 17:47:38,779 - mmseg - INFO - Iter [17500/160000]	lr: 9.020e-03, eta: 2 days, 5:42:06, time: 1.386, data_time: 0.015, memory: 6005, decode.loss_seg: 1.1595, decode.acc_seg: 50.4058, loss: 1.1595
2021-08-13 17:48:47,700 - mmseg - INFO - Iter [17550/160000]	lr: 9.017e-03, eta: 2 days, 5:41:07, time: 1.378, data_time: 0.015, memory: 6005, decode.loss_seg: 1.1648, decode.acc_seg: 50.6657, loss: 1.1648
2021-08-13 17:49:56,880 - mmseg - INFO - Iter [17600/160000]	lr: 9.014e-03, eta: 2 days, 5:40:10, time: 1.384, data_time: 0.015, memory: 6005, decode.loss_seg: 1.1328, decode.acc_seg: 50.6538, loss: 1.1328
2021-08-13 17:51:04,040 - mmseg - INFO - Iter [17650/160000]	lr: 9.012e-03, eta: 2 days, 5:38:57, time: 1.344, data_time: 0.014, memory: 6005, decode.loss_seg: 1.1678, decode.acc_seg: 50.1321, loss: 1.1678
2021-08-13 17:52:45,383 - mmseg - INFO - Iter [17700/160000]	lr: 9.009e-03, eta: 2 days, 5:42:18, time: 2.027, data_time: 0.733, memory: 6005, decode.loss_seg: 1.2006, decode.acc_seg: 49.7460, loss: 1.2006
2021-08-13 17:53:54,469 - mmseg - INFO - Iter [17750/160000]	lr: 9.006e-03, eta: 2 days, 5:41:19, time: 1.381, data_time: 0.015, memory: 6005, decode.loss_seg: 1.1376, decode.acc_seg: 49.9661, loss: 1.1376
2021-08-13 17:54:58,669 - mmseg - INFO - Iter [17800/160000]	lr: 9.003e-03, eta: 2 days, 5:39:42, time: 1.285, data_time: 0.014, memory: 6005, decode.loss_seg: 1.1435, decode.acc_seg: 50.8004, loss: 1.1435
2021-08-13 17:56:03,966 - mmseg - INFO - Iter [17850/160000]	lr: 9.000e-03, eta: 2 days, 5:38:13, time: 1.306, data_time: 0.014, memory: 6005, decode.loss_seg: 1.1401, decode.acc_seg: 49.1982, loss: 1.1401
2021-08-13 17:57:09,689 - mmseg - INFO - Iter [17900/160000]	lr: 8.997e-03, eta: 2 days, 5:36:48, time: 1.315, data_time: 0.015, memory: 6005, decode.loss_seg: 1.1196, decode.acc_seg: 50.2957, loss: 1.1196
2021-08-13 17:58:15,226 - mmseg - INFO - Iter [17950/160000]	lr: 8.995e-03, eta: 2 days, 5:35:21, time: 1.310, data_time: 0.015, memory: 6005, decode.loss_seg: 1.1577, decode.acc_seg: 50.0148, loss: 1.1577
2021-08-13 17:59:22,129 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-without-head_512x512_160k_ade20k.py
2021-08-13 17:59:22,129 - mmseg - INFO - Iter [18000/160000]	lr: 8.992e-03, eta: 2 days, 5:34:05, time: 1.339, data_time: 0.014, memory: 6005, decode.loss_seg: 1.1438, decode.acc_seg: 49.9250, loss: 1.1438
2021-08-13 18:00:24,492 - mmseg - INFO - Iter [18050/160000]	lr: 8.989e-03, eta: 2 days, 5:32:14, time: 1.247, data_time: 0.014, memory: 6005, decode.loss_seg: 1.1633, decode.acc_seg: 49.9180, loss: 1.1633
2021-08-13 18:01:29,292 - mmseg - INFO - Iter [18100/160000]	lr: 8.986e-03, eta: 2 days, 5:30:41, time: 1.295, data_time: 0.014, memory: 6005, decode.loss_seg: 1.1596, decode.acc_seg: 50.6031, loss: 1.1596
2021-08-13 18:02:33,550 - mmseg - INFO - Iter [18150/160000]	lr: 8.983e-03, eta: 2 days, 5:29:05, time: 1.285, data_time: 0.015, memory: 6005, decode.loss_seg: 1.1459, decode.acc_seg: 49.2329, loss: 1.1459
2021-08-13 18:03:39,164 - mmseg - INFO - Iter [18200/160000]	lr: 8.981e-03, eta: 2 days, 5:27:40, time: 1.312, data_time: 0.014, memory: 6005, decode.loss_seg: 1.1626, decode.acc_seg: 50.5547, loss: 1.1626
2021-08-13 18:04:44,238 - mmseg - INFO - Iter [18250/160000]	lr: 8.978e-03, eta: 2 days, 5:26:10, time: 1.301, data_time: 0.015, memory: 6005, decode.loss_seg: 1.1627, decode.acc_seg: 50.9191, loss: 1.1627
2021-08-13 18:06:53,157 - mmseg - INFO - Iter [18300/160000]	lr: 8.975e-03, eta: 2 days, 5:32:55, time: 2.579, data_time: 1.311, memory: 6005, decode.loss_seg: 1.1545, decode.acc_seg: 50.0511, loss: 1.1545
2021-08-13 18:07:58,867 - mmseg - INFO - Iter [18350/160000]	lr: 8.972e-03, eta: 2 days, 5:31:29, time: 1.314, data_time: 0.015, memory: 6005, decode.loss_seg: 1.1494, decode.acc_seg: 49.4511, loss: 1.1494
2021-08-13 18:09:03,969 - mmseg - INFO - Iter [18400/160000]	lr: 8.969e-03, eta: 2 days, 5:29:59, time: 1.302, data_time: 0.016, memory: 6005, decode.loss_seg: 1.1407, decode.acc_seg: 50.3171, loss: 1.1407
2021-08-13 18:10:10,485 - mmseg - INFO - Iter [18450/160000]	lr: 8.966e-03, eta: 2 days, 5:28:39, time: 1.330, data_time: 0.015, memory: 6005, decode.loss_seg: 1.1460, decode.acc_seg: 49.9422, loss: 1.1460
2021-08-13 18:11:15,765 - mmseg - INFO - Iter [18500/160000]	lr: 8.964e-03, eta: 2 days, 5:27:11, time: 1.306, data_time: 0.015, memory: 6005, decode.loss_seg: 1.1416, decode.acc_seg: 49.4275, loss: 1.1416
2021-08-13 18:12:21,415 - mmseg - INFO - Iter [18550/160000]	lr: 8.961e-03, eta: 2 days, 5:25:44, time: 1.312, data_time: 0.014, memory: 6005, decode.loss_seg: 1.1572, decode.acc_seg: 50.3099, loss: 1.1572
2021-08-13 18:13:25,166 - mmseg - INFO - Iter [18600/160000]	lr: 8.958e-03, eta: 2 days, 5:24:05, time: 1.276, data_time: 0.017, memory: 6005, decode.loss_seg: 1.1353, decode.acc_seg: 50.3221, loss: 1.1353
2021-08-13 18:14:27,915 - mmseg - INFO - Iter [18650/160000]	lr: 8.955e-03, eta: 2 days, 5:22:17, time: 1.255, data_time: 0.015, memory: 6005, decode.loss_seg: 1.1528, decode.acc_seg: 50.6645, loss: 1.1528
2021-08-13 18:15:31,531 - mmseg - INFO - Iter [18700/160000]	lr: 8.952e-03, eta: 2 days, 5:20:36, time: 1.272, data_time: 0.014, memory: 6005, decode.loss_seg: 1.1321, decode.acc_seg: 51.0910, loss: 1.1321
2021-08-13 18:16:36,462 - mmseg - INFO - Iter [18750/160000]	lr: 8.950e-03, eta: 2 days, 5:19:05, time: 1.298, data_time: 0.014, memory: 6005, decode.loss_seg: 1.1472, decode.acc_seg: 51.0918, loss: 1.1472
2021-08-13 18:17:42,344 - mmseg - INFO - Iter [18800/160000]	lr: 8.947e-03, eta: 2 days, 5:17:42, time: 1.317, data_time: 0.014, memory: 6005, decode.loss_seg: 1.1650, decode.acc_seg: 50.0709, loss: 1.1650
2021-08-13 18:18:48,219 - mmseg - INFO - Iter [18850/160000]	lr: 8.944e-03, eta: 2 days, 5:16:19, time: 1.318, data_time: 0.014, memory: 6005, decode.loss_seg: 1.1654, decode.acc_seg: 49.9573, loss: 1.1654
2021-08-13 18:19:52,979 - mmseg - INFO - Iter [18900/160000]	lr: 8.941e-03, eta: 2 days, 5:14:47, time: 1.295, data_time: 0.014, memory: 6005, decode.loss_seg: 1.1754, decode.acc_seg: 50.1890, loss: 1.1754
2021-08-13 18:21:30,853 - mmseg - INFO - Iter [18950/160000]	lr: 8.938e-03, eta: 2 days, 5:17:22, time: 1.957, data_time: 0.706, memory: 6005, decode.loss_seg: 1.1625, decode.acc_seg: 49.2122, loss: 1.1625
2021-08-13 18:22:35,089 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-without-head_512x512_160k_ade20k.py
2021-08-13 18:22:35,090 - mmseg - INFO - Iter [19000/160000]	lr: 8.935e-03, eta: 2 days, 5:15:46, time: 1.285, data_time: 0.018, memory: 6005, decode.loss_seg: 1.1190, decode.acc_seg: 50.7406, loss: 1.1190
2021-08-13 18:23:39,190 - mmseg - INFO - Iter [19050/160000]	lr: 8.933e-03, eta: 2 days, 5:14:09, time: 1.281, data_time: 0.016, memory: 6005, decode.loss_seg: 1.1583, decode.acc_seg: 49.7582, loss: 1.1583
2021-08-13 18:24:42,189 - mmseg - INFO - Iter [19100/160000]	lr: 8.930e-03, eta: 2 days, 5:12:24, time: 1.259, data_time: 0.016, memory: 6005, decode.loss_seg: 1.1306, decode.acc_seg: 50.8412, loss: 1.1306
2021-08-13 18:25:46,407 - mmseg - INFO - Iter [19150/160000]	lr: 8.927e-03, eta: 2 days, 5:10:48, time: 1.284, data_time: 0.016, memory: 6005, decode.loss_seg: 1.1209, decode.acc_seg: 51.3674, loss: 1.1209
2021-08-13 18:26:51,411 - mmseg - INFO - Iter [19200/160000]	lr: 8.924e-03, eta: 2 days, 5:09:19, time: 1.301, data_time: 0.017, memory: 6005, decode.loss_seg: 1.1210, decode.acc_seg: 50.4653, loss: 1.1210
2021-08-13 18:27:55,189 - mmseg - INFO - Iter [19250/160000]	lr: 8.921e-03, eta: 2 days, 5:07:40, time: 1.275, data_time: 0.015, memory: 6005, decode.loss_seg: 1.1823, decode.acc_seg: 50.0677, loss: 1.1823
2021-08-13 18:29:00,771 - mmseg - INFO - Iter [19300/160000]	lr: 8.918e-03, eta: 2 days, 5:06:15, time: 1.311, data_time: 0.016, memory: 6005, decode.loss_seg: 1.1443, decode.acc_seg: 51.5638, loss: 1.1443
2021-08-13 18:30:07,999 - mmseg - INFO - Iter [19350/160000]	lr: 8.916e-03, eta: 2 days, 5:05:02, time: 1.344, data_time: 0.015, memory: 6005, decode.loss_seg: 1.1246, decode.acc_seg: 51.0750, loss: 1.1246
2021-08-13 18:31:13,829 - mmseg - INFO - Iter [19400/160000]	lr: 8.913e-03, eta: 2 days, 5:03:39, time: 1.317, data_time: 0.016, memory: 6005, decode.loss_seg: 1.1123, decode.acc_seg: 50.9576, loss: 1.1123
2021-08-13 18:32:19,332 - mmseg - INFO - Iter [19450/160000]	lr: 8.910e-03, eta: 2 days, 5:02:13, time: 1.310, data_time: 0.015, memory: 6005, decode.loss_seg: 1.1015, decode.acc_seg: 50.4235, loss: 1.1015
2021-08-13 18:33:24,846 - mmseg - INFO - Iter [19500/160000]	lr: 8.907e-03, eta: 2 days, 5:00:48, time: 1.310, data_time: 0.016, memory: 6005, decode.loss_seg: 1.1229, decode.acc_seg: 50.7851, loss: 1.1229
2021-08-13 18:34:31,658 - mmseg - INFO - Iter [19550/160000]	lr: 8.904e-03, eta: 2 days, 4:59:32, time: 1.336, data_time: 0.016, memory: 6005, decode.loss_seg: 1.1730, decode.acc_seg: 51.0246, loss: 1.1730
2021-08-13 18:36:11,183 - mmseg - INFO - Iter [19600/160000]	lr: 8.902e-03, eta: 2 days, 5:02:11, time: 1.991, data_time: 0.719, memory: 6005, decode.loss_seg: 1.1341, decode.acc_seg: 50.3129, loss: 1.1341
2021-08-13 18:37:17,793 - mmseg - INFO - Iter [19650/160000]	lr: 8.899e-03, eta: 2 days, 5:00:53, time: 1.332, data_time: 0.015, memory: 6005, decode.loss_seg: 1.1458, decode.acc_seg: 49.9326, loss: 1.1458
2021-08-13 18:38:24,437 - mmseg - INFO - Iter [19700/160000]	lr: 8.896e-03, eta: 2 days, 4:59:35, time: 1.332, data_time: 0.014, memory: 6005, decode.loss_seg: 1.1066, decode.acc_seg: 51.5077, loss: 1.1066
2021-08-13 18:39:29,879 - mmseg - INFO - Iter [19750/160000]	lr: 8.893e-03, eta: 2 days, 4:58:09, time: 1.310, data_time: 0.015, memory: 6005, decode.loss_seg: 1.1399, decode.acc_seg: 50.2523, loss: 1.1399
2021-08-13 18:40:32,550 - mmseg - INFO - Iter [19800/160000]	lr: 8.890e-03, eta: 2 days, 4:56:24, time: 1.253, data_time: 0.015, memory: 6005, decode.loss_seg: 1.1207, decode.acc_seg: 50.3061, loss: 1.1207
2021-08-13 18:41:34,734 - mmseg - INFO - Iter [19850/160000]	lr: 8.887e-03, eta: 2 days, 4:54:35, time: 1.244, data_time: 0.017, memory: 6005, decode.loss_seg: 1.1466, decode.acc_seg: 50.0252, loss: 1.1466
2021-08-13 18:42:37,772 - mmseg - INFO - Iter [19900/160000]	lr: 8.885e-03, eta: 2 days, 4:52:52, time: 1.260, data_time: 0.015, memory: 6005, decode.loss_seg: 1.1554, decode.acc_seg: 50.3190, loss: 1.1554
2021-08-13 18:43:42,804 - mmseg - INFO - Iter [19950/160000]	lr: 8.882e-03, eta: 2 days, 4:51:24, time: 1.300, data_time: 0.016, memory: 6005, decode.loss_seg: 1.1192, decode.acc_seg: 51.1994, loss: 1.1192
2021-08-13 18:44:47,279 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-without-head_512x512_160k_ade20k.py
2021-08-13 18:44:47,279 - mmseg - INFO - Iter [20000/160000]	lr: 8.879e-03, eta: 2 days, 4:49:52, time: 1.290, data_time: 0.016, memory: 6005, decode.loss_seg: 1.1216, decode.acc_seg: 50.6925, loss: 1.1216
2021-08-13 18:45:51,786 - mmseg - INFO - Iter [20050/160000]	lr: 8.876e-03, eta: 2 days, 4:48:20, time: 1.290, data_time: 0.013, memory: 6005, decode.loss_seg: 1.1035, decode.acc_seg: 51.5297, loss: 1.1035
2021-08-13 18:46:55,467 - mmseg - INFO - Iter [20100/160000]	lr: 8.873e-03, eta: 2 days, 4:46:42, time: 1.273, data_time: 0.015, memory: 6005, decode.loss_seg: 1.1468, decode.acc_seg: 51.2175, loss: 1.1468
2021-08-13 18:48:01,163 - mmseg - INFO - Iter [20150/160000]	lr: 8.871e-03, eta: 2 days, 4:45:19, time: 1.314, data_time: 0.015, memory: 6005, decode.loss_seg: 1.1249, decode.acc_seg: 51.1886, loss: 1.1249
2021-08-13 18:49:40,192 - mmseg - INFO - Iter [20200/160000]	lr: 8.868e-03, eta: 2 days, 4:47:47, time: 1.981, data_time: 0.731, memory: 6005, decode.loss_seg: 1.1335, decode.acc_seg: 51.1767, loss: 1.1335
2021-08-13 18:50:44,497 - mmseg - INFO - Iter [20250/160000]	lr: 8.865e-03, eta: 2 days, 4:46:14, time: 1.286, data_time: 0.017, memory: 6005, decode.loss_seg: 1.0863, decode.acc_seg: 51.4592, loss: 1.0863
2021-08-13 18:51:47,381 - mmseg - INFO - Iter [20300/160000]	lr: 8.862e-03, eta: 2 days, 4:44:30, time: 1.256, data_time: 0.016, memory: 6005, decode.loss_seg: 1.1443, decode.acc_seg: 51.1766, loss: 1.1443
2021-08-13 18:52:51,274 - mmseg - INFO - Iter [20350/160000]	lr: 8.859e-03, eta: 2 days, 4:42:55, time: 1.279, data_time: 0.016, memory: 6005, decode.loss_seg: 1.0822, decode.acc_seg: 51.4974, loss: 1.0822
2021-08-13 18:53:54,690 - mmseg - INFO - Iter [20400/160000]	lr: 8.856e-03, eta: 2 days, 4:41:16, time: 1.268, data_time: 0.016, memory: 6005, decode.loss_seg: 1.1483, decode.acc_seg: 50.3967, loss: 1.1483
2021-08-13 18:54:58,873 - mmseg - INFO - Iter [20450/160000]	lr: 8.854e-03, eta: 2 days, 4:39:42, time: 1.284, data_time: 0.016, memory: 6005, decode.loss_seg: 1.1167, decode.acc_seg: 51.6275, loss: 1.1167
2021-08-13 18:56:03,030 - mmseg - INFO - Iter [20500/160000]	lr: 8.851e-03, eta: 2 days, 4:38:09, time: 1.283, data_time: 0.015, memory: 6005, decode.loss_seg: 1.1437, decode.acc_seg: 51.0531, loss: 1.1437
2021-08-13 18:57:05,630 - mmseg - INFO - Iter [20550/160000]	lr: 8.848e-03, eta: 2 days, 4:36:25, time: 1.252, data_time: 0.015, memory: 6005, decode.loss_seg: 1.1040, decode.acc_seg: 50.5914, loss: 1.1040
2021-08-13 18:58:09,589 - mmseg - INFO - Iter [20600/160000]	lr: 8.845e-03, eta: 2 days, 4:34:50, time: 1.279, data_time: 0.014, memory: 6005, decode.loss_seg: 1.1264, decode.acc_seg: 50.9724, loss: 1.1264
2021-08-13 18:59:13,184 - mmseg - INFO - Iter [20650/160000]	lr: 8.842e-03, eta: 2 days, 4:33:13, time: 1.271, data_time: 0.016, memory: 6005, decode.loss_seg: 1.1204, decode.acc_seg: 50.0195, loss: 1.1204
2021-08-13 19:00:17,567 - mmseg - INFO - Iter [20700/160000]	lr: 8.839e-03, eta: 2 days, 4:31:42, time: 1.289, data_time: 0.017, memory: 6005, decode.loss_seg: 1.1190, decode.acc_seg: 51.3507, loss: 1.1190
2021-08-13 19:01:21,406 - mmseg - INFO - Iter [20750/160000]	lr: 8.837e-03, eta: 2 days, 4:30:07, time: 1.276, data_time: 0.017, memory: 6005, decode.loss_seg: 1.1336, decode.acc_seg: 50.4639, loss: 1.1336
2021-08-13 19:02:25,049 - mmseg - INFO - Iter [20800/160000]	lr: 8.834e-03, eta: 2 days, 4:28:31, time: 1.273, data_time: 0.016, memory: 6005, decode.loss_seg: 1.1205, decode.acc_seg: 50.7698, loss: 1.1205
2021-08-13 19:04:06,006 - mmseg - INFO - Iter [20850/160000]	lr: 8.831e-03, eta: 2 days, 4:31:03, time: 2.018, data_time: 0.702, memory: 6005, decode.loss_seg: 1.1075, decode.acc_seg: 51.7606, loss: 1.1075
2021-08-13 19:05:11,619 - mmseg - INFO - Iter [20900/160000]	lr: 8.828e-03, eta: 2 days, 4:29:40, time: 1.312, data_time: 0.017, memory: 6005, decode.loss_seg: 1.0795, decode.acc_seg: 50.5698, loss: 1.0795
2021-08-13 19:06:17,136 - mmseg - INFO - Iter [20950/160000]	lr: 8.825e-03, eta: 2 days, 4:28:16, time: 1.310, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0625, decode.acc_seg: 52.7097, loss: 1.0625
2021-08-13 19:07:20,831 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-without-head_512x512_160k_ade20k.py
2021-08-13 19:07:20,831 - mmseg - INFO - Iter [21000/160000]	lr: 8.823e-03, eta: 2 days, 4:26:40, time: 1.275, data_time: 0.016, memory: 6005, decode.loss_seg: 1.1112, decode.acc_seg: 52.5167, loss: 1.1112
2021-08-13 19:08:25,144 - mmseg - INFO - Iter [21050/160000]	lr: 8.820e-03, eta: 2 days, 4:25:08, time: 1.286, data_time: 0.015, memory: 6005, decode.loss_seg: 1.1188, decode.acc_seg: 50.5616, loss: 1.1188
2021-08-13 19:09:29,548 - mmseg - INFO - Iter [21100/160000]	lr: 8.817e-03, eta: 2 days, 4:23:38, time: 1.289, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0950, decode.acc_seg: 50.9772, loss: 1.0950
2021-08-13 19:10:35,433 - mmseg - INFO - Iter [21150/160000]	lr: 8.814e-03, eta: 2 days, 4:22:16, time: 1.316, data_time: 0.014, memory: 6005, decode.loss_seg: 1.1413, decode.acc_seg: 50.4949, loss: 1.1413
2021-08-13 19:11:39,030 - mmseg - INFO - Iter [21200/160000]	lr: 8.811e-03, eta: 2 days, 4:20:41, time: 1.273, data_time: 0.017, memory: 6005, decode.loss_seg: 1.1153, decode.acc_seg: 51.8500, loss: 1.1153
2021-08-13 19:12:42,295 - mmseg - INFO - Iter [21250/160000]	lr: 8.808e-03, eta: 2 days, 4:19:03, time: 1.265, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0987, decode.acc_seg: 51.1791, loss: 1.0987
2021-08-13 19:13:46,234 - mmseg - INFO - Iter [21300/160000]	lr: 8.806e-03, eta: 2 days, 4:17:29, time: 1.279, data_time: 0.015, memory: 6005, decode.loss_seg: 1.1445, decode.acc_seg: 49.5282, loss: 1.1445
2021-08-13 19:14:49,267 - mmseg - INFO - Iter [21350/160000]	lr: 8.803e-03, eta: 2 days, 4:15:50, time: 1.261, data_time: 0.016, memory: 6005, decode.loss_seg: 1.1446, decode.acc_seg: 50.4435, loss: 1.1446
2021-08-13 19:15:53,050 - mmseg - INFO - Iter [21400/160000]	lr: 8.800e-03, eta: 2 days, 4:14:15, time: 1.275, data_time: 0.016, memory: 6005, decode.loss_seg: 1.1438, decode.acc_seg: 50.0429, loss: 1.1438
2021-08-13 19:16:58,819 - mmseg - INFO - Iter [21450/160000]	lr: 8.797e-03, eta: 2 days, 4:12:54, time: 1.316, data_time: 0.015, memory: 6005, decode.loss_seg: 1.1304, decode.acc_seg: 50.2167, loss: 1.1304
2021-08-13 19:18:39,654 - mmseg - INFO - Iter [21500/160000]	lr: 8.794e-03, eta: 2 days, 4:15:19, time: 2.017, data_time: 0.729, memory: 6005, decode.loss_seg: 1.0865, decode.acc_seg: 51.4778, loss: 1.0865
2021-08-13 19:19:43,459 - mmseg - INFO - Iter [21550/160000]	lr: 8.791e-03, eta: 2 days, 4:13:45, time: 1.276, data_time: 0.016, memory: 6005, decode.loss_seg: 1.1202, decode.acc_seg: 50.7768, loss: 1.1202
2021-08-13 19:20:46,281 - mmseg - INFO - Iter [21600/160000]	lr: 8.789e-03, eta: 2 days, 4:12:04, time: 1.256, data_time: 0.016, memory: 6005, decode.loss_seg: 1.0819, decode.acc_seg: 51.3349, loss: 1.0819
2021-08-13 19:21:49,406 - mmseg - INFO - Iter [21650/160000]	lr: 8.786e-03, eta: 2 days, 4:10:26, time: 1.263, data_time: 0.016, memory: 6005, decode.loss_seg: 1.1191, decode.acc_seg: 52.0125, loss: 1.1191
2021-08-13 19:22:52,205 - mmseg - INFO - Iter [21700/160000]	lr: 8.783e-03, eta: 2 days, 4:08:46, time: 1.256, data_time: 0.014, memory: 6005, decode.loss_seg: 1.1393, decode.acc_seg: 50.5132, loss: 1.1393
2021-08-13 19:23:57,389 - mmseg - INFO - Iter [21750/160000]	lr: 8.780e-03, eta: 2 days, 4:07:21, time: 1.303, data_time: 0.014, memory: 6005, decode.loss_seg: 1.0782, decode.acc_seg: 51.6939, loss: 1.0782
2021-08-13 19:25:00,842 - mmseg - INFO - Iter [21800/160000]	lr: 8.777e-03, eta: 2 days, 4:05:45, time: 1.269, data_time: 0.016, memory: 6005, decode.loss_seg: 1.1503, decode.acc_seg: 49.6322, loss: 1.1503
2021-08-13 19:26:05,557 - mmseg - INFO - Iter [21850/160000]	lr: 8.775e-03, eta: 2 days, 4:04:17, time: 1.294, data_time: 0.014, memory: 6005, decode.loss_seg: 1.1066, decode.acc_seg: 51.7051, loss: 1.1066
2021-08-13 19:27:08,671 - mmseg - INFO - Iter [21900/160000]	lr: 8.772e-03, eta: 2 days, 4:02:39, time: 1.261, data_time: 0.016, memory: 6005, decode.loss_seg: 1.0771, decode.acc_seg: 52.2845, loss: 1.0771
2021-08-13 19:28:13,513 - mmseg - INFO - Iter [21950/160000]	lr: 8.769e-03, eta: 2 days, 4:01:13, time: 1.297, data_time: 0.016, memory: 6005, decode.loss_seg: 1.1270, decode.acc_seg: 50.6817, loss: 1.1270
2021-08-13 19:29:16,056 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-without-head_512x512_160k_ade20k.py
2021-08-13 19:29:16,056 - mmseg - INFO - Iter [22000/160000]	lr: 8.766e-03, eta: 2 days, 3:59:32, time: 1.252, data_time: 0.015, memory: 6005, decode.loss_seg: 1.1013, decode.acc_seg: 51.8192, loss: 1.1013
2021-08-13 19:30:19,305 - mmseg - INFO - Iter [22050/160000]	lr: 8.763e-03, eta: 2 days, 3:57:55, time: 1.264, data_time: 0.015, memory: 6005, decode.loss_seg: 1.1573, decode.acc_seg: 51.4157, loss: 1.1573
2021-08-13 19:31:59,061 - mmseg - INFO - Iter [22100/160000]	lr: 8.760e-03, eta: 2 days, 4:00:07, time: 1.994, data_time: 0.742, memory: 6005, decode.loss_seg: 1.1144, decode.acc_seg: 50.4719, loss: 1.1144
2021-08-13 19:33:05,393 - mmseg - INFO - Iter [22150/160000]	lr: 8.758e-03, eta: 2 days, 3:58:49, time: 1.327, data_time: 0.017, memory: 6005, decode.loss_seg: 1.0894, decode.acc_seg: 51.1684, loss: 1.0894
2021-08-13 19:34:09,285 - mmseg - INFO - Iter [22200/160000]	lr: 8.755e-03, eta: 2 days, 3:57:17, time: 1.278, data_time: 0.016, memory: 6005, decode.loss_seg: 1.0988, decode.acc_seg: 52.4279, loss: 1.0988
2021-08-13 19:35:15,416 - mmseg - INFO - Iter [22250/160000]	lr: 8.752e-03, eta: 2 days, 3:55:58, time: 1.323, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0605, decode.acc_seg: 51.6162, loss: 1.0605
2021-08-13 19:36:21,988 - mmseg - INFO - Iter [22300/160000]	lr: 8.749e-03, eta: 2 days, 3:54:42, time: 1.332, data_time: 0.016, memory: 6005, decode.loss_seg: 1.0936, decode.acc_seg: 51.2898, loss: 1.0936
2021-08-13 19:37:25,285 - mmseg - INFO - Iter [22350/160000]	lr: 8.746e-03, eta: 2 days, 3:53:06, time: 1.265, data_time: 0.016, memory: 6005, decode.loss_seg: 1.0612, decode.acc_seg: 51.0241, loss: 1.0612
2021-08-13 19:38:31,215 - mmseg - INFO - Iter [22400/160000]	lr: 8.743e-03, eta: 2 days, 3:51:47, time: 1.319, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0789, decode.acc_seg: 51.9272, loss: 1.0789
2021-08-13 19:39:36,555 - mmseg - INFO - Iter [22450/160000]	lr: 8.741e-03, eta: 2 days, 3:50:24, time: 1.308, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0690, decode.acc_seg: 52.1064, loss: 1.0690
2021-08-13 19:40:40,295 - mmseg - INFO - Iter [22500/160000]	lr: 8.738e-03, eta: 2 days, 3:48:51, time: 1.274, data_time: 0.014, memory: 6005, decode.loss_seg: 1.1111, decode.acc_seg: 51.2550, loss: 1.1111
2021-08-13 19:41:45,621 - mmseg - INFO - Iter [22550/160000]	lr: 8.735e-03, eta: 2 days, 3:47:28, time: 1.307, data_time: 0.017, memory: 6005, decode.loss_seg: 1.1332, decode.acc_seg: 50.7977, loss: 1.1332
2021-08-13 19:42:48,044 - mmseg - INFO - Iter [22600/160000]	lr: 8.732e-03, eta: 2 days, 3:45:47, time: 1.248, data_time: 0.014, memory: 6005, decode.loss_seg: 1.1392, decode.acc_seg: 51.9002, loss: 1.1392
2021-08-13 19:43:55,079 - mmseg - INFO - Iter [22650/160000]	lr: 8.729e-03, eta: 2 days, 3:44:34, time: 1.340, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0934, decode.acc_seg: 51.8222, loss: 1.0934
2021-08-13 19:45:01,183 - mmseg - INFO - Iter [22700/160000]	lr: 8.726e-03, eta: 2 days, 3:43:16, time: 1.323, data_time: 0.016, memory: 6005, decode.loss_seg: 1.0957, decode.acc_seg: 50.0592, loss: 1.0957
2021-08-13 19:46:40,139 - mmseg - INFO - Iter [22750/160000]	lr: 8.724e-03, eta: 2 days, 3:45:17, time: 1.980, data_time: 0.715, memory: 6005, decode.loss_seg: 1.0847, decode.acc_seg: 51.2302, loss: 1.0847
2021-08-13 19:47:43,009 - mmseg - INFO - Iter [22800/160000]	lr: 8.721e-03, eta: 2 days, 3:43:38, time: 1.256, data_time: 0.016, memory: 6005, decode.loss_seg: 1.0592, decode.acc_seg: 51.1509, loss: 1.0592
2021-08-13 19:48:45,673 - mmseg - INFO - Iter [22850/160000]	lr: 8.718e-03, eta: 2 days, 3:42:00, time: 1.255, data_time: 0.017, memory: 6005, decode.loss_seg: 1.1118, decode.acc_seg: 51.2428, loss: 1.1118
2021-08-13 19:49:50,261 - mmseg - INFO - Iter [22900/160000]	lr: 8.715e-03, eta: 2 days, 3:40:32, time: 1.292, data_time: 0.016, memory: 6005, decode.loss_seg: 1.0876, decode.acc_seg: 52.3288, loss: 1.0876
2021-08-13 19:50:54,059 - mmseg - INFO - Iter [22950/160000]	lr: 8.712e-03, eta: 2 days, 3:39:00, time: 1.276, data_time: 0.016, memory: 6005, decode.loss_seg: 1.0847, decode.acc_seg: 49.9694, loss: 1.0847
2021-08-13 19:51:57,823 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-without-head_512x512_160k_ade20k.py
2021-08-13 19:51:57,824 - mmseg - INFO - Iter [23000/160000]	lr: 8.710e-03, eta: 2 days, 3:37:28, time: 1.276, data_time: 0.016, memory: 6005, decode.loss_seg: 1.0973, decode.acc_seg: 51.3200, loss: 1.0973
2021-08-13 19:53:02,875 - mmseg - INFO - Iter [23050/160000]	lr: 8.707e-03, eta: 2 days, 3:36:03, time: 1.300, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0861, decode.acc_seg: 53.0610, loss: 1.0861
2021-08-13 19:54:06,362 - mmseg - INFO - Iter [23100/160000]	lr: 8.704e-03, eta: 2 days, 3:34:30, time: 1.271, data_time: 0.017, memory: 6005, decode.loss_seg: 1.0731, decode.acc_seg: 51.1934, loss: 1.0731
2021-08-13 19:55:11,080 - mmseg - INFO - Iter [23150/160000]	lr: 8.701e-03, eta: 2 days, 3:33:04, time: 1.294, data_time: 0.014, memory: 6005, decode.loss_seg: 1.0824, decode.acc_seg: 51.6601, loss: 1.0824
2021-08-13 19:56:17,249 - mmseg - INFO - Iter [23200/160000]	lr: 8.698e-03, eta: 2 days, 3:31:46, time: 1.323, data_time: 0.015, memory: 6005, decode.loss_seg: 1.1083, decode.acc_seg: 50.7362, loss: 1.1083
2021-08-13 19:57:22,236 - mmseg - INFO - Iter [23250/160000]	lr: 8.695e-03, eta: 2 days, 3:30:22, time: 1.300, data_time: 0.016, memory: 6005, decode.loss_seg: 1.1064, decode.acc_seg: 51.0048, loss: 1.1064
2021-08-13 19:58:27,214 - mmseg - INFO - Iter [23300/160000]	lr: 8.693e-03, eta: 2 days, 3:28:58, time: 1.300, data_time: 0.017, memory: 6005, decode.loss_seg: 1.1127, decode.acc_seg: 51.3814, loss: 1.1127
2021-08-13 20:00:07,671 - mmseg - INFO - Iter [23350/160000]	lr: 8.690e-03, eta: 2 days, 3:31:01, time: 2.009, data_time: 0.710, memory: 6005, decode.loss_seg: 1.1167, decode.acc_seg: 50.9470, loss: 1.1167
2021-08-13 20:01:13,368 - mmseg - INFO - Iter [23400/160000]	lr: 8.687e-03, eta: 2 days, 3:29:41, time: 1.315, data_time: 0.016, memory: 6005, decode.loss_seg: 1.1022, decode.acc_seg: 51.6118, loss: 1.1022
2021-08-13 20:02:17,865 - mmseg - INFO - Iter [23450/160000]	lr: 8.684e-03, eta: 2 days, 3:28:13, time: 1.289, data_time: 0.014, memory: 6005, decode.loss_seg: 1.1288, decode.acc_seg: 51.5303, loss: 1.1288
2021-08-13 20:03:24,047 - mmseg - INFO - Iter [23500/160000]	lr: 8.681e-03, eta: 2 days, 3:26:56, time: 1.324, data_time: 0.014, memory: 6005, decode.loss_seg: 1.0972, decode.acc_seg: 52.2161, loss: 1.0972
2021-08-13 20:04:25,863 - mmseg - INFO - Iter [23550/160000]	lr: 8.678e-03, eta: 2 days, 3:25:13, time: 1.237, data_time: 0.014, memory: 6005, decode.loss_seg: 1.0670, decode.acc_seg: 50.6004, loss: 1.0670
2021-08-13 20:05:28,024 - mmseg - INFO - Iter [23600/160000]	lr: 8.676e-03, eta: 2 days, 3:23:32, time: 1.243, data_time: 0.015, memory: 6005, decode.loss_seg: 1.1008, decode.acc_seg: 51.3122, loss: 1.1008
2021-08-13 20:06:31,037 - mmseg - INFO - Iter [23650/160000]	lr: 8.673e-03, eta: 2 days, 3:21:57, time: 1.260, data_time: 0.015, memory: 6005, decode.loss_seg: 1.1001, decode.acc_seg: 50.5847, loss: 1.1001
2021-08-13 20:07:35,838 - mmseg - INFO - Iter [23700/160000]	lr: 8.670e-03, eta: 2 days, 3:20:32, time: 1.297, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0622, decode.acc_seg: 51.9978, loss: 1.0622
2021-08-13 20:08:41,995 - mmseg - INFO - Iter [23750/160000]	lr: 8.667e-03, eta: 2 days, 3:19:14, time: 1.322, data_time: 0.014, memory: 6005, decode.loss_seg: 1.0591, decode.acc_seg: 51.7925, loss: 1.0591
2021-08-13 20:09:47,254 - mmseg - INFO - Iter [23800/160000]	lr: 8.664e-03, eta: 2 days, 3:17:52, time: 1.306, data_time: 0.016, memory: 6005, decode.loss_seg: 1.1322, decode.acc_seg: 50.8195, loss: 1.1322
2021-08-13 20:10:51,776 - mmseg - INFO - Iter [23850/160000]	lr: 8.661e-03, eta: 2 days, 3:16:26, time: 1.290, data_time: 0.014, memory: 6005, decode.loss_seg: 1.1213, decode.acc_seg: 51.6795, loss: 1.1213
2021-08-13 20:11:56,114 - mmseg - INFO - Iter [23900/160000]	lr: 8.659e-03, eta: 2 days, 3:14:58, time: 1.287, data_time: 0.017, memory: 6005, decode.loss_seg: 1.1084, decode.acc_seg: 51.1212, loss: 1.1084
2021-08-13 20:13:00,609 - mmseg - INFO - Iter [23950/160000]	lr: 8.656e-03, eta: 2 days, 3:13:32, time: 1.289, data_time: 0.016, memory: 6005, decode.loss_seg: 1.1216, decode.acc_seg: 51.5013, loss: 1.1216
2021-08-13 20:14:38,622 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-without-head_512x512_160k_ade20k.py
2021-08-13 20:14:38,626 - mmseg - INFO - Iter [24000/160000]	lr: 8.653e-03, eta: 2 days, 3:15:15, time: 1.961, data_time: 0.701, memory: 6005, decode.loss_seg: 1.0884, decode.acc_seg: 51.7345, loss: 1.0884
2021-08-13 20:15:42,316 - mmseg - INFO - Iter [24050/160000]	lr: 8.650e-03, eta: 2 days, 3:13:44, time: 1.274, data_time: 0.014, memory: 6005, decode.loss_seg: 1.0769, decode.acc_seg: 51.9307, loss: 1.0769
2021-08-13 20:16:45,914 - mmseg - INFO - Iter [24100/160000]	lr: 8.647e-03, eta: 2 days, 3:12:12, time: 1.272, data_time: 0.014, memory: 6005, decode.loss_seg: 1.0816, decode.acc_seg: 51.1544, loss: 1.0816
2021-08-13 20:17:49,737 - mmseg - INFO - Iter [24150/160000]	lr: 8.644e-03, eta: 2 days, 3:10:42, time: 1.276, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0769, decode.acc_seg: 51.7875, loss: 1.0769
2021-08-13 20:18:54,708 - mmseg - INFO - Iter [24200/160000]	lr: 8.642e-03, eta: 2 days, 3:09:18, time: 1.299, data_time: 0.017, memory: 6005, decode.loss_seg: 1.0778, decode.acc_seg: 52.2329, loss: 1.0778
2021-08-13 20:19:59,493 - mmseg - INFO - Iter [24250/160000]	lr: 8.639e-03, eta: 2 days, 3:07:53, time: 1.296, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0727, decode.acc_seg: 52.0326, loss: 1.0727
2021-08-13 20:21:02,912 - mmseg - INFO - Iter [24300/160000]	lr: 8.636e-03, eta: 2 days, 3:06:21, time: 1.269, data_time: 0.016, memory: 6005, decode.loss_seg: 1.0970, decode.acc_seg: 50.4447, loss: 1.0970
2021-08-13 20:22:07,780 - mmseg - INFO - Iter [24350/160000]	lr: 8.633e-03, eta: 2 days, 3:04:57, time: 1.297, data_time: 0.015, memory: 6005, decode.loss_seg: 1.1003, decode.acc_seg: 51.4959, loss: 1.1003
2021-08-13 20:23:15,138 - mmseg - INFO - Iter [24400/160000]	lr: 8.630e-03, eta: 2 days, 3:03:47, time: 1.347, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0643, decode.acc_seg: 51.9911, loss: 1.0643
2021-08-13 20:24:18,438 - mmseg - INFO - Iter [24450/160000]	lr: 8.627e-03, eta: 2 days, 3:02:15, time: 1.267, data_time: 0.017, memory: 6005, decode.loss_seg: 1.1288, decode.acc_seg: 50.5189, loss: 1.1288
2021-08-13 20:25:22,503 - mmseg - INFO - Iter [24500/160000]	lr: 8.625e-03, eta: 2 days, 3:00:46, time: 1.281, data_time: 0.014, memory: 6005, decode.loss_seg: 1.0906, decode.acc_seg: 51.6438, loss: 1.0906
2021-08-13 20:26:26,182 - mmseg - INFO - Iter [24550/160000]	lr: 8.622e-03, eta: 2 days, 2:59:16, time: 1.274, data_time: 0.016, memory: 6005, decode.loss_seg: 1.1105, decode.acc_seg: 51.5171, loss: 1.1105
2021-08-13 20:27:30,343 - mmseg - INFO - Iter [24600/160000]	lr: 8.619e-03, eta: 2 days, 2:57:48, time: 1.283, data_time: 0.014, memory: 6005, decode.loss_seg: 1.1210, decode.acc_seg: 50.7995, loss: 1.1210
2021-08-13 20:29:08,771 - mmseg - INFO - Iter [24650/160000]	lr: 8.616e-03, eta: 2 days, 2:59:29, time: 1.968, data_time: 0.725, memory: 6005, decode.loss_seg: 1.0982, decode.acc_seg: 51.8945, loss: 1.0982
2021-08-13 20:30:13,413 - mmseg - INFO - Iter [24700/160000]	lr: 8.613e-03, eta: 2 days, 2:58:04, time: 1.292, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0670, decode.acc_seg: 51.2920, loss: 1.0670
2021-08-13 20:31:18,419 - mmseg - INFO - Iter [24750/160000]	lr: 8.610e-03, eta: 2 days, 2:56:41, time: 1.301, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0565, decode.acc_seg: 52.1685, loss: 1.0565
2021-08-13 20:32:23,500 - mmseg - INFO - Iter [24800/160000]	lr: 8.608e-03, eta: 2 days, 2:55:18, time: 1.301, data_time: 0.016, memory: 6005, decode.loss_seg: 1.0602, decode.acc_seg: 52.3426, loss: 1.0602
2021-08-13 20:33:28,647 - mmseg - INFO - Iter [24850/160000]	lr: 8.605e-03, eta: 2 days, 2:53:56, time: 1.302, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0642, decode.acc_seg: 51.7597, loss: 1.0642
2021-08-13 20:34:35,169 - mmseg - INFO - Iter [24900/160000]	lr: 8.602e-03, eta: 2 days, 2:52:41, time: 1.332, data_time: 0.017, memory: 6005, decode.loss_seg: 1.0906, decode.acc_seg: 51.1926, loss: 1.0906
2021-08-13 20:35:37,857 - mmseg - INFO - Iter [24950/160000]	lr: 8.599e-03, eta: 2 days, 2:51:06, time: 1.254, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0716, decode.acc_seg: 52.6449, loss: 1.0716
2021-08-13 20:36:41,275 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-without-head_512x512_160k_ade20k.py
2021-08-13 20:36:41,276 - mmseg - INFO - Iter [25000/160000]	lr: 8.596e-03, eta: 2 days, 2:49:35, time: 1.268, data_time: 0.016, memory: 6005, decode.loss_seg: 1.1084, decode.acc_seg: 51.7519, loss: 1.1084
2021-08-13 20:37:44,507 - mmseg - INFO - Iter [25050/160000]	lr: 8.593e-03, eta: 2 days, 2:48:02, time: 1.265, data_time: 0.015, memory: 6005, decode.loss_seg: 1.1036, decode.acc_seg: 50.9496, loss: 1.1036
2021-08-13 20:38:49,326 - mmseg - INFO - Iter [25100/160000]	lr: 8.591e-03, eta: 2 days, 2:46:38, time: 1.295, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0890, decode.acc_seg: 52.4565, loss: 1.0890
2021-08-13 20:39:54,020 - mmseg - INFO - Iter [25150/160000]	lr: 8.588e-03, eta: 2 days, 2:45:14, time: 1.294, data_time: 0.016, memory: 6005, decode.loss_seg: 1.0531, decode.acc_seg: 51.8188, loss: 1.0531
2021-08-13 20:40:59,476 - mmseg - INFO - Iter [25200/160000]	lr: 8.585e-03, eta: 2 days, 2:43:55, time: 1.310, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0880, decode.acc_seg: 51.6490, loss: 1.0880
2021-08-13 20:42:38,521 - mmseg - INFO - Iter [25250/160000]	lr: 8.582e-03, eta: 2 days, 2:45:34, time: 1.981, data_time: 0.709, memory: 6005, decode.loss_seg: 1.0841, decode.acc_seg: 52.2273, loss: 1.0841
2021-08-13 20:43:43,455 - mmseg - INFO - Iter [25300/160000]	lr: 8.579e-03, eta: 2 days, 2:44:11, time: 1.299, data_time: 0.016, memory: 6005, decode.loss_seg: 1.0468, decode.acc_seg: 52.6896, loss: 1.0468
2021-08-13 20:44:47,195 - mmseg - INFO - Iter [25350/160000]	lr: 8.576e-03, eta: 2 days, 2:42:41, time: 1.275, data_time: 0.017, memory: 6005, decode.loss_seg: 1.0662, decode.acc_seg: 51.8624, loss: 1.0662
2021-08-13 20:45:51,687 - mmseg - INFO - Iter [25400/160000]	lr: 8.574e-03, eta: 2 days, 2:41:16, time: 1.290, data_time: 0.016, memory: 6005, decode.loss_seg: 1.0742, decode.acc_seg: 52.3429, loss: 1.0742
2021-08-13 20:46:57,655 - mmseg - INFO - Iter [25450/160000]	lr: 8.571e-03, eta: 2 days, 2:39:58, time: 1.319, data_time: 0.016, memory: 6005, decode.loss_seg: 1.0899, decode.acc_seg: 52.4044, loss: 1.0899
2021-08-13 20:48:06,385 - mmseg - INFO - Iter [25500/160000]	lr: 8.568e-03, eta: 2 days, 2:38:56, time: 1.375, data_time: 0.016, memory: 6005, decode.loss_seg: 1.0977, decode.acc_seg: 52.4748, loss: 1.0977
2021-08-13 20:49:11,154 - mmseg - INFO - Iter [25550/160000]	lr: 8.565e-03, eta: 2 days, 2:37:32, time: 1.297, data_time: 0.016, memory: 6005, decode.loss_seg: 1.0783, decode.acc_seg: 51.0037, loss: 1.0783
2021-08-13 20:50:15,565 - mmseg - INFO - Iter [25600/160000]	lr: 8.562e-03, eta: 2 days, 2:36:07, time: 1.288, data_time: 0.015, memory: 6005, decode.loss_seg: 1.1246, decode.acc_seg: 50.4124, loss: 1.1246
2021-08-13 20:51:20,188 - mmseg - INFO - Iter [25650/160000]	lr: 8.559e-03, eta: 2 days, 2:34:43, time: 1.292, data_time: 0.016, memory: 6005, decode.loss_seg: 1.0632, decode.acc_seg: 52.4386, loss: 1.0632
2021-08-13 20:52:23,210 - mmseg - INFO - Iter [25700/160000]	lr: 8.557e-03, eta: 2 days, 2:33:10, time: 1.260, data_time: 0.016, memory: 6005, decode.loss_seg: 1.0866, decode.acc_seg: 51.0291, loss: 1.0866
2021-08-13 20:53:30,935 - mmseg - INFO - Iter [25750/160000]	lr: 8.554e-03, eta: 2 days, 2:32:02, time: 1.355, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0987, decode.acc_seg: 51.1400, loss: 1.0987
2021-08-13 20:54:35,214 - mmseg - INFO - Iter [25800/160000]	lr: 8.551e-03, eta: 2 days, 2:30:36, time: 1.286, data_time: 0.016, memory: 6005, decode.loss_seg: 1.0659, decode.acc_seg: 51.7934, loss: 1.0659
2021-08-13 20:55:38,924 - mmseg - INFO - Iter [25850/160000]	lr: 8.548e-03, eta: 2 days, 2:29:08, time: 1.274, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0822, decode.acc_seg: 52.4302, loss: 1.0822
2021-08-13 20:57:18,640 - mmseg - INFO - Iter [25900/160000]	lr: 8.545e-03, eta: 2 days, 2:30:45, time: 1.995, data_time: 0.723, memory: 6005, decode.loss_seg: 1.0491, decode.acc_seg: 52.3734, loss: 1.0491
2021-08-13 20:58:21,345 - mmseg - INFO - Iter [25950/160000]	lr: 8.542e-03, eta: 2 days, 2:29:11, time: 1.254, data_time: 0.016, memory: 6005, decode.loss_seg: 1.0407, decode.acc_seg: 51.9700, loss: 1.0407
2021-08-13 20:59:23,748 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-without-head_512x512_160k_ade20k.py
2021-08-13 20:59:23,749 - mmseg - INFO - Iter [26000/160000]	lr: 8.540e-03, eta: 2 days, 2:27:36, time: 1.248, data_time: 0.016, memory: 6005, decode.loss_seg: 1.0363, decode.acc_seg: 52.3419, loss: 1.0363
2021-08-13 21:00:27,271 - mmseg - INFO - Iter [26050/160000]	lr: 8.537e-03, eta: 2 days, 2:26:06, time: 1.271, data_time: 0.017, memory: 6005, decode.loss_seg: 1.0742, decode.acc_seg: 51.8667, loss: 1.0742
2021-08-13 21:01:32,919 - mmseg - INFO - Iter [26100/160000]	lr: 8.534e-03, eta: 2 days, 2:24:47, time: 1.312, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0484, decode.acc_seg: 52.3867, loss: 1.0484
2021-08-13 21:02:41,164 - mmseg - INFO - Iter [26150/160000]	lr: 8.531e-03, eta: 2 days, 2:23:42, time: 1.366, data_time: 0.017, memory: 6005, decode.loss_seg: 1.0723, decode.acc_seg: 51.4428, loss: 1.0723
2021-08-13 21:03:44,570 - mmseg - INFO - Iter [26200/160000]	lr: 8.528e-03, eta: 2 days, 2:22:12, time: 1.268, data_time: 0.016, memory: 6005, decode.loss_seg: 1.0915, decode.acc_seg: 51.8829, loss: 1.0915
2021-08-13 21:04:47,489 - mmseg - INFO - Iter [26250/160000]	lr: 8.525e-03, eta: 2 days, 2:20:39, time: 1.258, data_time: 0.017, memory: 6005, decode.loss_seg: 1.0619, decode.acc_seg: 51.3424, loss: 1.0619
2021-08-13 21:05:50,276 - mmseg - INFO - Iter [26300/160000]	lr: 8.523e-03, eta: 2 days, 2:19:06, time: 1.256, data_time: 0.017, memory: 6005, decode.loss_seg: 1.0882, decode.acc_seg: 51.1481, loss: 1.0882
2021-08-13 21:06:54,391 - mmseg - INFO - Iter [26350/160000]	lr: 8.520e-03, eta: 2 days, 2:17:40, time: 1.282, data_time: 0.015, memory: 6005, decode.loss_seg: 1.1020, decode.acc_seg: 51.8319, loss: 1.1020
2021-08-13 21:07:57,709 - mmseg - INFO - Iter [26400/160000]	lr: 8.517e-03, eta: 2 days, 2:16:10, time: 1.266, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0822, decode.acc_seg: 53.0869, loss: 1.0822
2021-08-13 21:09:01,979 - mmseg - INFO - Iter [26450/160000]	lr: 8.514e-03, eta: 2 days, 2:14:45, time: 1.286, data_time: 0.016, memory: 6005, decode.loss_seg: 1.0803, decode.acc_seg: 51.6734, loss: 1.0803
2021-08-13 21:10:07,278 - mmseg - INFO - Iter [26500/160000]	lr: 8.511e-03, eta: 2 days, 2:13:25, time: 1.306, data_time: 0.014, memory: 6005, decode.loss_seg: 1.0668, decode.acc_seg: 51.9709, loss: 1.0668
2021-08-13 21:11:50,219 - mmseg - INFO - Iter [26550/160000]	lr: 8.508e-03, eta: 2 days, 2:15:14, time: 2.058, data_time: 0.727, memory: 6005, decode.loss_seg: 1.0138, decode.acc_seg: 52.8830, loss: 1.0138
2021-08-13 21:12:55,902 - mmseg - INFO - Iter [26600/160000]	lr: 8.506e-03, eta: 2 days, 2:13:56, time: 1.313, data_time: 0.016, memory: 6005, decode.loss_seg: 1.0739, decode.acc_seg: 51.3462, loss: 1.0739
2021-08-13 21:14:04,917 - mmseg - INFO - Iter [26650/160000]	lr: 8.503e-03, eta: 2 days, 2:12:54, time: 1.381, data_time: 0.016, memory: 6005, decode.loss_seg: 1.0732, decode.acc_seg: 51.5048, loss: 1.0732
2021-08-13 21:15:14,085 - mmseg - INFO - Iter [26700/160000]	lr: 8.500e-03, eta: 2 days, 2:11:53, time: 1.383, data_time: 0.016, memory: 6005, decode.loss_seg: 1.0735, decode.acc_seg: 51.4316, loss: 1.0735
2021-08-13 21:16:22,704 - mmseg - INFO - Iter [26750/160000]	lr: 8.497e-03, eta: 2 days, 2:10:50, time: 1.373, data_time: 0.017, memory: 6005, decode.loss_seg: 1.0252, decode.acc_seg: 52.9885, loss: 1.0252
2021-08-13 21:17:30,569 - mmseg - INFO - Iter [26800/160000]	lr: 8.494e-03, eta: 2 days, 2:09:42, time: 1.357, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0682, decode.acc_seg: 51.3802, loss: 1.0682
2021-08-13 21:18:37,252 - mmseg - INFO - Iter [26850/160000]	lr: 8.491e-03, eta: 2 days, 2:08:29, time: 1.334, data_time: 0.014, memory: 6005, decode.loss_seg: 1.0771, decode.acc_seg: 51.3360, loss: 1.0771
2021-08-13 21:19:42,137 - mmseg - INFO - Iter [26900/160000]	lr: 8.489e-03, eta: 2 days, 2:07:07, time: 1.297, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0651, decode.acc_seg: 52.0232, loss: 1.0651
2021-08-13 21:20:49,508 - mmseg - INFO - Iter [26950/160000]	lr: 8.486e-03, eta: 2 days, 2:05:57, time: 1.347, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0399, decode.acc_seg: 52.6084, loss: 1.0399
2021-08-13 21:21:57,543 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-without-head_512x512_160k_ade20k.py
2021-08-13 21:21:57,543 - mmseg - INFO - Iter [27000/160000]	lr: 8.483e-03, eta: 2 days, 2:04:51, time: 1.360, data_time: 0.016, memory: 6005, decode.loss_seg: 1.0782, decode.acc_seg: 52.2924, loss: 1.0782
2021-08-13 21:23:03,405 - mmseg - INFO - Iter [27050/160000]	lr: 8.480e-03, eta: 2 days, 2:03:34, time: 1.318, data_time: 0.017, memory: 6005, decode.loss_seg: 1.0614, decode.acc_seg: 52.0432, loss: 1.0614
2021-08-13 21:24:06,515 - mmseg - INFO - Iter [27100/160000]	lr: 8.477e-03, eta: 2 days, 2:02:03, time: 1.262, data_time: 0.017, memory: 6005, decode.loss_seg: 1.0952, decode.acc_seg: 51.9093, loss: 1.0952
2021-08-13 21:25:46,029 - mmseg - INFO - Iter [27150/160000]	lr: 8.474e-03, eta: 2 days, 2:03:31, time: 1.990, data_time: 0.729, memory: 6005, decode.loss_seg: 1.0740, decode.acc_seg: 52.5629, loss: 1.0740
2021-08-13 21:26:50,590 - mmseg - INFO - Iter [27200/160000]	lr: 8.472e-03, eta: 2 days, 2:02:07, time: 1.291, data_time: 0.014, memory: 6005, decode.loss_seg: 1.0906, decode.acc_seg: 50.8745, loss: 1.0906
2021-08-13 21:27:54,003 - mmseg - INFO - Iter [27250/160000]	lr: 8.469e-03, eta: 2 days, 2:00:37, time: 1.268, data_time: 0.014, memory: 6005, decode.loss_seg: 1.0504, decode.acc_seg: 52.5901, loss: 1.0504
2021-08-13 21:28:58,098 - mmseg - INFO - Iter [27300/160000]	lr: 8.466e-03, eta: 2 days, 1:59:12, time: 1.282, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0466, decode.acc_seg: 53.3673, loss: 1.0466
2021-08-13 21:30:02,111 - mmseg - INFO - Iter [27350/160000]	lr: 8.463e-03, eta: 2 days, 1:57:45, time: 1.280, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0407, decode.acc_seg: 52.2720, loss: 1.0407
2021-08-13 21:31:09,375 - mmseg - INFO - Iter [27400/160000]	lr: 8.460e-03, eta: 2 days, 1:56:35, time: 1.344, data_time: 0.014, memory: 6005, decode.loss_seg: 1.1075, decode.acc_seg: 50.8956, loss: 1.1075
2021-08-13 21:32:16,442 - mmseg - INFO - Iter [27450/160000]	lr: 8.457e-03, eta: 2 days, 1:55:24, time: 1.342, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0730, decode.acc_seg: 52.1092, loss: 1.0730
2021-08-13 21:33:21,439 - mmseg - INFO - Iter [27500/160000]	lr: 8.455e-03, eta: 2 days, 1:54:02, time: 1.300, data_time: 0.014, memory: 6005, decode.loss_seg: 1.0368, decode.acc_seg: 53.4524, loss: 1.0368
2021-08-13 21:34:25,363 - mmseg - INFO - Iter [27550/160000]	lr: 8.452e-03, eta: 2 days, 1:52:36, time: 1.279, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0822, decode.acc_seg: 51.5186, loss: 1.0822
2021-08-13 21:35:29,818 - mmseg - INFO - Iter [27600/160000]	lr: 8.449e-03, eta: 2 days, 1:51:12, time: 1.289, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0718, decode.acc_seg: 52.1875, loss: 1.0718
2021-08-13 21:36:33,673 - mmseg - INFO - Iter [27650/160000]	lr: 8.446e-03, eta: 2 days, 1:49:46, time: 1.277, data_time: 0.016, memory: 6005, decode.loss_seg: 1.0584, decode.acc_seg: 52.2234, loss: 1.0584
2021-08-13 21:37:37,934 - mmseg - INFO - Iter [27700/160000]	lr: 8.443e-03, eta: 2 days, 1:48:21, time: 1.285, data_time: 0.016, memory: 6005, decode.loss_seg: 1.0432, decode.acc_seg: 53.1981, loss: 1.0432
2021-08-13 21:38:40,986 - mmseg - INFO - Iter [27750/160000]	lr: 8.440e-03, eta: 2 days, 1:46:51, time: 1.262, data_time: 0.016, memory: 6005, decode.loss_seg: 1.0827, decode.acc_seg: 51.4064, loss: 1.0827
2021-08-13 21:40:20,420 - mmseg - INFO - Iter [27800/160000]	lr: 8.438e-03, eta: 2 days, 1:48:14, time: 1.988, data_time: 0.727, memory: 6005, decode.loss_seg: 1.0926, decode.acc_seg: 51.7158, loss: 1.0926
2021-08-13 21:41:26,056 - mmseg - INFO - Iter [27850/160000]	lr: 8.435e-03, eta: 2 days, 1:46:56, time: 1.313, data_time: 0.016, memory: 6005, decode.loss_seg: 1.0178, decode.acc_seg: 53.0073, loss: 1.0178
2021-08-13 21:42:30,248 - mmseg - INFO - Iter [27900/160000]	lr: 8.432e-03, eta: 2 days, 1:45:31, time: 1.283, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0436, decode.acc_seg: 52.3832, loss: 1.0436
2021-08-13 21:43:33,024 - mmseg - INFO - Iter [27950/160000]	lr: 8.429e-03, eta: 2 days, 1:43:59, time: 1.256, data_time: 0.016, memory: 6005, decode.loss_seg: 1.0528, decode.acc_seg: 52.3931, loss: 1.0528
2021-08-13 21:44:36,132 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-without-head_512x512_160k_ade20k.py
2021-08-13 21:44:36,133 - mmseg - INFO - Iter [28000/160000]	lr: 8.426e-03, eta: 2 days, 1:42:29, time: 1.262, data_time: 0.014, memory: 6005, decode.loss_seg: 1.0359, decode.acc_seg: 52.7577, loss: 1.0359
2021-08-13 21:45:39,861 - mmseg - INFO - Iter [28050/160000]	lr: 8.423e-03, eta: 2 days, 1:41:03, time: 1.275, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0501, decode.acc_seg: 52.7713, loss: 1.0501
2021-08-13 21:46:44,038 - mmseg - INFO - Iter [28100/160000]	lr: 8.421e-03, eta: 2 days, 1:39:38, time: 1.283, data_time: 0.013, memory: 6005, decode.loss_seg: 1.0492, decode.acc_seg: 52.1635, loss: 1.0492
2021-08-13 21:47:48,736 - mmseg - INFO - Iter [28150/160000]	lr: 8.418e-03, eta: 2 days, 1:38:16, time: 1.295, data_time: 0.014, memory: 6005, decode.loss_seg: 1.0294, decode.acc_seg: 52.9896, loss: 1.0294
2021-08-13 21:48:52,402 - mmseg - INFO - Iter [28200/160000]	lr: 8.415e-03, eta: 2 days, 1:36:49, time: 1.273, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0491, decode.acc_seg: 52.8943, loss: 1.0491
2021-08-13 21:49:57,059 - mmseg - INFO - Iter [28250/160000]	lr: 8.412e-03, eta: 2 days, 1:35:26, time: 1.292, data_time: 0.015, memory: 6005, decode.loss_seg: 1.1087, decode.acc_seg: 52.1426, loss: 1.1087
2021-08-13 21:51:02,928 - mmseg - INFO - Iter [28300/160000]	lr: 8.409e-03, eta: 2 days, 1:34:10, time: 1.318, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0116, decode.acc_seg: 52.9230, loss: 1.0116
2021-08-13 21:52:07,057 - mmseg - INFO - Iter [28350/160000]	lr: 8.406e-03, eta: 2 days, 1:32:45, time: 1.282, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0896, decode.acc_seg: 52.5459, loss: 1.0896
2021-08-13 21:53:44,713 - mmseg - INFO - Iter [28400/160000]	lr: 8.403e-03, eta: 2 days, 1:33:56, time: 1.953, data_time: 0.731, memory: 6005, decode.loss_seg: 1.0648, decode.acc_seg: 52.8608, loss: 1.0648
2021-08-13 21:54:50,111 - mmseg - INFO - Iter [28450/160000]	lr: 8.401e-03, eta: 2 days, 1:32:38, time: 1.308, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0599, decode.acc_seg: 52.2234, loss: 1.0599
2021-08-13 21:55:53,151 - mmseg - INFO - Iter [28500/160000]	lr: 8.398e-03, eta: 2 days, 1:31:08, time: 1.260, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0371, decode.acc_seg: 52.3922, loss: 1.0371
2021-08-13 21:56:58,211 - mmseg - INFO - Iter [28550/160000]	lr: 8.395e-03, eta: 2 days, 1:29:47, time: 1.301, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0532, decode.acc_seg: 52.0378, loss: 1.0532
2021-08-13 21:58:02,127 - mmseg - INFO - Iter [28600/160000]	lr: 8.392e-03, eta: 2 days, 1:28:22, time: 1.279, data_time: 0.016, memory: 6005, decode.loss_seg: 0.9972, decode.acc_seg: 53.3764, loss: 0.9972
2021-08-13 21:59:05,680 - mmseg - INFO - Iter [28650/160000]	lr: 8.389e-03, eta: 2 days, 1:26:55, time: 1.271, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0450, decode.acc_seg: 52.9646, loss: 1.0450
2021-08-13 22:00:10,758 - mmseg - INFO - Iter [28700/160000]	lr: 8.386e-03, eta: 2 days, 1:25:35, time: 1.301, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0686, decode.acc_seg: 52.1101, loss: 1.0686
2021-08-13 22:01:13,866 - mmseg - INFO - Iter [28750/160000]	lr: 8.384e-03, eta: 2 days, 1:24:06, time: 1.262, data_time: 0.016, memory: 6005, decode.loss_seg: 1.0160, decode.acc_seg: 52.9420, loss: 1.0160
2021-08-13 22:02:17,488 - mmseg - INFO - Iter [28800/160000]	lr: 8.381e-03, eta: 2 days, 1:22:39, time: 1.273, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0257, decode.acc_seg: 51.6577, loss: 1.0257
2021-08-13 22:03:21,690 - mmseg - INFO - Iter [28850/160000]	lr: 8.378e-03, eta: 2 days, 1:21:15, time: 1.284, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0447, decode.acc_seg: 53.1300, loss: 1.0447
2021-08-13 22:04:25,654 - mmseg - INFO - Iter [28900/160000]	lr: 8.375e-03, eta: 2 days, 1:19:51, time: 1.279, data_time: 0.014, memory: 6005, decode.loss_seg: 1.0642, decode.acc_seg: 51.7724, loss: 1.0642
2021-08-13 22:05:32,961 - mmseg - INFO - Iter [28950/160000]	lr: 8.372e-03, eta: 2 days, 1:18:41, time: 1.345, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0478, decode.acc_seg: 52.1824, loss: 1.0478
2021-08-13 22:06:40,844 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-without-head_512x512_160k_ade20k.py
2021-08-13 22:06:40,844 - mmseg - INFO - Iter [29000/160000]	lr: 8.369e-03, eta: 2 days, 1:17:34, time: 1.359, data_time: 0.016, memory: 6005, decode.loss_seg: 1.0477, decode.acc_seg: 52.0544, loss: 1.0477
2021-08-13 22:08:19,943 - mmseg - INFO - Iter [29050/160000]	lr: 8.367e-03, eta: 2 days, 1:18:47, time: 1.982, data_time: 0.717, memory: 6005, decode.loss_seg: 1.0774, decode.acc_seg: 52.1783, loss: 1.0774
2021-08-13 22:09:24,886 - mmseg - INFO - Iter [29100/160000]	lr: 8.364e-03, eta: 2 days, 1:17:27, time: 1.299, data_time: 0.017, memory: 6005, decode.loss_seg: 1.0248, decode.acc_seg: 52.0769, loss: 1.0248
2021-08-13 22:10:29,182 - mmseg - INFO - Iter [29150/160000]	lr: 8.361e-03, eta: 2 days, 1:16:04, time: 1.287, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0223, decode.acc_seg: 53.4025, loss: 1.0223
2021-08-13 22:11:33,920 - mmseg - INFO - Iter [29200/160000]	lr: 8.358e-03, eta: 2 days, 1:14:42, time: 1.294, data_time: 0.017, memory: 6005, decode.loss_seg: 1.0603, decode.acc_seg: 52.2573, loss: 1.0603
2021-08-13 22:12:41,298 - mmseg - INFO - Iter [29250/160000]	lr: 8.355e-03, eta: 2 days, 1:13:33, time: 1.348, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0322, decode.acc_seg: 52.2642, loss: 1.0322
2021-08-13 22:13:45,469 - mmseg - INFO - Iter [29300/160000]	lr: 8.352e-03, eta: 2 days, 1:12:09, time: 1.284, data_time: 0.017, memory: 6005, decode.loss_seg: 1.0136, decode.acc_seg: 52.9146, loss: 1.0136
2021-08-13 22:14:52,274 - mmseg - INFO - Iter [29350/160000]	lr: 8.350e-03, eta: 2 days, 1:10:57, time: 1.335, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0438, decode.acc_seg: 52.5407, loss: 1.0438
2021-08-13 22:15:56,707 - mmseg - INFO - Iter [29400/160000]	lr: 8.347e-03, eta: 2 days, 1:09:34, time: 1.288, data_time: 0.017, memory: 6005, decode.loss_seg: 1.0418, decode.acc_seg: 52.9470, loss: 1.0418
2021-08-13 22:17:01,023 - mmseg - INFO - Iter [29450/160000]	lr: 8.344e-03, eta: 2 days, 1:08:11, time: 1.287, data_time: 0.016, memory: 6005, decode.loss_seg: 1.0635, decode.acc_seg: 52.0612, loss: 1.0635
2021-08-13 22:18:04,770 - mmseg - INFO - Iter [29500/160000]	lr: 8.341e-03, eta: 2 days, 1:06:46, time: 1.275, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0640, decode.acc_seg: 52.4342, loss: 1.0640
2021-08-13 22:19:07,581 - mmseg - INFO - Iter [29550/160000]	lr: 8.338e-03, eta: 2 days, 1:05:16, time: 1.255, data_time: 0.017, memory: 6005, decode.loss_seg: 1.0685, decode.acc_seg: 52.5858, loss: 1.0685
2021-08-13 22:20:10,923 - mmseg - INFO - Iter [29600/160000]	lr: 8.335e-03, eta: 2 days, 1:03:49, time: 1.268, data_time: 0.017, memory: 6005, decode.loss_seg: 1.0663, decode.acc_seg: 51.8332, loss: 1.0663
2021-08-13 22:21:13,556 - mmseg - INFO - Iter [29650/160000]	lr: 8.332e-03, eta: 2 days, 1:02:19, time: 1.252, data_time: 0.017, memory: 6005, decode.loss_seg: 1.0189, decode.acc_seg: 52.9470, loss: 1.0189
2021-08-13 22:22:52,534 - mmseg - INFO - Iter [29700/160000]	lr: 8.330e-03, eta: 2 days, 1:03:28, time: 1.979, data_time: 0.720, memory: 6005, decode.loss_seg: 0.9993, decode.acc_seg: 52.1767, loss: 0.9993
2021-08-13 22:23:55,442 - mmseg - INFO - Iter [29750/160000]	lr: 8.327e-03, eta: 2 days, 1:01:59, time: 1.258, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0185, decode.acc_seg: 53.3272, loss: 1.0185
2021-08-13 22:25:00,490 - mmseg - INFO - Iter [29800/160000]	lr: 8.324e-03, eta: 2 days, 1:00:40, time: 1.301, data_time: 0.014, memory: 6005, decode.loss_seg: 1.0206, decode.acc_seg: 53.1803, loss: 1.0206
2021-08-13 22:26:06,194 - mmseg - INFO - Iter [29850/160000]	lr: 8.321e-03, eta: 2 days, 0:59:23, time: 1.314, data_time: 0.014, memory: 6005, decode.loss_seg: 1.0873, decode.acc_seg: 52.6680, loss: 1.0873
2021-08-13 22:27:10,690 - mmseg - INFO - Iter [29900/160000]	lr: 8.318e-03, eta: 2 days, 0:58:01, time: 1.289, data_time: 0.013, memory: 6005, decode.loss_seg: 1.0305, decode.acc_seg: 52.7633, loss: 1.0305
2021-08-13 22:28:13,443 - mmseg - INFO - Iter [29950/160000]	lr: 8.315e-03, eta: 2 days, 0:56:32, time: 1.256, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0229, decode.acc_seg: 53.0442, loss: 1.0229
2021-08-13 22:29:16,406 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-without-head_512x512_160k_ade20k.py
2021-08-13 22:29:16,407 - mmseg - INFO - Iter [30000/160000]	lr: 8.313e-03, eta: 2 days, 0:55:03, time: 1.260, data_time: 0.014, memory: 6005, decode.loss_seg: 1.0434, decode.acc_seg: 52.1262, loss: 1.0434
2021-08-13 22:30:19,422 - mmseg - INFO - Iter [30050/160000]	lr: 8.310e-03, eta: 2 days, 0:53:35, time: 1.259, data_time: 0.016, memory: 6005, decode.loss_seg: 1.0352, decode.acc_seg: 53.0853, loss: 1.0352
2021-08-13 22:31:24,611 - mmseg - INFO - Iter [30100/160000]	lr: 8.307e-03, eta: 2 days, 0:52:16, time: 1.304, data_time: 0.016, memory: 6005, decode.loss_seg: 1.0305, decode.acc_seg: 52.7108, loss: 1.0305
2021-08-13 22:32:28,622 - mmseg - INFO - Iter [30150/160000]	lr: 8.304e-03, eta: 2 days, 0:50:53, time: 1.281, data_time: 0.016, memory: 6005, decode.loss_seg: 1.0357, decode.acc_seg: 53.4612, loss: 1.0357
2021-08-13 22:33:32,349 - mmseg - INFO - Iter [30200/160000]	lr: 8.301e-03, eta: 2 days, 0:49:28, time: 1.274, data_time: 0.016, memory: 6005, decode.loss_seg: 1.0423, decode.acc_seg: 51.9764, loss: 1.0423
2021-08-13 22:34:36,237 - mmseg - INFO - Iter [30250/160000]	lr: 8.298e-03, eta: 2 days, 0:48:04, time: 1.277, data_time: 0.016, memory: 6005, decode.loss_seg: 1.0571, decode.acc_seg: 53.1031, loss: 1.0571
2021-08-13 22:36:15,224 - mmseg - INFO - Iter [30300/160000]	lr: 8.296e-03, eta: 2 days, 0:49:10, time: 1.980, data_time: 0.712, memory: 6005, decode.loss_seg: 1.0857, decode.acc_seg: 50.9669, loss: 1.0857
2021-08-13 22:37:18,744 - mmseg - INFO - Iter [30350/160000]	lr: 8.293e-03, eta: 2 days, 0:47:44, time: 1.271, data_time: 0.016, memory: 6005, decode.loss_seg: 1.0342, decode.acc_seg: 52.1240, loss: 1.0342
2021-08-13 22:38:23,616 - mmseg - INFO - Iter [30400/160000]	lr: 8.290e-03, eta: 2 days, 0:46:24, time: 1.296, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0346, decode.acc_seg: 53.5389, loss: 1.0346
2021-08-13 22:39:27,945 - mmseg - INFO - Iter [30450/160000]	lr: 8.287e-03, eta: 2 days, 0:45:02, time: 1.287, data_time: 0.016, memory: 6005, decode.loss_seg: 1.0562, decode.acc_seg: 52.7744, loss: 1.0562
2021-08-13 22:40:33,400 - mmseg - INFO - Iter [30500/160000]	lr: 8.284e-03, eta: 2 days, 0:43:44, time: 1.309, data_time: 0.016, memory: 6005, decode.loss_seg: 1.0212, decode.acc_seg: 52.6659, loss: 1.0212
2021-08-13 22:41:37,581 - mmseg - INFO - Iter [30550/160000]	lr: 8.281e-03, eta: 2 days, 0:42:22, time: 1.283, data_time: 0.016, memory: 6005, decode.loss_seg: 1.0165, decode.acc_seg: 52.0205, loss: 1.0165
2021-08-13 22:42:42,849 - mmseg - INFO - Iter [30600/160000]	lr: 8.278e-03, eta: 2 days, 0:41:04, time: 1.306, data_time: 0.016, memory: 6005, decode.loss_seg: 1.0142, decode.acc_seg: 52.8403, loss: 1.0142
2021-08-13 22:43:49,030 - mmseg - INFO - Iter [30650/160000]	lr: 8.276e-03, eta: 2 days, 0:39:49, time: 1.322, data_time: 0.014, memory: 6005, decode.loss_seg: 1.0255, decode.acc_seg: 53.2963, loss: 1.0255
2021-08-13 22:44:58,506 - mmseg - INFO - Iter [30700/160000]	lr: 8.273e-03, eta: 2 days, 0:38:49, time: 1.390, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0313, decode.acc_seg: 53.2851, loss: 1.0313
2021-08-13 22:46:01,173 - mmseg - INFO - Iter [30750/160000]	lr: 8.270e-03, eta: 2 days, 0:37:20, time: 1.255, data_time: 0.016, memory: 6005, decode.loss_seg: 1.0875, decode.acc_seg: 51.2547, loss: 1.0875
2021-08-13 22:47:04,515 - mmseg - INFO - Iter [30800/160000]	lr: 8.267e-03, eta: 2 days, 0:35:54, time: 1.267, data_time: 0.014, memory: 6005, decode.loss_seg: 1.0402, decode.acc_seg: 52.5769, loss: 1.0402
2021-08-13 22:48:08,797 - mmseg - INFO - Iter [30850/160000]	lr: 8.264e-03, eta: 2 days, 0:34:32, time: 1.284, data_time: 0.016, memory: 6005, decode.loss_seg: 1.0222, decode.acc_seg: 52.9978, loss: 1.0222
2021-08-13 22:49:13,623 - mmseg - INFO - Iter [30900/160000]	lr: 8.261e-03, eta: 2 days, 0:33:12, time: 1.298, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0788, decode.acc_seg: 52.4856, loss: 1.0788
2021-08-13 22:50:55,675 - mmseg - INFO - Iter [30950/160000]	lr: 8.259e-03, eta: 2 days, 0:34:28, time: 2.040, data_time: 0.737, memory: 6005, decode.loss_seg: 1.0335, decode.acc_seg: 52.7877, loss: 1.0335
2021-08-13 22:52:01,387 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-without-head_512x512_160k_ade20k.py
2021-08-13 22:52:01,387 - mmseg - INFO - Iter [31000/160000]	lr: 8.256e-03, eta: 2 days, 0:33:11, time: 1.315, data_time: 0.017, memory: 6005, decode.loss_seg: 1.0022, decode.acc_seg: 53.5919, loss: 1.0022
2021-08-13 22:53:05,843 - mmseg - INFO - Iter [31050/160000]	lr: 8.253e-03, eta: 2 days, 0:31:50, time: 1.290, data_time: 0.017, memory: 6005, decode.loss_seg: 1.0181, decode.acc_seg: 53.1840, loss: 1.0181
2021-08-13 22:54:11,396 - mmseg - INFO - Iter [31100/160000]	lr: 8.250e-03, eta: 2 days, 0:30:33, time: 1.311, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0156, decode.acc_seg: 52.6890, loss: 1.0156
2021-08-13 22:55:15,881 - mmseg - INFO - Iter [31150/160000]	lr: 8.247e-03, eta: 2 days, 0:29:12, time: 1.289, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0348, decode.acc_seg: 52.3234, loss: 1.0348
2021-08-13 22:56:20,302 - mmseg - INFO - Iter [31200/160000]	lr: 8.244e-03, eta: 2 days, 0:27:51, time: 1.288, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0662, decode.acc_seg: 51.8691, loss: 1.0662
2021-08-13 22:57:24,159 - mmseg - INFO - Iter [31250/160000]	lr: 8.241e-03, eta: 2 days, 0:26:27, time: 1.278, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0395, decode.acc_seg: 53.1346, loss: 1.0395
2021-08-13 22:58:27,767 - mmseg - INFO - Iter [31300/160000]	lr: 8.239e-03, eta: 2 days, 0:25:02, time: 1.272, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0233, decode.acc_seg: 53.2656, loss: 1.0233
2021-08-13 22:59:31,525 - mmseg - INFO - Iter [31350/160000]	lr: 8.236e-03, eta: 2 days, 0:23:38, time: 1.275, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0595, decode.acc_seg: 52.9588, loss: 1.0595
2021-08-13 23:00:38,852 - mmseg - INFO - Iter [31400/160000]	lr: 8.233e-03, eta: 2 days, 0:22:29, time: 1.345, data_time: 0.014, memory: 6005, decode.loss_seg: 1.0542, decode.acc_seg: 53.0443, loss: 1.0542
2021-08-13 23:01:47,387 - mmseg - INFO - Iter [31450/160000]	lr: 8.230e-03, eta: 2 days, 0:21:25, time: 1.371, data_time: 0.016, memory: 6005, decode.loss_seg: 1.0377, decode.acc_seg: 52.2034, loss: 1.0377
2021-08-13 23:02:52,657 - mmseg - INFO - Iter [31500/160000]	lr: 8.227e-03, eta: 2 days, 0:20:07, time: 1.306, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0506, decode.acc_seg: 51.5240, loss: 1.0506
2021-08-13 23:03:56,017 - mmseg - INFO - Iter [31550/160000]	lr: 8.224e-03, eta: 2 days, 0:18:42, time: 1.267, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0335, decode.acc_seg: 52.6884, loss: 1.0335
2021-08-13 23:05:36,108 - mmseg - INFO - Iter [31600/160000]	lr: 8.222e-03, eta: 2 days, 0:19:45, time: 2.002, data_time: 0.713, memory: 6005, decode.loss_seg: 0.9989, decode.acc_seg: 53.3668, loss: 0.9989
2021-08-13 23:06:40,232 - mmseg - INFO - Iter [31650/160000]	lr: 8.219e-03, eta: 2 days, 0:18:23, time: 1.283, data_time: 0.016, memory: 6005, decode.loss_seg: 1.0113, decode.acc_seg: 53.9244, loss: 1.0113
2021-08-13 23:07:45,344 - mmseg - INFO - Iter [31700/160000]	lr: 8.216e-03, eta: 2 days, 0:17:05, time: 1.302, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0289, decode.acc_seg: 53.2163, loss: 1.0289
2021-08-13 23:08:48,910 - mmseg - INFO - Iter [31750/160000]	lr: 8.213e-03, eta: 2 days, 0:15:40, time: 1.271, data_time: 0.015, memory: 6005, decode.loss_seg: 0.9974, decode.acc_seg: 53.4381, loss: 0.9974
2021-08-13 23:09:52,360 - mmseg - INFO - Iter [31800/160000]	lr: 8.210e-03, eta: 2 days, 0:14:15, time: 1.270, data_time: 0.016, memory: 6005, decode.loss_seg: 1.0309, decode.acc_seg: 53.0159, loss: 1.0309
2021-08-13 23:10:58,390 - mmseg - INFO - Iter [31850/160000]	lr: 8.207e-03, eta: 2 days, 0:13:00, time: 1.320, data_time: 0.016, memory: 6005, decode.loss_seg: 1.0251, decode.acc_seg: 51.7355, loss: 1.0251
2021-08-13 23:12:02,847 - mmseg - INFO - Iter [31900/160000]	lr: 8.204e-03, eta: 2 days, 0:11:40, time: 1.290, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0600, decode.acc_seg: 52.1911, loss: 1.0600
2021-08-13 23:13:05,812 - mmseg - INFO - Iter [31950/160000]	lr: 8.202e-03, eta: 2 days, 0:10:13, time: 1.259, data_time: 0.016, memory: 6005, decode.loss_seg: 1.0205, decode.acc_seg: 52.9934, loss: 1.0205
2021-08-13 23:14:08,818 - mmseg - INFO - Saving checkpoint at 32000 iterations
2021-08-13 23:14:09,196 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-without-head_512x512_160k_ade20k.py
2021-08-13 23:14:09,198 - mmseg - INFO - Iter [32000/160000]	lr: 8.199e-03, eta: 2 days, 0:08:48, time: 1.268, data_time: 0.014, memory: 6005, decode.loss_seg: 1.0544, decode.acc_seg: 52.7189, loss: 1.0544
2021-08-13 23:16:48,447 - mmseg - INFO - per class results:
2021-08-13 23:16:48,477 - mmseg - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        | 56.52 | 78.27 |
|       building      | 68.97 | 82.58 |
|         sky         | 87.29 |  90.3 |
|        floor        | 58.69 |  81.5 |
|         tree        | 57.83 | 79.55 |
|       ceiling       | 66.88 | 78.06 |
|         road        | 58.25 |  89.8 |
|         bed         | 56.88 |  84.0 |
|      windowpane     | 40.49 | 64.44 |
|        grass        | 52.36 | 65.86 |
|       cabinet       |  32.4 | 67.37 |
|       sidewalk      | 24.59 | 30.06 |
|        person       | 40.12 | 49.88 |
|        earth        | 20.95 | 32.22 |
|         door        | 16.69 | 24.37 |
|        table        | 27.42 | 35.99 |
|       mountain      |  31.5 | 51.83 |
|        plant        | 31.23 | 50.31 |
|       curtain       | 36.01 | 55.49 |
|        chair        | 23.52 | 35.77 |
|         car         | 45.24 |  83.0 |
|        water        | 31.83 | 51.72 |
|       painting      | 43.44 | 62.16 |
|         sofa        | 31.83 | 41.42 |
|        shelf        | 17.77 | 25.81 |
|        house        | 35.66 | 50.49 |
|         sea         | 32.72 | 51.75 |
|        mirror       | 18.47 | 21.93 |
|         rug         | 20.13 | 21.48 |
|        field        | 19.96 | 47.83 |
|       armchair      | 12.96 |  16.3 |
|         seat        | 23.54 | 42.55 |
|        fence        | 15.89 | 22.19 |
|         desk        | 10.01 | 11.32 |
|         rock        |  8.76 | 11.57 |
|       wardrobe      | 15.18 | 16.92 |
|         lamp        | 26.64 | 33.52 |
|       bathtub       | 28.24 | 37.67 |
|       railing       | 15.17 | 22.05 |
|       cushion       | 16.17 | 20.82 |
|         base        |  0.28 |  0.3  |
|         box         |  1.62 |  1.72 |
|        column       |  5.21 |  5.42 |
|      signboard      |  8.58 |  9.67 |
|   chest of drawers  | 27.08 |  31.8 |
|       counter       |  5.62 |  6.01 |
|         sand        | 11.47 | 15.03 |
|         sink        |  25.2 | 44.99 |
|      skyscraper     | 39.11 | 72.46 |
|      fireplace      | 45.31 | 52.93 |
|     refrigerator    | 26.18 | 36.37 |
|      grandstand     | 12.47 | 29.62 |
|         path        |  3.07 |  3.34 |
|        stairs       |  7.55 |  7.96 |
|        runway       | 39.08 | 49.83 |
|         case        | 18.75 | 27.15 |
|      pool table     | 58.79 |  66.2 |
|        pillow       | 24.73 |  30.0 |
|     screen door     |  9.09 |  9.85 |
|       stairway      | 10.35 | 17.22 |
|        river        |  1.65 |  1.73 |
|        bridge       | 11.73 | 23.52 |
|       bookcase      | 15.64 | 18.58 |
|        blind        |  1.17 |  1.19 |
|     coffee table    | 27.61 | 39.79 |
|        toilet       | 42.86 | 59.78 |
|        flower       |  7.72 |  8.53 |
|         book        | 14.28 | 15.71 |
|         hill        |  3.45 |  5.35 |
|        bench        | 15.56 | 19.16 |
|      countertop     | 13.98 |  16.3 |
|        stove        | 24.16 |  42.6 |
|         palm        | 17.83 | 21.96 |
|    kitchen island   | 13.75 | 16.43 |
|       computer      |  17.2 | 18.92 |
|     swivel chair    |  7.16 |  7.42 |
|         boat        | 14.34 | 17.71 |
|         bar         |  6.01 |  6.76 |
|    arcade machine   |  1.52 |  3.07 |
|        hovel        |  7.71 |  9.91 |
|         bus         | 25.11 | 28.81 |
|        towel        |  3.3  |  3.59 |
|        light        |  16.8 | 18.29 |
|        truck        |  3.64 |  4.79 |
|        tower        | 27.85 | 30.99 |
|      chandelier     |  38.2 | 53.35 |
|        awning       |  6.96 |  9.45 |
|     streetlight     |  1.94 |  2.05 |
|        booth        |  1.59 |  1.68 |
| television receiver | 17.63 | 22.56 |
|       airplane      | 17.86 | 24.44 |
|      dirt track     |  0.0  |  0.0  |
|       apparel       |  1.47 |  2.7  |
|         pole        |  2.72 |  2.97 |
|         land        |  0.0  |  0.0  |
|      bannister      |  0.0  |  0.0  |
|      escalator      |  3.32 |  6.79 |
|       ottoman       |  0.0  |  0.0  |
|        bottle       |  2.21 |  2.63 |
|        buffet       |  0.0  |  0.0  |
|        poster       |  0.0  |  0.0  |
|        stage        |  0.78 |  1.05 |
|         van         |  0.0  |  0.0  |
|         ship        |  0.0  |  0.0  |
|       fountain      |  0.09 |  0.1  |
|    conveyer belt    | 12.21 | 18.97 |
|        canopy       |  0.0  |  0.0  |
|        washer       | 38.01 | 57.46 |
|      plaything      |  0.0  |  0.0  |
|    swimming pool    | 10.57 | 15.59 |
|        stool        |  0.0  |  0.0  |
|        barrel       |  0.18 |  3.11 |
|        basket       |  0.0  |  0.0  |
|      waterfall      | 33.02 | 48.96 |
|         tent        |  9.5  | 19.02 |
|         bag         |  0.0  |  0.0  |
|       minibike      |  3.05 |  3.2  |
|        cradle       | 40.35 | 61.34 |
|         oven        |  3.17 |  3.46 |
|         ball        | 20.91 | 25.71 |
|         food        | 10.59 | 11.51 |
|         step        |  0.0  |  0.0  |
|         tank        |  0.0  |  0.0  |
|      trade name     | 12.48 | 13.44 |
|      microwave      | 14.15 | 15.85 |
|         pot         |  0.99 |  1.01 |
|        animal       |  2.3  |  2.33 |
|       bicycle       |  4.41 |  6.72 |
|         lake        |  0.0  |  0.0  |
|      dishwasher     |  12.0 | 16.34 |
|        screen       |  33.0 | 51.31 |
|       blanket       |  0.0  |  0.0  |
|      sculpture      |  0.0  |  0.0  |
|         hood        |  9.23 |  10.2 |
|        sconce       |  0.0  |  0.0  |
|         vase        |  4.62 |  5.5  |
|    traffic light    |  0.0  |  0.0  |
|         tray        |  0.91 |  0.95 |
|        ashcan       |  0.0  |  0.0  |
|         fan         |  1.08 |  1.09 |
|         pier        |  0.0  |  0.0  |
|      crt screen     |  0.0  |  0.0  |
|        plate        |  1.17 |  1.17 |
|       monitor       |  2.54 |  2.6  |
|    bulletin board   |  0.0  |  0.0  |
|        shower       |  0.0  |  0.0  |
|       radiator      |  0.0  |  0.0  |
|        glass        |  0.0  |  0.0  |
|        clock        |  0.0  |  0.0  |
|         flag        |  0.0  |  0.0  |
+---------------------+-------+-------+
2021-08-13 23:16:48,478 - mmseg - INFO - Summary:
2021-08-13 23:16:48,478 - mmseg - INFO - 
+-------+-------+------+
|  aAcc |  mIoU | mAcc |
+-------+-------+------+
| 65.38 | 16.37 | 22.7 |
+-------+-------+------+
2021-08-13 23:16:48,579 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-without-head_512x512_160k_ade20k.py
2021-08-13 23:16:48,580 - mmseg - INFO - Iter(val) [250]	aAcc: 0.6538, mIoU: 0.1637, mAcc: 0.2270, IoU.wall: 0.5652, IoU.building: 0.6897, IoU.sky: 0.8729, IoU.floor: 0.5869, IoU.tree: 0.5783, IoU.ceiling: 0.6688, IoU.road: 0.5825, IoU.bed : 0.5688, IoU.windowpane: 0.4049, IoU.grass: 0.5236, IoU.cabinet: 0.3240, IoU.sidewalk: 0.2459, IoU.person: 0.4012, IoU.earth: 0.2095, IoU.door: 0.1669, IoU.table: 0.2742, IoU.mountain: 0.3150, IoU.plant: 0.3123, IoU.curtain: 0.3601, IoU.chair: 0.2352, IoU.car: 0.4524, IoU.water: 0.3183, IoU.painting: 0.4344, IoU.sofa: 0.3183, IoU.shelf: 0.1777, IoU.house: 0.3566, IoU.sea: 0.3272, IoU.mirror: 0.1847, IoU.rug: 0.2013, IoU.field: 0.1996, IoU.armchair: 0.1296, IoU.seat: 0.2354, IoU.fence: 0.1589, IoU.desk: 0.1001, IoU.rock: 0.0876, IoU.wardrobe: 0.1518, IoU.lamp: 0.2664, IoU.bathtub: 0.2824, IoU.railing: 0.1517, IoU.cushion: 0.1617, IoU.base: 0.0028, IoU.box: 0.0162, IoU.column: 0.0521, IoU.signboard: 0.0858, IoU.chest of drawers: 0.2708, IoU.counter: 0.0562, IoU.sand: 0.1147, IoU.sink: 0.2520, IoU.skyscraper: 0.3911, IoU.fireplace: 0.4531, IoU.refrigerator: 0.2618, IoU.grandstand: 0.1247, IoU.path: 0.0307, IoU.stairs: 0.0755, IoU.runway: 0.3908, IoU.case: 0.1875, IoU.pool table: 0.5879, IoU.pillow: 0.2473, IoU.screen door: 0.0909, IoU.stairway: 0.1035, IoU.river: 0.0165, IoU.bridge: 0.1173, IoU.bookcase: 0.1564, IoU.blind: 0.0117, IoU.coffee table: 0.2761, IoU.toilet: 0.4286, IoU.flower: 0.0772, IoU.book: 0.1428, IoU.hill: 0.0345, IoU.bench: 0.1556, IoU.countertop: 0.1398, IoU.stove: 0.2416, IoU.palm: 0.1783, IoU.kitchen island: 0.1375, IoU.computer: 0.1720, IoU.swivel chair: 0.0716, IoU.boat: 0.1434, IoU.bar: 0.0601, IoU.arcade machine: 0.0152, IoU.hovel: 0.0771, IoU.bus: 0.2511, IoU.towel: 0.0330, IoU.light: 0.1680, IoU.truck: 0.0364, IoU.tower: 0.2785, IoU.chandelier: 0.3820, IoU.awning: 0.0696, IoU.streetlight: 0.0194, IoU.booth: 0.0159, IoU.television receiver: 0.1763, IoU.airplane: 0.1786, IoU.dirt track: 0.0000, IoU.apparel: 0.0147, IoU.pole: 0.0272, IoU.land: 0.0000, IoU.bannister: 0.0000, IoU.escalator: 0.0332, IoU.ottoman: 0.0000, IoU.bottle: 0.0221, IoU.buffet: 0.0000, IoU.poster: 0.0000, IoU.stage: 0.0078, IoU.van: 0.0000, IoU.ship: 0.0000, IoU.fountain: 0.0009, IoU.conveyer belt: 0.1221, IoU.canopy: 0.0000, IoU.washer: 0.3801, IoU.plaything: 0.0000, IoU.swimming pool: 0.1057, IoU.stool: 0.0000, IoU.barrel: 0.0018, IoU.basket: 0.0000, IoU.waterfall: 0.3302, IoU.tent: 0.0950, IoU.bag: 0.0000, IoU.minibike: 0.0305, IoU.cradle: 0.4035, IoU.oven: 0.0317, IoU.ball: 0.2091, IoU.food: 0.1059, IoU.step: 0.0000, IoU.tank: 0.0000, IoU.trade name: 0.1248, IoU.microwave: 0.1415, IoU.pot: 0.0099, IoU.animal: 0.0230, IoU.bicycle: 0.0441, IoU.lake: 0.0000, IoU.dishwasher: 0.1200, IoU.screen: 0.3300, IoU.blanket: 0.0000, IoU.sculpture: 0.0000, IoU.hood: 0.0923, IoU.sconce: 0.0000, IoU.vase: 0.0462, IoU.traffic light: 0.0000, IoU.tray: 0.0091, IoU.ashcan: 0.0000, IoU.fan: 0.0108, IoU.pier: 0.0000, IoU.crt screen: 0.0000, IoU.plate: 0.0117, IoU.monitor: 0.0254, IoU.bulletin board: 0.0000, IoU.shower: 0.0000, IoU.radiator: 0.0000, IoU.glass: 0.0000, IoU.clock: 0.0000, IoU.flag: 0.0000, Acc.wall: 0.7827, Acc.building: 0.8258, Acc.sky: 0.9030, Acc.floor: 0.8150, Acc.tree: 0.7955, Acc.ceiling: 0.7806, Acc.road: 0.8980, Acc.bed : 0.8400, Acc.windowpane: 0.6444, Acc.grass: 0.6586, Acc.cabinet: 0.6737, Acc.sidewalk: 0.3006, Acc.person: 0.4988, Acc.earth: 0.3222, Acc.door: 0.2437, Acc.table: 0.3599, Acc.mountain: 0.5183, Acc.plant: 0.5031, Acc.curtain: 0.5549, Acc.chair: 0.3577, Acc.car: 0.8300, Acc.water: 0.5172, Acc.painting: 0.6216, Acc.sofa: 0.4142, Acc.shelf: 0.2581, Acc.house: 0.5049, Acc.sea: 0.5175, Acc.mirror: 0.2193, Acc.rug: 0.2148, Acc.field: 0.4783, Acc.armchair: 0.1630, Acc.seat: 0.4255, Acc.fence: 0.2219, Acc.desk: 0.1132, Acc.rock: 0.1157, Acc.wardrobe: 0.1692, Acc.lamp: 0.3352, Acc.bathtub: 0.3767, Acc.railing: 0.2205, Acc.cushion: 0.2082, Acc.base: 0.0030, Acc.box: 0.0172, Acc.column: 0.0542, Acc.signboard: 0.0967, Acc.chest of drawers: 0.3180, Acc.counter: 0.0601, Acc.sand: 0.1503, Acc.sink: 0.4499, Acc.skyscraper: 0.7246, Acc.fireplace: 0.5293, Acc.refrigerator: 0.3637, Acc.grandstand: 0.2962, Acc.path: 0.0334, Acc.stairs: 0.0796, Acc.runway: 0.4983, Acc.case: 0.2715, Acc.pool table: 0.6620, Acc.pillow: 0.3000, Acc.screen door: 0.0985, Acc.stairway: 0.1722, Acc.river: 0.0173, Acc.bridge: 0.2352, Acc.bookcase: 0.1858, Acc.blind: 0.0119, Acc.coffee table: 0.3979, Acc.toilet: 0.5978, Acc.flower: 0.0853, Acc.book: 0.1571, Acc.hill: 0.0535, Acc.bench: 0.1916, Acc.countertop: 0.1630, Acc.stove: 0.4260, Acc.palm: 0.2196, Acc.kitchen island: 0.1643, Acc.computer: 0.1892, Acc.swivel chair: 0.0742, Acc.boat: 0.1771, Acc.bar: 0.0676, Acc.arcade machine: 0.0307, Acc.hovel: 0.0991, Acc.bus: 0.2881, Acc.towel: 0.0359, Acc.light: 0.1829, Acc.truck: 0.0479, Acc.tower: 0.3099, Acc.chandelier: 0.5335, Acc.awning: 0.0945, Acc.streetlight: 0.0205, Acc.booth: 0.0168, Acc.television receiver: 0.2256, Acc.airplane: 0.2444, Acc.dirt track: 0.0000, Acc.apparel: 0.0270, Acc.pole: 0.0297, Acc.land: 0.0000, Acc.bannister: 0.0000, Acc.escalator: 0.0679, Acc.ottoman: 0.0000, Acc.bottle: 0.0263, Acc.buffet: 0.0000, Acc.poster: 0.0000, Acc.stage: 0.0105, Acc.van: 0.0000, Acc.ship: 0.0000, Acc.fountain: 0.0010, Acc.conveyer belt: 0.1897, Acc.canopy: 0.0000, Acc.washer: 0.5746, Acc.plaything: 0.0000, Acc.swimming pool: 0.1559, Acc.stool: 0.0000, Acc.barrel: 0.0311, Acc.basket: 0.0000, Acc.waterfall: 0.4896, Acc.tent: 0.1902, Acc.bag: 0.0000, Acc.minibike: 0.0320, Acc.cradle: 0.6134, Acc.oven: 0.0346, Acc.ball: 0.2571, Acc.food: 0.1151, Acc.step: 0.0000, Acc.tank: 0.0000, Acc.trade name: 0.1344, Acc.microwave: 0.1585, Acc.pot: 0.0101, Acc.animal: 0.0233, Acc.bicycle: 0.0672, Acc.lake: 0.0000, Acc.dishwasher: 0.1634, Acc.screen: 0.5131, Acc.blanket: 0.0000, Acc.sculpture: 0.0000, Acc.hood: 0.1020, Acc.sconce: 0.0000, Acc.vase: 0.0550, Acc.traffic light: 0.0000, Acc.tray: 0.0095, Acc.ashcan: 0.0000, Acc.fan: 0.0109, Acc.pier: 0.0000, Acc.crt screen: 0.0000, Acc.plate: 0.0117, Acc.monitor: 0.0260, Acc.bulletin board: 0.0000, Acc.shower: 0.0000, Acc.radiator: 0.0000, Acc.glass: 0.0000, Acc.clock: 0.0000, Acc.flag: 0.0000
2021-08-13 23:17:53,856 - mmseg - INFO - Iter [32050/160000]	lr: 8.196e-03, eta: 2 days, 0:18:07, time: 4.493, data_time: 3.203, memory: 6005, decode.loss_seg: 1.0264, decode.acc_seg: 53.3236, loss: 1.0264
2021-08-13 23:18:59,321 - mmseg - INFO - Iter [32100/160000]	lr: 8.193e-03, eta: 2 days, 0:16:49, time: 1.308, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0344, decode.acc_seg: 52.7471, loss: 1.0344
2021-08-13 23:20:03,140 - mmseg - INFO - Iter [32150/160000]	lr: 8.190e-03, eta: 2 days, 0:15:24, time: 1.278, data_time: 0.016, memory: 6005, decode.loss_seg: 1.0505, decode.acc_seg: 52.9614, loss: 1.0505
2021-08-13 23:21:40,477 - mmseg - INFO - Iter [32200/160000]	lr: 8.187e-03, eta: 2 days, 0:16:13, time: 1.946, data_time: 0.721, memory: 6005, decode.loss_seg: 1.0036, decode.acc_seg: 52.6978, loss: 1.0036
2021-08-13 23:22:47,502 - mmseg - INFO - Iter [32250/160000]	lr: 8.185e-03, eta: 2 days, 0:15:01, time: 1.342, data_time: 0.016, memory: 6005, decode.loss_seg: 0.9968, decode.acc_seg: 54.4789, loss: 0.9968
2021-08-13 23:23:51,463 - mmseg - INFO - Iter [32300/160000]	lr: 8.182e-03, eta: 2 days, 0:13:37, time: 1.279, data_time: 0.014, memory: 6005, decode.loss_seg: 1.0525, decode.acc_seg: 53.4273, loss: 1.0525
2021-08-13 23:24:55,688 - mmseg - INFO - Iter [32350/160000]	lr: 8.179e-03, eta: 2 days, 0:12:15, time: 1.284, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0022, decode.acc_seg: 52.8993, loss: 1.0022
2021-08-13 23:25:59,399 - mmseg - INFO - Iter [32400/160000]	lr: 8.176e-03, eta: 2 days, 0:10:50, time: 1.275, data_time: 0.016, memory: 6005, decode.loss_seg: 1.0349, decode.acc_seg: 52.2575, loss: 1.0349
2021-08-13 23:27:04,096 - mmseg - INFO - Iter [32450/160000]	lr: 8.173e-03, eta: 2 days, 0:09:29, time: 1.294, data_time: 0.017, memory: 6005, decode.loss_seg: 1.0059, decode.acc_seg: 53.5983, loss: 1.0059
2021-08-13 23:28:06,072 - mmseg - INFO - Iter [32500/160000]	lr: 8.170e-03, eta: 2 days, 0:07:58, time: 1.239, data_time: 0.016, memory: 6005, decode.loss_seg: 1.0307, decode.acc_seg: 52.0095, loss: 1.0307
2021-08-13 23:29:09,447 - mmseg - INFO - Iter [32550/160000]	lr: 8.167e-03, eta: 2 days, 0:06:32, time: 1.268, data_time: 0.016, memory: 6005, decode.loss_seg: 1.0336, decode.acc_seg: 53.4758, loss: 1.0336
2021-08-13 23:30:13,815 - mmseg - INFO - Iter [32600/160000]	lr: 8.165e-03, eta: 2 days, 0:05:10, time: 1.287, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0159, decode.acc_seg: 52.5235, loss: 1.0159
2021-08-13 23:31:17,212 - mmseg - INFO - Iter [32650/160000]	lr: 8.162e-03, eta: 2 days, 0:03:44, time: 1.267, data_time: 0.018, memory: 6005, decode.loss_seg: 1.0344, decode.acc_seg: 52.6700, loss: 1.0344
2021-08-13 23:32:20,993 - mmseg - INFO - Iter [32700/160000]	lr: 8.159e-03, eta: 2 days, 0:02:20, time: 1.276, data_time: 0.017, memory: 6005, decode.loss_seg: 1.0264, decode.acc_seg: 53.6727, loss: 1.0264
2021-08-13 23:33:26,884 - mmseg - INFO - Iter [32750/160000]	lr: 8.156e-03, eta: 2 days, 0:01:04, time: 1.318, data_time: 0.016, memory: 6005, decode.loss_seg: 1.0105, decode.acc_seg: 52.6854, loss: 1.0105
2021-08-13 23:34:32,632 - mmseg - INFO - Iter [32800/160000]	lr: 8.153e-03, eta: 1 day, 23:59:48, time: 1.314, data_time: 0.014, memory: 6005, decode.loss_seg: 1.0379, decode.acc_seg: 52.6168, loss: 1.0379
2021-08-13 23:36:12,262 - mmseg - INFO - Iter [32850/160000]	lr: 8.150e-03, eta: 2 days, 0:00:43, time: 1.992, data_time: 0.723, memory: 6005, decode.loss_seg: 1.0078, decode.acc_seg: 53.2963, loss: 1.0078
2021-08-13 23:37:15,620 - mmseg - INFO - Iter [32900/160000]	lr: 8.148e-03, eta: 1 day, 23:59:17, time: 1.268, data_time: 0.018, memory: 6005, decode.loss_seg: 1.0086, decode.acc_seg: 52.8231, loss: 1.0086
2021-08-13 23:38:20,176 - mmseg - INFO - Iter [32950/160000]	lr: 8.145e-03, eta: 1 day, 23:57:56, time: 1.291, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0325, decode.acc_seg: 52.4204, loss: 1.0325
2021-08-13 23:39:25,576 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-without-head_512x512_160k_ade20k.py
2021-08-13 23:39:25,577 - mmseg - INFO - Iter [33000/160000]	lr: 8.142e-03, eta: 1 day, 23:56:38, time: 1.308, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0305, decode.acc_seg: 52.9277, loss: 1.0305
2021-08-13 23:40:28,504 - mmseg - INFO - Iter [33050/160000]	lr: 8.139e-03, eta: 1 day, 23:55:11, time: 1.259, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0181, decode.acc_seg: 52.0339, loss: 1.0181
2021-08-13 23:41:33,677 - mmseg - INFO - Iter [33100/160000]	lr: 8.136e-03, eta: 1 day, 23:53:52, time: 1.302, data_time: 0.016, memory: 6005, decode.loss_seg: 0.9929, decode.acc_seg: 54.0084, loss: 0.9929
2021-08-13 23:42:39,370 - mmseg - INFO - Iter [33150/160000]	lr: 8.133e-03, eta: 1 day, 23:52:36, time: 1.314, data_time: 0.016, memory: 6005, decode.loss_seg: 1.0167, decode.acc_seg: 53.3910, loss: 1.0167
2021-08-13 23:43:42,856 - mmseg - INFO - Iter [33200/160000]	lr: 8.130e-03, eta: 1 day, 23:51:11, time: 1.271, data_time: 0.017, memory: 6005, decode.loss_seg: 1.0079, decode.acc_seg: 53.0437, loss: 1.0079
2021-08-13 23:44:48,050 - mmseg - INFO - Iter [33250/160000]	lr: 8.128e-03, eta: 1 day, 23:49:52, time: 1.303, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0238, decode.acc_seg: 52.7891, loss: 1.0238
2021-08-13 23:45:53,242 - mmseg - INFO - Iter [33300/160000]	lr: 8.125e-03, eta: 1 day, 23:48:34, time: 1.304, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0674, decode.acc_seg: 52.0201, loss: 1.0674
2021-08-13 23:46:58,674 - mmseg - INFO - Iter [33350/160000]	lr: 8.122e-03, eta: 1 day, 23:47:16, time: 1.308, data_time: 0.014, memory: 6005, decode.loss_seg: 1.0467, decode.acc_seg: 52.5958, loss: 1.0467
2021-08-13 23:48:07,712 - mmseg - INFO - Iter [33400/160000]	lr: 8.119e-03, eta: 1 day, 23:46:13, time: 1.381, data_time: 0.016, memory: 6005, decode.loss_seg: 1.0136, decode.acc_seg: 53.5644, loss: 1.0136
2021-08-13 23:49:49,679 - mmseg - INFO - Iter [33450/160000]	lr: 8.116e-03, eta: 1 day, 23:47:14, time: 2.040, data_time: 0.705, memory: 6005, decode.loss_seg: 1.0300, decode.acc_seg: 53.4509, loss: 1.0300
2021-08-13 23:50:53,844 - mmseg - INFO - Iter [33500/160000]	lr: 8.113e-03, eta: 1 day, 23:45:51, time: 1.283, data_time: 0.016, memory: 6005, decode.loss_seg: 0.9920, decode.acc_seg: 52.7976, loss: 0.9920
2021-08-13 23:51:59,672 - mmseg - INFO - Iter [33550/160000]	lr: 8.110e-03, eta: 1 day, 23:44:35, time: 1.316, data_time: 0.014, memory: 6005, decode.loss_seg: 1.0164, decode.acc_seg: 54.1125, loss: 1.0164
2021-08-13 23:53:08,368 - mmseg - INFO - Iter [33600/160000]	lr: 8.108e-03, eta: 1 day, 23:43:30, time: 1.374, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0425, decode.acc_seg: 53.1848, loss: 1.0425
2021-08-13 23:54:14,900 - mmseg - INFO - Iter [33650/160000]	lr: 8.105e-03, eta: 1 day, 23:42:17, time: 1.332, data_time: 0.016, memory: 6005, decode.loss_seg: 1.0191, decode.acc_seg: 53.1449, loss: 1.0191
2021-08-13 23:55:17,490 - mmseg - INFO - Iter [33700/160000]	lr: 8.102e-03, eta: 1 day, 23:40:49, time: 1.252, data_time: 0.015, memory: 6005, decode.loss_seg: 0.9971, decode.acc_seg: 53.0134, loss: 0.9971
2021-08-13 23:56:21,865 - mmseg - INFO - Iter [33750/160000]	lr: 8.099e-03, eta: 1 day, 23:39:27, time: 1.286, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0269, decode.acc_seg: 52.9549, loss: 1.0269
2021-08-13 23:57:27,931 - mmseg - INFO - Iter [33800/160000]	lr: 8.096e-03, eta: 1 day, 23:38:13, time: 1.323, data_time: 0.017, memory: 6005, decode.loss_seg: 0.9967, decode.acc_seg: 54.0125, loss: 0.9967
2021-08-13 23:58:32,025 - mmseg - INFO - Iter [33850/160000]	lr: 8.093e-03, eta: 1 day, 23:36:50, time: 1.281, data_time: 0.014, memory: 6005, decode.loss_seg: 1.0357, decode.acc_seg: 52.4874, loss: 1.0357
2021-08-13 23:59:38,142 - mmseg - INFO - Iter [33900/160000]	lr: 8.090e-03, eta: 1 day, 23:35:36, time: 1.323, data_time: 0.016, memory: 6005, decode.loss_seg: 1.0376, decode.acc_seg: 53.5367, loss: 1.0376
2021-08-14 00:00:44,460 - mmseg - INFO - Iter [33950/160000]	lr: 8.088e-03, eta: 1 day, 23:34:22, time: 1.326, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0572, decode.acc_seg: 52.9554, loss: 1.0572
2021-08-14 00:01:48,624 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-without-head_512x512_160k_ade20k.py
2021-08-14 00:01:48,625 - mmseg - INFO - Iter [34000/160000]	lr: 8.085e-03, eta: 1 day, 23:33:00, time: 1.284, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0205, decode.acc_seg: 52.7488, loss: 1.0205
2021-08-14 00:02:54,709 - mmseg - INFO - Iter [34050/160000]	lr: 8.082e-03, eta: 1 day, 23:31:45, time: 1.322, data_time: 0.014, memory: 6005, decode.loss_seg: 0.9886, decode.acc_seg: 53.8721, loss: 0.9886
2021-08-14 00:04:41,153 - mmseg - INFO - Iter [34100/160000]	lr: 8.079e-03, eta: 1 day, 23:32:59, time: 2.128, data_time: 0.850, memory: 6005, decode.loss_seg: 1.0274, decode.acc_seg: 52.3212, loss: 1.0274
2021-08-14 00:05:46,607 - mmseg - INFO - Iter [34150/160000]	lr: 8.076e-03, eta: 1 day, 23:31:42, time: 1.310, data_time: 0.016, memory: 6005, decode.loss_seg: 0.9993, decode.acc_seg: 52.2267, loss: 0.9993
2021-08-14 00:06:50,497 - mmseg - INFO - Iter [34200/160000]	lr: 8.073e-03, eta: 1 day, 23:30:19, time: 1.278, data_time: 0.016, memory: 6005, decode.loss_seg: 0.9969, decode.acc_seg: 53.6349, loss: 0.9969
2021-08-14 00:07:54,605 - mmseg - INFO - Iter [34250/160000]	lr: 8.071e-03, eta: 1 day, 23:28:57, time: 1.282, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0060, decode.acc_seg: 53.5183, loss: 1.0060
2021-08-14 00:09:00,056 - mmseg - INFO - Iter [34300/160000]	lr: 8.068e-03, eta: 1 day, 23:27:39, time: 1.308, data_time: 0.014, memory: 6005, decode.loss_seg: 0.9905, decode.acc_seg: 54.1659, loss: 0.9905
2021-08-14 00:10:06,520 - mmseg - INFO - Iter [34350/160000]	lr: 8.065e-03, eta: 1 day, 23:26:26, time: 1.330, data_time: 0.017, memory: 6005, decode.loss_seg: 1.0275, decode.acc_seg: 52.5876, loss: 1.0275
2021-08-14 00:11:14,287 - mmseg - INFO - Iter [34400/160000]	lr: 8.062e-03, eta: 1 day, 23:25:17, time: 1.355, data_time: 0.014, memory: 6005, decode.loss_seg: 1.0145, decode.acc_seg: 53.4311, loss: 1.0145
2021-08-14 00:12:18,489 - mmseg - INFO - Iter [34450/160000]	lr: 8.059e-03, eta: 1 day, 23:23:56, time: 1.285, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0107, decode.acc_seg: 52.8028, loss: 1.0107
2021-08-14 00:13:22,716 - mmseg - INFO - Iter [34500/160000]	lr: 8.056e-03, eta: 1 day, 23:22:34, time: 1.283, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0447, decode.acc_seg: 52.9708, loss: 1.0447
2021-08-14 00:14:31,151 - mmseg - INFO - Iter [34550/160000]	lr: 8.053e-03, eta: 1 day, 23:21:28, time: 1.369, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0344, decode.acc_seg: 52.8461, loss: 1.0344
2021-08-14 00:15:36,203 - mmseg - INFO - Iter [34600/160000]	lr: 8.051e-03, eta: 1 day, 23:20:09, time: 1.301, data_time: 0.016, memory: 6005, decode.loss_seg: 1.0120, decode.acc_seg: 53.6439, loss: 1.0120
2021-08-14 00:16:40,799 - mmseg - INFO - Iter [34650/160000]	lr: 8.048e-03, eta: 1 day, 23:18:49, time: 1.292, data_time: 0.016, memory: 6005, decode.loss_seg: 0.9424, decode.acc_seg: 54.3246, loss: 0.9424
2021-08-14 00:17:45,602 - mmseg - INFO - Iter [34700/160000]	lr: 8.045e-03, eta: 1 day, 23:17:30, time: 1.296, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0559, decode.acc_seg: 52.3240, loss: 1.0559
2021-08-14 00:19:24,907 - mmseg - INFO - Iter [34750/160000]	lr: 8.042e-03, eta: 1 day, 23:18:15, time: 1.986, data_time: 0.725, memory: 6005, decode.loss_seg: 0.9848, decode.acc_seg: 53.1368, loss: 0.9848
2021-08-14 00:20:31,707 - mmseg - INFO - Iter [34800/160000]	lr: 8.039e-03, eta: 1 day, 23:17:03, time: 1.337, data_time: 0.016, memory: 6005, decode.loss_seg: 1.0001, decode.acc_seg: 53.9192, loss: 1.0001
2021-08-14 00:21:36,073 - mmseg - INFO - Iter [34850/160000]	lr: 8.036e-03, eta: 1 day, 23:15:42, time: 1.287, data_time: 0.016, memory: 6005, decode.loss_seg: 0.9927, decode.acc_seg: 52.7266, loss: 0.9927
2021-08-14 00:22:41,730 - mmseg - INFO - Iter [34900/160000]	lr: 8.033e-03, eta: 1 day, 23:14:26, time: 1.312, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0169, decode.acc_seg: 53.7736, loss: 1.0169
2021-08-14 00:23:47,406 - mmseg - INFO - Iter [34950/160000]	lr: 8.031e-03, eta: 1 day, 23:13:10, time: 1.314, data_time: 0.016, memory: 6005, decode.loss_seg: 0.9956, decode.acc_seg: 53.6079, loss: 0.9956
2021-08-14 00:24:53,964 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-without-head_512x512_160k_ade20k.py
2021-08-14 00:24:53,965 - mmseg - INFO - Iter [35000/160000]	lr: 8.028e-03, eta: 1 day, 23:11:57, time: 1.331, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0154, decode.acc_seg: 53.5956, loss: 1.0154
2021-08-14 00:26:01,641 - mmseg - INFO - Iter [35050/160000]	lr: 8.025e-03, eta: 1 day, 23:10:48, time: 1.354, data_time: 0.016, memory: 6005, decode.loss_seg: 1.0127, decode.acc_seg: 52.0108, loss: 1.0127
2021-08-14 00:27:07,123 - mmseg - INFO - Iter [35100/160000]	lr: 8.022e-03, eta: 1 day, 23:09:31, time: 1.310, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0084, decode.acc_seg: 53.0205, loss: 1.0084
2021-08-14 00:28:12,205 - mmseg - INFO - Iter [35150/160000]	lr: 8.019e-03, eta: 1 day, 23:08:13, time: 1.302, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0354, decode.acc_seg: 53.4588, loss: 1.0354
2021-08-14 00:29:14,897 - mmseg - INFO - Iter [35200/160000]	lr: 8.016e-03, eta: 1 day, 23:06:46, time: 1.254, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0362, decode.acc_seg: 53.5860, loss: 1.0362
2021-08-14 00:30:16,988 - mmseg - INFO - Iter [35250/160000]	lr: 8.013e-03, eta: 1 day, 23:05:17, time: 1.241, data_time: 0.014, memory: 6005, decode.loss_seg: 1.0048, decode.acc_seg: 53.9719, loss: 1.0048
2021-08-14 00:31:21,007 - mmseg - INFO - Iter [35300/160000]	lr: 8.011e-03, eta: 1 day, 23:03:55, time: 1.281, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0136, decode.acc_seg: 52.8190, loss: 1.0136
2021-08-14 00:33:03,426 - mmseg - INFO - Iter [35350/160000]	lr: 8.008e-03, eta: 1 day, 23:04:49, time: 2.049, data_time: 0.727, memory: 6005, decode.loss_seg: 1.0302, decode.acc_seg: 52.6215, loss: 1.0302
2021-08-14 00:34:09,285 - mmseg - INFO - Iter [35400/160000]	lr: 8.005e-03, eta: 1 day, 23:03:34, time: 1.317, data_time: 0.016, memory: 6005, decode.loss_seg: 1.0007, decode.acc_seg: 53.8818, loss: 1.0007
2021-08-14 00:35:15,615 - mmseg - INFO - Iter [35450/160000]	lr: 8.002e-03, eta: 1 day, 23:02:20, time: 1.327, data_time: 0.014, memory: 6005, decode.loss_seg: 1.0270, decode.acc_seg: 52.4182, loss: 1.0270
2021-08-14 00:36:19,095 - mmseg - INFO - Iter [35500/160000]	lr: 7.999e-03, eta: 1 day, 23:00:56, time: 1.269, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0244, decode.acc_seg: 53.4588, loss: 1.0244
2021-08-14 00:37:24,550 - mmseg - INFO - Iter [35550/160000]	lr: 7.996e-03, eta: 1 day, 22:59:39, time: 1.309, data_time: 0.016, memory: 6005, decode.loss_seg: 0.9726, decode.acc_seg: 53.5530, loss: 0.9726
2021-08-14 00:38:28,135 - mmseg - INFO - Iter [35600/160000]	lr: 7.993e-03, eta: 1 day, 22:58:16, time: 1.272, data_time: 0.016, memory: 6005, decode.loss_seg: 1.0294, decode.acc_seg: 52.3263, loss: 1.0294
2021-08-14 00:39:31,115 - mmseg - INFO - Iter [35650/160000]	lr: 7.991e-03, eta: 1 day, 22:56:51, time: 1.259, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0210, decode.acc_seg: 52.6253, loss: 1.0210
2021-08-14 00:40:35,670 - mmseg - INFO - Iter [35700/160000]	lr: 7.988e-03, eta: 1 day, 22:55:31, time: 1.292, data_time: 0.015, memory: 6005, decode.loss_seg: 0.9759, decode.acc_seg: 53.9792, loss: 0.9759
2021-08-14 00:41:39,946 - mmseg - INFO - Iter [35750/160000]	lr: 7.985e-03, eta: 1 day, 22:54:10, time: 1.285, data_time: 0.014, memory: 6005, decode.loss_seg: 1.0005, decode.acc_seg: 52.9507, loss: 1.0005
2021-08-14 00:42:43,723 - mmseg - INFO - Iter [35800/160000]	lr: 7.982e-03, eta: 1 day, 22:52:48, time: 1.276, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0240, decode.acc_seg: 53.3460, loss: 1.0240
2021-08-14 00:43:48,016 - mmseg - INFO - Iter [35850/160000]	lr: 7.979e-03, eta: 1 day, 22:51:27, time: 1.285, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0106, decode.acc_seg: 53.3851, loss: 1.0106
2021-08-14 00:44:50,492 - mmseg - INFO - Iter [35900/160000]	lr: 7.976e-03, eta: 1 day, 22:50:00, time: 1.250, data_time: 0.018, memory: 6005, decode.loss_seg: 1.0163, decode.acc_seg: 53.0167, loss: 1.0163
2021-08-14 00:45:54,725 - mmseg - INFO - Iter [35950/160000]	lr: 7.973e-03, eta: 1 day, 22:48:40, time: 1.285, data_time: 0.014, memory: 6005, decode.loss_seg: 1.0231, decode.acc_seg: 52.7247, loss: 1.0231
2021-08-14 00:47:33,784 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-without-head_512x512_160k_ade20k.py
2021-08-14 00:47:33,788 - mmseg - INFO - Iter [36000/160000]	lr: 7.971e-03, eta: 1 day, 22:49:19, time: 1.982, data_time: 0.724, memory: 6005, decode.loss_seg: 0.9927, decode.acc_seg: 52.6430, loss: 0.9927
2021-08-14 00:48:37,210 - mmseg - INFO - Iter [36050/160000]	lr: 7.968e-03, eta: 1 day, 22:47:55, time: 1.268, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0376, decode.acc_seg: 53.5270, loss: 1.0376
2021-08-14 00:49:41,312 - mmseg - INFO - Iter [36100/160000]	lr: 7.965e-03, eta: 1 day, 22:46:34, time: 1.282, data_time: 0.016, memory: 6005, decode.loss_seg: 0.9755, decode.acc_seg: 54.5828, loss: 0.9755
2021-08-14 00:50:47,265 - mmseg - INFO - Iter [36150/160000]	lr: 7.962e-03, eta: 1 day, 22:45:19, time: 1.319, data_time: 0.014, memory: 6005, decode.loss_seg: 0.9742, decode.acc_seg: 53.7411, loss: 0.9742
2021-08-14 00:51:51,396 - mmseg - INFO - Iter [36200/160000]	lr: 7.959e-03, eta: 1 day, 22:43:58, time: 1.283, data_time: 0.015, memory: 6005, decode.loss_seg: 0.9615, decode.acc_seg: 53.7420, loss: 0.9615
2021-08-14 00:52:53,910 - mmseg - INFO - Iter [36250/160000]	lr: 7.956e-03, eta: 1 day, 22:42:32, time: 1.251, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0005, decode.acc_seg: 53.4406, loss: 1.0005
2021-08-14 00:53:59,371 - mmseg - INFO - Iter [36300/160000]	lr: 7.953e-03, eta: 1 day, 22:41:15, time: 1.309, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0742, decode.acc_seg: 52.6832, loss: 1.0742
2021-08-14 00:55:04,187 - mmseg - INFO - Iter [36350/160000]	lr: 7.951e-03, eta: 1 day, 22:39:57, time: 1.297, data_time: 0.017, memory: 6005, decode.loss_seg: 1.0165, decode.acc_seg: 53.6229, loss: 1.0165
2021-08-14 00:56:08,079 - mmseg - INFO - Iter [36400/160000]	lr: 7.948e-03, eta: 1 day, 22:38:35, time: 1.278, data_time: 0.015, memory: 6005, decode.loss_seg: 0.9762, decode.acc_seg: 53.3200, loss: 0.9762
2021-08-14 00:57:12,462 - mmseg - INFO - Iter [36450/160000]	lr: 7.945e-03, eta: 1 day, 22:37:15, time: 1.288, data_time: 0.017, memory: 6005, decode.loss_seg: 0.9935, decode.acc_seg: 53.2689, loss: 0.9935
2021-08-14 00:58:16,339 - mmseg - INFO - Iter [36500/160000]	lr: 7.942e-03, eta: 1 day, 22:35:54, time: 1.277, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0151, decode.acc_seg: 52.9921, loss: 1.0151
2021-08-14 00:59:19,255 - mmseg - INFO - Iter [36550/160000]	lr: 7.939e-03, eta: 1 day, 22:34:29, time: 1.259, data_time: 0.018, memory: 6005, decode.loss_seg: 1.0175, decode.acc_seg: 53.1058, loss: 1.0175
2021-08-14 01:00:57,477 - mmseg - INFO - Iter [36600/160000]	lr: 7.936e-03, eta: 1 day, 22:35:03, time: 1.964, data_time: 0.691, memory: 6005, decode.loss_seg: 1.0084, decode.acc_seg: 53.7539, loss: 1.0084
2021-08-14 01:02:01,461 - mmseg - INFO - Iter [36650/160000]	lr: 7.933e-03, eta: 1 day, 22:33:42, time: 1.280, data_time: 0.018, memory: 6005, decode.loss_seg: 0.9821, decode.acc_seg: 53.8664, loss: 0.9821
2021-08-14 01:03:05,416 - mmseg - INFO - Iter [36700/160000]	lr: 7.931e-03, eta: 1 day, 22:32:20, time: 1.279, data_time: 0.015, memory: 6005, decode.loss_seg: 0.9882, decode.acc_seg: 54.1392, loss: 0.9882
2021-08-14 01:04:09,155 - mmseg - INFO - Iter [36750/160000]	lr: 7.928e-03, eta: 1 day, 22:30:58, time: 1.274, data_time: 0.016, memory: 6005, decode.loss_seg: 0.9626, decode.acc_seg: 54.2695, loss: 0.9626
2021-08-14 01:05:13,920 - mmseg - INFO - Iter [36800/160000]	lr: 7.925e-03, eta: 1 day, 22:29:40, time: 1.296, data_time: 0.016, memory: 6005, decode.loss_seg: 1.0444, decode.acc_seg: 53.4539, loss: 1.0444
2021-08-14 01:06:20,560 - mmseg - INFO - Iter [36850/160000]	lr: 7.922e-03, eta: 1 day, 22:28:28, time: 1.332, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0387, decode.acc_seg: 52.5251, loss: 1.0387
2021-08-14 01:07:25,127 - mmseg - INFO - Iter [36900/160000]	lr: 7.919e-03, eta: 1 day, 22:27:08, time: 1.292, data_time: 0.016, memory: 6005, decode.loss_seg: 1.0194, decode.acc_seg: 53.0854, loss: 1.0194
2021-08-14 01:08:30,748 - mmseg - INFO - Iter [36950/160000]	lr: 7.916e-03, eta: 1 day, 22:25:53, time: 1.312, data_time: 0.015, memory: 6005, decode.loss_seg: 0.9988, decode.acc_seg: 54.1205, loss: 0.9988
2021-08-14 01:09:35,457 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-without-head_512x512_160k_ade20k.py
2021-08-14 01:09:35,458 - mmseg - INFO - Iter [37000/160000]	lr: 7.913e-03, eta: 1 day, 22:24:34, time: 1.295, data_time: 0.016, memory: 6005, decode.loss_seg: 1.0009, decode.acc_seg: 53.1807, loss: 1.0009
2021-08-14 01:10:39,489 - mmseg - INFO - Iter [37050/160000]	lr: 7.911e-03, eta: 1 day, 22:23:14, time: 1.281, data_time: 0.016, memory: 6005, decode.loss_seg: 1.0109, decode.acc_seg: 52.9372, loss: 1.0109
2021-08-14 01:11:42,371 - mmseg - INFO - Iter [37100/160000]	lr: 7.908e-03, eta: 1 day, 22:21:49, time: 1.258, data_time: 0.015, memory: 6005, decode.loss_seg: 0.9980, decode.acc_seg: 53.9478, loss: 0.9980
2021-08-14 01:12:47,362 - mmseg - INFO - Iter [37150/160000]	lr: 7.905e-03, eta: 1 day, 22:20:31, time: 1.300, data_time: 0.016, memory: 6005, decode.loss_seg: 0.9889, decode.acc_seg: 52.2419, loss: 0.9889
2021-08-14 01:13:50,696 - mmseg - INFO - Iter [37200/160000]	lr: 7.902e-03, eta: 1 day, 22:19:08, time: 1.266, data_time: 0.016, memory: 6005, decode.loss_seg: 1.0422, decode.acc_seg: 53.4406, loss: 1.0422
2021-08-14 01:15:29,965 - mmseg - INFO - Iter [37250/160000]	lr: 7.899e-03, eta: 1 day, 22:19:44, time: 1.986, data_time: 0.680, memory: 6005, decode.loss_seg: 0.9770, decode.acc_seg: 53.5577, loss: 0.9770
2021-08-14 01:16:35,536 - mmseg - INFO - Iter [37300/160000]	lr: 7.896e-03, eta: 1 day, 22:18:28, time: 1.310, data_time: 0.017, memory: 6005, decode.loss_seg: 0.9867, decode.acc_seg: 53.3750, loss: 0.9867
2021-08-14 01:17:42,251 - mmseg - INFO - Iter [37350/160000]	lr: 7.893e-03, eta: 1 day, 22:17:16, time: 1.335, data_time: 0.016, memory: 6005, decode.loss_seg: 0.9904, decode.acc_seg: 53.8048, loss: 0.9904
2021-08-14 01:18:45,262 - mmseg - INFO - Iter [37400/160000]	lr: 7.891e-03, eta: 1 day, 22:15:52, time: 1.261, data_time: 0.016, memory: 6005, decode.loss_seg: 1.0002, decode.acc_seg: 54.6000, loss: 1.0002
2021-08-14 01:19:48,483 - mmseg - INFO - Iter [37450/160000]	lr: 7.888e-03, eta: 1 day, 22:14:29, time: 1.264, data_time: 0.016, memory: 6005, decode.loss_seg: 1.0190, decode.acc_seg: 53.8044, loss: 1.0190
2021-08-14 01:20:52,289 - mmseg - INFO - Iter [37500/160000]	lr: 7.885e-03, eta: 1 day, 22:13:08, time: 1.276, data_time: 0.014, memory: 6005, decode.loss_seg: 1.0001, decode.acc_seg: 53.2964, loss: 1.0001
2021-08-14 01:21:57,132 - mmseg - INFO - Iter [37550/160000]	lr: 7.882e-03, eta: 1 day, 22:11:50, time: 1.296, data_time: 0.014, memory: 6005, decode.loss_seg: 0.9622, decode.acc_seg: 54.5347, loss: 0.9622
2021-08-14 01:23:00,827 - mmseg - INFO - Iter [37600/160000]	lr: 7.879e-03, eta: 1 day, 22:10:28, time: 1.274, data_time: 0.014, memory: 6005, decode.loss_seg: 1.0013, decode.acc_seg: 53.3483, loss: 1.0013
2021-08-14 01:24:06,259 - mmseg - INFO - Iter [37650/160000]	lr: 7.876e-03, eta: 1 day, 22:09:12, time: 1.308, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0043, decode.acc_seg: 53.0706, loss: 1.0043
2021-08-14 01:25:11,621 - mmseg - INFO - Iter [37700/160000]	lr: 7.873e-03, eta: 1 day, 22:07:56, time: 1.308, data_time: 0.016, memory: 6005, decode.loss_seg: 0.9864, decode.acc_seg: 53.6370, loss: 0.9864
2021-08-14 01:26:16,832 - mmseg - INFO - Iter [37750/160000]	lr: 7.871e-03, eta: 1 day, 22:06:39, time: 1.305, data_time: 0.016, memory: 6005, decode.loss_seg: 1.0170, decode.acc_seg: 53.3370, loss: 1.0170
2021-08-14 01:27:19,793 - mmseg - INFO - Iter [37800/160000]	lr: 7.868e-03, eta: 1 day, 22:05:15, time: 1.259, data_time: 0.015, memory: 6005, decode.loss_seg: 0.9899, decode.acc_seg: 54.4487, loss: 0.9899
2021-08-14 01:28:27,170 - mmseg - INFO - Iter [37850/160000]	lr: 7.865e-03, eta: 1 day, 22:04:06, time: 1.346, data_time: 0.014, memory: 6005, decode.loss_seg: 1.0161, decode.acc_seg: 52.6959, loss: 1.0161
2021-08-14 01:30:09,145 - mmseg - INFO - Iter [37900/160000]	lr: 7.862e-03, eta: 1 day, 22:04:48, time: 2.040, data_time: 0.711, memory: 6005, decode.loss_seg: 0.9557, decode.acc_seg: 53.5324, loss: 0.9557
2021-08-14 01:31:14,609 - mmseg - INFO - Iter [37950/160000]	lr: 7.859e-03, eta: 1 day, 22:03:32, time: 1.310, data_time: 0.016, memory: 6005, decode.loss_seg: 0.9912, decode.acc_seg: 52.9086, loss: 0.9912
2021-08-14 01:32:18,999 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-without-head_512x512_160k_ade20k.py
2021-08-14 01:32:18,999 - mmseg - INFO - Iter [38000/160000]	lr: 7.856e-03, eta: 1 day, 22:02:13, time: 1.288, data_time: 0.015, memory: 6005, decode.loss_seg: 0.9928, decode.acc_seg: 53.8030, loss: 0.9928
2021-08-14 01:33:22,437 - mmseg - INFO - Iter [38050/160000]	lr: 7.853e-03, eta: 1 day, 22:00:50, time: 1.269, data_time: 0.016, memory: 6005, decode.loss_seg: 0.9968, decode.acc_seg: 54.5032, loss: 0.9968
2021-08-14 01:34:25,531 - mmseg - INFO - Iter [38100/160000]	lr: 7.851e-03, eta: 1 day, 21:59:27, time: 1.261, data_time: 0.015, memory: 6005, decode.loss_seg: 0.9719, decode.acc_seg: 54.5803, loss: 0.9719
2021-08-14 01:35:30,863 - mmseg - INFO - Iter [38150/160000]	lr: 7.848e-03, eta: 1 day, 21:58:11, time: 1.306, data_time: 0.016, memory: 6005, decode.loss_seg: 0.9879, decode.acc_seg: 54.5922, loss: 0.9879
2021-08-14 01:36:36,027 - mmseg - INFO - Iter [38200/160000]	lr: 7.845e-03, eta: 1 day, 21:56:54, time: 1.305, data_time: 0.018, memory: 6005, decode.loss_seg: 1.0152, decode.acc_seg: 53.1910, loss: 1.0152
2021-08-14 01:37:40,784 - mmseg - INFO - Iter [38250/160000]	lr: 7.842e-03, eta: 1 day, 21:55:36, time: 1.294, data_time: 0.015, memory: 6005, decode.loss_seg: 0.9876, decode.acc_seg: 52.6678, loss: 0.9876
2021-08-14 01:38:48,014 - mmseg - INFO - Iter [38300/160000]	lr: 7.839e-03, eta: 1 day, 21:54:26, time: 1.345, data_time: 0.015, memory: 6005, decode.loss_seg: 0.9870, decode.acc_seg: 54.2317, loss: 0.9870
2021-08-14 01:39:52,487 - mmseg - INFO - Iter [38350/160000]	lr: 7.836e-03, eta: 1 day, 21:53:07, time: 1.290, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0077, decode.acc_seg: 53.9671, loss: 1.0077
2021-08-14 01:40:56,475 - mmseg - INFO - Iter [38400/160000]	lr: 7.833e-03, eta: 1 day, 21:51:47, time: 1.279, data_time: 0.016, memory: 6005, decode.loss_seg: 1.0097, decode.acc_seg: 53.4552, loss: 1.0097
2021-08-14 01:42:03,336 - mmseg - INFO - Iter [38450/160000]	lr: 7.831e-03, eta: 1 day, 21:50:36, time: 1.338, data_time: 0.016, memory: 6005, decode.loss_seg: 0.9899, decode.acc_seg: 54.4052, loss: 0.9899
2021-08-14 01:43:43,959 - mmseg - INFO - Iter [38500/160000]	lr: 7.828e-03, eta: 1 day, 21:51:11, time: 2.012, data_time: 0.728, memory: 6005, decode.loss_seg: 1.0322, decode.acc_seg: 52.0202, loss: 1.0322
2021-08-14 01:44:48,375 - mmseg - INFO - Iter [38550/160000]	lr: 7.825e-03, eta: 1 day, 21:49:52, time: 1.287, data_time: 0.016, memory: 6005, decode.loss_seg: 0.9328, decode.acc_seg: 54.2212, loss: 0.9328
2021-08-14 01:45:53,680 - mmseg - INFO - Iter [38600/160000]	lr: 7.822e-03, eta: 1 day, 21:48:36, time: 1.307, data_time: 0.017, memory: 6005, decode.loss_seg: 0.9591, decode.acc_seg: 53.5230, loss: 0.9591
2021-08-14 01:46:58,812 - mmseg - INFO - Iter [38650/160000]	lr: 7.819e-03, eta: 1 day, 21:47:19, time: 1.302, data_time: 0.017, memory: 6005, decode.loss_seg: 0.9410, decode.acc_seg: 54.2535, loss: 0.9410
2021-08-14 01:48:03,403 - mmseg - INFO - Iter [38700/160000]	lr: 7.816e-03, eta: 1 day, 21:46:01, time: 1.291, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0000, decode.acc_seg: 53.7016, loss: 1.0000
2021-08-14 01:49:11,342 - mmseg - INFO - Iter [38750/160000]	lr: 7.813e-03, eta: 1 day, 21:44:53, time: 1.359, data_time: 0.016, memory: 6005, decode.loss_seg: 0.9882, decode.acc_seg: 53.9238, loss: 0.9882
2021-08-14 01:50:15,948 - mmseg - INFO - Iter [38800/160000]	lr: 7.811e-03, eta: 1 day, 21:43:35, time: 1.293, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0245, decode.acc_seg: 53.5454, loss: 1.0245
2021-08-14 01:51:20,757 - mmseg - INFO - Iter [38850/160000]	lr: 7.808e-03, eta: 1 day, 21:42:18, time: 1.296, data_time: 0.016, memory: 6005, decode.loss_seg: 1.0099, decode.acc_seg: 53.6675, loss: 1.0099
2021-08-14 01:52:27,211 - mmseg - INFO - Iter [38900/160000]	lr: 7.805e-03, eta: 1 day, 21:41:05, time: 1.328, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0176, decode.acc_seg: 52.6448, loss: 1.0176
2021-08-14 01:53:32,630 - mmseg - INFO - Iter [38950/160000]	lr: 7.802e-03, eta: 1 day, 21:39:49, time: 1.308, data_time: 0.016, memory: 6005, decode.loss_seg: 1.0443, decode.acc_seg: 52.1825, loss: 1.0443
2021-08-14 01:54:37,706 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-without-head_512x512_160k_ade20k.py
2021-08-14 01:54:37,707 - mmseg - INFO - Iter [39000/160000]	lr: 7.799e-03, eta: 1 day, 21:38:33, time: 1.302, data_time: 0.016, memory: 6005, decode.loss_seg: 0.9837, decode.acc_seg: 53.3524, loss: 0.9837
2021-08-14 01:55:40,500 - mmseg - INFO - Iter [39050/160000]	lr: 7.796e-03, eta: 1 day, 21:37:09, time: 1.257, data_time: 0.016, memory: 6005, decode.loss_seg: 0.9695, decode.acc_seg: 52.9018, loss: 0.9695
2021-08-14 01:56:45,696 - mmseg - INFO - Iter [39100/160000]	lr: 7.793e-03, eta: 1 day, 21:35:53, time: 1.303, data_time: 0.014, memory: 6005, decode.loss_seg: 0.9975, decode.acc_seg: 53.0687, loss: 0.9975
2021-08-14 01:58:29,626 - mmseg - INFO - Iter [39150/160000]	lr: 7.790e-03, eta: 1 day, 21:36:36, time: 2.080, data_time: 0.747, memory: 6005, decode.loss_seg: 0.9871, decode.acc_seg: 52.8491, loss: 0.9871
2021-08-14 01:59:35,585 - mmseg - INFO - Iter [39200/160000]	lr: 7.788e-03, eta: 1 day, 21:35:22, time: 1.319, data_time: 0.016, memory: 6005, decode.loss_seg: 1.0057, decode.acc_seg: 53.9192, loss: 1.0057
2021-08-14 02:00:38,786 - mmseg - INFO - Iter [39250/160000]	lr: 7.785e-03, eta: 1 day, 21:34:00, time: 1.264, data_time: 0.015, memory: 6005, decode.loss_seg: 0.9679, decode.acc_seg: 54.2900, loss: 0.9679
2021-08-14 02:01:43,391 - mmseg - INFO - Iter [39300/160000]	lr: 7.782e-03, eta: 1 day, 21:32:42, time: 1.293, data_time: 0.015, memory: 6005, decode.loss_seg: 0.9734, decode.acc_seg: 54.0700, loss: 0.9734
2021-08-14 02:02:48,386 - mmseg - INFO - Iter [39350/160000]	lr: 7.779e-03, eta: 1 day, 21:31:25, time: 1.299, data_time: 0.016, memory: 6005, decode.loss_seg: 0.9887, decode.acc_seg: 53.5234, loss: 0.9887
2021-08-14 02:03:52,333 - mmseg - INFO - Iter [39400/160000]	lr: 7.776e-03, eta: 1 day, 21:30:05, time: 1.279, data_time: 0.016, memory: 6005, decode.loss_seg: 0.9972, decode.acc_seg: 54.3476, loss: 0.9972
2021-08-14 02:04:56,442 - mmseg - INFO - Iter [39450/160000]	lr: 7.773e-03, eta: 1 day, 21:28:45, time: 1.283, data_time: 0.014, memory: 6005, decode.loss_seg: 0.9960, decode.acc_seg: 54.3539, loss: 0.9960
2021-08-14 02:05:59,378 - mmseg - INFO - Iter [39500/160000]	lr: 7.770e-03, eta: 1 day, 21:27:22, time: 1.258, data_time: 0.015, memory: 6005, decode.loss_seg: 0.9989, decode.acc_seg: 52.8234, loss: 0.9989
2021-08-14 02:07:03,295 - mmseg - INFO - Iter [39550/160000]	lr: 7.768e-03, eta: 1 day, 21:26:02, time: 1.277, data_time: 0.014, memory: 6005, decode.loss_seg: 1.0076, decode.acc_seg: 52.9734, loss: 1.0076
2021-08-14 02:08:10,296 - mmseg - INFO - Iter [39600/160000]	lr: 7.765e-03, eta: 1 day, 21:24:51, time: 1.341, data_time: 0.015, memory: 6005, decode.loss_seg: 0.9813, decode.acc_seg: 54.0749, loss: 0.9813
2021-08-14 02:09:16,671 - mmseg - INFO - Iter [39650/160000]	lr: 7.762e-03, eta: 1 day, 21:23:39, time: 1.328, data_time: 0.014, memory: 6005, decode.loss_seg: 0.9891, decode.acc_seg: 53.8527, loss: 0.9891
2021-08-14 02:10:22,910 - mmseg - INFO - Iter [39700/160000]	lr: 7.759e-03, eta: 1 day, 21:22:26, time: 1.325, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0212, decode.acc_seg: 53.1187, loss: 1.0212
2021-08-14 02:11:24,694 - mmseg - INFO - Iter [39750/160000]	lr: 7.756e-03, eta: 1 day, 21:21:00, time: 1.236, data_time: 0.014, memory: 6005, decode.loss_seg: 1.0013, decode.acc_seg: 52.7535, loss: 1.0013
2021-08-14 02:13:07,649 - mmseg - INFO - Iter [39800/160000]	lr: 7.753e-03, eta: 1 day, 21:21:38, time: 2.059, data_time: 0.710, memory: 6005, decode.loss_seg: 0.9551, decode.acc_seg: 54.4016, loss: 0.9551
2021-08-14 02:14:10,736 - mmseg - INFO - Iter [39850/160000]	lr: 7.750e-03, eta: 1 day, 21:20:15, time: 1.261, data_time: 0.015, memory: 6005, decode.loss_seg: 0.9979, decode.acc_seg: 53.3801, loss: 0.9979
2021-08-14 02:15:16,602 - mmseg - INFO - Iter [39900/160000]	lr: 7.747e-03, eta: 1 day, 21:19:01, time: 1.317, data_time: 0.015, memory: 6005, decode.loss_seg: 0.9964, decode.acc_seg: 54.0839, loss: 0.9964
2021-08-14 02:16:20,958 - mmseg - INFO - Iter [39950/160000]	lr: 7.745e-03, eta: 1 day, 21:17:42, time: 1.288, data_time: 0.016, memory: 6005, decode.loss_seg: 0.9936, decode.acc_seg: 53.8499, loss: 0.9936
2021-08-14 02:17:29,337 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-without-head_512x512_160k_ade20k.py
2021-08-14 02:17:29,337 - mmseg - INFO - Iter [40000/160000]	lr: 7.742e-03, eta: 1 day, 21:16:36, time: 1.366, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0007, decode.acc_seg: 53.6416, loss: 1.0007
2021-08-14 02:18:36,974 - mmseg - INFO - Iter [40050/160000]	lr: 7.739e-03, eta: 1 day, 21:15:27, time: 1.354, data_time: 0.017, memory: 6005, decode.loss_seg: 0.9797, decode.acc_seg: 54.4124, loss: 0.9797
2021-08-14 02:19:41,958 - mmseg - INFO - Iter [40100/160000]	lr: 7.736e-03, eta: 1 day, 21:14:10, time: 1.298, data_time: 0.015, memory: 6005, decode.loss_seg: 0.9932, decode.acc_seg: 53.3861, loss: 0.9932
2021-08-14 02:20:47,299 - mmseg - INFO - Iter [40150/160000]	lr: 7.733e-03, eta: 1 day, 21:12:55, time: 1.307, data_time: 0.016, memory: 6005, decode.loss_seg: 1.0073, decode.acc_seg: 53.6764, loss: 1.0073
2021-08-14 02:21:50,668 - mmseg - INFO - Iter [40200/160000]	lr: 7.730e-03, eta: 1 day, 21:11:33, time: 1.268, data_time: 0.017, memory: 6005, decode.loss_seg: 0.9566, decode.acc_seg: 53.7107, loss: 0.9566
2021-08-14 02:22:54,395 - mmseg - INFO - Iter [40250/160000]	lr: 7.727e-03, eta: 1 day, 21:10:13, time: 1.275, data_time: 0.017, memory: 6005, decode.loss_seg: 1.0090, decode.acc_seg: 53.6333, loss: 1.0090
2021-08-14 02:23:58,576 - mmseg - INFO - Iter [40300/160000]	lr: 7.725e-03, eta: 1 day, 21:08:54, time: 1.283, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0077, decode.acc_seg: 53.5213, loss: 1.0077
2021-08-14 02:25:03,790 - mmseg - INFO - Iter [40350/160000]	lr: 7.722e-03, eta: 1 day, 21:07:38, time: 1.304, data_time: 0.015, memory: 6005, decode.loss_seg: 0.9745, decode.acc_seg: 53.9024, loss: 0.9745
2021-08-14 02:26:43,385 - mmseg - INFO - Iter [40400/160000]	lr: 7.719e-03, eta: 1 day, 21:08:04, time: 1.992, data_time: 0.699, memory: 6005, decode.loss_seg: 0.9793, decode.acc_seg: 52.9673, loss: 0.9793
2021-08-14 02:27:50,469 - mmseg - INFO - Iter [40450/160000]	lr: 7.716e-03, eta: 1 day, 21:06:54, time: 1.341, data_time: 0.016, memory: 6005, decode.loss_seg: 0.9832, decode.acc_seg: 53.9449, loss: 0.9832
2021-08-14 02:28:54,756 - mmseg - INFO - Iter [40500/160000]	lr: 7.713e-03, eta: 1 day, 21:05:35, time: 1.286, data_time: 0.015, memory: 6005, decode.loss_seg: 0.9650, decode.acc_seg: 54.1496, loss: 0.9650
2021-08-14 02:30:02,159 - mmseg - INFO - Iter [40550/160000]	lr: 7.710e-03, eta: 1 day, 21:04:25, time: 1.347, data_time: 0.015, memory: 6005, decode.loss_seg: 0.9983, decode.acc_seg: 54.1235, loss: 0.9983
2021-08-14 02:31:10,482 - mmseg - INFO - Iter [40600/160000]	lr: 7.707e-03, eta: 1 day, 21:03:19, time: 1.366, data_time: 0.015, memory: 6005, decode.loss_seg: 0.9795, decode.acc_seg: 53.4628, loss: 0.9795
2021-08-14 02:32:16,987 - mmseg - INFO - Iter [40650/160000]	lr: 7.705e-03, eta: 1 day, 21:02:07, time: 1.331, data_time: 0.018, memory: 6005, decode.loss_seg: 0.9978, decode.acc_seg: 53.1767, loss: 0.9978
2021-08-14 02:33:20,785 - mmseg - INFO - Iter [40700/160000]	lr: 7.702e-03, eta: 1 day, 21:00:47, time: 1.276, data_time: 0.016, memory: 6005, decode.loss_seg: 0.9718, decode.acc_seg: 53.9428, loss: 0.9718
2021-08-14 02:34:25,252 - mmseg - INFO - Iter [40750/160000]	lr: 7.699e-03, eta: 1 day, 20:59:29, time: 1.289, data_time: 0.014, memory: 6005, decode.loss_seg: 0.9815, decode.acc_seg: 54.1851, loss: 0.9815
2021-08-14 02:35:29,314 - mmseg - INFO - Iter [40800/160000]	lr: 7.696e-03, eta: 1 day, 20:58:10, time: 1.281, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0181, decode.acc_seg: 53.3743, loss: 1.0181
2021-08-14 02:36:34,043 - mmseg - INFO - Iter [40850/160000]	lr: 7.693e-03, eta: 1 day, 20:56:52, time: 1.295, data_time: 0.015, memory: 6005, decode.loss_seg: 0.9995, decode.acc_seg: 53.2856, loss: 0.9995
2021-08-14 02:37:40,007 - mmseg - INFO - Iter [40900/160000]	lr: 7.690e-03, eta: 1 day, 20:55:39, time: 1.320, data_time: 0.014, memory: 6005, decode.loss_seg: 1.0167, decode.acc_seg: 54.1227, loss: 1.0167
2021-08-14 02:38:46,097 - mmseg - INFO - Iter [40950/160000]	lr: 7.687e-03, eta: 1 day, 20:54:26, time: 1.320, data_time: 0.014, memory: 6005, decode.loss_seg: 0.9986, decode.acc_seg: 54.4575, loss: 0.9986
2021-08-14 02:39:55,033 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-without-head_512x512_160k_ade20k.py
2021-08-14 02:39:55,034 - mmseg - INFO - Iter [41000/160000]	lr: 7.684e-03, eta: 1 day, 20:53:21, time: 1.379, data_time: 0.015, memory: 6005, decode.loss_seg: 0.9729, decode.acc_seg: 53.7471, loss: 0.9729
2021-08-14 02:41:35,165 - mmseg - INFO - Iter [41050/160000]	lr: 7.682e-03, eta: 1 day, 20:53:46, time: 2.003, data_time: 0.720, memory: 6005, decode.loss_seg: 0.9648, decode.acc_seg: 54.9644, loss: 0.9648
2021-08-14 02:42:39,251 - mmseg - INFO - Iter [41100/160000]	lr: 7.679e-03, eta: 1 day, 20:52:27, time: 1.282, data_time: 0.015, memory: 6005, decode.loss_seg: 0.9481, decode.acc_seg: 54.3971, loss: 0.9481
2021-08-14 02:43:42,202 - mmseg - INFO - Iter [41150/160000]	lr: 7.676e-03, eta: 1 day, 20:51:05, time: 1.259, data_time: 0.017, memory: 6005, decode.loss_seg: 0.9993, decode.acc_seg: 53.8995, loss: 0.9993
2021-08-14 02:44:47,509 - mmseg - INFO - Iter [41200/160000]	lr: 7.673e-03, eta: 1 day, 20:49:49, time: 1.306, data_time: 0.015, memory: 6005, decode.loss_seg: 0.9809, decode.acc_seg: 54.7737, loss: 0.9809
2021-08-14 02:45:52,969 - mmseg - INFO - Iter [41250/160000]	lr: 7.670e-03, eta: 1 day, 20:48:34, time: 1.310, data_time: 0.014, memory: 6005, decode.loss_seg: 0.9981, decode.acc_seg: 54.2641, loss: 0.9981
2021-08-14 02:46:56,477 - mmseg - INFO - Iter [41300/160000]	lr: 7.667e-03, eta: 1 day, 20:47:14, time: 1.270, data_time: 0.015, memory: 6005, decode.loss_seg: 0.9613, decode.acc_seg: 53.8305, loss: 0.9613
2021-08-14 02:48:00,027 - mmseg - INFO - Iter [41350/160000]	lr: 7.664e-03, eta: 1 day, 20:45:53, time: 1.271, data_time: 0.014, memory: 6005, decode.loss_seg: 0.9788, decode.acc_seg: 54.1959, loss: 0.9788
2021-08-14 02:49:03,604 - mmseg - INFO - Iter [41400/160000]	lr: 7.661e-03, eta: 1 day, 20:44:33, time: 1.272, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0039, decode.acc_seg: 53.2985, loss: 1.0039
2021-08-14 02:50:09,223 - mmseg - INFO - Iter [41450/160000]	lr: 7.659e-03, eta: 1 day, 20:43:18, time: 1.311, data_time: 0.014, memory: 6005, decode.loss_seg: 1.0064, decode.acc_seg: 52.9652, loss: 1.0064
2021-08-14 02:51:14,924 - mmseg - INFO - Iter [41500/160000]	lr: 7.656e-03, eta: 1 day, 20:42:04, time: 1.314, data_time: 0.016, memory: 6005, decode.loss_seg: 1.0076, decode.acc_seg: 53.5830, loss: 1.0076
2021-08-14 02:52:18,334 - mmseg - INFO - Iter [41550/160000]	lr: 7.653e-03, eta: 1 day, 20:40:44, time: 1.269, data_time: 0.015, memory: 6005, decode.loss_seg: 0.9668, decode.acc_seg: 53.6090, loss: 0.9668
2021-08-14 02:53:21,654 - mmseg - INFO - Iter [41600/160000]	lr: 7.650e-03, eta: 1 day, 20:39:23, time: 1.267, data_time: 0.015, memory: 6005, decode.loss_seg: 0.9976, decode.acc_seg: 54.1473, loss: 0.9976
2021-08-14 02:55:01,385 - mmseg - INFO - Iter [41650/160000]	lr: 7.647e-03, eta: 1 day, 20:39:45, time: 1.994, data_time: 0.674, memory: 6005, decode.loss_seg: 0.9919, decode.acc_seg: 53.9506, loss: 0.9919
2021-08-14 02:56:05,616 - mmseg - INFO - Iter [41700/160000]	lr: 7.644e-03, eta: 1 day, 20:38:27, time: 1.285, data_time: 0.016, memory: 6005, decode.loss_seg: 0.9304, decode.acc_seg: 54.1611, loss: 0.9304
2021-08-14 02:57:12,205 - mmseg - INFO - Iter [41750/160000]	lr: 7.641e-03, eta: 1 day, 20:37:15, time: 1.332, data_time: 0.014, memory: 6005, decode.loss_seg: 0.9441, decode.acc_seg: 55.4147, loss: 0.9441
2021-08-14 02:58:15,337 - mmseg - INFO - Iter [41800/160000]	lr: 7.639e-03, eta: 1 day, 20:35:54, time: 1.262, data_time: 0.014, memory: 6005, decode.loss_seg: 0.9400, decode.acc_seg: 54.7105, loss: 0.9400
2021-08-14 02:59:19,627 - mmseg - INFO - Iter [41850/160000]	lr: 7.636e-03, eta: 1 day, 20:34:36, time: 1.286, data_time: 0.018, memory: 6005, decode.loss_seg: 1.0003, decode.acc_seg: 54.0455, loss: 1.0003
2021-08-14 03:00:24,154 - mmseg - INFO - Iter [41900/160000]	lr: 7.633e-03, eta: 1 day, 20:33:18, time: 1.291, data_time: 0.014, memory: 6005, decode.loss_seg: 0.9951, decode.acc_seg: 52.9090, loss: 0.9951
2021-08-14 03:01:26,941 - mmseg - INFO - Iter [41950/160000]	lr: 7.630e-03, eta: 1 day, 20:31:56, time: 1.255, data_time: 0.016, memory: 6005, decode.loss_seg: 1.0028, decode.acc_seg: 53.3092, loss: 1.0028
2021-08-14 03:02:30,032 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-without-head_512x512_160k_ade20k.py
2021-08-14 03:02:30,032 - mmseg - INFO - Iter [42000/160000]	lr: 7.627e-03, eta: 1 day, 20:30:34, time: 1.261, data_time: 0.015, memory: 6005, decode.loss_seg: 0.9718, decode.acc_seg: 53.4293, loss: 0.9718
2021-08-14 03:03:34,428 - mmseg - INFO - Iter [42050/160000]	lr: 7.624e-03, eta: 1 day, 20:29:17, time: 1.288, data_time: 0.016, memory: 6005, decode.loss_seg: 0.9488, decode.acc_seg: 53.4890, loss: 0.9488
2021-08-14 03:04:39,605 - mmseg - INFO - Iter [42100/160000]	lr: 7.621e-03, eta: 1 day, 20:28:01, time: 1.304, data_time: 0.015, memory: 6005, decode.loss_seg: 0.9822, decode.acc_seg: 53.4093, loss: 0.9822
2021-08-14 03:05:43,690 - mmseg - INFO - Iter [42150/160000]	lr: 7.618e-03, eta: 1 day, 20:26:43, time: 1.281, data_time: 0.015, memory: 6005, decode.loss_seg: 0.9736, decode.acc_seg: 53.9049, loss: 0.9736
2021-08-14 03:06:47,054 - mmseg - INFO - Iter [42200/160000]	lr: 7.616e-03, eta: 1 day, 20:25:22, time: 1.268, data_time: 0.014, memory: 6005, decode.loss_seg: 1.0019, decode.acc_seg: 52.8873, loss: 1.0019
2021-08-14 03:07:51,117 - mmseg - INFO - Iter [42250/160000]	lr: 7.613e-03, eta: 1 day, 20:24:04, time: 1.280, data_time: 0.014, memory: 6005, decode.loss_seg: 1.0177, decode.acc_seg: 52.9570, loss: 1.0177
2021-08-14 03:09:29,947 - mmseg - INFO - Iter [42300/160000]	lr: 7.610e-03, eta: 1 day, 20:24:22, time: 1.978, data_time: 0.712, memory: 6005, decode.loss_seg: 0.9699, decode.acc_seg: 53.4730, loss: 0.9699
2021-08-14 03:10:33,794 - mmseg - INFO - Iter [42350/160000]	lr: 7.607e-03, eta: 1 day, 20:23:03, time: 1.277, data_time: 0.014, memory: 6005, decode.loss_seg: 0.9405, decode.acc_seg: 54.0389, loss: 0.9405
2021-08-14 03:11:36,938 - mmseg - INFO - Iter [42400/160000]	lr: 7.604e-03, eta: 1 day, 20:21:42, time: 1.262, data_time: 0.016, memory: 6005, decode.loss_seg: 0.9629, decode.acc_seg: 53.9334, loss: 0.9629
2021-08-14 03:12:40,401 - mmseg - INFO - Iter [42450/160000]	lr: 7.601e-03, eta: 1 day, 20:20:21, time: 1.269, data_time: 0.016, memory: 6005, decode.loss_seg: 0.9949, decode.acc_seg: 53.0587, loss: 0.9949
2021-08-14 03:13:44,430 - mmseg - INFO - Iter [42500/160000]	lr: 7.598e-03, eta: 1 day, 20:19:03, time: 1.281, data_time: 0.016, memory: 6005, decode.loss_seg: 0.9692, decode.acc_seg: 54.8014, loss: 0.9692
2021-08-14 03:14:50,644 - mmseg - INFO - Iter [42550/160000]	lr: 7.595e-03, eta: 1 day, 20:17:50, time: 1.323, data_time: 0.015, memory: 6005, decode.loss_seg: 0.9699, decode.acc_seg: 53.9187, loss: 0.9699
2021-08-14 03:15:55,342 - mmseg - INFO - Iter [42600/160000]	lr: 7.593e-03, eta: 1 day, 20:16:34, time: 1.295, data_time: 0.017, memory: 6005, decode.loss_seg: 0.9838, decode.acc_seg: 54.6014, loss: 0.9838
2021-08-14 03:16:57,676 - mmseg - INFO - Iter [42650/160000]	lr: 7.590e-03, eta: 1 day, 20:15:10, time: 1.246, data_time: 0.015, memory: 6005, decode.loss_seg: 0.9847, decode.acc_seg: 53.5757, loss: 0.9847
2021-08-14 03:18:01,746 - mmseg - INFO - Iter [42700/160000]	lr: 7.587e-03, eta: 1 day, 20:13:52, time: 1.281, data_time: 0.015, memory: 6005, decode.loss_seg: 0.9675, decode.acc_seg: 53.9471, loss: 0.9675
2021-08-14 03:19:04,645 - mmseg - INFO - Iter [42750/160000]	lr: 7.584e-03, eta: 1 day, 20:12:31, time: 1.259, data_time: 0.016, memory: 6005, decode.loss_seg: 0.9767, decode.acc_seg: 54.4725, loss: 0.9767
2021-08-14 03:20:09,301 - mmseg - INFO - Iter [42800/160000]	lr: 7.581e-03, eta: 1 day, 20:11:14, time: 1.293, data_time: 0.013, memory: 6005, decode.loss_seg: 0.9348, decode.acc_seg: 56.1135, loss: 0.9348
2021-08-14 03:21:12,159 - mmseg - INFO - Iter [42850/160000]	lr: 7.578e-03, eta: 1 day, 20:09:52, time: 1.257, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0004, decode.acc_seg: 53.8240, loss: 1.0004
2021-08-14 03:22:17,560 - mmseg - INFO - Iter [42900/160000]	lr: 7.575e-03, eta: 1 day, 20:08:38, time: 1.309, data_time: 0.016, memory: 6005, decode.loss_seg: 0.9916, decode.acc_seg: 53.2541, loss: 0.9916
2021-08-14 03:23:56,546 - mmseg - INFO - Iter [42950/160000]	lr: 7.572e-03, eta: 1 day, 20:08:55, time: 1.979, data_time: 0.729, memory: 6005, decode.loss_seg: 0.9285, decode.acc_seg: 54.2088, loss: 0.9285
2021-08-14 03:25:02,044 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-without-head_512x512_160k_ade20k.py
2021-08-14 03:25:02,045 - mmseg - INFO - Iter [43000/160000]	lr: 7.570e-03, eta: 1 day, 20:07:40, time: 1.310, data_time: 0.013, memory: 6005, decode.loss_seg: 0.9189, decode.acc_seg: 55.3881, loss: 0.9189
2021-08-14 03:26:06,337 - mmseg - INFO - Iter [43050/160000]	lr: 7.567e-03, eta: 1 day, 20:06:23, time: 1.286, data_time: 0.015, memory: 6005, decode.loss_seg: 0.9704, decode.acc_seg: 54.6655, loss: 0.9704
2021-08-14 03:27:12,913 - mmseg - INFO - Iter [43100/160000]	lr: 7.564e-03, eta: 1 day, 20:05:11, time: 1.332, data_time: 0.014, memory: 6005, decode.loss_seg: 0.9806, decode.acc_seg: 53.4207, loss: 0.9806
2021-08-14 03:28:15,685 - mmseg - INFO - Iter [43150/160000]	lr: 7.561e-03, eta: 1 day, 20:03:50, time: 1.256, data_time: 0.015, memory: 6005, decode.loss_seg: 0.9323, decode.acc_seg: 55.0813, loss: 0.9323
2021-08-14 03:29:18,170 - mmseg - INFO - Iter [43200/160000]	lr: 7.558e-03, eta: 1 day, 20:02:27, time: 1.249, data_time: 0.015, memory: 6005, decode.loss_seg: 0.9660, decode.acc_seg: 54.9382, loss: 0.9660
2021-08-14 03:30:22,755 - mmseg - INFO - Iter [43250/160000]	lr: 7.555e-03, eta: 1 day, 20:01:10, time: 1.292, data_time: 0.014, memory: 6005, decode.loss_seg: 1.0139, decode.acc_seg: 52.7319, loss: 1.0139
2021-08-14 03:31:26,540 - mmseg - INFO - Iter [43300/160000]	lr: 7.552e-03, eta: 1 day, 19:59:51, time: 1.275, data_time: 0.014, memory: 6005, decode.loss_seg: 0.9937, decode.acc_seg: 54.1961, loss: 0.9937
2021-08-14 03:32:32,298 - mmseg - INFO - Iter [43350/160000]	lr: 7.549e-03, eta: 1 day, 19:58:38, time: 1.315, data_time: 0.014, memory: 6005, decode.loss_seg: 0.9886, decode.acc_seg: 53.5962, loss: 0.9886
2021-08-14 03:33:36,819 - mmseg - INFO - Iter [43400/160000]	lr: 7.547e-03, eta: 1 day, 19:57:21, time: 1.292, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0291, decode.acc_seg: 52.8511, loss: 1.0291
2021-08-14 03:34:40,371 - mmseg - INFO - Iter [43450/160000]	lr: 7.544e-03, eta: 1 day, 19:56:02, time: 1.271, data_time: 0.014, memory: 6005, decode.loss_seg: 0.9794, decode.acc_seg: 54.2613, loss: 0.9794
2021-08-14 03:35:43,422 - mmseg - INFO - Iter [43500/160000]	lr: 7.541e-03, eta: 1 day, 19:54:41, time: 1.260, data_time: 0.014, memory: 6005, decode.loss_seg: 0.9691, decode.acc_seg: 54.9849, loss: 0.9691
2021-08-14 03:37:22,278 - mmseg - INFO - Iter [43550/160000]	lr: 7.538e-03, eta: 1 day, 19:54:56, time: 1.977, data_time: 0.724, memory: 6005, decode.loss_seg: 0.9786, decode.acc_seg: 54.3561, loss: 0.9786
2021-08-14 03:38:26,287 - mmseg - INFO - Iter [43600/160000]	lr: 7.535e-03, eta: 1 day, 19:53:38, time: 1.280, data_time: 0.017, memory: 6005, decode.loss_seg: 0.9216, decode.acc_seg: 54.6502, loss: 0.9216
2021-08-14 03:39:30,686 - mmseg - INFO - Iter [43650/160000]	lr: 7.532e-03, eta: 1 day, 19:52:21, time: 1.287, data_time: 0.014, memory: 6005, decode.loss_seg: 0.9808, decode.acc_seg: 53.5172, loss: 0.9808
2021-08-14 03:40:35,843 - mmseg - INFO - Iter [43700/160000]	lr: 7.529e-03, eta: 1 day, 19:51:06, time: 1.304, data_time: 0.016, memory: 6005, decode.loss_seg: 0.9396, decode.acc_seg: 55.1145, loss: 0.9396
2021-08-14 03:41:39,879 - mmseg - INFO - Iter [43750/160000]	lr: 7.527e-03, eta: 1 day, 19:49:48, time: 1.281, data_time: 0.016, memory: 6005, decode.loss_seg: 0.9571, decode.acc_seg: 54.8181, loss: 0.9571
2021-08-14 03:42:42,486 - mmseg - INFO - Iter [43800/160000]	lr: 7.524e-03, eta: 1 day, 19:48:26, time: 1.252, data_time: 0.016, memory: 6005, decode.loss_seg: 0.9981, decode.acc_seg: 53.1588, loss: 0.9981
2021-08-14 03:43:47,637 - mmseg - INFO - Iter [43850/160000]	lr: 7.521e-03, eta: 1 day, 19:47:11, time: 1.302, data_time: 0.015, memory: 6005, decode.loss_seg: 0.9438, decode.acc_seg: 55.0002, loss: 0.9438
2021-08-14 03:44:53,850 - mmseg - INFO - Iter [43900/160000]	lr: 7.518e-03, eta: 1 day, 19:45:58, time: 1.324, data_time: 0.015, memory: 6005, decode.loss_seg: 0.9575, decode.acc_seg: 54.4574, loss: 0.9575
2021-08-14 03:45:58,705 - mmseg - INFO - Iter [43950/160000]	lr: 7.515e-03, eta: 1 day, 19:44:43, time: 1.298, data_time: 0.015, memory: 6005, decode.loss_seg: 1.0401, decode.acc_seg: 53.3249, loss: 1.0401
2021-08-14 03:47:04,408 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-without-head_512x512_160k_ade20k.py
2021-08-14 03:47:04,409 - mmseg - INFO - Iter [44000/160000]	lr: 7.512e-03, eta: 1 day, 19:43:29, time: 1.314, data_time: 0.014, memory: 6005, decode.loss_seg: 0.9592, decode.acc_seg: 53.7183, loss: 0.9592
2021-08-14 03:48:07,022 - mmseg - INFO - Iter [44050/160000]	lr: 7.509e-03, eta: 1 day, 19:42:08, time: 1.252, data_time: 0.015, memory: 6005, decode.loss_seg: 0.9733, decode.acc_seg: 53.7468, loss: 0.9733
2021-08-14 03:49:12,970 - mmseg - INFO - Iter [44100/160000]	lr: 7.506e-03, eta: 1 day, 19:40:55, time: 1.318, data_time: 0.016, memory: 6005, decode.loss_seg: 1.0033, decode.acc_seg: 53.3634, loss: 1.0033
2021-08-14 03:50:18,975 - mmseg - INFO - Iter [44150/160000]	lr: 7.503e-03, eta: 1 day, 19:39:42, time: 1.321, data_time: 0.017, memory: 6005, decode.loss_seg: 0.9586, decode.acc_seg: 54.7423, loss: 0.9586
2021-08-14 03:51:58,076 - mmseg - INFO - Iter [44200/160000]	lr: 7.501e-03, eta: 1 day, 19:39:56, time: 1.981, data_time: 0.720, memory: 6005, decode.loss_seg: 0.9556, decode.acc_seg: 55.0069, loss: 0.9556
2021-08-14 03:53:02,115 - mmseg - INFO - Iter [44250/160000]	lr: 7.498e-03, eta: 1 day, 19:38:38, time: 1.282, data_time: 0.016, memory: 6005, decode.loss_seg: 0.9517, decode.acc_seg: 54.0538, loss: 0.9517
2021-08-14 03:54:07,121 - mmseg - INFO - Iter [44300/160000]	lr: 7.495e-03, eta: 1 day, 19:37:23, time: 1.299, data_time: 0.014, memory: 6005, decode.loss_seg: 1.0226, decode.acc_seg: 54.5636, loss: 1.0226
2021-08-14 03:55:10,878 - mmseg - INFO - Iter [44350/160000]	lr: 7.492e-03, eta: 1 day, 19:36:04, time: 1.276, data_time: 0.016, memory: 6005, decode.loss_seg: 0.9550, decode.acc_seg: 54.6530, loss: 0.9550
2021-08-14 03:56:14,986 - mmseg - INFO - Iter [44400/160000]	lr: 7.489e-03, eta: 1 day, 19:34:47, time: 1.282, data_time: 0.015, memory: 6005, decode.loss_seg: 0.9775, decode.acc_seg: 53.9634, loss: 0.9775
2021-08-14 03:57:19,602 - mmseg - INFO - Iter [44450/160000]	lr: 7.486e-03, eta: 1 day, 19:33:30, time: 1.292, data_time: 0.015, memory: 6005, decode.loss_seg: 0.9684, decode.acc_seg: 53.9045, loss: 0.9684
2021-08-14 03:58:25,540 - mmseg - INFO - Iter [44500/160000]	lr: 7.483e-03, eta: 1 day, 19:32:18, time: 1.319, data_time: 0.014, memory: 6005, decode.loss_seg: 0.9716, decode.acc_seg: 54.3324, loss: 0.9716
2021-08-14 03:59:28,155 - mmseg - INFO - Iter [44550/160000]	lr: 7.480e-03, eta: 1 day, 19:30:56, time: 1.252, data_time: 0.016, memory: 6005, decode.loss_seg: 0.9318, decode.acc_seg: 54.7102, loss: 0.9318
2021-08-14 04:00:31,275 - mmseg - INFO - Iter [44600/160000]	lr: 7.478e-03, eta: 1 day, 19:29:36, time: 1.262, data_time: 0.015, memory: 6005, decode.loss_seg: 0.9772, decode.acc_seg: 53.7709, loss: 0.9772
2021-08-14 04:01:35,734 - mmseg - INFO - Iter [44650/160000]	lr: 7.475e-03, eta: 1 day, 19:28:19, time: 1.289, data_time: 0.015, memory: 6005, decode.loss_seg: 0.9882, decode.acc_seg: 53.9790, loss: 0.9882
2021-08-14 04:02:39,337 - mmseg - INFO - Iter [44700/160000]	lr: 7.472e-03, eta: 1 day, 19:27:01, time: 1.271, data_time: 0.014, memory: 6005, decode.loss_seg: 0.9598, decode.acc_seg: 55.3845, loss: 0.9598
2021-08-14 04:03:42,860 - mmseg - INFO - Iter [44750/160000]	lr: 7.469e-03, eta: 1 day, 19:25:42, time: 1.271, data_time: 0.016, memory: 6005, decode.loss_seg: 1.0008, decode.acc_seg: 53.7664, loss: 1.0008
2021-08-14 04:04:46,211 - mmseg - INFO - Iter [44800/160000]	lr: 7.466e-03, eta: 1 day, 19:24:22, time: 1.267, data_time: 0.014, memory: 6005, decode.loss_seg: 0.9680, decode.acc_seg: 54.1108, loss: 0.9680
2021-08-14 04:06:29,647 - mmseg - INFO - Iter [44850/160000]	lr: 7.463e-03, eta: 1 day, 19:24:46, time: 2.068, data_time: 0.712, memory: 6005, decode.loss_seg: 0.9379, decode.acc_seg: 54.6310, loss: 0.9379
2021-08-14 04:07:34,210 - mmseg - INFO - Iter [44900/160000]	lr: 7.460e-03, eta: 1 day, 19:23:30, time: 1.292, data_time: 0.016, memory: 6005, decode.loss_seg: 0.9525, decode.acc_seg: 54.9401, loss: 0.9525
2021-08-14 04:08:38,769 - mmseg - INFO - Iter [44950/160000]	lr: 7.457e-03, eta: 1 day, 19:22:13, time: 1.291, data_time: 0.015, memory: 6005, decode.loss_seg: 0.9611, decode.acc_seg: 54.7050, loss: 0.9611
2021-08-14 04:09:44,005 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-without-head_512x512_160k_ade20k.py
2021-08-14 04:09:44,006 - mmseg - INFO - Iter [45000/160000]	lr: 7.455e-03, eta: 1 day, 19:20:59, time: 1.304, data_time: 0.014, memory: 6005, decode.loss_seg: 0.9662, decode.acc_seg: 54.5019, loss: 0.9662
2021-08-14 04:10:49,304 - mmseg - INFO - Iter [45050/160000]	lr: 7.452e-03, eta: 1 day, 19:19:44, time: 1.306, data_time: 0.016, memory: 6005, decode.loss_seg: 0.9571, decode.acc_seg: 53.5200, loss: 0.9571
2021-08-14 04:11:54,020 - mmseg - INFO - Iter [45100/160000]	lr: 7.449e-03, eta: 1 day, 19:18:29, time: 1.294, data_time: 0.015, memory: 6005, decode.loss_seg: 0.9490, decode.acc_seg: 54.0784, loss: 0.9490
2021-08-14 04:13:01,909 - mmseg - INFO - Iter [45150/160000]	lr: 7.446e-03, eta: 1 day, 19:17:21, time: 1.357, data_time: 0.015, memory: 6005, decode.loss_seg: 0.9428, decode.acc_seg: 54.3667, loss: 0.9428
2021-08-14 04:14:07,721 - mmseg - INFO - Iter [45200/160000]	lr: 7.443e-03, eta: 1 day, 19:16:08, time: 1.317, data_time: 0.016, memory: 6005, decode.loss_seg: 0.9681, decode.acc_seg: 53.4752, loss: 0.9681
2021-08-14 04:15:10,803 - mmseg - INFO - Iter [45250/160000]	lr: 7.440e-03, eta: 1 day, 19:14:48, time: 1.261, data_time: 0.014, memory: 6005, decode.loss_seg: 0.9989, decode.acc_seg: 53.5453, loss: 0.9989
2021-08-14 04:16:14,591 - mmseg - INFO - Iter [45300/160000]	lr: 7.437e-03, eta: 1 day, 19:13:30, time: 1.276, data_time: 0.017, memory: 6005, decode.loss_seg: 0.9907, decode.acc_seg: 54.1379, loss: 0.9907
2021-08-14 04:17:18,588 - mmseg - INFO - Iter [45350/160000]	lr: 7.434e-03, eta: 1 day, 19:12:12, time: 1.279, data_time: 0.015, memory: 6005, decode.loss_seg: 0.9812, decode.acc_seg: 53.5620, loss: 0.9812
2021-08-14 04:18:25,852 - mmseg - INFO - Iter [45400/160000]	lr: 7.432e-03, eta: 1 day, 19:11:03, time: 1.346, data_time: 0.015, memory: 6005, decode.loss_seg: 0.9687, decode.acc_seg: 54.6013, loss: 0.9687
2021-08-14 04:20:04,386 - mmseg - INFO - Iter [45450/160000]	lr: 7.429e-03, eta: 1 day, 19:11:13, time: 1.970, data_time: 0.697, memory: 6005, decode.loss_seg: 0.9778, decode.acc_seg: 54.4859, loss: 0.9778
2021-08-14 04:21:07,915 - mmseg - INFO - Iter [45500/160000]	lr: 7.426e-03, eta: 1 day, 19:09:54, time: 1.271, data_time: 0.016, memory: 6005, decode.loss_seg: 0.9300, decode.acc_seg: 54.2527, loss: 0.9300
2021-08-14 04:22:14,168 - mmseg - INFO - Iter [45550/160000]	lr: 7.423e-03, eta: 1 day, 19:08:42, time: 1.325, data_time: 0.013, memory: 6005, decode.loss_seg: 0.9441, decode.acc_seg: 55.0018, loss: 0.9441
2021-08-14 04:23:17,766 - mmseg - INFO - Iter [45600/160000]	lr: 7.420e-03, eta: 1 day, 19:07:23, time: 1.271, data_time: 0.015, memory: 6005, decode.loss_seg: 0.9737, decode.acc_seg: 54.4152, loss: 0.9737
2021-08-14 04:24:22,324 - mmseg - INFO - Iter [45650/160000]	lr: 7.417e-03, eta: 1 day, 19:06:07, time: 1.292, data_time: 0.015, memory: 6005, decode.loss_seg: 0.9431, decode.acc_seg: 54.3729, loss: 0.9431
2021-08-14 04:25:26,067 - mmseg - INFO - Iter [45700/160000]	lr: 7.414e-03, eta: 1 day, 19:04:49, time: 1.274, data_time: 0.014, memory: 6005, decode.loss_seg: 0.9703, decode.acc_seg: 54.3132, loss: 0.9703
2021-08-14 04:26:29,837 - mmseg - INFO - Iter [45750/160000]	lr: 7.411e-03, eta: 1 day, 19:03:31, time: 1.276, data_time: 0.015, memory: 6005, decode.loss_seg: 0.9939, decode.acc_seg: 53.9219, loss: 0.9939
2021-08-14 04:27:33,814 - mmseg - INFO - Iter [45800/160000]	lr: 7.409e-03, eta: 1 day, 19:02:14, time: 1.278, data_time: 0.015, memory: 6005, decode.loss_seg: 0.9584, decode.acc_seg: 54.6364, loss: 0.9584
2021-08-14 04:28:38,165 - mmseg - INFO - Iter [45850/160000]	lr: 7.406e-03, eta: 1 day, 19:00:57, time: 1.288, data_time: 0.016, memory: 6005, decode.loss_seg: 0.9788, decode.acc_seg: 54.0530, loss: 0.9788
2021-08-14 04:29:42,056 - mmseg - INFO - Iter [45900/160000]	lr: 7.403e-03, eta: 1 day, 18:59:40, time: 1.278, data_time: 0.015, memory: 6005, decode.loss_seg: 0.9825, decode.acc_seg: 53.7582, loss: 0.9825
2021-08-14 04:30:47,335 - mmseg - INFO - Iter [45950/160000]	lr: 7.400e-03, eta: 1 day, 18:58:25, time: 1.305, data_time: 0.016, memory: 6005, decode.loss_seg: 0.9521, decode.acc_seg: 54.7289, loss: 0.9521
2021-08-14 04:31:51,283 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-without-head_512x512_160k_ade20k.py
2021-08-14 04:31:51,284 - mmseg - INFO - Iter [46000/160000]	lr: 7.397e-03, eta: 1 day, 18:57:08, time: 1.280, data_time: 0.015, memory: 6005, decode.loss_seg: 0.9918, decode.acc_seg: 54.6337, loss: 0.9918
2021-08-14 04:32:53,951 - mmseg - INFO - Iter [46050/160000]	lr: 7.394e-03, eta: 1 day, 18:55:47, time: 1.254, data_time: 0.015, memory: 6005, decode.loss_seg: 0.9580, decode.acc_seg: 53.9917, loss: 0.9580
2021-08-14 04:34:33,040 - mmseg - INFO - Iter [46100/160000]	lr: 7.391e-03, eta: 1 day, 18:55:57, time: 1.981, data_time: 0.742, memory: 6005, decode.loss_seg: 0.9402, decode.acc_seg: 54.8722, loss: 0.9402
2021-08-14 04:35:37,028 - mmseg - INFO - Iter [46150/160000]	lr: 7.388e-03, eta: 1 day, 18:54:40, time: 1.281, data_time: 0.015, memory: 6005, decode.loss_seg: 0.9592, decode.acc_seg: 54.4625, loss: 0.9592
2021-08-14 04:36:40,521 - mmseg - INFO - Iter [46200/160000]	lr: 7.385e-03, eta: 1 day, 18:53:21, time: 1.270, data_time: 0.015, memory: 6005, decode.loss_seg: 0.9712, decode.acc_seg: 54.5972, loss: 0.9712
2021-08-14 04:37:43,709 - mmseg - INFO - Iter [46250/160000]	lr: 7.383e-03, eta: 1 day, 18:52:02, time: 1.264, data_time: 0.016, memory: 6005, decode.loss_seg: 0.9586, decode.acc_seg: 54.4556, loss: 0.9586
2021-08-14 04:38:46,588 - mmseg - INFO - Iter [46300/160000]	lr: 7.380e-03, eta: 1 day, 18:50:42, time: 1.258, data_time: 0.017, memory: 6005, decode.loss_seg: 0.9506, decode.acc_seg: 53.9754, loss: 0.9506
2021-08-14 04:39:50,058 - mmseg - INFO - Iter [46350/160000]	lr: 7.377e-03, eta: 1 day, 18:49:23, time: 1.269, data_time: 0.015, memory: 6005, decode.loss_seg: 0.9721, decode.acc_seg: 53.3889, loss: 0.9721
2021-08-14 04:40:54,505 - mmseg - INFO - Iter [46400/160000]	lr: 7.374e-03, eta: 1 day, 18:48:07, time: 1.289, data_time: 0.017, memory: 6005, decode.loss_seg: 0.9792, decode.acc_seg: 53.3383, loss: 0.9792
2021-08-14 04:42:00,641 - mmseg - INFO - Iter [46450/160000]	lr: 7.371e-03, eta: 1 day, 18:46:55, time: 1.322, data_time: 0.015, memory: 6005, decode.loss_seg: 0.9589, decode.acc_seg: 54.9054, loss: 0.9589
2021-08-14 04:43:08,014 - mmseg - INFO - Iter [46500/160000]	lr: 7.368e-03, eta: 1 day, 18:45:46, time: 1.348, data_time: 0.014, memory: 6005, decode.loss_seg: 0.9646, decode.acc_seg: 54.3786, loss: 0.9646
2021-08-14 04:44:11,156 - mmseg - INFO - Iter [46550/160000]	lr: 7.365e-03, eta: 1 day, 18:44:27, time: 1.263, data_time: 0.015, memory: 6005, decode.loss_seg: 0.9383, decode.acc_seg: 55.1092, loss: 0.9383
2021-08-14 04:45:16,884 - mmseg - INFO - Iter [46600/160000]	lr: 7.362e-03, eta: 1 day, 18:43:14, time: 1.315, data_time: 0.015, memory: 6005, decode.loss_seg: 0.9603, decode.acc_seg: 54.4568, loss: 0.9603
2021-08-14 04:46:22,388 - mmseg - INFO - Iter [46650/160000]	lr: 7.360e-03, eta: 1 day, 18:42:01, time: 1.310, data_time: 0.015, memory: 6005, decode.loss_seg: 0.9806, decode.acc_seg: 54.3609, loss: 0.9806
2021-08-14 04:48:01,331 - mmseg - INFO - Iter [46700/160000]	lr: 7.357e-03, eta: 1 day, 18:42:08, time: 1.979, data_time: 0.717, memory: 6005, decode.loss_seg: 0.9851, decode.acc_seg: 54.1283, loss: 0.9851
2021-08-14 04:49:05,744 - mmseg - INFO - Iter [46750/160000]	lr: 7.354e-03, eta: 1 day, 18:40:52, time: 1.288, data_time: 0.015, memory: 6005, decode.loss_seg: 0.9527, decode.acc_seg: 54.5748, loss: 0.9527
2021-08-14 04:50:12,888 - mmseg - INFO - Iter [46800/160000]	lr: 7.351e-03, eta: 1 day, 18:39:43, time: 1.342, data_time: 0.014, memory: 6005, decode.loss_seg: 0.9400, decode.acc_seg: 54.1351, loss: 0.9400
2021-08-14 04:51:19,301 - mmseg - INFO - Iter [46850/160000]	lr: 7.348e-03, eta: 1 day, 18:38:31, time: 1.329, data_time: 0.015, memory: 6005, decode.loss_seg: 0.9121, decode.acc_seg: 54.7593, loss: 0.9121
2021-08-14 04:52:24,376 - mmseg - INFO - Iter [46900/160000]	lr: 7.345e-03, eta: 1 day, 18:37:17, time: 1.302, data_time: 0.015, memory: 6005, decode.loss_seg: 0.9753, decode.acc_seg: 54.6065, loss: 0.9753
2021-08-14 04:53:28,679 - mmseg - INFO - Iter [46950/160000]	lr: 7.342e-03, eta: 1 day, 18:36:01, time: 1.285, data_time: 0.015, memory: 6005, decode.loss_seg: 0.9470, decode.acc_seg: 55.8504, loss: 0.9470
2021-08-14 04:54:32,644 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-without-head_512x512_160k_ade20k.py
2021-08-14 04:54:32,645 - mmseg - INFO - Iter [47000/160000]	lr: 7.339e-03, eta: 1 day, 18:34:44, time: 1.280, data_time: 0.016, memory: 6005, decode.loss_seg: 0.9401, decode.acc_seg: 55.2203, loss: 0.9401
2021-08-14 04:55:36,849 - mmseg - INFO - Iter [47050/160000]	lr: 7.336e-03, eta: 1 day, 18:33:27, time: 1.283, data_time: 0.014, memory: 6005, decode.loss_seg: 0.9734, decode.acc_seg: 53.8913, loss: 0.9734
2021-08-14 04:56:41,473 - mmseg - INFO - Iter [47100/160000]	lr: 7.334e-03, eta: 1 day, 18:32:12, time: 1.293, data_time: 0.015, memory: 6005, decode.loss_seg: 0.9272, decode.acc_seg: 54.4708, loss: 0.9272
2021-08-14 04:57:45,476 - mmseg - INFO - Iter [47150/160000]	lr: 7.331e-03, eta: 1 day, 18:30:55, time: 1.281, data_time: 0.015, memory: 6005, decode.loss_seg: 0.9545, decode.acc_seg: 55.2876, loss: 0.9545
2021-08-14 04:58:50,758 - mmseg - INFO - Iter [47200/160000]	lr: 7.328e-03, eta: 1 day, 18:29:41, time: 1.305, data_time: 0.014, memory: 6005, decode.loss_seg: 0.9862, decode.acc_seg: 54.0934, loss: 0.9862
2021-08-14 04:59:55,098 - mmseg - INFO - Iter [47250/160000]	lr: 7.325e-03, eta: 1 day, 18:28:25, time: 1.288, data_time: 0.015, memory: 6005, decode.loss_seg: 0.9720, decode.acc_seg: 54.1113, loss: 0.9720
2021-08-14 05:01:00,336 - mmseg - INFO - Iter [47300/160000]	lr: 7.322e-03, eta: 1 day, 18:27:11, time: 1.304, data_time: 0.014, memory: 6005, decode.loss_seg: 1.0094, decode.acc_seg: 53.8574, loss: 1.0094
2021-08-14 05:02:39,973 - mmseg - INFO - Iter [47350/160000]	lr: 7.319e-03, eta: 1 day, 18:27:19, time: 1.993, data_time: 0.692, memory: 6005, decode.loss_seg: 0.9397, decode.acc_seg: 54.6443, loss: 0.9397
2021-08-14 05:03:44,047 - mmseg - INFO - Iter [47400/160000]	lr: 7.316e-03, eta: 1 day, 18:26:02, time: 1.281, data_time: 0.016, memory: 6005, decode.loss_seg: 0.9611, decode.acc_seg: 53.1710, loss: 0.9611
2021-08-14 05:04:49,794 - mmseg - INFO - Iter [47450/160000]	lr: 7.313e-03, eta: 1 day, 18:24:49, time: 1.316, data_time: 0.016, memory: 6005, decode.loss_seg: 0.9538, decode.acc_seg: 54.2985, loss: 0.9538
2021-08-14 05:05:56,333 - mmseg - INFO - Iter [47500/160000]	lr: 7.311e-03, eta: 1 day, 18:23:38, time: 1.331, data_time: 0.015, memory: 6005, decode.loss_seg: 0.9533, decode.acc_seg: 55.1063, loss: 0.9533
2021-08-14 05:07:00,986 - mmseg - INFO - Iter [47550/160000]	lr: 7.308e-03, eta: 1 day, 18:22:23, time: 1.293, data_time: 0.014, memory: 6005, decode.loss_seg: 0.9688, decode.acc_seg: 53.7343, loss: 0.9688
2021-08-14 05:08:05,144 - mmseg - INFO - Iter [47600/160000]	lr: 7.305e-03, eta: 1 day, 18:21:06, time: 1.283, data_time: 0.015, memory: 6005, decode.loss_seg: 0.9356, decode.acc_seg: 55.0119, loss: 0.9356
2021-08-14 05:09:08,090 - mmseg - INFO - Iter [47650/160000]	lr: 7.302e-03, eta: 1 day, 18:19:47, time: 1.259, data_time: 0.015, memory: 6005, decode.loss_seg: 0.9931, decode.acc_seg: 54.8960, loss: 0.9931
2021-08-14 05:10:12,400 - mmseg - INFO - Iter [47700/160000]	lr: 7.299e-03, eta: 1 day, 18:18:31, time: 1.286, data_time: 0.015, memory: 6005, decode.loss_seg: 0.9277, decode.acc_seg: 56.2476, loss: 0.9277
2021-08-14 05:11:18,561 - mmseg - INFO - Iter [47750/160000]	lr: 7.296e-03, eta: 1 day, 18:17:19, time: 1.324, data_time: 0.017, memory: 6005, decode.loss_seg: 0.9915, decode.acc_seg: 53.0523, loss: 0.9915
2021-08-14 05:12:23,783 - mmseg - INFO - Iter [47800/160000]	lr: 7.293e-03, eta: 1 day, 18:16:05, time: 1.304, data_time: 0.016, memory: 6005, decode.loss_seg: 0.9454, decode.acc_seg: 55.0500, loss: 0.9454
2021-08-14 05:13:27,987 - mmseg - INFO - Iter [47850/160000]	lr: 7.290e-03, eta: 1 day, 18:14:49, time: 1.285, data_time: 0.015, memory: 6005, decode.loss_seg: 0.9804, decode.acc_seg: 54.5162, loss: 0.9804
2021-08-14 05:14:32,112 - mmseg - INFO - Iter [47900/160000]	lr: 7.287e-03, eta: 1 day, 18:13:33, time: 1.282, data_time: 0.015, memory: 6005, decode.loss_seg: 0.9433, decode.acc_seg: 54.8577, loss: 0.9433
2021-08-14 05:15:35,708 - mmseg - INFO - Iter [47950/160000]	lr: 7.285e-03, eta: 1 day, 18:12:15, time: 1.271, data_time: 0.015, memory: 6005, decode.loss_seg: 0.9656, decode.acc_seg: 55.4452, loss: 0.9656
2021-08-14 05:17:16,189 - mmseg - INFO - Saving checkpoint at 48000 iterations
2021-08-14 05:17:16,563 - mmseg - INFO - Exp name: fcn-resize-concat_litehr30-without-head_512x512_160k_ade20k.py
2021-08-14 05:17:16,563 - mmseg - INFO - Iter [48000/160000]	lr: 7.282e-03, eta: 1 day, 18:12:24, time: 2.018, data_time: 0.732, memory: 6005, decode.loss_seg: 0.9190, decode.acc_seg: 54.9115, loss: 0.9190
