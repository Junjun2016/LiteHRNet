2021-08-13 22:50:24,454 - mmseg - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.7.6 (default, Jan  8 2020, 19:59:22) [GCC 7.3.0]
CUDA available: True
GPU 0,1,2,3,4,5,6,7: TITAN Xp
CUDA_HOME: /mnt/lustre/share/polaris/dep/cuda-9.0-cudnn7.6.5
NVCC: Cuda compilation tools, release 9.0, V9.0.176
GCC: gcc (GCC) 5.4.0
PyTorch: 1.5.0
PyTorch compiling details: PyTorch built with:
  - GCC 5.4
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.1 Product Build 20200208 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v0.21.1 (Git Hash 912ce228837d1ce28e1a61806118835de03f5751)
  - OpenMP 201307 (a.k.a. OpenMP 4.0)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 9.0
  - NVCC architecture flags: -gencode;arch=compute_52,code=sm_52;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_70,code=compute_70
  - CuDNN 7.6.5
  - Magma 2.5.0
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_INTERNAL_THREADPOOL_IMPL -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=ON, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

TorchVision: 0.6.0
OpenCV: 4.2.0
MMCV: 1.3.11
MMCV Compiler: n/a
MMCV CUDA Compiler: n/a
MMSegmentation: 0.16.0+2bb6f37
------------------------------------------------------------

2021-08-13 22:50:24,455 - mmseg - INFO - Distributed training: True
2021-08-13 22:50:24,883 - mmseg - INFO - Config:
norm_cfg = dict(type='SyncBN', requires_grad=True)
model = dict(
    type='EncoderDecoder',
    backbone=dict(
        type='LiteHRNet',
        norm_cfg=dict(type='SyncBN', requires_grad=True),
        norm_eval=False,
        extra=dict(
            stem=dict(stem_channels=32, out_channels=32, expand_ratio=1),
            num_stages=3,
            stages_spec=dict(
                num_modules=(3, 8, 3),
                num_branches=(2, 3, 4),
                num_blocks=(2, 2, 2),
                module_type=('LITE', 'LITE', 'LITE'),
                with_fuse=(True, True, True),
                reduce_ratios=(8, 8, 8),
                num_channels=((40, 80), (40, 80, 160), (40, 80, 160, 320))),
            with_head=True)),
    decode_head=dict(
        type='FCNHead',
        in_channels=40,
        in_index=0,
        channels=40,
        input_transform=None,
        kernel_size=3,
        num_convs=2,
        concat_input=True,
        dropout_ratio=0.1,
        num_classes=150,
        norm_cfg=dict(type='SyncBN', requires_grad=True),
        align_corners=False,
        loss_decode=dict(
            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0)),
    train_cfg=dict(),
    test_cfg=dict(mode='whole'))
dataset_type = 'ADE20KDataset'
data_root = 'data/ade/ADEChallengeData2016'
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
crop_size = (512, 512)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations', reduce_zero_label=True),
    dict(type='Resize', img_scale=(2048, 512), ratio_range=(0.5, 2.0)),
    dict(type='RandomCrop', crop_size=(512, 512), cat_max_ratio=0.75),
    dict(type='RandomFlip', prob=0.5),
    dict(type='PhotoMetricDistortion'),
    dict(
        type='Normalize',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='Pad', size=(512, 512), pad_val=0, seg_pad_val=255),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_semantic_seg'])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(2048, 512),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
data = dict(
    samples_per_gpu=4,
    workers_per_gpu=4,
    train=dict(
        type='ADE20KDataset',
        data_root='data/ade/ADEChallengeData2016',
        img_dir='images/training',
        ann_dir='annotations/training',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations', reduce_zero_label=True),
            dict(type='Resize', img_scale=(2048, 512), ratio_range=(0.5, 2.0)),
            dict(type='RandomCrop', crop_size=(512, 512), cat_max_ratio=0.75),
            dict(type='RandomFlip', prob=0.5),
            dict(type='PhotoMetricDistortion'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='Pad', size=(512, 512), pad_val=0, seg_pad_val=255),
            dict(type='DefaultFormatBundle'),
            dict(type='Collect', keys=['img', 'gt_semantic_seg'])
        ]),
    val=dict(
        type='ADE20KDataset',
        data_root='data/ade/ADEChallengeData2016',
        img_dir='images/validation',
        ann_dir='annotations/validation',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(2048, 512),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]),
    test=dict(
        type='ADE20KDataset',
        data_root='data/ade/ADEChallengeData2016',
        img_dir='images/validation',
        ann_dir='annotations/validation',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(2048, 512),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]))
log_config = dict(
    interval=50, hooks=[dict(type='TextLoggerHook', by_epoch=False)])
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]
cudnn_benchmark = True
optimizer = dict(type='SGD', lr=0.01, momentum=0.9, weight_decay=0.0005)
optimizer_config = dict()
lr_config = dict(policy='poly', power=0.9, min_lr=0.0001, by_epoch=False)
runner = dict(type='IterBasedRunner', max_iters=160000)
checkpoint_config = dict(by_epoch=False, interval=16000)
evaluation = dict(interval=16000, metric='mIoU')
work_dir = './work_dirs/fcn_litehr30-with-head_512x512_160k_ade20k'
gpu_ids = range(0, 1)

2021-08-13 22:50:24,883 - mmseg - INFO - Set random seed to 0, deterministic: False
2021-08-13 22:50:25,341 - mmseg - INFO - initialize LiteHRNet with init_cfg [{'type': 'Normal', 'std': 0.001, 'layer': 'Conv2d'}, {'type': 'Constant', 'val': 1, 'layer': ['_BatchNorm', 'GroupNorm']}]
2021-08-13 22:50:25,671 - mmseg - INFO - initialize FCNHead with init_cfg {'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
Name of parameter - Initialization information

backbone.stem.conv1.conv.weight - torch.Size([32, 3, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.stem.conv1.bn.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stem.conv1.bn.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stem.branch1.0.conv.weight - torch.Size([16, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stem.branch1.0.bn.weight - torch.Size([16]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stem.branch1.0.bn.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stem.branch1.1.conv.weight - torch.Size([16, 16, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stem.branch1.1.bn.weight - torch.Size([16]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stem.branch1.1.bn.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stem.expand_conv.conv.weight - torch.Size([32, 16, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.stem.expand_conv.bn.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stem.expand_conv.bn.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stem.depthwise_conv.conv.weight - torch.Size([32, 1, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.stem.depthwise_conv.bn.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stem.depthwise_conv.bn.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stem.linear_conv.conv.weight - torch.Size([16, 32, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.stem.linear_conv.bn.weight - torch.Size([16]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stem.linear_conv.bn.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.transition0.0.0.weight - torch.Size([32, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.transition0.0.1.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.transition0.0.1.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.transition0.0.2.weight - torch.Size([40, 32, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.transition0.0.3.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.transition0.0.3.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.transition0.1.0.0.weight - torch.Size([32, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.transition0.1.0.1.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.transition0.1.0.1.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.transition0.1.0.2.weight - torch.Size([80, 32, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.transition0.1.0.3.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.transition0.1.0.3.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.0.cross_resolution_weighting.conv1.conv.weight - torch.Size([7, 60, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.layers.0.cross_resolution_weighting.conv1.bn.weight - torch.Size([7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.0.cross_resolution_weighting.conv1.bn.bias - torch.Size([7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.0.cross_resolution_weighting.conv2.conv.weight - torch.Size([60, 7, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.layers.0.cross_resolution_weighting.conv2.bn.weight - torch.Size([60]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.0.cross_resolution_weighting.conv2.bn.bias - torch.Size([60]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.0.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.layers.0.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.0.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.0.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.layers.0.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.0.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.0.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.layers.0.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.0.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.layers.0.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.0.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.layers.0.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.0.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.layers.0.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.1.cross_resolution_weighting.conv1.conv.weight - torch.Size([7, 60, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.layers.1.cross_resolution_weighting.conv1.bn.weight - torch.Size([7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.1.cross_resolution_weighting.conv1.bn.bias - torch.Size([7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.1.cross_resolution_weighting.conv2.conv.weight - torch.Size([60, 7, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.layers.1.cross_resolution_weighting.conv2.bn.weight - torch.Size([60]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.1.cross_resolution_weighting.conv2.bn.bias - torch.Size([60]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.1.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.layers.1.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.1.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.1.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.layers.1.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.1.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.1.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.layers.1.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.1.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.layers.1.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.1.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.layers.1.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.1.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.layers.1.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.fuse_layers.0.1.0.weight - torch.Size([40, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.fuse_layers.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.fuse_layers.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.fuse_layers.1.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.fuse_layers.1.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.fuse_layers.1.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.fuse_layers.1.0.0.2.weight - torch.Size([80, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.fuse_layers.1.0.0.3.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.fuse_layers.1.0.0.3.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.0.cross_resolution_weighting.conv1.conv.weight - torch.Size([7, 60, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.layers.0.cross_resolution_weighting.conv1.bn.weight - torch.Size([7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.0.cross_resolution_weighting.conv1.bn.bias - torch.Size([7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.0.cross_resolution_weighting.conv2.conv.weight - torch.Size([60, 7, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.layers.0.cross_resolution_weighting.conv2.bn.weight - torch.Size([60]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.0.cross_resolution_weighting.conv2.bn.bias - torch.Size([60]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.0.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.layers.0.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.0.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.0.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.layers.0.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.0.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.0.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.layers.0.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.0.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.layers.0.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.0.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.layers.0.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.0.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.layers.0.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.1.cross_resolution_weighting.conv1.conv.weight - torch.Size([7, 60, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.layers.1.cross_resolution_weighting.conv1.bn.weight - torch.Size([7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.1.cross_resolution_weighting.conv1.bn.bias - torch.Size([7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.1.cross_resolution_weighting.conv2.conv.weight - torch.Size([60, 7, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.layers.1.cross_resolution_weighting.conv2.bn.weight - torch.Size([60]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.1.cross_resolution_weighting.conv2.bn.bias - torch.Size([60]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.1.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.layers.1.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.1.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.1.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.layers.1.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.1.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.1.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.layers.1.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.1.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.layers.1.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.1.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.layers.1.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.1.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.layers.1.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.fuse_layers.0.1.0.weight - torch.Size([40, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.fuse_layers.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.fuse_layers.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.fuse_layers.1.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.fuse_layers.1.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.fuse_layers.1.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.fuse_layers.1.0.0.2.weight - torch.Size([80, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.fuse_layers.1.0.0.3.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.fuse_layers.1.0.0.3.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.0.cross_resolution_weighting.conv1.conv.weight - torch.Size([7, 60, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.2.layers.0.cross_resolution_weighting.conv1.bn.weight - torch.Size([7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.0.cross_resolution_weighting.conv1.bn.bias - torch.Size([7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.0.cross_resolution_weighting.conv2.conv.weight - torch.Size([60, 7, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.2.layers.0.cross_resolution_weighting.conv2.bn.weight - torch.Size([60]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.0.cross_resolution_weighting.conv2.bn.bias - torch.Size([60]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.0.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.2.layers.0.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.0.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.0.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.2.layers.0.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.0.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.0.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.2.layers.0.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.0.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.2.layers.0.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.0.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.2.layers.0.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.0.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.2.layers.0.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.1.cross_resolution_weighting.conv1.conv.weight - torch.Size([7, 60, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.2.layers.1.cross_resolution_weighting.conv1.bn.weight - torch.Size([7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.1.cross_resolution_weighting.conv1.bn.bias - torch.Size([7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.1.cross_resolution_weighting.conv2.conv.weight - torch.Size([60, 7, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.2.layers.1.cross_resolution_weighting.conv2.bn.weight - torch.Size([60]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.1.cross_resolution_weighting.conv2.bn.bias - torch.Size([60]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.1.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.2.layers.1.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.1.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.1.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.2.layers.1.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.1.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.1.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.2.layers.1.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.1.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.2.layers.1.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.1.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.2.layers.1.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.1.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.2.layers.1.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.fuse_layers.0.1.0.weight - torch.Size([40, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.2.fuse_layers.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.fuse_layers.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.fuse_layers.1.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.2.fuse_layers.1.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.fuse_layers.1.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.fuse_layers.1.0.0.2.weight - torch.Size([80, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.2.fuse_layers.1.0.0.3.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.fuse_layers.1.0.0.3.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.transition1.2.0.0.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.transition1.2.0.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.transition1.2.0.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.transition1.2.0.2.weight - torch.Size([160, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.transition1.2.0.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.transition1.2.0.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.0.cross_resolution_weighting.conv1.conv.weight - torch.Size([17, 140, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.0.cross_resolution_weighting.conv1.bn.weight - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.0.cross_resolution_weighting.conv1.bn.bias - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.0.cross_resolution_weighting.conv2.conv.weight - torch.Size([140, 17, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.0.cross_resolution_weighting.conv2.bn.weight - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.0.cross_resolution_weighting.conv2.bn.bias - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.0.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.0.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.0.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.0.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.0.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.0.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.0.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.0.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.0.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.0.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.0.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.0.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.0.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.0.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.0.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.0.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.0.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.0.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.0.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.0.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.0.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.1.cross_resolution_weighting.conv1.conv.weight - torch.Size([17, 140, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.1.cross_resolution_weighting.conv1.bn.weight - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.1.cross_resolution_weighting.conv1.bn.bias - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.1.cross_resolution_weighting.conv2.conv.weight - torch.Size([140, 17, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.1.cross_resolution_weighting.conv2.bn.weight - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.1.cross_resolution_weighting.conv2.bn.bias - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.1.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.1.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.1.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.1.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.1.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.1.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.1.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.1.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.1.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.1.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.1.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.1.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.1.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.1.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.1.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.1.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.1.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.1.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.1.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.1.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.1.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.0.1.0.weight - torch.Size([40, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.fuse_layers.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.0.2.0.weight - torch.Size([40, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.fuse_layers.0.2.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.0.2.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.1.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.fuse_layers.1.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.1.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.1.0.0.2.weight - torch.Size([80, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.fuse_layers.1.0.0.3.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.1.0.0.3.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.1.2.0.weight - torch.Size([80, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.fuse_layers.1.2.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.1.2.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.2.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.fuse_layers.2.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.2.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.2.0.0.2.weight - torch.Size([40, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.fuse_layers.2.0.0.3.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.2.0.0.3.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.2.0.1.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.fuse_layers.2.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.2.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.2.0.1.2.weight - torch.Size([160, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.fuse_layers.2.0.1.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.2.0.1.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.2.1.0.0.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.fuse_layers.2.1.0.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.2.1.0.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.2.1.0.2.weight - torch.Size([160, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.fuse_layers.2.1.0.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.2.1.0.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.0.cross_resolution_weighting.conv1.conv.weight - torch.Size([17, 140, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.0.cross_resolution_weighting.conv1.bn.weight - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.0.cross_resolution_weighting.conv1.bn.bias - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.0.cross_resolution_weighting.conv2.conv.weight - torch.Size([140, 17, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.0.cross_resolution_weighting.conv2.bn.weight - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.0.cross_resolution_weighting.conv2.bn.bias - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.0.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.0.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.0.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.0.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.0.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.0.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.0.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.0.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.0.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.0.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.0.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.0.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.0.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.0.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.0.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.0.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.0.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.0.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.0.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.0.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.0.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.1.cross_resolution_weighting.conv1.conv.weight - torch.Size([17, 140, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.1.cross_resolution_weighting.conv1.bn.weight - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.1.cross_resolution_weighting.conv1.bn.bias - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.1.cross_resolution_weighting.conv2.conv.weight - torch.Size([140, 17, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.1.cross_resolution_weighting.conv2.bn.weight - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.1.cross_resolution_weighting.conv2.bn.bias - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.1.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.1.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.1.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.1.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.1.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.1.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.1.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.1.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.1.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.1.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.1.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.1.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.1.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.1.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.1.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.1.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.1.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.1.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.1.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.1.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.1.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.0.1.0.weight - torch.Size([40, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.fuse_layers.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.0.2.0.weight - torch.Size([40, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.fuse_layers.0.2.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.0.2.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.1.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.fuse_layers.1.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.1.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.1.0.0.2.weight - torch.Size([80, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.fuse_layers.1.0.0.3.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.1.0.0.3.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.1.2.0.weight - torch.Size([80, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.fuse_layers.1.2.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.1.2.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.2.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.fuse_layers.2.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.2.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.2.0.0.2.weight - torch.Size([40, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.fuse_layers.2.0.0.3.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.2.0.0.3.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.2.0.1.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.fuse_layers.2.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.2.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.2.0.1.2.weight - torch.Size([160, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.fuse_layers.2.0.1.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.2.0.1.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.2.1.0.0.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.fuse_layers.2.1.0.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.2.1.0.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.2.1.0.2.weight - torch.Size([160, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.fuse_layers.2.1.0.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.2.1.0.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.0.cross_resolution_weighting.conv1.conv.weight - torch.Size([17, 140, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.0.cross_resolution_weighting.conv1.bn.weight - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.0.cross_resolution_weighting.conv1.bn.bias - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.0.cross_resolution_weighting.conv2.conv.weight - torch.Size([140, 17, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.0.cross_resolution_weighting.conv2.bn.weight - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.0.cross_resolution_weighting.conv2.bn.bias - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.0.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.0.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.0.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.0.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.0.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.0.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.0.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.0.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.0.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.0.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.0.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.0.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.0.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.0.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.0.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.0.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.0.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.0.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.0.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.0.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.0.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.1.cross_resolution_weighting.conv1.conv.weight - torch.Size([17, 140, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.1.cross_resolution_weighting.conv1.bn.weight - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.1.cross_resolution_weighting.conv1.bn.bias - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.1.cross_resolution_weighting.conv2.conv.weight - torch.Size([140, 17, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.1.cross_resolution_weighting.conv2.bn.weight - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.1.cross_resolution_weighting.conv2.bn.bias - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.1.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.1.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.1.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.1.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.1.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.1.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.1.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.1.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.1.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.1.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.1.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.1.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.1.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.1.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.1.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.1.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.1.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.1.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.1.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.1.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.1.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.0.1.0.weight - torch.Size([40, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.fuse_layers.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.0.2.0.weight - torch.Size([40, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.fuse_layers.0.2.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.0.2.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.1.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.fuse_layers.1.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.1.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.1.0.0.2.weight - torch.Size([80, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.fuse_layers.1.0.0.3.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.1.0.0.3.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.1.2.0.weight - torch.Size([80, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.fuse_layers.1.2.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.1.2.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.2.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.fuse_layers.2.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.2.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.2.0.0.2.weight - torch.Size([40, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.fuse_layers.2.0.0.3.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.2.0.0.3.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.2.0.1.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.fuse_layers.2.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.2.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.2.0.1.2.weight - torch.Size([160, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.fuse_layers.2.0.1.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.2.0.1.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.2.1.0.0.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.fuse_layers.2.1.0.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.2.1.0.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.2.1.0.2.weight - torch.Size([160, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.fuse_layers.2.1.0.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.2.1.0.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.0.cross_resolution_weighting.conv1.conv.weight - torch.Size([17, 140, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.0.cross_resolution_weighting.conv1.bn.weight - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.0.cross_resolution_weighting.conv1.bn.bias - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.0.cross_resolution_weighting.conv2.conv.weight - torch.Size([140, 17, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.0.cross_resolution_weighting.conv2.bn.weight - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.0.cross_resolution_weighting.conv2.bn.bias - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.0.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.0.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.0.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.0.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.0.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.0.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.0.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.0.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.0.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.0.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.0.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.0.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.0.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.0.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.0.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.0.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.0.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.0.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.0.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.0.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.0.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.1.cross_resolution_weighting.conv1.conv.weight - torch.Size([17, 140, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.1.cross_resolution_weighting.conv1.bn.weight - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.1.cross_resolution_weighting.conv1.bn.bias - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.1.cross_resolution_weighting.conv2.conv.weight - torch.Size([140, 17, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.1.cross_resolution_weighting.conv2.bn.weight - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.1.cross_resolution_weighting.conv2.bn.bias - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.1.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.1.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.1.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.1.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.1.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.1.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.1.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.1.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.1.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.1.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.1.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.1.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.1.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.1.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.1.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.1.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.1.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.1.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.1.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.1.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.1.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.0.1.0.weight - torch.Size([40, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.fuse_layers.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.0.2.0.weight - torch.Size([40, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.fuse_layers.0.2.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.0.2.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.1.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.fuse_layers.1.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.1.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.1.0.0.2.weight - torch.Size([80, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.fuse_layers.1.0.0.3.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.1.0.0.3.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.1.2.0.weight - torch.Size([80, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.fuse_layers.1.2.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.1.2.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.2.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.fuse_layers.2.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.2.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.2.0.0.2.weight - torch.Size([40, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.fuse_layers.2.0.0.3.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.2.0.0.3.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.2.0.1.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.fuse_layers.2.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.2.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.2.0.1.2.weight - torch.Size([160, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.fuse_layers.2.0.1.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.2.0.1.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.2.1.0.0.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.fuse_layers.2.1.0.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.2.1.0.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.2.1.0.2.weight - torch.Size([160, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.fuse_layers.2.1.0.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.2.1.0.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.0.cross_resolution_weighting.conv1.conv.weight - torch.Size([17, 140, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.layers.0.cross_resolution_weighting.conv1.bn.weight - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.0.cross_resolution_weighting.conv1.bn.bias - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.0.cross_resolution_weighting.conv2.conv.weight - torch.Size([140, 17, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.layers.0.cross_resolution_weighting.conv2.bn.weight - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.0.cross_resolution_weighting.conv2.bn.bias - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.0.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.layers.0.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.0.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.0.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.layers.0.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.0.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.0.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.layers.0.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.0.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.0.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.layers.0.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.0.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.layers.0.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.0.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.layers.0.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.0.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.layers.0.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.0.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.layers.0.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.0.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.layers.0.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.1.cross_resolution_weighting.conv1.conv.weight - torch.Size([17, 140, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.layers.1.cross_resolution_weighting.conv1.bn.weight - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.1.cross_resolution_weighting.conv1.bn.bias - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.1.cross_resolution_weighting.conv2.conv.weight - torch.Size([140, 17, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.layers.1.cross_resolution_weighting.conv2.bn.weight - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.1.cross_resolution_weighting.conv2.bn.bias - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.1.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.layers.1.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.1.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.1.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.layers.1.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.1.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.1.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.layers.1.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.1.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.1.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.layers.1.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.1.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.layers.1.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.1.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.layers.1.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.1.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.layers.1.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.1.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.layers.1.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.1.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.layers.1.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.fuse_layers.0.1.0.weight - torch.Size([40, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.fuse_layers.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.fuse_layers.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.fuse_layers.0.2.0.weight - torch.Size([40, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.fuse_layers.0.2.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.fuse_layers.0.2.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.fuse_layers.1.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.fuse_layers.1.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.fuse_layers.1.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.fuse_layers.1.0.0.2.weight - torch.Size([80, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.fuse_layers.1.0.0.3.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.fuse_layers.1.0.0.3.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.fuse_layers.1.2.0.weight - torch.Size([80, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.fuse_layers.1.2.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.fuse_layers.1.2.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.fuse_layers.2.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.fuse_layers.2.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.fuse_layers.2.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.fuse_layers.2.0.0.2.weight - torch.Size([40, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.fuse_layers.2.0.0.3.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.fuse_layers.2.0.0.3.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.fuse_layers.2.0.1.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.fuse_layers.2.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.fuse_layers.2.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.fuse_layers.2.0.1.2.weight - torch.Size([160, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.fuse_layers.2.0.1.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.fuse_layers.2.0.1.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.fuse_layers.2.1.0.0.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.fuse_layers.2.1.0.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.fuse_layers.2.1.0.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.fuse_layers.2.1.0.2.weight - torch.Size([160, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.fuse_layers.2.1.0.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.fuse_layers.2.1.0.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.0.cross_resolution_weighting.conv1.conv.weight - torch.Size([17, 140, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.layers.0.cross_resolution_weighting.conv1.bn.weight - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.0.cross_resolution_weighting.conv1.bn.bias - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.0.cross_resolution_weighting.conv2.conv.weight - torch.Size([140, 17, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.layers.0.cross_resolution_weighting.conv2.bn.weight - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.0.cross_resolution_weighting.conv2.bn.bias - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.0.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.layers.0.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.0.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.0.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.layers.0.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.0.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.0.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.layers.0.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.0.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.0.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.layers.0.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.0.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.layers.0.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.0.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.layers.0.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.0.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.layers.0.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.0.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.layers.0.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.0.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.layers.0.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.1.cross_resolution_weighting.conv1.conv.weight - torch.Size([17, 140, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.layers.1.cross_resolution_weighting.conv1.bn.weight - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.1.cross_resolution_weighting.conv1.bn.bias - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.1.cross_resolution_weighting.conv2.conv.weight - torch.Size([140, 17, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.layers.1.cross_resolution_weighting.conv2.bn.weight - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.1.cross_resolution_weighting.conv2.bn.bias - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.1.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.layers.1.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.1.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.1.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.layers.1.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.1.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.1.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.layers.1.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.1.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.1.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.layers.1.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.1.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.layers.1.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.1.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.layers.1.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.1.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.layers.1.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.1.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.layers.1.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.1.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.layers.1.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.fuse_layers.0.1.0.weight - torch.Size([40, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.fuse_layers.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.fuse_layers.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.fuse_layers.0.2.0.weight - torch.Size([40, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.fuse_layers.0.2.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.fuse_layers.0.2.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.fuse_layers.1.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.fuse_layers.1.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.fuse_layers.1.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.fuse_layers.1.0.0.2.weight - torch.Size([80, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.fuse_layers.1.0.0.3.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.fuse_layers.1.0.0.3.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.fuse_layers.1.2.0.weight - torch.Size([80, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.fuse_layers.1.2.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.fuse_layers.1.2.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.fuse_layers.2.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.fuse_layers.2.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.fuse_layers.2.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.fuse_layers.2.0.0.2.weight - torch.Size([40, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.fuse_layers.2.0.0.3.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.fuse_layers.2.0.0.3.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.fuse_layers.2.0.1.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.fuse_layers.2.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.fuse_layers.2.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.fuse_layers.2.0.1.2.weight - torch.Size([160, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.fuse_layers.2.0.1.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.fuse_layers.2.0.1.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.fuse_layers.2.1.0.0.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.fuse_layers.2.1.0.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.fuse_layers.2.1.0.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.fuse_layers.2.1.0.2.weight - torch.Size([160, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.fuse_layers.2.1.0.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.fuse_layers.2.1.0.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.0.cross_resolution_weighting.conv1.conv.weight - torch.Size([17, 140, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.layers.0.cross_resolution_weighting.conv1.bn.weight - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.0.cross_resolution_weighting.conv1.bn.bias - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.0.cross_resolution_weighting.conv2.conv.weight - torch.Size([140, 17, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.layers.0.cross_resolution_weighting.conv2.bn.weight - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.0.cross_resolution_weighting.conv2.bn.bias - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.0.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.layers.0.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.0.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.0.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.layers.0.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.0.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.0.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.layers.0.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.0.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.0.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.layers.0.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.0.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.layers.0.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.0.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.layers.0.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.0.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.layers.0.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.0.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.layers.0.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.0.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.layers.0.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.1.cross_resolution_weighting.conv1.conv.weight - torch.Size([17, 140, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.layers.1.cross_resolution_weighting.conv1.bn.weight - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.1.cross_resolution_weighting.conv1.bn.bias - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.1.cross_resolution_weighting.conv2.conv.weight - torch.Size([140, 17, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.layers.1.cross_resolution_weighting.conv2.bn.weight - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.1.cross_resolution_weighting.conv2.bn.bias - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.1.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.layers.1.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.1.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.1.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.layers.1.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.1.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.1.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.layers.1.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.1.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.1.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.layers.1.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.1.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.layers.1.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.1.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.layers.1.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.1.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.layers.1.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.1.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.layers.1.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.1.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.layers.1.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.fuse_layers.0.1.0.weight - torch.Size([40, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.fuse_layers.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.fuse_layers.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.fuse_layers.0.2.0.weight - torch.Size([40, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.fuse_layers.0.2.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.fuse_layers.0.2.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.fuse_layers.1.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.fuse_layers.1.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.fuse_layers.1.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.fuse_layers.1.0.0.2.weight - torch.Size([80, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.fuse_layers.1.0.0.3.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.fuse_layers.1.0.0.3.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.fuse_layers.1.2.0.weight - torch.Size([80, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.fuse_layers.1.2.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.fuse_layers.1.2.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.fuse_layers.2.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.fuse_layers.2.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.fuse_layers.2.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.fuse_layers.2.0.0.2.weight - torch.Size([40, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.fuse_layers.2.0.0.3.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.fuse_layers.2.0.0.3.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.fuse_layers.2.0.1.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.fuse_layers.2.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.fuse_layers.2.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.fuse_layers.2.0.1.2.weight - torch.Size([160, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.fuse_layers.2.0.1.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.fuse_layers.2.0.1.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.fuse_layers.2.1.0.0.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.fuse_layers.2.1.0.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.fuse_layers.2.1.0.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.fuse_layers.2.1.0.2.weight - torch.Size([160, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.fuse_layers.2.1.0.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.fuse_layers.2.1.0.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.0.cross_resolution_weighting.conv1.conv.weight - torch.Size([17, 140, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.layers.0.cross_resolution_weighting.conv1.bn.weight - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.0.cross_resolution_weighting.conv1.bn.bias - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.0.cross_resolution_weighting.conv2.conv.weight - torch.Size([140, 17, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.layers.0.cross_resolution_weighting.conv2.bn.weight - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.0.cross_resolution_weighting.conv2.bn.bias - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.0.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.layers.0.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.0.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.0.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.layers.0.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.0.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.0.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.layers.0.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.0.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.0.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.layers.0.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.0.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.layers.0.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.0.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.layers.0.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.0.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.layers.0.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.0.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.layers.0.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.0.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.layers.0.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.1.cross_resolution_weighting.conv1.conv.weight - torch.Size([17, 140, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.layers.1.cross_resolution_weighting.conv1.bn.weight - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.1.cross_resolution_weighting.conv1.bn.bias - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.1.cross_resolution_weighting.conv2.conv.weight - torch.Size([140, 17, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.layers.1.cross_resolution_weighting.conv2.bn.weight - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.1.cross_resolution_weighting.conv2.bn.bias - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.1.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.layers.1.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.1.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.1.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.layers.1.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.1.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.1.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.layers.1.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.1.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.1.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.layers.1.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.1.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.layers.1.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.1.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.layers.1.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.1.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.layers.1.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.1.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.layers.1.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.1.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.layers.1.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.fuse_layers.0.1.0.weight - torch.Size([40, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.fuse_layers.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.fuse_layers.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.fuse_layers.0.2.0.weight - torch.Size([40, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.fuse_layers.0.2.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.fuse_layers.0.2.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.fuse_layers.1.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.fuse_layers.1.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.fuse_layers.1.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.fuse_layers.1.0.0.2.weight - torch.Size([80, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.fuse_layers.1.0.0.3.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.fuse_layers.1.0.0.3.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.fuse_layers.1.2.0.weight - torch.Size([80, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.fuse_layers.1.2.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.fuse_layers.1.2.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.fuse_layers.2.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.fuse_layers.2.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.fuse_layers.2.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.fuse_layers.2.0.0.2.weight - torch.Size([40, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.fuse_layers.2.0.0.3.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.fuse_layers.2.0.0.3.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.fuse_layers.2.0.1.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.fuse_layers.2.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.fuse_layers.2.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.fuse_layers.2.0.1.2.weight - torch.Size([160, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.fuse_layers.2.0.1.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.fuse_layers.2.0.1.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.fuse_layers.2.1.0.0.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.fuse_layers.2.1.0.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.fuse_layers.2.1.0.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.fuse_layers.2.1.0.2.weight - torch.Size([160, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.fuse_layers.2.1.0.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.fuse_layers.2.1.0.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.transition2.3.0.0.weight - torch.Size([160, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.transition2.3.0.1.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.transition2.3.0.1.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.transition2.3.0.2.weight - torch.Size([320, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.transition2.3.0.3.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.transition2.3.0.3.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.cross_resolution_weighting.conv1.conv.weight - torch.Size([37, 300, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.0.cross_resolution_weighting.conv1.bn.weight - torch.Size([37]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.cross_resolution_weighting.conv1.bn.bias - torch.Size([37]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.cross_resolution_weighting.conv2.conv.weight - torch.Size([300, 37, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.0.cross_resolution_weighting.conv2.bn.weight - torch.Size([300]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.cross_resolution_weighting.conv2.bn.bias - torch.Size([300]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.0.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.0.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.0.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.depthwise_convs.3.conv.weight - torch.Size([160, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.0.depthwise_convs.3.bn.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.depthwise_convs.3.bn.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.0.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.0.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.0.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.0.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.0.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.0.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.spatial_weighting.3.conv1.conv.weight - torch.Size([40, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.0.spatial_weighting.3.conv1.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.spatial_weighting.3.conv2.conv.weight - torch.Size([160, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.0.spatial_weighting.3.conv2.conv.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.cross_resolution_weighting.conv1.conv.weight - torch.Size([37, 300, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.1.cross_resolution_weighting.conv1.bn.weight - torch.Size([37]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.cross_resolution_weighting.conv1.bn.bias - torch.Size([37]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.cross_resolution_weighting.conv2.conv.weight - torch.Size([300, 37, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.1.cross_resolution_weighting.conv2.bn.weight - torch.Size([300]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.cross_resolution_weighting.conv2.bn.bias - torch.Size([300]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.1.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.1.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.1.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.depthwise_convs.3.conv.weight - torch.Size([160, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.1.depthwise_convs.3.bn.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.depthwise_convs.3.bn.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.1.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.1.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.1.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.1.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.1.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.1.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.spatial_weighting.3.conv1.conv.weight - torch.Size([40, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.1.spatial_weighting.3.conv1.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.spatial_weighting.3.conv2.conv.weight - torch.Size([160, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.1.spatial_weighting.3.conv2.conv.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.0.1.0.weight - torch.Size([40, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.0.2.0.weight - torch.Size([40, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.0.2.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.0.2.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.0.3.0.weight - torch.Size([40, 320, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.0.3.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.0.3.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.1.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.1.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.1.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.1.0.0.2.weight - torch.Size([80, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.1.0.0.3.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.1.0.0.3.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.1.2.0.weight - torch.Size([80, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.1.2.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.1.2.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.1.3.0.weight - torch.Size([80, 320, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.1.3.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.1.3.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.2.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.2.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.2.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.2.0.0.2.weight - torch.Size([40, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.2.0.0.3.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.2.0.0.3.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.2.0.1.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.2.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.2.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.2.0.1.2.weight - torch.Size([160, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.2.0.1.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.2.0.1.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.2.1.0.0.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.2.1.0.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.2.1.0.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.2.1.0.2.weight - torch.Size([160, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.2.1.0.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.2.1.0.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.2.3.0.weight - torch.Size([160, 320, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.2.3.1.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.2.3.1.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.3.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.0.0.2.weight - torch.Size([40, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.3.0.0.3.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.0.0.3.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.0.1.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.3.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.0.1.2.weight - torch.Size([40, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.3.0.1.3.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.0.1.3.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.0.2.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.3.0.2.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.0.2.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.0.2.2.weight - torch.Size([320, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.3.0.2.3.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.0.2.3.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.1.0.0.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.3.1.0.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.1.0.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.1.0.2.weight - torch.Size([80, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.3.1.0.3.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.1.0.3.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.1.1.0.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.3.1.1.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.1.1.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.1.1.2.weight - torch.Size([320, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.3.1.1.3.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.1.1.3.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.2.0.0.weight - torch.Size([160, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.3.2.0.1.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.2.0.1.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.2.0.2.weight - torch.Size([320, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.3.2.0.3.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.2.0.3.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.cross_resolution_weighting.conv1.conv.weight - torch.Size([37, 300, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.0.cross_resolution_weighting.conv1.bn.weight - torch.Size([37]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.cross_resolution_weighting.conv1.bn.bias - torch.Size([37]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.cross_resolution_weighting.conv2.conv.weight - torch.Size([300, 37, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.0.cross_resolution_weighting.conv2.bn.weight - torch.Size([300]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.cross_resolution_weighting.conv2.bn.bias - torch.Size([300]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.0.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.0.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.0.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.depthwise_convs.3.conv.weight - torch.Size([160, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.0.depthwise_convs.3.bn.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.depthwise_convs.3.bn.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.0.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.0.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.0.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.0.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.0.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.0.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.spatial_weighting.3.conv1.conv.weight - torch.Size([40, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.0.spatial_weighting.3.conv1.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.spatial_weighting.3.conv2.conv.weight - torch.Size([160, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.0.spatial_weighting.3.conv2.conv.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.cross_resolution_weighting.conv1.conv.weight - torch.Size([37, 300, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.1.cross_resolution_weighting.conv1.bn.weight - torch.Size([37]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.cross_resolution_weighting.conv1.bn.bias - torch.Size([37]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.cross_resolution_weighting.conv2.conv.weight - torch.Size([300, 37, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.1.cross_resolution_weighting.conv2.bn.weight - torch.Size([300]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.cross_resolution_weighting.conv2.bn.bias - torch.Size([300]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.1.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.1.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.1.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.depthwise_convs.3.conv.weight - torch.Size([160, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.1.depthwise_convs.3.bn.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.depthwise_convs.3.bn.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.1.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.1.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.1.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.1.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.1.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.1.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.spatial_weighting.3.conv1.conv.weight - torch.Size([40, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.1.spatial_weighting.3.conv1.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.spatial_weighting.3.conv2.conv.weight - torch.Size([160, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.1.spatial_weighting.3.conv2.conv.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.0.1.0.weight - torch.Size([40, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.0.2.0.weight - torch.Size([40, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.0.2.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.0.2.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.0.3.0.weight - torch.Size([40, 320, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.0.3.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.0.3.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.1.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.1.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.1.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.1.0.0.2.weight - torch.Size([80, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.1.0.0.3.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.1.0.0.3.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.1.2.0.weight - torch.Size([80, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.1.2.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.1.2.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.1.3.0.weight - torch.Size([80, 320, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.1.3.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.1.3.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.2.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.2.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.2.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.2.0.0.2.weight - torch.Size([40, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.2.0.0.3.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.2.0.0.3.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.2.0.1.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.2.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.2.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.2.0.1.2.weight - torch.Size([160, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.2.0.1.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.2.0.1.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.2.1.0.0.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.2.1.0.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.2.1.0.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.2.1.0.2.weight - torch.Size([160, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.2.1.0.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.2.1.0.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.2.3.0.weight - torch.Size([160, 320, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.2.3.1.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.2.3.1.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.3.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.0.0.2.weight - torch.Size([40, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.3.0.0.3.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.0.0.3.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.0.1.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.3.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.0.1.2.weight - torch.Size([40, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.3.0.1.3.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.0.1.3.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.0.2.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.3.0.2.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.0.2.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.0.2.2.weight - torch.Size([320, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.3.0.2.3.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.0.2.3.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.1.0.0.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.3.1.0.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.1.0.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.1.0.2.weight - torch.Size([80, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.3.1.0.3.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.1.0.3.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.1.1.0.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.3.1.1.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.1.1.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.1.1.2.weight - torch.Size([320, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.3.1.1.3.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.1.1.3.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.2.0.0.weight - torch.Size([160, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.3.2.0.1.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.2.0.1.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.2.0.2.weight - torch.Size([320, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.3.2.0.3.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.2.0.3.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.0.cross_resolution_weighting.conv1.conv.weight - torch.Size([37, 300, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.0.cross_resolution_weighting.conv1.bn.weight - torch.Size([37]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.0.cross_resolution_weighting.conv1.bn.bias - torch.Size([37]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.0.cross_resolution_weighting.conv2.conv.weight - torch.Size([300, 37, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.0.cross_resolution_weighting.conv2.bn.weight - torch.Size([300]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.0.cross_resolution_weighting.conv2.bn.bias - torch.Size([300]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.0.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.0.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.0.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.0.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.0.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.0.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.0.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.0.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.0.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.0.depthwise_convs.3.conv.weight - torch.Size([160, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.0.depthwise_convs.3.bn.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.0.depthwise_convs.3.bn.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.0.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.0.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.0.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.0.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.0.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.0.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.0.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.0.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.0.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.0.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.0.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.0.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.0.spatial_weighting.3.conv1.conv.weight - torch.Size([40, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.0.spatial_weighting.3.conv1.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.0.spatial_weighting.3.conv2.conv.weight - torch.Size([160, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.0.spatial_weighting.3.conv2.conv.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.1.cross_resolution_weighting.conv1.conv.weight - torch.Size([37, 300, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.1.cross_resolution_weighting.conv1.bn.weight - torch.Size([37]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.1.cross_resolution_weighting.conv1.bn.bias - torch.Size([37]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.1.cross_resolution_weighting.conv2.conv.weight - torch.Size([300, 37, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.1.cross_resolution_weighting.conv2.bn.weight - torch.Size([300]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.1.cross_resolution_weighting.conv2.bn.bias - torch.Size([300]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.1.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.1.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.1.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.1.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.1.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.1.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.1.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.1.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.1.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.1.depthwise_convs.3.conv.weight - torch.Size([160, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.1.depthwise_convs.3.bn.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.1.depthwise_convs.3.bn.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.1.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.1.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.1.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.1.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.1.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.1.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.1.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.1.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.1.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.1.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.1.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.1.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.1.spatial_weighting.3.conv1.conv.weight - torch.Size([40, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.1.spatial_weighting.3.conv1.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.1.spatial_weighting.3.conv2.conv.weight - torch.Size([160, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.1.spatial_weighting.3.conv2.conv.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.0.1.0.weight - torch.Size([40, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.0.2.0.weight - torch.Size([40, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.0.2.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.0.2.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.0.3.0.weight - torch.Size([40, 320, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.0.3.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.0.3.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.1.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.1.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.1.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.1.0.0.2.weight - torch.Size([80, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.1.0.0.3.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.1.0.0.3.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.1.2.0.weight - torch.Size([80, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.1.2.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.1.2.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.1.3.0.weight - torch.Size([80, 320, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.1.3.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.1.3.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.2.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.2.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.2.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.2.0.0.2.weight - torch.Size([40, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.2.0.0.3.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.2.0.0.3.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.2.0.1.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.2.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.2.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.2.0.1.2.weight - torch.Size([160, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.2.0.1.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.2.0.1.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.2.1.0.0.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.2.1.0.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.2.1.0.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.2.1.0.2.weight - torch.Size([160, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.2.1.0.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.2.1.0.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.2.3.0.weight - torch.Size([160, 320, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.2.3.1.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.2.3.1.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.3.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.0.0.2.weight - torch.Size([40, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.3.0.0.3.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.0.0.3.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.0.1.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.3.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.0.1.2.weight - torch.Size([40, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.3.0.1.3.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.0.1.3.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.0.2.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.3.0.2.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.0.2.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.0.2.2.weight - torch.Size([320, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.3.0.2.3.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.0.2.3.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.1.0.0.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.3.1.0.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.1.0.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.1.0.2.weight - torch.Size([80, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.3.1.0.3.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.1.0.3.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.1.1.0.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.3.1.1.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.1.1.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.1.1.2.weight - torch.Size([320, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.3.1.1.3.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.1.1.3.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.2.0.0.weight - torch.Size([160, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.3.2.0.1.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.2.0.1.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.2.0.2.weight - torch.Size([320, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.3.2.0.3.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.2.0.3.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.head_layer.projects.0.depthwise_conv.conv.weight - torch.Size([320, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.head_layer.projects.0.depthwise_conv.bn.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.head_layer.projects.0.depthwise_conv.bn.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.head_layer.projects.0.pointwise_conv.conv.weight - torch.Size([160, 320, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.head_layer.projects.0.pointwise_conv.bn.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.head_layer.projects.0.pointwise_conv.bn.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.head_layer.projects.1.depthwise_conv.conv.weight - torch.Size([160, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.head_layer.projects.1.depthwise_conv.bn.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.head_layer.projects.1.depthwise_conv.bn.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.head_layer.projects.1.pointwise_conv.conv.weight - torch.Size([80, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.head_layer.projects.1.pointwise_conv.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.head_layer.projects.1.pointwise_conv.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.head_layer.projects.2.depthwise_conv.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.head_layer.projects.2.depthwise_conv.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.head_layer.projects.2.depthwise_conv.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.head_layer.projects.2.pointwise_conv.conv.weight - torch.Size([40, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.head_layer.projects.2.pointwise_conv.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.head_layer.projects.2.pointwise_conv.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.head_layer.projects.3.depthwise_conv.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.head_layer.projects.3.depthwise_conv.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.head_layer.projects.3.depthwise_conv.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.head_layer.projects.3.pointwise_conv.conv.weight - torch.Size([40, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.head_layer.projects.3.pointwise_conv.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.head_layer.projects.3.pointwise_conv.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.conv_seg.weight - torch.Size([150, 40, 1, 1]): 
NormalInit: mean=0, std=0.01, bias=0 

decode_head.conv_seg.bias - torch.Size([150]): 
NormalInit: mean=0, std=0.01, bias=0 

decode_head.convs.0.conv.weight - torch.Size([40, 40, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.convs.0.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.convs.0.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.convs.1.conv.weight - torch.Size([40, 40, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.conv_cat.conv.weight - torch.Size([40, 80, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

decode_head.conv_cat.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.conv_cat.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  
2021-08-13 22:50:25,691 - mmseg - INFO - EncoderDecoder(
  (backbone): LiteHRNet(
    (stem): Stem(
      (conv1): ConvModule(
        (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (branch1): Sequential(
        (0): ConvModule(
          (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)
          (bn): SyncBatchNorm(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): ConvModule(
          (conv): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): SyncBatchNorm(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (expand_conv): ConvModule(
        (conv): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (depthwise_conv): ConvModule(
        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)
        (bn): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (linear_conv): ConvModule(
        (conv): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): SyncBatchNorm(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (transition0): ModuleList(
      (0): Sequential(
        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
        (1): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Conv2d(32, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (3): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (4): ReLU()
      )
      (1): Sequential(
        (0): Sequential(
          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)
          (1): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Conv2d(32, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU()
        )
      )
    )
    (stage0): Sequential(
      (0): LiteHRModule(
        (layers): Sequential(
          (0): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(60, 7, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(7, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
          (1): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(60, 7, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(7, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
        )
        (fuse_layers): ModuleList(
          (0): ModuleList(
            (0): None
            (1): Sequential(
              (0): Conv2d(80, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
          )
          (1): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): None
          )
        )
        (relu): ReLU()
      )
      (1): LiteHRModule(
        (layers): Sequential(
          (0): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(60, 7, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(7, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
          (1): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(60, 7, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(7, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
        )
        (fuse_layers): ModuleList(
          (0): ModuleList(
            (0): None
            (1): Sequential(
              (0): Conv2d(80, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
          )
          (1): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): None
          )
        )
        (relu): ReLU()
      )
      (2): LiteHRModule(
        (layers): Sequential(
          (0): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(60, 7, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(7, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
          (1): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(60, 7, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(7, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
        )
        (fuse_layers): ModuleList(
          (0): ModuleList(
            (0): None
            (1): Sequential(
              (0): Conv2d(80, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
          )
          (1): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): None
          )
        )
        (relu): ReLU()
      )
    )
    (transition1): ModuleList(
      (0): None
      (1): None
      (2): Sequential(
        (0): Sequential(
          (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=80, bias=False)
          (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Conv2d(80, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU()
        )
      )
    )
    (stage1): Sequential(
      (0): LiteHRModule(
        (layers): Sequential(
          (0): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(140, 17, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(17, 140, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
          (1): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(140, 17, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(17, 140, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
        )
        (fuse_layers): ModuleList(
          (0): ModuleList(
            (0): None
            (1): Sequential(
              (0): Conv2d(80, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
            (2): Sequential(
              (0): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=4.0, mode=nearest)
            )
          )
          (1): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): None
            (2): Sequential(
              (0): Conv2d(160, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
          )
          (2): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (1): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=80, bias=False)
                (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(80, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): None
          )
        )
        (relu): ReLU()
      )
      (1): LiteHRModule(
        (layers): Sequential(
          (0): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(140, 17, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(17, 140, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
          (1): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(140, 17, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(17, 140, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
        )
        (fuse_layers): ModuleList(
          (0): ModuleList(
            (0): None
            (1): Sequential(
              (0): Conv2d(80, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
            (2): Sequential(
              (0): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=4.0, mode=nearest)
            )
          )
          (1): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): None
            (2): Sequential(
              (0): Conv2d(160, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
          )
          (2): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (1): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=80, bias=False)
                (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(80, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): None
          )
        )
        (relu): ReLU()
      )
      (2): LiteHRModule(
        (layers): Sequential(
          (0): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(140, 17, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(17, 140, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
          (1): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(140, 17, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(17, 140, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
        )
        (fuse_layers): ModuleList(
          (0): ModuleList(
            (0): None
            (1): Sequential(
              (0): Conv2d(80, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
            (2): Sequential(
              (0): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=4.0, mode=nearest)
            )
          )
          (1): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): None
            (2): Sequential(
              (0): Conv2d(160, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
          )
          (2): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (1): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=80, bias=False)
                (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(80, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): None
          )
        )
        (relu): ReLU()
      )
      (3): LiteHRModule(
        (layers): Sequential(
          (0): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(140, 17, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(17, 140, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
          (1): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(140, 17, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(17, 140, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
        )
        (fuse_layers): ModuleList(
          (0): ModuleList(
            (0): None
            (1): Sequential(
              (0): Conv2d(80, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
            (2): Sequential(
              (0): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=4.0, mode=nearest)
            )
          )
          (1): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): None
            (2): Sequential(
              (0): Conv2d(160, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
          )
          (2): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (1): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=80, bias=False)
                (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(80, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): None
          )
        )
        (relu): ReLU()
      )
      (4): LiteHRModule(
        (layers): Sequential(
          (0): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(140, 17, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(17, 140, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
          (1): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(140, 17, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(17, 140, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
        )
        (fuse_layers): ModuleList(
          (0): ModuleList(
            (0): None
            (1): Sequential(
              (0): Conv2d(80, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
            (2): Sequential(
              (0): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=4.0, mode=nearest)
            )
          )
          (1): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): None
            (2): Sequential(
              (0): Conv2d(160, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
          )
          (2): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (1): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=80, bias=False)
                (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(80, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): None
          )
        )
        (relu): ReLU()
      )
      (5): LiteHRModule(
        (layers): Sequential(
          (0): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(140, 17, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(17, 140, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
          (1): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(140, 17, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(17, 140, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
        )
        (fuse_layers): ModuleList(
          (0): ModuleList(
            (0): None
            (1): Sequential(
              (0): Conv2d(80, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
            (2): Sequential(
              (0): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=4.0, mode=nearest)
            )
          )
          (1): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): None
            (2): Sequential(
              (0): Conv2d(160, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
          )
          (2): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (1): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=80, bias=False)
                (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(80, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): None
          )
        )
        (relu): ReLU()
      )
      (6): LiteHRModule(
        (layers): Sequential(
          (0): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(140, 17, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(17, 140, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
          (1): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(140, 17, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(17, 140, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
        )
        (fuse_layers): ModuleList(
          (0): ModuleList(
            (0): None
            (1): Sequential(
              (0): Conv2d(80, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
            (2): Sequential(
              (0): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=4.0, mode=nearest)
            )
          )
          (1): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): None
            (2): Sequential(
              (0): Conv2d(160, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
          )
          (2): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (1): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=80, bias=False)
                (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(80, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): None
          )
        )
        (relu): ReLU()
      )
      (7): LiteHRModule(
        (layers): Sequential(
          (0): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(140, 17, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(17, 140, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
          (1): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(140, 17, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(17, 140, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
        )
        (fuse_layers): ModuleList(
          (0): ModuleList(
            (0): None
            (1): Sequential(
              (0): Conv2d(80, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
            (2): Sequential(
              (0): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=4.0, mode=nearest)
            )
          )
          (1): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): None
            (2): Sequential(
              (0): Conv2d(160, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
          )
          (2): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (1): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=80, bias=False)
                (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(80, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): None
          )
        )
        (relu): ReLU()
      )
    )
    (transition2): ModuleList(
      (0): None
      (1): None
      (2): None
      (3): Sequential(
        (0): Sequential(
          (0): Conv2d(160, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=160, bias=False)
          (1): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Conv2d(160, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): SyncBatchNorm(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU()
        )
      )
    )
    (stage2): Sequential(
      (0): LiteHRModule(
        (layers): Sequential(
          (0): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(300, 37, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(37, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(37, 300, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): ConvModule(
                (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (3): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
          (1): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(300, 37, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(37, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(37, 300, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): ConvModule(
                (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (3): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
        )
        (fuse_layers): ModuleList(
          (0): ModuleList(
            (0): None
            (1): Sequential(
              (0): Conv2d(80, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
            (2): Sequential(
              (0): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=4.0, mode=nearest)
            )
            (3): Sequential(
              (0): Conv2d(320, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=8.0, mode=nearest)
            )
          )
          (1): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): None
            (2): Sequential(
              (0): Conv2d(160, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
            (3): Sequential(
              (0): Conv2d(320, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=4.0, mode=nearest)
            )
          )
          (2): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (1): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=80, bias=False)
                (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(80, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): None
            (3): Sequential(
              (0): Conv2d(320, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
          )
          (3): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (1): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (2): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=80, bias=False)
                (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (1): Sequential(
                (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=80, bias=False)
                (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(80, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): Sequential(
              (0): Sequential(
                (0): Conv2d(160, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=160, bias=False)
                (1): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(160, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): None
          )
        )
        (relu): ReLU()
      )
      (1): LiteHRModule(
        (layers): Sequential(
          (0): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(300, 37, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(37, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(37, 300, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): ConvModule(
                (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (3): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
          (1): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(300, 37, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(37, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(37, 300, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): ConvModule(
                (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (3): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
        )
        (fuse_layers): ModuleList(
          (0): ModuleList(
            (0): None
            (1): Sequential(
              (0): Conv2d(80, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
            (2): Sequential(
              (0): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=4.0, mode=nearest)
            )
            (3): Sequential(
              (0): Conv2d(320, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=8.0, mode=nearest)
            )
          )
          (1): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): None
            (2): Sequential(
              (0): Conv2d(160, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
            (3): Sequential(
              (0): Conv2d(320, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=4.0, mode=nearest)
            )
          )
          (2): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (1): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=80, bias=False)
                (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(80, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): None
            (3): Sequential(
              (0): Conv2d(320, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
          )
          (3): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (1): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (2): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=80, bias=False)
                (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (1): Sequential(
                (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=80, bias=False)
                (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(80, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): Sequential(
              (0): Sequential(
                (0): Conv2d(160, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=160, bias=False)
                (1): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(160, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): None
          )
        )
        (relu): ReLU()
      )
      (2): LiteHRModule(
        (layers): Sequential(
          (0): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(300, 37, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(37, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(37, 300, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): ConvModule(
                (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (3): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
          (1): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(300, 37, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(37, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(37, 300, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): ConvModule(
                (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (3): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
        )
        (fuse_layers): ModuleList(
          (0): ModuleList(
            (0): None
            (1): Sequential(
              (0): Conv2d(80, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
            (2): Sequential(
              (0): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=4.0, mode=nearest)
            )
            (3): Sequential(
              (0): Conv2d(320, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=8.0, mode=nearest)
            )
          )
          (1): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): None
            (2): Sequential(
              (0): Conv2d(160, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
            (3): Sequential(
              (0): Conv2d(320, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=4.0, mode=nearest)
            )
          )
          (2): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (1): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=80, bias=False)
                (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(80, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): None
            (3): Sequential(
              (0): Conv2d(320, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
          )
          (3): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (1): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (2): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=80, bias=False)
                (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (1): Sequential(
                (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=80, bias=False)
                (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(80, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): Sequential(
              (0): Sequential(
                (0): Conv2d(160, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=160, bias=False)
                (1): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(160, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): None
          )
        )
        (relu): ReLU()
      )
    )
    (head_layer): IterativeHead(
      (projects): ModuleList(
        (0): DepthwiseSeparableConvModule(
          (depthwise_conv): ConvModule(
            (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)
            (bn): SyncBatchNorm(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise_conv): ConvModule(
            (conv): Conv2d(320, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (activate): ReLU(inplace=True)
          )
        )
        (1): DepthwiseSeparableConvModule(
          (depthwise_conv): ConvModule(
            (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
            (bn): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise_conv): ConvModule(
            (conv): Conv2d(160, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (activate): ReLU(inplace=True)
          )
        )
        (2): DepthwiseSeparableConvModule(
          (depthwise_conv): ConvModule(
            (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
            (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise_conv): ConvModule(
            (conv): Conv2d(80, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (activate): ReLU(inplace=True)
          )
        )
        (3): DepthwiseSeparableConvModule(
          (depthwise_conv): ConvModule(
            (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
            (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (pointwise_conv): ConvModule(
            (conv): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (activate): ReLU(inplace=True)
          )
        )
      )
    )
  )
  init_cfg=[{'type': 'Normal', 'std': 0.001, 'layer': 'Conv2d'}, {'type': 'Constant', 'val': 1, 'layer': ['_BatchNorm', 'GroupNorm']}]
  (decode_head): FCNHead(
    input_transform=None, ignore_index=255, align_corners=False
    (loss_decode): CrossEntropyLoss()
    (conv_seg): Conv2d(40, 150, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (convs): Sequential(
      (0): ConvModule(
        (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (conv_cat): ConvModule(
      (conv): Conv2d(80, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
)
2021-08-13 22:50:26,253 - mmseg - INFO - Loaded 20210 images
2021-08-13 22:50:32,314 - mmseg - INFO - Loaded 2000 images
2021-08-13 22:50:32,315 - mmseg - INFO - Start running, host: hejunjun@SH-IDC2-172-20-20-73, work_dir: /mnt/lustrenew/hejunjun/mmseg_dev/lite_hrnet/mmsegmentation/work_dirs/fcn_litehr30-with-head_512x512_160k_ade20k
2021-08-13 22:50:32,315 - mmseg - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(NORMAL      ) CheckpointHook                     
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
2021-08-13 22:50:32,316 - mmseg - INFO - workflow: [('train', 1)], max: 160000 iters
2021-08-13 22:52:14,892 - mmseg - INFO - Iter [50/160000]	lr: 9.997e-03, eta: 2 days, 13:18:47, time: 1.380, data_time: 0.021, memory: 5723, decode.loss_seg: 3.4885, decode.acc_seg: 13.9343, loss: 3.4885
2021-08-13 22:53:19,639 - mmseg - INFO - Iter [100/160000]	lr: 9.994e-03, eta: 2 days, 11:24:07, time: 1.295, data_time: 0.013, memory: 5723, decode.loss_seg: 2.8882, decode.acc_seg: 18.9838, loss: 2.8882
2021-08-13 22:54:23,570 - mmseg - INFO - Iter [150/160000]	lr: 9.992e-03, eta: 2 days, 10:31:19, time: 1.279, data_time: 0.014, memory: 5723, decode.loss_seg: 2.7384, decode.acc_seg: 21.5401, loss: 2.7384
2021-08-13 22:55:26,511 - mmseg - INFO - Iter [200/160000]	lr: 9.989e-03, eta: 2 days, 9:50:19, time: 1.258, data_time: 0.013, memory: 5723, decode.loss_seg: 2.6057, decode.acc_seg: 24.1715, loss: 2.6057
2021-08-13 22:56:31,523 - mmseg - INFO - Iter [250/160000]	lr: 9.986e-03, eta: 2 days, 9:47:58, time: 1.301, data_time: 0.013, memory: 5723, decode.loss_seg: 2.5334, decode.acc_seg: 24.7007, loss: 2.5334
2021-08-13 22:57:35,233 - mmseg - INFO - Iter [300/160000]	lr: 9.983e-03, eta: 2 days, 9:34:06, time: 1.274, data_time: 0.013, memory: 5723, decode.loss_seg: 2.4826, decode.acc_seg: 25.0984, loss: 2.4826
2021-08-13 22:58:39,223 - mmseg - INFO - Iter [350/160000]	lr: 9.981e-03, eta: 2 days, 9:26:25, time: 1.280, data_time: 0.013, memory: 5723, decode.loss_seg: 2.4641, decode.acc_seg: 25.3619, loss: 2.4641
2021-08-13 22:59:42,799 - mmseg - INFO - Iter [400/160000]	lr: 9.978e-03, eta: 2 days, 9:17:22, time: 1.271, data_time: 0.013, memory: 5723, decode.loss_seg: 2.4366, decode.acc_seg: 27.0178, loss: 2.4366
2021-08-13 23:00:49,186 - mmseg - INFO - Iter [450/160000]	lr: 9.975e-03, eta: 2 days, 9:26:39, time: 1.327, data_time: 0.013, memory: 5723, decode.loss_seg: 2.3740, decode.acc_seg: 26.2757, loss: 2.3740
2021-08-13 23:01:53,573 - mmseg - INFO - Iter [500/160000]	lr: 9.972e-03, eta: 2 days, 9:23:34, time: 1.289, data_time: 0.013, memory: 5723, decode.loss_seg: 2.3820, decode.acc_seg: 27.2147, loss: 2.3820
2021-08-13 23:02:57,622 - mmseg - INFO - Iter [550/160000]	lr: 9.969e-03, eta: 2 days, 9:18:51, time: 1.280, data_time: 0.013, memory: 5723, decode.loss_seg: 2.3416, decode.acc_seg: 27.8860, loss: 2.3416
2021-08-13 23:04:01,929 - mmseg - INFO - Iter [600/160000]	lr: 9.967e-03, eta: 2 days, 9:16:10, time: 1.287, data_time: 0.013, memory: 5723, decode.loss_seg: 2.3640, decode.acc_seg: 28.8871, loss: 2.3640
2021-08-13 23:05:44,709 - mmseg - INFO - Iter [650/160000]	lr: 9.964e-03, eta: 2 days, 11:50:48, time: 2.056, data_time: 0.731, memory: 5723, decode.loss_seg: 2.3272, decode.acc_seg: 28.3861, loss: 2.3272
2021-08-13 23:06:50,363 - mmseg - INFO - Iter [700/160000]	lr: 9.961e-03, eta: 2 days, 11:42:17, time: 1.313, data_time: 0.014, memory: 5723, decode.loss_seg: 2.3018, decode.acc_seg: 28.2282, loss: 2.3018
2021-08-13 23:07:54,212 - mmseg - INFO - Iter [750/160000]	lr: 9.958e-03, eta: 2 days, 11:28:22, time: 1.277, data_time: 0.013, memory: 5723, decode.loss_seg: 2.3066, decode.acc_seg: 29.3065, loss: 2.3066
2021-08-13 23:08:56,389 - mmseg - INFO - Iter [800/160000]	lr: 9.955e-03, eta: 2 days, 11:10:22, time: 1.243, data_time: 0.013, memory: 5723, decode.loss_seg: 2.2209, decode.acc_seg: 31.1481, loss: 2.2209
2021-08-13 23:10:00,826 - mmseg - INFO - Iter [850/160000]	lr: 9.953e-03, eta: 2 days, 11:01:34, time: 1.289, data_time: 0.014, memory: 5723, decode.loss_seg: 2.2098, decode.acc_seg: 29.6219, loss: 2.2098
2021-08-13 23:11:05,884 - mmseg - INFO - Iter [900/160000]	lr: 9.950e-03, eta: 2 days, 10:55:33, time: 1.302, data_time: 0.014, memory: 5723, decode.loss_seg: 2.2071, decode.acc_seg: 29.9073, loss: 2.2071
2021-08-13 23:12:07,479 - mmseg - INFO - Iter [950/160000]	lr: 9.947e-03, eta: 2 days, 10:40:16, time: 1.232, data_time: 0.014, memory: 5723, decode.loss_seg: 2.1465, decode.acc_seg: 30.5572, loss: 2.1465
2021-08-13 23:13:11,168 - mmseg - INFO - Exp name: fcn_litehr30-with-head_512x512_160k_ade20k.py
2021-08-13 23:13:11,169 - mmseg - INFO - Iter [1000/160000]	lr: 9.944e-03, eta: 2 days, 10:31:50, time: 1.273, data_time: 0.014, memory: 5723, decode.loss_seg: 2.1692, decode.acc_seg: 31.9385, loss: 2.1692
2021-08-13 23:14:13,727 - mmseg - INFO - Iter [1050/160000]	lr: 9.942e-03, eta: 2 days, 10:21:27, time: 1.252, data_time: 0.015, memory: 5723, decode.loss_seg: 2.1613, decode.acc_seg: 30.2507, loss: 2.1613
2021-08-13 23:15:18,105 - mmseg - INFO - Iter [1100/160000]	lr: 9.939e-03, eta: 2 days, 10:16:19, time: 1.288, data_time: 0.015, memory: 5723, decode.loss_seg: 2.1140, decode.acc_seg: 32.2429, loss: 2.1140
2021-08-13 23:16:22,399 - mmseg - INFO - Iter [1150/160000]	lr: 9.936e-03, eta: 2 days, 10:11:14, time: 1.285, data_time: 0.014, memory: 5723, decode.loss_seg: 2.1192, decode.acc_seg: 31.9365, loss: 2.1192
2021-08-13 23:17:25,963 - mmseg - INFO - Iter [1200/160000]	lr: 9.933e-03, eta: 2 days, 10:04:56, time: 1.272, data_time: 0.013, memory: 5723, decode.loss_seg: 2.0723, decode.acc_seg: 33.3332, loss: 2.0723
2021-08-13 23:18:29,581 - mmseg - INFO - Iter [1250/160000]	lr: 9.930e-03, eta: 2 days, 9:59:09, time: 1.272, data_time: 0.014, memory: 5723, decode.loss_seg: 2.0343, decode.acc_seg: 34.1504, loss: 2.0343
2021-08-13 23:20:08,153 - mmseg - INFO - Iter [1300/160000]	lr: 9.928e-03, eta: 2 days, 11:04:44, time: 1.970, data_time: 0.729, memory: 5723, decode.loss_seg: 2.1058, decode.acc_seg: 32.3168, loss: 2.1058
2021-08-13 23:21:11,403 - mmseg - INFO - Iter [1350/160000]	lr: 9.925e-03, eta: 2 days, 10:56:18, time: 1.266, data_time: 0.015, memory: 5723, decode.loss_seg: 2.0340, decode.acc_seg: 34.0443, loss: 2.0340
2021-08-13 23:22:15,287 - mmseg - INFO - Iter [1400/160000]	lr: 9.922e-03, eta: 2 days, 10:49:30, time: 1.277, data_time: 0.013, memory: 5723, decode.loss_seg: 2.0762, decode.acc_seg: 32.3255, loss: 2.0762
2021-08-13 23:23:19,051 - mmseg - INFO - Iter [1450/160000]	lr: 9.919e-03, eta: 2 days, 10:43:01, time: 1.276, data_time: 0.015, memory: 5723, decode.loss_seg: 2.0044, decode.acc_seg: 33.7840, loss: 2.0044
2021-08-13 23:24:20,936 - mmseg - INFO - Iter [1500/160000]	lr: 9.916e-03, eta: 2 days, 10:33:30, time: 1.238, data_time: 0.014, memory: 5723, decode.loss_seg: 2.0237, decode.acc_seg: 33.6948, loss: 2.0237
2021-08-13 23:25:24,299 - mmseg - INFO - Iter [1550/160000]	lr: 9.914e-03, eta: 2 days, 10:26:59, time: 1.267, data_time: 0.013, memory: 5723, decode.loss_seg: 1.9483, decode.acc_seg: 34.9594, loss: 1.9483
2021-08-13 23:26:28,321 - mmseg - INFO - Iter [1600/160000]	lr: 9.911e-03, eta: 2 days, 10:21:56, time: 1.280, data_time: 0.013, memory: 5723, decode.loss_seg: 2.0224, decode.acc_seg: 33.2541, loss: 2.0224
2021-08-13 23:27:32,501 - mmseg - INFO - Iter [1650/160000]	lr: 9.908e-03, eta: 2 days, 10:17:28, time: 1.285, data_time: 0.013, memory: 5723, decode.loss_seg: 1.9479, decode.acc_seg: 34.7913, loss: 1.9479
2021-08-13 23:28:35,300 - mmseg - INFO - Iter [1700/160000]	lr: 9.905e-03, eta: 2 days, 10:10:57, time: 1.256, data_time: 0.013, memory: 5723, decode.loss_seg: 1.9862, decode.acc_seg: 34.9301, loss: 1.9862
2021-08-13 23:29:36,920 - mmseg - INFO - Iter [1750/160000]	lr: 9.903e-03, eta: 2 days, 10:03:00, time: 1.232, data_time: 0.013, memory: 5723, decode.loss_seg: 1.9900, decode.acc_seg: 34.7771, loss: 1.9900
2021-08-13 23:30:39,750 - mmseg - INFO - Iter [1800/160000]	lr: 9.900e-03, eta: 2 days, 9:57:15, time: 1.257, data_time: 0.014, memory: 5723, decode.loss_seg: 1.9540, decode.acc_seg: 35.2086, loss: 1.9540
2021-08-13 23:31:42,099 - mmseg - INFO - Iter [1850/160000]	lr: 9.897e-03, eta: 2 days, 9:51:01, time: 1.247, data_time: 0.012, memory: 5723, decode.loss_seg: 1.9547, decode.acc_seg: 34.9005, loss: 1.9547
2021-08-13 23:33:22,487 - mmseg - INFO - Iter [1900/160000]	lr: 9.894e-03, eta: 2 days, 10:37:46, time: 2.007, data_time: 0.721, memory: 5723, decode.loss_seg: 1.9805, decode.acc_seg: 34.9635, loss: 1.9805
2021-08-13 23:34:23,981 - mmseg - INFO - Iter [1950/160000]	lr: 9.891e-03, eta: 2 days, 10:29:37, time: 1.231, data_time: 0.014, memory: 5723, decode.loss_seg: 1.9242, decode.acc_seg: 34.2060, loss: 1.9242
2021-08-13 23:35:26,153 - mmseg - INFO - Exp name: fcn_litehr30-with-head_512x512_160k_ade20k.py
2021-08-13 23:35:26,154 - mmseg - INFO - Iter [2000/160000]	lr: 9.889e-03, eta: 2 days, 10:22:39, time: 1.243, data_time: 0.013, memory: 5723, decode.loss_seg: 1.9787, decode.acc_seg: 34.8670, loss: 1.9787
2021-08-13 23:36:29,805 - mmseg - INFO - Iter [2050/160000]	lr: 9.886e-03, eta: 2 days, 10:17:52, time: 1.273, data_time: 0.015, memory: 5723, decode.loss_seg: 1.8797, decode.acc_seg: 36.7431, loss: 1.8797
2021-08-13 23:37:32,426 - mmseg - INFO - Iter [2100/160000]	lr: 9.883e-03, eta: 2 days, 10:12:00, time: 1.253, data_time: 0.015, memory: 5723, decode.loss_seg: 1.9678, decode.acc_seg: 35.1687, loss: 1.9678
2021-08-13 23:38:37,986 - mmseg - INFO - Iter [2150/160000]	lr: 9.880e-03, eta: 2 days, 10:09:54, time: 1.311, data_time: 0.016, memory: 5723, decode.loss_seg: 1.9466, decode.acc_seg: 34.4311, loss: 1.9466
2021-08-13 23:39:40,917 - mmseg - INFO - Iter [2200/160000]	lr: 9.877e-03, eta: 2 days, 10:04:45, time: 1.259, data_time: 0.013, memory: 5723, decode.loss_seg: 1.8901, decode.acc_seg: 35.3413, loss: 1.8901
2021-08-13 23:40:42,237 - mmseg - INFO - Iter [2250/160000]	lr: 9.875e-03, eta: 2 days, 9:57:53, time: 1.226, data_time: 0.013, memory: 5723, decode.loss_seg: 1.9104, decode.acc_seg: 36.1394, loss: 1.9104
2021-08-13 23:41:43,840 - mmseg - INFO - Iter [2300/160000]	lr: 9.872e-03, eta: 2 days, 9:51:33, time: 1.231, data_time: 0.014, memory: 5723, decode.loss_seg: 1.9283, decode.acc_seg: 35.3487, loss: 1.9283
2021-08-13 23:42:45,869 - mmseg - INFO - Iter [2350/160000]	lr: 9.869e-03, eta: 2 days, 9:46:00, time: 1.241, data_time: 0.015, memory: 5723, decode.loss_seg: 1.9142, decode.acc_seg: 35.9822, loss: 1.9142
2021-08-13 23:43:47,593 - mmseg - INFO - Iter [2400/160000]	lr: 9.866e-03, eta: 2 days, 9:40:15, time: 1.234, data_time: 0.014, memory: 5723, decode.loss_seg: 1.8529, decode.acc_seg: 37.9459, loss: 1.8529
2021-08-13 23:44:48,650 - mmseg - INFO - Iter [2450/160000]	lr: 9.864e-03, eta: 2 days, 9:34:01, time: 1.221, data_time: 0.015, memory: 5723, decode.loss_seg: 1.8514, decode.acc_seg: 37.1496, loss: 1.8514
2021-08-13 23:45:49,491 - mmseg - INFO - Iter [2500/160000]	lr: 9.861e-03, eta: 2 days, 9:27:43, time: 1.216, data_time: 0.015, memory: 5723, decode.loss_seg: 1.9229, decode.acc_seg: 36.3415, loss: 1.9229
2021-08-13 23:47:29,527 - mmseg - INFO - Iter [2550/160000]	lr: 9.858e-03, eta: 2 days, 10:01:59, time: 2.001, data_time: 0.706, memory: 5723, decode.loss_seg: 1.8426, decode.acc_seg: 36.9911, loss: 1.8426
2021-08-13 23:48:32,533 - mmseg - INFO - Iter [2600/160000]	lr: 9.855e-03, eta: 2 days, 9:57:33, time: 1.261, data_time: 0.016, memory: 5723, decode.loss_seg: 1.8108, decode.acc_seg: 37.1636, loss: 1.8108
2021-08-13 23:49:35,527 - mmseg - INFO - Iter [2650/160000]	lr: 9.852e-03, eta: 2 days, 9:53:12, time: 1.260, data_time: 0.014, memory: 5723, decode.loss_seg: 1.8763, decode.acc_seg: 37.4922, loss: 1.8763
2021-08-13 23:50:38,434 - mmseg - INFO - Iter [2700/160000]	lr: 9.850e-03, eta: 2 days, 9:48:50, time: 1.257, data_time: 0.016, memory: 5723, decode.loss_seg: 1.8728, decode.acc_seg: 37.0448, loss: 1.8728
2021-08-13 23:51:41,961 - mmseg - INFO - Iter [2750/160000]	lr: 9.847e-03, eta: 2 days, 9:45:16, time: 1.271, data_time: 0.016, memory: 5723, decode.loss_seg: 1.8805, decode.acc_seg: 36.2484, loss: 1.8805
2021-08-13 23:52:45,594 - mmseg - INFO - Iter [2800/160000]	lr: 9.844e-03, eta: 2 days, 9:41:50, time: 1.273, data_time: 0.015, memory: 5723, decode.loss_seg: 1.7577, decode.acc_seg: 38.2179, loss: 1.7577
2021-08-13 23:53:47,234 - mmseg - INFO - Iter [2850/160000]	lr: 9.841e-03, eta: 2 days, 9:36:40, time: 1.233, data_time: 0.016, memory: 5723, decode.loss_seg: 1.8594, decode.acc_seg: 36.7794, loss: 1.8594
2021-08-13 23:54:48,680 - mmseg - INFO - Iter [2900/160000]	lr: 9.838e-03, eta: 2 days, 9:31:28, time: 1.229, data_time: 0.015, memory: 5723, decode.loss_seg: 1.7979, decode.acc_seg: 38.0852, loss: 1.7979
2021-08-13 23:55:51,472 - mmseg - INFO - Iter [2950/160000]	lr: 9.836e-03, eta: 2 days, 9:27:36, time: 1.256, data_time: 0.015, memory: 5723, decode.loss_seg: 1.7957, decode.acc_seg: 38.4929, loss: 1.7957
2021-08-13 23:56:54,785 - mmseg - INFO - Exp name: fcn_litehr30-with-head_512x512_160k_ade20k.py
2021-08-13 23:56:54,786 - mmseg - INFO - Iter [3000/160000]	lr: 9.833e-03, eta: 2 days, 9:24:17, time: 1.267, data_time: 0.016, memory: 5723, decode.loss_seg: 1.8492, decode.acc_seg: 37.5025, loss: 1.8492
2021-08-13 23:57:57,384 - mmseg - INFO - Iter [3050/160000]	lr: 9.830e-03, eta: 2 days, 9:20:24, time: 1.251, data_time: 0.015, memory: 5723, decode.loss_seg: 1.8517, decode.acc_seg: 37.7218, loss: 1.8517
2021-08-13 23:59:02,345 - mmseg - INFO - Iter [3100/160000]	lr: 9.827e-03, eta: 2 days, 9:18:38, time: 1.299, data_time: 0.016, memory: 5723, decode.loss_seg: 1.8218, decode.acc_seg: 38.1465, loss: 1.8218
2021-08-14 00:00:06,701 - mmseg - INFO - Iter [3150/160000]	lr: 9.824e-03, eta: 2 days, 9:15:30, time: 1.266, data_time: 0.016, memory: 5723, decode.loss_seg: 1.8105, decode.acc_seg: 38.5547, loss: 1.8105
2021-08-14 00:02:13,351 - mmseg - INFO - Iter [3200/160000]	lr: 9.822e-03, eta: 2 days, 10:05:04, time: 2.555, data_time: 1.225, memory: 5723, decode.loss_seg: 1.8289, decode.acc_seg: 37.0977, loss: 1.8289
2021-08-14 00:03:19,949 - mmseg - INFO - Iter [3250/160000]	lr: 9.819e-03, eta: 2 days, 10:03:51, time: 1.331, data_time: 0.014, memory: 5723, decode.loss_seg: 1.8366, decode.acc_seg: 38.6149, loss: 1.8366
2021-08-14 00:04:24,246 - mmseg - INFO - Iter [3300/160000]	lr: 9.816e-03, eta: 2 days, 10:00:52, time: 1.286, data_time: 0.014, memory: 5723, decode.loss_seg: 1.8131, decode.acc_seg: 38.5539, loss: 1.8131
2021-08-14 00:05:33,307 - mmseg - INFO - Iter [3350/160000]	lr: 9.813e-03, eta: 2 days, 10:01:38, time: 1.381, data_time: 0.014, memory: 5723, decode.loss_seg: 1.8048, decode.acc_seg: 38.4768, loss: 1.8048
2021-08-14 00:06:40,023 - mmseg - INFO - Iter [3400/160000]	lr: 9.811e-03, eta: 2 days, 10:00:35, time: 1.336, data_time: 0.015, memory: 5723, decode.loss_seg: 1.7739, decode.acc_seg: 39.0688, loss: 1.7739
2021-08-14 00:07:42,373 - mmseg - INFO - Iter [3450/160000]	lr: 9.808e-03, eta: 2 days, 9:56:12, time: 1.247, data_time: 0.014, memory: 5723, decode.loss_seg: 1.8091, decode.acc_seg: 38.0269, loss: 1.8091
2021-08-14 00:08:44,580 - mmseg - INFO - Iter [3500/160000]	lr: 9.805e-03, eta: 2 days, 9:51:46, time: 1.243, data_time: 0.014, memory: 5723, decode.loss_seg: 1.7820, decode.acc_seg: 38.2718, loss: 1.7820
2021-08-14 00:09:45,256 - mmseg - INFO - Iter [3550/160000]	lr: 9.802e-03, eta: 2 days, 9:46:23, time: 1.215, data_time: 0.015, memory: 5723, decode.loss_seg: 1.7656, decode.acc_seg: 38.0307, loss: 1.7656
2021-08-14 00:10:51,995 - mmseg - INFO - Iter [3600/160000]	lr: 9.799e-03, eta: 2 days, 9:45:27, time: 1.334, data_time: 0.013, memory: 5723, decode.loss_seg: 1.7797, decode.acc_seg: 38.7749, loss: 1.7797
2021-08-14 00:11:53,956 - mmseg - INFO - Iter [3650/160000]	lr: 9.797e-03, eta: 2 days, 9:41:08, time: 1.240, data_time: 0.014, memory: 5723, decode.loss_seg: 1.7705, decode.acc_seg: 38.8441, loss: 1.7705
2021-08-14 00:12:57,789 - mmseg - INFO - Iter [3700/160000]	lr: 9.794e-03, eta: 2 days, 9:38:13, time: 1.277, data_time: 0.015, memory: 5723, decode.loss_seg: 1.7535, decode.acc_seg: 39.3532, loss: 1.7535
2021-08-14 00:14:03,514 - mmseg - INFO - Iter [3750/160000]	lr: 9.791e-03, eta: 2 days, 9:36:38, time: 1.314, data_time: 0.013, memory: 5723, decode.loss_seg: 1.7388, decode.acc_seg: 39.2869, loss: 1.7388
2021-08-14 00:16:09,966 - mmseg - INFO - Iter [3800/160000]	lr: 9.788e-03, eta: 2 days, 10:16:42, time: 2.529, data_time: 1.236, memory: 5723, decode.loss_seg: 1.7905, decode.acc_seg: 38.7066, loss: 1.7905
2021-08-14 00:17:11,771 - mmseg - INFO - Iter [3850/160000]	lr: 9.785e-03, eta: 2 days, 10:11:58, time: 1.237, data_time: 0.014, memory: 5723, decode.loss_seg: 1.7412, decode.acc_seg: 39.3247, loss: 1.7412
2021-08-14 00:18:13,809 - mmseg - INFO - Iter [3900/160000]	lr: 9.783e-03, eta: 2 days, 10:07:29, time: 1.241, data_time: 0.013, memory: 5723, decode.loss_seg: 1.6880, decode.acc_seg: 40.1966, loss: 1.6880
2021-08-14 00:19:16,817 - mmseg - INFO - Iter [3950/160000]	lr: 9.780e-03, eta: 2 days, 10:03:44, time: 1.261, data_time: 0.013, memory: 5723, decode.loss_seg: 1.7845, decode.acc_seg: 39.4311, loss: 1.7845
2021-08-14 00:20:18,857 - mmseg - INFO - Exp name: fcn_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 00:20:18,858 - mmseg - INFO - Iter [4000/160000]	lr: 9.777e-03, eta: 2 days, 9:59:24, time: 1.241, data_time: 0.013, memory: 5723, decode.loss_seg: 1.7225, decode.acc_seg: 39.7099, loss: 1.7225
2021-08-14 00:21:21,037 - mmseg - INFO - Iter [4050/160000]	lr: 9.774e-03, eta: 2 days, 9:55:15, time: 1.243, data_time: 0.013, memory: 5723, decode.loss_seg: 1.7477, decode.acc_seg: 39.3107, loss: 1.7477
2021-08-14 00:22:23,886 - mmseg - INFO - Iter [4100/160000]	lr: 9.771e-03, eta: 2 days, 9:51:35, time: 1.257, data_time: 0.012, memory: 5723, decode.loss_seg: 1.7399, decode.acc_seg: 39.1958, loss: 1.7399
2021-08-14 00:23:27,688 - mmseg - INFO - Iter [4150/160000]	lr: 9.769e-03, eta: 2 days, 9:48:35, time: 1.276, data_time: 0.014, memory: 5723, decode.loss_seg: 1.7437, decode.acc_seg: 38.9293, loss: 1.7437
2021-08-14 00:24:29,298 - mmseg - INFO - Iter [4200/160000]	lr: 9.766e-03, eta: 2 days, 9:44:18, time: 1.233, data_time: 0.013, memory: 5723, decode.loss_seg: 1.7288, decode.acc_seg: 38.9655, loss: 1.7288
2021-08-14 00:25:31,197 - mmseg - INFO - Iter [4250/160000]	lr: 9.763e-03, eta: 2 days, 9:40:15, time: 1.238, data_time: 0.013, memory: 5723, decode.loss_seg: 1.7051, decode.acc_seg: 40.2406, loss: 1.7051
2021-08-14 00:26:32,615 - mmseg - INFO - Iter [4300/160000]	lr: 9.760e-03, eta: 2 days, 9:35:59, time: 1.228, data_time: 0.013, memory: 5723, decode.loss_seg: 1.7059, decode.acc_seg: 39.8882, loss: 1.7059
2021-08-14 00:27:35,846 - mmseg - INFO - Iter [4350/160000]	lr: 9.757e-03, eta: 2 days, 9:32:51, time: 1.264, data_time: 0.014, memory: 5723, decode.loss_seg: 1.7454, decode.acc_seg: 39.3362, loss: 1.7454
2021-08-14 00:28:41,894 - mmseg - INFO - Iter [4400/160000]	lr: 9.755e-03, eta: 2 days, 9:31:28, time: 1.321, data_time: 0.013, memory: 5723, decode.loss_seg: 1.7166, decode.acc_seg: 39.7304, loss: 1.7166
2021-08-14 00:30:20,167 - mmseg - INFO - Iter [4450/160000]	lr: 9.752e-03, eta: 2 days, 9:48:49, time: 1.965, data_time: 0.695, memory: 5723, decode.loss_seg: 1.6911, decode.acc_seg: 40.5570, loss: 1.6911
2021-08-14 00:31:22,562 - mmseg - INFO - Iter [4500/160000]	lr: 9.749e-03, eta: 2 days, 9:45:08, time: 1.249, data_time: 0.015, memory: 5723, decode.loss_seg: 1.6977, decode.acc_seg: 39.1817, loss: 1.6977
2021-08-14 00:32:23,537 - mmseg - INFO - Iter [4550/160000]	lr: 9.746e-03, eta: 2 days, 9:40:39, time: 1.219, data_time: 0.012, memory: 5723, decode.loss_seg: 1.7476, decode.acc_seg: 39.1801, loss: 1.7476
2021-08-14 00:33:24,528 - mmseg - INFO - Iter [4600/160000]	lr: 9.744e-03, eta: 2 days, 9:36:17, time: 1.220, data_time: 0.014, memory: 5723, decode.loss_seg: 1.7191, decode.acc_seg: 40.4188, loss: 1.7191
2021-08-14 00:34:27,867 - mmseg - INFO - Iter [4650/160000]	lr: 9.741e-03, eta: 2 days, 9:33:17, time: 1.267, data_time: 0.014, memory: 5723, decode.loss_seg: 1.6263, decode.acc_seg: 41.2189, loss: 1.6263
2021-08-14 00:35:28,573 - mmseg - INFO - Iter [4700/160000]	lr: 9.738e-03, eta: 2 days, 9:28:53, time: 1.214, data_time: 0.014, memory: 5723, decode.loss_seg: 1.6538, decode.acc_seg: 40.6841, loss: 1.6538
2021-08-14 00:36:31,020 - mmseg - INFO - Iter [4750/160000]	lr: 9.735e-03, eta: 2 days, 9:25:29, time: 1.248, data_time: 0.015, memory: 5723, decode.loss_seg: 1.6929, decode.acc_seg: 39.7898, loss: 1.6929
2021-08-14 00:37:33,290 - mmseg - INFO - Iter [4800/160000]	lr: 9.732e-03, eta: 2 days, 9:22:04, time: 1.246, data_time: 0.015, memory: 5723, decode.loss_seg: 1.6732, decode.acc_seg: 40.9212, loss: 1.6732
2021-08-14 00:38:35,674 - mmseg - INFO - Iter [4850/160000]	lr: 9.730e-03, eta: 2 days, 9:18:44, time: 1.247, data_time: 0.013, memory: 5723, decode.loss_seg: 1.7035, decode.acc_seg: 40.5463, loss: 1.7035
2021-08-14 00:39:37,558 - mmseg - INFO - Iter [4900/160000]	lr: 9.727e-03, eta: 2 days, 9:15:12, time: 1.238, data_time: 0.015, memory: 5723, decode.loss_seg: 1.6567, decode.acc_seg: 42.2532, loss: 1.6567
2021-08-14 00:40:39,839 - mmseg - INFO - Iter [4950/160000]	lr: 9.724e-03, eta: 2 days, 9:11:55, time: 1.246, data_time: 0.014, memory: 5723, decode.loss_seg: 1.7267, decode.acc_seg: 39.8576, loss: 1.7267
2021-08-14 00:41:41,741 - mmseg - INFO - Exp name: fcn_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 00:41:41,741 - mmseg - INFO - Iter [5000/160000]	lr: 9.721e-03, eta: 2 days, 9:08:30, time: 1.239, data_time: 0.015, memory: 5723, decode.loss_seg: 1.6915, decode.acc_seg: 40.7065, loss: 1.6915
2021-08-14 00:43:19,622 - mmseg - INFO - Iter [5050/160000]	lr: 9.718e-03, eta: 2 days, 9:23:31, time: 1.958, data_time: 0.742, memory: 5723, decode.loss_seg: 1.6863, decode.acc_seg: 40.5209, loss: 1.6863
2021-08-14 00:44:25,893 - mmseg - INFO - Iter [5100/160000]	lr: 9.716e-03, eta: 2 days, 9:22:10, time: 1.324, data_time: 0.014, memory: 5723, decode.loss_seg: 1.5715, decode.acc_seg: 41.5668, loss: 1.5715
2021-08-14 00:45:31,709 - mmseg - INFO - Iter [5150/160000]	lr: 9.713e-03, eta: 2 days, 9:20:38, time: 1.317, data_time: 0.013, memory: 5723, decode.loss_seg: 1.6737, decode.acc_seg: 40.2577, loss: 1.6737
2021-08-14 00:46:35,410 - mmseg - INFO - Iter [5200/160000]	lr: 9.710e-03, eta: 2 days, 9:18:04, time: 1.274, data_time: 0.013, memory: 5723, decode.loss_seg: 1.6674, decode.acc_seg: 41.3569, loss: 1.6674
2021-08-14 00:47:39,175 - mmseg - INFO - Iter [5250/160000]	lr: 9.707e-03, eta: 2 days, 9:15:34, time: 1.276, data_time: 0.015, memory: 5723, decode.loss_seg: 1.6332, decode.acc_seg: 41.8348, loss: 1.6332
2021-08-14 00:48:40,432 - mmseg - INFO - Iter [5300/160000]	lr: 9.704e-03, eta: 2 days, 9:11:51, time: 1.225, data_time: 0.013, memory: 5723, decode.loss_seg: 1.6834, decode.acc_seg: 41.0921, loss: 1.6834
2021-08-14 00:49:43,007 - mmseg - INFO - Iter [5350/160000]	lr: 9.702e-03, eta: 2 days, 9:08:50, time: 1.252, data_time: 0.013, memory: 5723, decode.loss_seg: 1.7209, decode.acc_seg: 40.3228, loss: 1.7209
2021-08-14 00:50:44,112 - mmseg - INFO - Iter [5400/160000]	lr: 9.699e-03, eta: 2 days, 9:05:08, time: 1.222, data_time: 0.015, memory: 5723, decode.loss_seg: 1.6650, decode.acc_seg: 42.4572, loss: 1.6650
2021-08-14 00:51:44,461 - mmseg - INFO - Iter [5450/160000]	lr: 9.696e-03, eta: 2 days, 9:01:07, time: 1.206, data_time: 0.013, memory: 5723, decode.loss_seg: 1.6199, decode.acc_seg: 41.5747, loss: 1.6199
2021-08-14 00:52:46,425 - mmseg - INFO - Iter [5500/160000]	lr: 9.693e-03, eta: 2 days, 8:57:57, time: 1.240, data_time: 0.014, memory: 5723, decode.loss_seg: 1.5799, decode.acc_seg: 42.1237, loss: 1.5799
2021-08-14 00:53:48,129 - mmseg - INFO - Iter [5550/160000]	lr: 9.690e-03, eta: 2 days, 8:54:40, time: 1.234, data_time: 0.013, memory: 5723, decode.loss_seg: 1.6611, decode.acc_seg: 41.8348, loss: 1.6611
2021-08-14 00:54:49,595 - mmseg - INFO - Iter [5600/160000]	lr: 9.688e-03, eta: 2 days, 8:51:20, time: 1.229, data_time: 0.013, memory: 5723, decode.loss_seg: 1.5834, decode.acc_seg: 41.1926, loss: 1.5834
2021-08-14 00:55:50,723 - mmseg - INFO - Iter [5650/160000]	lr: 9.685e-03, eta: 2 days, 8:47:53, time: 1.223, data_time: 0.014, memory: 5723, decode.loss_seg: 1.6233, decode.acc_seg: 41.1088, loss: 1.6233
2021-08-14 00:57:29,411 - mmseg - INFO - Iter [5700/160000]	lr: 9.682e-03, eta: 2 days, 9:01:25, time: 1.973, data_time: 0.691, memory: 5723, decode.loss_seg: 1.6605, decode.acc_seg: 40.5686, loss: 1.6605
2021-08-14 00:58:33,102 - mmseg - INFO - Iter [5750/160000]	lr: 9.679e-03, eta: 2 days, 8:59:03, time: 1.274, data_time: 0.014, memory: 5723, decode.loss_seg: 1.6165, decode.acc_seg: 40.7961, loss: 1.6165
2021-08-14 00:59:37,272 - mmseg - INFO - Iter [5800/160000]	lr: 9.676e-03, eta: 2 days, 8:56:55, time: 1.283, data_time: 0.013, memory: 5723, decode.loss_seg: 1.6412, decode.acc_seg: 41.9455, loss: 1.6412
2021-08-14 01:00:40,705 - mmseg - INFO - Iter [5850/160000]	lr: 9.674e-03, eta: 2 days, 8:54:28, time: 1.269, data_time: 0.014, memory: 5723, decode.loss_seg: 1.6275, decode.acc_seg: 41.4015, loss: 1.6275
2021-08-14 01:01:44,327 - mmseg - INFO - Iter [5900/160000]	lr: 9.671e-03, eta: 2 days, 8:52:07, time: 1.272, data_time: 0.016, memory: 5723, decode.loss_seg: 1.6350, decode.acc_seg: 41.5445, loss: 1.6350
2021-08-14 01:02:45,250 - mmseg - INFO - Iter [5950/160000]	lr: 9.668e-03, eta: 2 days, 8:48:38, time: 1.219, data_time: 0.015, memory: 5723, decode.loss_seg: 1.6316, decode.acc_seg: 40.5202, loss: 1.6316
2021-08-14 01:03:46,971 - mmseg - INFO - Exp name: fcn_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 01:03:46,972 - mmseg - INFO - Iter [6000/160000]	lr: 9.665e-03, eta: 2 days, 8:45:33, time: 1.235, data_time: 0.014, memory: 5723, decode.loss_seg: 1.5700, decode.acc_seg: 42.0221, loss: 1.5700
2021-08-14 01:04:49,755 - mmseg - INFO - Iter [6050/160000]	lr: 9.663e-03, eta: 2 days, 8:42:56, time: 1.256, data_time: 0.014, memory: 5723, decode.loss_seg: 1.6015, decode.acc_seg: 42.5370, loss: 1.6015
2021-08-14 01:05:51,678 - mmseg - INFO - Iter [6100/160000]	lr: 9.660e-03, eta: 2 days, 8:39:58, time: 1.238, data_time: 0.013, memory: 5723, decode.loss_seg: 1.6189, decode.acc_seg: 41.7657, loss: 1.6189
2021-08-14 01:06:52,709 - mmseg - INFO - Iter [6150/160000]	lr: 9.657e-03, eta: 2 days, 8:36:40, time: 1.221, data_time: 0.014, memory: 5723, decode.loss_seg: 1.6158, decode.acc_seg: 43.6110, loss: 1.6158
2021-08-14 01:07:56,705 - mmseg - INFO - Iter [6200/160000]	lr: 9.654e-03, eta: 2 days, 8:34:39, time: 1.280, data_time: 0.013, memory: 5723, decode.loss_seg: 1.5907, decode.acc_seg: 43.2006, loss: 1.5907
2021-08-14 01:09:03,571 - mmseg - INFO - Iter [6250/160000]	lr: 9.651e-03, eta: 2 days, 8:33:48, time: 1.337, data_time: 0.014, memory: 5723, decode.loss_seg: 1.6106, decode.acc_seg: 41.7466, loss: 1.6106
2021-08-14 01:10:07,592 - mmseg - INFO - Iter [6300/160000]	lr: 9.649e-03, eta: 2 days, 8:31:48, time: 1.280, data_time: 0.016, memory: 5723, decode.loss_seg: 1.6651, decode.acc_seg: 41.7383, loss: 1.6651
2021-08-14 01:11:46,137 - mmseg - INFO - Iter [6350/160000]	lr: 9.646e-03, eta: 2 days, 8:43:46, time: 1.972, data_time: 0.708, memory: 5723, decode.loss_seg: 1.6350, decode.acc_seg: 42.7659, loss: 1.6350
2021-08-14 01:12:51,980 - mmseg - INFO - Iter [6400/160000]	lr: 9.643e-03, eta: 2 days, 8:42:24, time: 1.316, data_time: 0.016, memory: 5723, decode.loss_seg: 1.5750, decode.acc_seg: 42.8005, loss: 1.5750
2021-08-14 01:13:54,033 - mmseg - INFO - Iter [6450/160000]	lr: 9.640e-03, eta: 2 days, 8:39:33, time: 1.241, data_time: 0.014, memory: 5723, decode.loss_seg: 1.5933, decode.acc_seg: 41.8795, loss: 1.5933
2021-08-14 01:14:57,728 - mmseg - INFO - Iter [6500/160000]	lr: 9.637e-03, eta: 2 days, 8:37:22, time: 1.274, data_time: 0.015, memory: 5723, decode.loss_seg: 1.6381, decode.acc_seg: 41.0628, loss: 1.6381
2021-08-14 01:16:01,119 - mmseg - INFO - Iter [6550/160000]	lr: 9.635e-03, eta: 2 days, 8:35:06, time: 1.268, data_time: 0.016, memory: 5723, decode.loss_seg: 1.6119, decode.acc_seg: 41.3911, loss: 1.6119
2021-08-14 01:17:03,729 - mmseg - INFO - Iter [6600/160000]	lr: 9.632e-03, eta: 2 days, 8:32:31, time: 1.251, data_time: 0.012, memory: 5723, decode.loss_seg: 1.5704, decode.acc_seg: 42.3236, loss: 1.5704
2021-08-14 01:18:09,094 - mmseg - INFO - Iter [6650/160000]	lr: 9.629e-03, eta: 2 days, 8:31:01, time: 1.307, data_time: 0.013, memory: 5723, decode.loss_seg: 1.6129, decode.acc_seg: 41.6120, loss: 1.6129
2021-08-14 01:19:13,299 - mmseg - INFO - Iter [6700/160000]	lr: 9.626e-03, eta: 2 days, 8:29:07, time: 1.285, data_time: 0.014, memory: 5723, decode.loss_seg: 1.5766, decode.acc_seg: 43.5500, loss: 1.5766
2021-08-14 01:20:17,012 - mmseg - INFO - Iter [6750/160000]	lr: 9.623e-03, eta: 2 days, 8:27:01, time: 1.274, data_time: 0.013, memory: 5723, decode.loss_seg: 1.5920, decode.acc_seg: 41.8116, loss: 1.5920
2021-08-14 01:21:17,924 - mmseg - INFO - Iter [6800/160000]	lr: 9.621e-03, eta: 2 days, 8:23:54, time: 1.219, data_time: 0.014, memory: 5723, decode.loss_seg: 1.6259, decode.acc_seg: 42.5376, loss: 1.6259
2021-08-14 01:22:21,260 - mmseg - INFO - Iter [6850/160000]	lr: 9.618e-03, eta: 2 days, 8:21:42, time: 1.267, data_time: 0.013, memory: 5723, decode.loss_seg: 1.6150, decode.acc_seg: 42.2472, loss: 1.6150
2021-08-14 01:23:25,027 - mmseg - INFO - Iter [6900/160000]	lr: 9.615e-03, eta: 2 days, 8:19:40, time: 1.274, data_time: 0.012, memory: 5723, decode.loss_seg: 1.5908, decode.acc_seg: 43.9171, loss: 1.5908
2021-08-14 01:25:04,852 - mmseg - INFO - Iter [6950/160000]	lr: 9.612e-03, eta: 2 days, 8:30:55, time: 1.997, data_time: 0.664, memory: 5723, decode.loss_seg: 1.5424, decode.acc_seg: 42.5576, loss: 1.5424
2021-08-14 01:26:07,692 - mmseg - INFO - Exp name: fcn_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 01:26:07,692 - mmseg - INFO - Iter [7000/160000]	lr: 9.609e-03, eta: 2 days, 8:28:29, time: 1.257, data_time: 0.014, memory: 5723, decode.loss_seg: 1.5834, decode.acc_seg: 42.3584, loss: 1.5834
2021-08-14 01:27:09,592 - mmseg - INFO - Iter [7050/160000]	lr: 9.607e-03, eta: 2 days, 8:25:44, time: 1.238, data_time: 0.015, memory: 5723, decode.loss_seg: 1.5863, decode.acc_seg: 42.8005, loss: 1.5863
2021-08-14 01:28:14,204 - mmseg - INFO - Iter [7100/160000]	lr: 9.604e-03, eta: 2 days, 8:23:58, time: 1.292, data_time: 0.013, memory: 5723, decode.loss_seg: 1.5964, decode.acc_seg: 41.9660, loss: 1.5964
2021-08-14 01:29:15,820 - mmseg - INFO - Iter [7150/160000]	lr: 9.601e-03, eta: 2 days, 8:21:10, time: 1.233, data_time: 0.014, memory: 5723, decode.loss_seg: 1.5735, decode.acc_seg: 43.0366, loss: 1.5735
2021-08-14 01:30:19,260 - mmseg - INFO - Iter [7200/160000]	lr: 9.598e-03, eta: 2 days, 8:19:02, time: 1.269, data_time: 0.016, memory: 5723, decode.loss_seg: 1.5137, decode.acc_seg: 43.2442, loss: 1.5137
2021-08-14 01:31:22,042 - mmseg - INFO - Iter [7250/160000]	lr: 9.595e-03, eta: 2 days, 8:16:40, time: 1.255, data_time: 0.015, memory: 5723, decode.loss_seg: 1.5483, decode.acc_seg: 43.6981, loss: 1.5483
2021-08-14 01:32:24,637 - mmseg - INFO - Iter [7300/160000]	lr: 9.593e-03, eta: 2 days, 8:14:16, time: 1.252, data_time: 0.013, memory: 5723, decode.loss_seg: 1.5860, decode.acc_seg: 43.0053, loss: 1.5860
2021-08-14 01:33:26,372 - mmseg - INFO - Iter [7350/160000]	lr: 9.590e-03, eta: 2 days, 8:11:35, time: 1.235, data_time: 0.013, memory: 5723, decode.loss_seg: 1.5752, decode.acc_seg: 42.7559, loss: 1.5752
2021-08-14 01:34:30,503 - mmseg - INFO - Iter [7400/160000]	lr: 9.587e-03, eta: 2 days, 8:09:45, time: 1.283, data_time: 0.013, memory: 5723, decode.loss_seg: 1.5138, decode.acc_seg: 43.2187, loss: 1.5138
2021-08-14 01:35:32,108 - mmseg - INFO - Iter [7450/160000]	lr: 9.584e-03, eta: 2 days, 8:07:03, time: 1.231, data_time: 0.014, memory: 5723, decode.loss_seg: 1.5798, decode.acc_seg: 43.6851, loss: 1.5798
2021-08-14 01:36:34,061 - mmseg - INFO - Iter [7500/160000]	lr: 9.581e-03, eta: 2 days, 8:04:31, time: 1.240, data_time: 0.014, memory: 5723, decode.loss_seg: 1.6218, decode.acc_seg: 42.6315, loss: 1.6218
2021-08-14 01:37:35,718 - mmseg - INFO - Iter [7550/160000]	lr: 9.579e-03, eta: 2 days, 8:01:53, time: 1.233, data_time: 0.015, memory: 5723, decode.loss_seg: 1.5397, decode.acc_seg: 43.7095, loss: 1.5397
2021-08-14 01:39:14,911 - mmseg - INFO - Iter [7600/160000]	lr: 9.576e-03, eta: 2 days, 8:11:49, time: 1.983, data_time: 0.726, memory: 5723, decode.loss_seg: 1.5118, decode.acc_seg: 43.5650, loss: 1.5118
2021-08-14 01:40:16,716 - mmseg - INFO - Iter [7650/160000]	lr: 9.573e-03, eta: 2 days, 8:09:12, time: 1.237, data_time: 0.013, memory: 5723, decode.loss_seg: 1.5609, decode.acc_seg: 42.9394, loss: 1.5609
2021-08-14 01:41:19,393 - mmseg - INFO - Iter [7700/160000]	lr: 9.570e-03, eta: 2 days, 8:06:53, time: 1.254, data_time: 0.015, memory: 5723, decode.loss_seg: 1.5272, decode.acc_seg: 44.2085, loss: 1.5272
2021-08-14 01:42:21,232 - mmseg - INFO - Iter [7750/160000]	lr: 9.567e-03, eta: 2 days, 8:04:18, time: 1.236, data_time: 0.013, memory: 5723, decode.loss_seg: 1.5423, decode.acc_seg: 42.7722, loss: 1.5423
2021-08-14 01:43:24,282 - mmseg - INFO - Iter [7800/160000]	lr: 9.565e-03, eta: 2 days, 8:02:09, time: 1.261, data_time: 0.015, memory: 5723, decode.loss_seg: 1.5668, decode.acc_seg: 42.5854, loss: 1.5668
2021-08-14 01:44:26,121 - mmseg - INFO - Iter [7850/160000]	lr: 9.562e-03, eta: 2 days, 7:59:37, time: 1.237, data_time: 0.014, memory: 5723, decode.loss_seg: 1.5183, decode.acc_seg: 43.7038, loss: 1.5183
2021-08-14 01:45:28,714 - mmseg - INFO - Iter [7900/160000]	lr: 9.559e-03, eta: 2 days, 7:57:20, time: 1.251, data_time: 0.013, memory: 5723, decode.loss_seg: 1.5606, decode.acc_seg: 43.1407, loss: 1.5606
2021-08-14 01:46:30,858 - mmseg - INFO - Iter [7950/160000]	lr: 9.556e-03, eta: 2 days, 7:54:56, time: 1.243, data_time: 0.013, memory: 5723, decode.loss_seg: 1.5449, decode.acc_seg: 43.1316, loss: 1.5449
2021-08-14 01:47:34,668 - mmseg - INFO - Exp name: fcn_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 01:47:34,669 - mmseg - INFO - Iter [8000/160000]	lr: 9.553e-03, eta: 2 days, 7:53:05, time: 1.277, data_time: 0.016, memory: 5723, decode.loss_seg: 1.5481, decode.acc_seg: 43.3068, loss: 1.5481
2021-08-14 01:48:37,736 - mmseg - INFO - Iter [8050/160000]	lr: 9.551e-03, eta: 2 days, 7:51:00, time: 1.261, data_time: 0.015, memory: 5723, decode.loss_seg: 1.5169, decode.acc_seg: 43.7027, loss: 1.5169
2021-08-14 01:49:41,024 - mmseg - INFO - Iter [8100/160000]	lr: 9.548e-03, eta: 2 days, 7:49:00, time: 1.266, data_time: 0.013, memory: 5723, decode.loss_seg: 1.5580, decode.acc_seg: 44.0895, loss: 1.5580
2021-08-14 01:50:42,972 - mmseg - INFO - Iter [8150/160000]	lr: 9.545e-03, eta: 2 days, 7:46:35, time: 1.238, data_time: 0.014, memory: 5723, decode.loss_seg: 1.5626, decode.acc_seg: 43.6533, loss: 1.5626
2021-08-14 01:51:45,123 - mmseg - INFO - Iter [8200/160000]	lr: 9.542e-03, eta: 2 days, 7:44:16, time: 1.243, data_time: 0.013, memory: 5723, decode.loss_seg: 1.5286, decode.acc_seg: 43.0891, loss: 1.5286
2021-08-14 01:53:22,219 - mmseg - INFO - Iter [8250/160000]	lr: 9.539e-03, eta: 2 days, 7:52:40, time: 1.942, data_time: 0.661, memory: 5723, decode.loss_seg: 1.4876, decode.acc_seg: 44.4009, loss: 1.4876
2021-08-14 01:54:24,008 - mmseg - INFO - Iter [8300/160000]	lr: 9.537e-03, eta: 2 days, 7:50:12, time: 1.236, data_time: 0.013, memory: 5723, decode.loss_seg: 1.5574, decode.acc_seg: 43.5039, loss: 1.5574
2021-08-14 01:55:25,566 - mmseg - INFO - Iter [8350/160000]	lr: 9.534e-03, eta: 2 days, 7:47:40, time: 1.231, data_time: 0.012, memory: 5723, decode.loss_seg: 1.5362, decode.acc_seg: 44.3091, loss: 1.5362
2021-08-14 01:56:26,195 - mmseg - INFO - Iter [8400/160000]	lr: 9.531e-03, eta: 2 days, 7:44:53, time: 1.213, data_time: 0.014, memory: 5723, decode.loss_seg: 1.5111, decode.acc_seg: 43.8664, loss: 1.5111
2021-08-14 01:57:29,685 - mmseg - INFO - Iter [8450/160000]	lr: 9.528e-03, eta: 2 days, 7:42:59, time: 1.270, data_time: 0.014, memory: 5723, decode.loss_seg: 1.5253, decode.acc_seg: 43.2826, loss: 1.5253
2021-08-14 01:58:31,842 - mmseg - INFO - Iter [8500/160000]	lr: 9.525e-03, eta: 2 days, 7:40:40, time: 1.243, data_time: 0.014, memory: 5723, decode.loss_seg: 1.5341, decode.acc_seg: 43.2502, loss: 1.5341
2021-08-14 01:59:36,091 - mmseg - INFO - Iter [8550/160000]	lr: 9.523e-03, eta: 2 days, 7:39:00, time: 1.285, data_time: 0.013, memory: 5723, decode.loss_seg: 1.5445, decode.acc_seg: 43.2082, loss: 1.5445
2021-08-14 02:00:41,911 - mmseg - INFO - Iter [8600/160000]	lr: 9.520e-03, eta: 2 days, 7:37:49, time: 1.317, data_time: 0.013, memory: 5723, decode.loss_seg: 1.5044, decode.acc_seg: 44.1252, loss: 1.5044
2021-08-14 02:01:46,799 - mmseg - INFO - Iter [8650/160000]	lr: 9.517e-03, eta: 2 days, 7:36:20, time: 1.296, data_time: 0.013, memory: 5723, decode.loss_seg: 1.5310, decode.acc_seg: 44.1810, loss: 1.5310
2021-08-14 02:02:52,495 - mmseg - INFO - Iter [8700/160000]	lr: 9.514e-03, eta: 2 days, 7:35:06, time: 1.314, data_time: 0.014, memory: 5723, decode.loss_seg: 1.5237, decode.acc_seg: 44.1140, loss: 1.5237
2021-08-14 02:04:00,289 - mmseg - INFO - Iter [8750/160000]	lr: 9.511e-03, eta: 2 days, 7:34:29, time: 1.356, data_time: 0.014, memory: 5723, decode.loss_seg: 1.5036, decode.acc_seg: 43.9662, loss: 1.5036
2021-08-14 02:05:08,249 - mmseg - INFO - Iter [8800/160000]	lr: 9.509e-03, eta: 2 days, 7:33:54, time: 1.359, data_time: 0.014, memory: 5723, decode.loss_seg: 1.5060, decode.acc_seg: 43.5711, loss: 1.5060
2021-08-14 02:06:47,760 - mmseg - INFO - Iter [8850/160000]	lr: 9.506e-03, eta: 2 days, 7:42:18, time: 1.991, data_time: 0.746, memory: 5723, decode.loss_seg: 1.5420, decode.acc_seg: 43.4369, loss: 1.5420
2021-08-14 02:07:52,214 - mmseg - INFO - Iter [8900/160000]	lr: 9.503e-03, eta: 2 days, 7:40:40, time: 1.289, data_time: 0.015, memory: 5723, decode.loss_seg: 1.4741, decode.acc_seg: 44.5127, loss: 1.4741
2021-08-14 02:08:56,372 - mmseg - INFO - Iter [8950/160000]	lr: 9.500e-03, eta: 2 days, 7:38:58, time: 1.284, data_time: 0.014, memory: 5723, decode.loss_seg: 1.4898, decode.acc_seg: 44.3729, loss: 1.4898
2021-08-14 02:10:01,446 - mmseg - INFO - Exp name: fcn_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 02:10:01,447 - mmseg - INFO - Iter [9000/160000]	lr: 9.497e-03, eta: 2 days, 7:37:30, time: 1.301, data_time: 0.015, memory: 5723, decode.loss_seg: 1.5172, decode.acc_seg: 43.8425, loss: 1.5172
2021-08-14 02:11:04,117 - mmseg - INFO - Iter [9050/160000]	lr: 9.495e-03, eta: 2 days, 7:35:23, time: 1.253, data_time: 0.014, memory: 5723, decode.loss_seg: 1.4891, decode.acc_seg: 44.4687, loss: 1.4891
2021-08-14 02:12:06,923 - mmseg - INFO - Iter [9100/160000]	lr: 9.492e-03, eta: 2 days, 7:33:19, time: 1.257, data_time: 0.015, memory: 5723, decode.loss_seg: 1.4769, decode.acc_seg: 44.2719, loss: 1.4769
2021-08-14 02:13:10,980 - mmseg - INFO - Iter [9150/160000]	lr: 9.489e-03, eta: 2 days, 7:31:37, time: 1.281, data_time: 0.015, memory: 5723, decode.loss_seg: 1.5154, decode.acc_seg: 44.6706, loss: 1.5154
2021-08-14 02:14:16,462 - mmseg - INFO - Iter [9200/160000]	lr: 9.486e-03, eta: 2 days, 7:30:17, time: 1.309, data_time: 0.015, memory: 5723, decode.loss_seg: 1.5213, decode.acc_seg: 43.5961, loss: 1.5213
2021-08-14 02:15:22,199 - mmseg - INFO - Iter [9250/160000]	lr: 9.483e-03, eta: 2 days, 7:29:02, time: 1.314, data_time: 0.013, memory: 5723, decode.loss_seg: 1.4397, decode.acc_seg: 44.1404, loss: 1.4397
2021-08-14 02:16:27,827 - mmseg - INFO - Iter [9300/160000]	lr: 9.481e-03, eta: 2 days, 7:27:46, time: 1.313, data_time: 0.014, memory: 5723, decode.loss_seg: 1.5029, decode.acc_seg: 43.9779, loss: 1.5029
2021-08-14 02:17:29,855 - mmseg - INFO - Iter [9350/160000]	lr: 9.478e-03, eta: 2 days, 7:25:32, time: 1.240, data_time: 0.014, memory: 5723, decode.loss_seg: 1.5568, decode.acc_seg: 43.7946, loss: 1.5568
2021-08-14 02:18:32,328 - mmseg - INFO - Iter [9400/160000]	lr: 9.475e-03, eta: 2 days, 7:23:26, time: 1.251, data_time: 0.016, memory: 5723, decode.loss_seg: 1.5036, decode.acc_seg: 43.8082, loss: 1.5036
2021-08-14 02:19:36,079 - mmseg - INFO - Iter [9450/160000]	lr: 9.472e-03, eta: 2 days, 7:21:41, time: 1.275, data_time: 0.013, memory: 5723, decode.loss_seg: 1.5194, decode.acc_seg: 43.2263, loss: 1.5194
2021-08-14 02:21:13,842 - mmseg - INFO - Iter [9500/160000]	lr: 9.469e-03, eta: 2 days, 7:28:55, time: 1.955, data_time: 0.722, memory: 5723, decode.loss_seg: 1.4479, decode.acc_seg: 45.9540, loss: 1.4479
2021-08-14 02:22:21,841 - mmseg - INFO - Iter [9550/160000]	lr: 9.467e-03, eta: 2 days, 7:28:13, time: 1.359, data_time: 0.013, memory: 5723, decode.loss_seg: 1.4745, decode.acc_seg: 44.0822, loss: 1.4745
2021-08-14 02:23:27,928 - mmseg - INFO - Iter [9600/160000]	lr: 9.464e-03, eta: 2 days, 7:27:03, time: 1.322, data_time: 0.015, memory: 5723, decode.loss_seg: 1.5098, decode.acc_seg: 44.2919, loss: 1.5098
2021-08-14 02:24:32,499 - mmseg - INFO - Iter [9650/160000]	lr: 9.461e-03, eta: 2 days, 7:25:29, time: 1.292, data_time: 0.015, memory: 5723, decode.loss_seg: 1.5267, decode.acc_seg: 44.0063, loss: 1.5267
2021-08-14 02:25:35,646 - mmseg - INFO - Iter [9700/160000]	lr: 9.458e-03, eta: 2 days, 7:23:32, time: 1.263, data_time: 0.014, memory: 5723, decode.loss_seg: 1.4880, decode.acc_seg: 43.8890, loss: 1.4880
2021-08-14 02:26:41,101 - mmseg - INFO - Iter [9750/160000]	lr: 9.455e-03, eta: 2 days, 7:22:13, time: 1.310, data_time: 0.014, memory: 5723, decode.loss_seg: 1.4420, decode.acc_seg: 46.3530, loss: 1.4420
2021-08-14 02:27:47,765 - mmseg - INFO - Iter [9800/160000]	lr: 9.453e-03, eta: 2 days, 7:21:11, time: 1.332, data_time: 0.014, memory: 5723, decode.loss_seg: 1.4886, decode.acc_seg: 44.1572, loss: 1.4886
2021-08-14 02:28:48,747 - mmseg - INFO - Iter [9850/160000]	lr: 9.450e-03, eta: 2 days, 7:18:44, time: 1.221, data_time: 0.015, memory: 5723, decode.loss_seg: 1.4584, decode.acc_seg: 45.1140, loss: 1.4584
2021-08-14 02:29:50,866 - mmseg - INFO - Iter [9900/160000]	lr: 9.447e-03, eta: 2 days, 7:16:33, time: 1.242, data_time: 0.013, memory: 5723, decode.loss_seg: 1.4880, decode.acc_seg: 45.5758, loss: 1.4880
2021-08-14 02:30:58,725 - mmseg - INFO - Iter [9950/160000]	lr: 9.444e-03, eta: 2 days, 7:15:51, time: 1.357, data_time: 0.014, memory: 5723, decode.loss_seg: 1.4597, decode.acc_seg: 43.6903, loss: 1.4597
2021-08-14 02:32:06,046 - mmseg - INFO - Exp name: fcn_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 02:32:06,047 - mmseg - INFO - Iter [10000/160000]	lr: 9.441e-03, eta: 2 days, 7:15:01, time: 1.348, data_time: 0.016, memory: 5723, decode.loss_seg: 1.5029, decode.acc_seg: 44.6040, loss: 1.5029
2021-08-14 02:33:09,559 - mmseg - INFO - Iter [10050/160000]	lr: 9.439e-03, eta: 2 days, 7:13:13, time: 1.270, data_time: 0.014, memory: 5723, decode.loss_seg: 1.4595, decode.acc_seg: 45.3145, loss: 1.4595
2021-08-14 02:34:47,454 - mmseg - INFO - Iter [10100/160000]	lr: 9.436e-03, eta: 2 days, 7:19:55, time: 1.958, data_time: 0.691, memory: 5723, decode.loss_seg: 1.5081, decode.acc_seg: 43.9854, loss: 1.5081
2021-08-14 02:35:49,051 - mmseg - INFO - Iter [10150/160000]	lr: 9.433e-03, eta: 2 days, 7:17:38, time: 1.232, data_time: 0.015, memory: 5723, decode.loss_seg: 1.4403, decode.acc_seg: 45.2779, loss: 1.4403
2021-08-14 02:36:51,550 - mmseg - INFO - Iter [10200/160000]	lr: 9.430e-03, eta: 2 days, 7:15:34, time: 1.250, data_time: 0.015, memory: 5723, decode.loss_seg: 1.4265, decode.acc_seg: 46.5602, loss: 1.4265
2021-08-14 02:37:54,049 - mmseg - INFO - Iter [10250/160000]	lr: 9.427e-03, eta: 2 days, 7:13:30, time: 1.250, data_time: 0.014, memory: 5723, decode.loss_seg: 1.4736, decode.acc_seg: 45.0365, loss: 1.4736
2021-08-14 02:38:55,778 - mmseg - INFO - Iter [10300/160000]	lr: 9.425e-03, eta: 2 days, 7:11:16, time: 1.234, data_time: 0.014, memory: 5723, decode.loss_seg: 1.4602, decode.acc_seg: 45.1154, loss: 1.4602
2021-08-14 02:39:58,625 - mmseg - INFO - Iter [10350/160000]	lr: 9.422e-03, eta: 2 days, 7:09:19, time: 1.257, data_time: 0.014, memory: 5723, decode.loss_seg: 1.4824, decode.acc_seg: 44.7537, loss: 1.4824
2021-08-14 02:41:01,714 - mmseg - INFO - Iter [10400/160000]	lr: 9.419e-03, eta: 2 days, 7:07:26, time: 1.262, data_time: 0.015, memory: 5723, decode.loss_seg: 1.4683, decode.acc_seg: 44.9563, loss: 1.4683
2021-08-14 02:42:05,187 - mmseg - INFO - Iter [10450/160000]	lr: 9.416e-03, eta: 2 days, 7:05:38, time: 1.269, data_time: 0.014, memory: 5723, decode.loss_seg: 1.4949, decode.acc_seg: 44.3118, loss: 1.4949
2021-08-14 02:43:06,292 - mmseg - INFO - Iter [10500/160000]	lr: 9.413e-03, eta: 2 days, 7:03:18, time: 1.223, data_time: 0.013, memory: 5723, decode.loss_seg: 1.4563, decode.acc_seg: 44.6103, loss: 1.4563
2021-08-14 02:44:10,489 - mmseg - INFO - Iter [10550/160000]	lr: 9.411e-03, eta: 2 days, 7:01:42, time: 1.283, data_time: 0.016, memory: 5723, decode.loss_seg: 1.4672, decode.acc_seg: 44.6014, loss: 1.4672
2021-08-14 02:45:15,507 - mmseg - INFO - Iter [10600/160000]	lr: 9.408e-03, eta: 2 days, 7:00:18, time: 1.301, data_time: 0.014, memory: 5723, decode.loss_seg: 1.4535, decode.acc_seg: 45.9265, loss: 1.4535
2021-08-14 02:46:18,844 - mmseg - INFO - Iter [10650/160000]	lr: 9.405e-03, eta: 2 days, 6:58:31, time: 1.267, data_time: 0.014, memory: 5723, decode.loss_seg: 1.4288, decode.acc_seg: 45.0556, loss: 1.4288
2021-08-14 02:47:23,593 - mmseg - INFO - Iter [10700/160000]	lr: 9.402e-03, eta: 2 days, 6:57:03, time: 1.294, data_time: 0.014, memory: 5723, decode.loss_seg: 1.5022, decode.acc_seg: 44.3757, loss: 1.5022
2021-08-14 02:49:03,613 - mmseg - INFO - Iter [10750/160000]	lr: 9.399e-03, eta: 2 days, 7:03:46, time: 2.001, data_time: 0.700, memory: 5723, decode.loss_seg: 1.4527, decode.acc_seg: 44.5662, loss: 1.4527
2021-08-14 02:50:06,306 - mmseg - INFO - Iter [10800/160000]	lr: 9.397e-03, eta: 2 days, 7:01:48, time: 1.253, data_time: 0.014, memory: 5723, decode.loss_seg: 1.4235, decode.acc_seg: 45.0940, loss: 1.4235
2021-08-14 02:51:07,731 - mmseg - INFO - Iter [10850/160000]	lr: 9.394e-03, eta: 2 days, 6:59:34, time: 1.229, data_time: 0.015, memory: 5723, decode.loss_seg: 1.4672, decode.acc_seg: 45.2105, loss: 1.4672
2021-08-14 02:52:09,865 - mmseg - INFO - Iter [10900/160000]	lr: 9.391e-03, eta: 2 days, 6:57:30, time: 1.243, data_time: 0.015, memory: 5723, decode.loss_seg: 1.4667, decode.acc_seg: 45.3787, loss: 1.4667
2021-08-14 02:53:14,321 - mmseg - INFO - Iter [10950/160000]	lr: 9.388e-03, eta: 2 days, 6:55:57, time: 1.288, data_time: 0.012, memory: 5723, decode.loss_seg: 1.4221, decode.acc_seg: 44.6807, loss: 1.4221
2021-08-14 02:54:17,863 - mmseg - INFO - Exp name: fcn_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 02:54:17,864 - mmseg - INFO - Iter [11000/160000]	lr: 9.385e-03, eta: 2 days, 6:54:13, time: 1.271, data_time: 0.013, memory: 5723, decode.loss_seg: 1.4839, decode.acc_seg: 45.1554, loss: 1.4839
2021-08-14 02:55:23,868 - mmseg - INFO - Iter [11050/160000]	lr: 9.383e-03, eta: 2 days, 6:53:02, time: 1.319, data_time: 0.013, memory: 5723, decode.loss_seg: 1.4620, decode.acc_seg: 45.0282, loss: 1.4620
2021-08-14 02:56:28,534 - mmseg - INFO - Iter [11100/160000]	lr: 9.380e-03, eta: 2 days, 6:51:34, time: 1.294, data_time: 0.014, memory: 5723, decode.loss_seg: 1.4597, decode.acc_seg: 44.4611, loss: 1.4597
2021-08-14 02:57:32,780 - mmseg - INFO - Iter [11150/160000]	lr: 9.377e-03, eta: 2 days, 6:50:00, time: 1.285, data_time: 0.013, memory: 5723, decode.loss_seg: 1.4763, decode.acc_seg: 44.2136, loss: 1.4763
2021-08-14 02:58:35,395 - mmseg - INFO - Iter [11200/160000]	lr: 9.374e-03, eta: 2 days, 6:48:04, time: 1.251, data_time: 0.013, memory: 5723, decode.loss_seg: 1.4351, decode.acc_seg: 45.8477, loss: 1.4351
2021-08-14 02:59:40,127 - mmseg - INFO - Iter [11250/160000]	lr: 9.371e-03, eta: 2 days, 6:46:38, time: 1.295, data_time: 0.015, memory: 5723, decode.loss_seg: 1.4581, decode.acc_seg: 44.4266, loss: 1.4581
2021-08-14 03:00:45,206 - mmseg - INFO - Iter [11300/160000]	lr: 9.369e-03, eta: 2 days, 6:45:15, time: 1.302, data_time: 0.016, memory: 5723, decode.loss_seg: 1.4884, decode.acc_seg: 44.7629, loss: 1.4884
2021-08-14 03:01:50,243 - mmseg - INFO - Iter [11350/160000]	lr: 9.366e-03, eta: 2 days, 6:43:53, time: 1.301, data_time: 0.015, memory: 5723, decode.loss_seg: 1.4109, decode.acc_seg: 46.7626, loss: 1.4109
2021-08-14 03:03:30,135 - mmseg - INFO - Iter [11400/160000]	lr: 9.363e-03, eta: 2 days, 6:50:04, time: 1.997, data_time: 0.703, memory: 5723, decode.loss_seg: 1.4171, decode.acc_seg: 45.4082, loss: 1.4171
2021-08-14 03:04:32,352 - mmseg - INFO - Iter [11450/160000]	lr: 9.360e-03, eta: 2 days, 6:48:03, time: 1.244, data_time: 0.014, memory: 5723, decode.loss_seg: 1.4723, decode.acc_seg: 45.6775, loss: 1.4723
2021-08-14 03:05:33,903 - mmseg - INFO - Iter [11500/160000]	lr: 9.357e-03, eta: 2 days, 6:45:55, time: 1.232, data_time: 0.014, memory: 5723, decode.loss_seg: 1.4577, decode.acc_seg: 44.9224, loss: 1.4577
2021-08-14 03:06:38,337 - mmseg - INFO - Iter [11550/160000]	lr: 9.354e-03, eta: 2 days, 6:44:23, time: 1.288, data_time: 0.013, memory: 5723, decode.loss_seg: 1.4491, decode.acc_seg: 46.1179, loss: 1.4491
2021-08-14 03:07:43,732 - mmseg - INFO - Iter [11600/160000]	lr: 9.352e-03, eta: 2 days, 6:43:04, time: 1.308, data_time: 0.014, memory: 5723, decode.loss_seg: 1.4249, decode.acc_seg: 45.6025, loss: 1.4249
2021-08-14 03:08:49,548 - mmseg - INFO - Iter [11650/160000]	lr: 9.349e-03, eta: 2 days, 6:41:50, time: 1.316, data_time: 0.014, memory: 5723, decode.loss_seg: 1.4377, decode.acc_seg: 45.6634, loss: 1.4377
2021-08-14 03:09:57,570 - mmseg - INFO - Iter [11700/160000]	lr: 9.346e-03, eta: 2 days, 6:41:05, time: 1.360, data_time: 0.014, memory: 5723, decode.loss_seg: 1.4221, decode.acc_seg: 46.2482, loss: 1.4221
2021-08-14 03:11:00,414 - mmseg - INFO - Iter [11750/160000]	lr: 9.343e-03, eta: 2 days, 6:39:15, time: 1.258, data_time: 0.015, memory: 5723, decode.loss_seg: 1.4092, decode.acc_seg: 46.0676, loss: 1.4092
2021-08-14 03:12:02,560 - mmseg - INFO - Iter [11800/160000]	lr: 9.340e-03, eta: 2 days, 6:37:15, time: 1.242, data_time: 0.014, memory: 5723, decode.loss_seg: 1.4523, decode.acc_seg: 45.2999, loss: 1.4523
2021-08-14 03:13:05,028 - mmseg - INFO - Iter [11850/160000]	lr: 9.338e-03, eta: 2 days, 6:35:21, time: 1.250, data_time: 0.015, memory: 5723, decode.loss_seg: 1.4728, decode.acc_seg: 44.1767, loss: 1.4728
2021-08-14 03:14:08,135 - mmseg - INFO - Iter [11900/160000]	lr: 9.335e-03, eta: 2 days, 6:33:34, time: 1.262, data_time: 0.015, memory: 5723, decode.loss_seg: 1.4114, decode.acc_seg: 45.0257, loss: 1.4114
2021-08-14 03:15:09,110 - mmseg - INFO - Iter [11950/160000]	lr: 9.332e-03, eta: 2 days, 6:31:22, time: 1.219, data_time: 0.013, memory: 5723, decode.loss_seg: 1.4435, decode.acc_seg: 46.2306, loss: 1.4435
2021-08-14 03:16:46,465 - mmseg - INFO - Exp name: fcn_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 03:16:46,470 - mmseg - INFO - Iter [12000/160000]	lr: 9.329e-03, eta: 2 days, 6:36:38, time: 1.947, data_time: 0.693, memory: 5723, decode.loss_seg: 1.4459, decode.acc_seg: 44.9641, loss: 1.4459
2021-08-14 03:17:48,531 - mmseg - INFO - Iter [12050/160000]	lr: 9.326e-03, eta: 2 days, 6:34:39, time: 1.242, data_time: 0.013, memory: 5723, decode.loss_seg: 1.4263, decode.acc_seg: 45.3787, loss: 1.4263
2021-08-14 03:18:51,560 - mmseg - INFO - Iter [12100/160000]	lr: 9.324e-03, eta: 2 days, 6:32:51, time: 1.261, data_time: 0.012, memory: 5723, decode.loss_seg: 1.4185, decode.acc_seg: 45.8845, loss: 1.4185
2021-08-14 03:19:54,740 - mmseg - INFO - Iter [12150/160000]	lr: 9.321e-03, eta: 2 days, 6:31:06, time: 1.264, data_time: 0.012, memory: 5723, decode.loss_seg: 1.4247, decode.acc_seg: 45.9952, loss: 1.4247
2021-08-14 03:20:57,964 - mmseg - INFO - Iter [12200/160000]	lr: 9.318e-03, eta: 2 days, 6:29:21, time: 1.264, data_time: 0.013, memory: 5723, decode.loss_seg: 1.4616, decode.acc_seg: 44.6870, loss: 1.4616
2021-08-14 03:22:00,556 - mmseg - INFO - Iter [12250/160000]	lr: 9.315e-03, eta: 2 days, 6:27:29, time: 1.251, data_time: 0.013, memory: 5723, decode.loss_seg: 1.4212, decode.acc_seg: 46.4652, loss: 1.4212
2021-08-14 03:23:07,003 - mmseg - INFO - Iter [12300/160000]	lr: 9.312e-03, eta: 2 days, 6:26:24, time: 1.329, data_time: 0.013, memory: 5723, decode.loss_seg: 1.4193, decode.acc_seg: 45.8542, loss: 1.4193
2021-08-14 03:24:08,853 - mmseg - INFO - Iter [12350/160000]	lr: 9.310e-03, eta: 2 days, 6:24:24, time: 1.237, data_time: 0.013, memory: 5723, decode.loss_seg: 1.4272, decode.acc_seg: 45.6679, loss: 1.4272
2021-08-14 03:25:12,900 - mmseg - INFO - Iter [12400/160000]	lr: 9.307e-03, eta: 2 days, 6:22:50, time: 1.280, data_time: 0.013, memory: 5723, decode.loss_seg: 1.3966, decode.acc_seg: 45.4624, loss: 1.3966
2021-08-14 03:26:17,224 - mmseg - INFO - Iter [12450/160000]	lr: 9.304e-03, eta: 2 days, 6:21:20, time: 1.287, data_time: 0.013, memory: 5723, decode.loss_seg: 1.4303, decode.acc_seg: 45.4113, loss: 1.4303
2021-08-14 03:27:19,366 - mmseg - INFO - Iter [12500/160000]	lr: 9.301e-03, eta: 2 days, 6:19:25, time: 1.243, data_time: 0.013, memory: 5723, decode.loss_seg: 1.4182, decode.acc_seg: 46.8890, loss: 1.4182
2021-08-14 03:28:21,330 - mmseg - INFO - Iter [12550/160000]	lr: 9.298e-03, eta: 2 days, 6:17:28, time: 1.239, data_time: 0.013, memory: 5723, decode.loss_seg: 1.4130, decode.acc_seg: 45.2769, loss: 1.4130
2021-08-14 03:29:23,015 - mmseg - INFO - Iter [12600/160000]	lr: 9.296e-03, eta: 2 days, 6:15:28, time: 1.234, data_time: 0.014, memory: 5723, decode.loss_seg: 1.4110, decode.acc_seg: 46.2623, loss: 1.4110
2021-08-14 03:31:00,111 - mmseg - INFO - Iter [12650/160000]	lr: 9.293e-03, eta: 2 days, 6:20:21, time: 1.942, data_time: 0.656, memory: 5723, decode.loss_seg: 1.3987, decode.acc_seg: 46.0217, loss: 1.3987
2021-08-14 03:32:04,413 - mmseg - INFO - Iter [12700/160000]	lr: 9.290e-03, eta: 2 days, 6:18:51, time: 1.286, data_time: 0.016, memory: 5723, decode.loss_seg: 1.3933, decode.acc_seg: 46.5093, loss: 1.3933
2021-08-14 03:33:08,531 - mmseg - INFO - Iter [12750/160000]	lr: 9.287e-03, eta: 2 days, 6:17:18, time: 1.281, data_time: 0.012, memory: 5723, decode.loss_seg: 1.3868, decode.acc_seg: 46.7660, loss: 1.3868
2021-08-14 03:34:11,466 - mmseg - INFO - Iter [12800/160000]	lr: 9.284e-03, eta: 2 days, 6:15:32, time: 1.260, data_time: 0.014, memory: 5723, decode.loss_seg: 1.4182, decode.acc_seg: 46.1559, loss: 1.4182
2021-08-14 03:35:14,322 - mmseg - INFO - Iter [12850/160000]	lr: 9.282e-03, eta: 2 days, 6:13:46, time: 1.257, data_time: 0.013, memory: 5723, decode.loss_seg: 1.3986, decode.acc_seg: 46.0658, loss: 1.3986
2021-08-14 03:36:16,735 - mmseg - INFO - Iter [12900/160000]	lr: 9.279e-03, eta: 2 days, 6:11:55, time: 1.248, data_time: 0.014, memory: 5723, decode.loss_seg: 1.4032, decode.acc_seg: 45.4261, loss: 1.4032
2021-08-14 03:37:19,577 - mmseg - INFO - Iter [12950/160000]	lr: 9.276e-03, eta: 2 days, 6:10:09, time: 1.256, data_time: 0.014, memory: 5723, decode.loss_seg: 1.4237, decode.acc_seg: 46.3414, loss: 1.4237
2021-08-14 03:38:23,870 - mmseg - INFO - Exp name: fcn_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 03:38:23,870 - mmseg - INFO - Iter [13000/160000]	lr: 9.273e-03, eta: 2 days, 6:08:40, time: 1.286, data_time: 0.013, memory: 5723, decode.loss_seg: 1.4279, decode.acc_seg: 46.5172, loss: 1.4279
2021-08-14 03:39:27,263 - mmseg - INFO - Iter [13050/160000]	lr: 9.270e-03, eta: 2 days, 6:07:01, time: 1.268, data_time: 0.014, memory: 5723, decode.loss_seg: 1.4077, decode.acc_seg: 46.3193, loss: 1.4077
2021-08-14 03:40:30,089 - mmseg - INFO - Iter [13100/160000]	lr: 9.267e-03, eta: 2 days, 6:05:16, time: 1.257, data_time: 0.013, memory: 5723, decode.loss_seg: 1.3595, decode.acc_seg: 45.2634, loss: 1.3595
2021-08-14 03:41:33,263 - mmseg - INFO - Iter [13150/160000]	lr: 9.265e-03, eta: 2 days, 6:03:35, time: 1.263, data_time: 0.012, memory: 5723, decode.loss_seg: 1.4421, decode.acc_seg: 44.9280, loss: 1.4421
2021-08-14 03:42:37,788 - mmseg - INFO - Iter [13200/160000]	lr: 9.262e-03, eta: 2 days, 6:02:09, time: 1.291, data_time: 0.016, memory: 5723, decode.loss_seg: 1.3955, decode.acc_seg: 46.2940, loss: 1.3955
2021-08-14 03:43:41,847 - mmseg - INFO - Iter [13250/160000]	lr: 9.259e-03, eta: 2 days, 6:00:39, time: 1.281, data_time: 0.015, memory: 5723, decode.loss_seg: 1.4110, decode.acc_seg: 45.3206, loss: 1.4110
2021-08-14 03:45:20,018 - mmseg - INFO - Iter [13300/160000]	lr: 9.256e-03, eta: 2 days, 6:05:24, time: 1.963, data_time: 0.725, memory: 5723, decode.loss_seg: 1.4016, decode.acc_seg: 45.9676, loss: 1.4016
2021-08-14 03:46:20,279 - mmseg - INFO - Iter [13350/160000]	lr: 9.253e-03, eta: 2 days, 6:03:11, time: 1.205, data_time: 0.013, memory: 5723, decode.loss_seg: 1.3784, decode.acc_seg: 46.2308, loss: 1.3784
2021-08-14 03:47:24,301 - mmseg - INFO - Iter [13400/160000]	lr: 9.251e-03, eta: 2 days, 6:01:39, time: 1.280, data_time: 0.013, memory: 5723, decode.loss_seg: 1.3652, decode.acc_seg: 47.0167, loss: 1.3652
2021-08-14 03:48:26,242 - mmseg - INFO - Iter [13450/160000]	lr: 9.248e-03, eta: 2 days, 5:59:45, time: 1.239, data_time: 0.014, memory: 5723, decode.loss_seg: 1.4306, decode.acc_seg: 45.7576, loss: 1.4306
2021-08-14 03:49:29,019 - mmseg - INFO - Iter [13500/160000]	lr: 9.245e-03, eta: 2 days, 5:58:00, time: 1.256, data_time: 0.015, memory: 5723, decode.loss_seg: 1.3997, decode.acc_seg: 45.9384, loss: 1.3997
2021-08-14 03:50:30,738 - mmseg - INFO - Iter [13550/160000]	lr: 9.242e-03, eta: 2 days, 5:56:04, time: 1.234, data_time: 0.013, memory: 5723, decode.loss_seg: 1.3666, decode.acc_seg: 46.0768, loss: 1.3666
2021-08-14 03:51:32,550 - mmseg - INFO - Iter [13600/160000]	lr: 9.239e-03, eta: 2 days, 5:54:10, time: 1.237, data_time: 0.014, memory: 5723, decode.loss_seg: 1.4286, decode.acc_seg: 46.8059, loss: 1.4286
2021-08-14 03:52:35,297 - mmseg - INFO - Iter [13650/160000]	lr: 9.237e-03, eta: 2 days, 5:52:25, time: 1.254, data_time: 0.012, memory: 5723, decode.loss_seg: 1.3823, decode.acc_seg: 46.8718, loss: 1.3823
2021-08-14 03:53:38,391 - mmseg - INFO - Iter [13700/160000]	lr: 9.234e-03, eta: 2 days, 5:50:45, time: 1.262, data_time: 0.014, memory: 5723, decode.loss_seg: 1.4171, decode.acc_seg: 45.9434, loss: 1.4171
2021-08-14 03:54:42,050 - mmseg - INFO - Iter [13750/160000]	lr: 9.231e-03, eta: 2 days, 5:49:11, time: 1.273, data_time: 0.013, memory: 5723, decode.loss_seg: 1.4042, decode.acc_seg: 46.2606, loss: 1.4042
2021-08-14 03:55:46,033 - mmseg - INFO - Iter [13800/160000]	lr: 9.228e-03, eta: 2 days, 5:47:41, time: 1.279, data_time: 0.013, memory: 5723, decode.loss_seg: 1.3758, decode.acc_seg: 46.7548, loss: 1.3758
2021-08-14 03:56:49,273 - mmseg - INFO - Iter [13850/160000]	lr: 9.225e-03, eta: 2 days, 5:46:04, time: 1.265, data_time: 0.013, memory: 5723, decode.loss_seg: 1.4151, decode.acc_seg: 46.0051, loss: 1.4151
2021-08-14 03:58:28,310 - mmseg - INFO - Iter [13900/160000]	lr: 9.223e-03, eta: 2 days, 5:50:43, time: 1.982, data_time: 0.723, memory: 5723, decode.loss_seg: 1.4133, decode.acc_seg: 45.9513, loss: 1.4133
2021-08-14 03:59:29,973 - mmseg - INFO - Iter [13950/160000]	lr: 9.220e-03, eta: 2 days, 5:48:47, time: 1.233, data_time: 0.013, memory: 5723, decode.loss_seg: 1.3890, decode.acc_seg: 45.5604, loss: 1.3890
2021-08-14 04:00:32,899 - mmseg - INFO - Exp name: fcn_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 04:00:32,900 - mmseg - INFO - Iter [14000/160000]	lr: 9.217e-03, eta: 2 days, 5:47:05, time: 1.258, data_time: 0.013, memory: 5723, decode.loss_seg: 1.4254, decode.acc_seg: 46.1664, loss: 1.4254
2021-08-14 04:01:35,053 - mmseg - INFO - Iter [14050/160000]	lr: 9.214e-03, eta: 2 days, 5:45:16, time: 1.242, data_time: 0.014, memory: 5723, decode.loss_seg: 1.3415, decode.acc_seg: 46.8615, loss: 1.3415
2021-08-14 04:02:37,355 - mmseg - INFO - Iter [14100/160000]	lr: 9.211e-03, eta: 2 days, 5:43:29, time: 1.247, data_time: 0.015, memory: 5723, decode.loss_seg: 1.3970, decode.acc_seg: 45.6430, loss: 1.3970
2021-08-14 04:03:38,852 - mmseg - INFO - Iter [14150/160000]	lr: 9.208e-03, eta: 2 days, 5:41:33, time: 1.230, data_time: 0.014, memory: 5723, decode.loss_seg: 1.3791, decode.acc_seg: 46.1004, loss: 1.3791
2021-08-14 04:04:41,000 - mmseg - INFO - Iter [14200/160000]	lr: 9.206e-03, eta: 2 days, 5:39:44, time: 1.243, data_time: 0.013, memory: 5723, decode.loss_seg: 1.3833, decode.acc_seg: 46.9650, loss: 1.3833
2021-08-14 04:05:43,198 - mmseg - INFO - Iter [14250/160000]	lr: 9.203e-03, eta: 2 days, 5:37:57, time: 1.244, data_time: 0.013, memory: 5723, decode.loss_seg: 1.3831, decode.acc_seg: 46.5552, loss: 1.3831
2021-08-14 04:06:44,220 - mmseg - INFO - Iter [14300/160000]	lr: 9.200e-03, eta: 2 days, 5:35:57, time: 1.220, data_time: 0.012, memory: 5723, decode.loss_seg: 1.3735, decode.acc_seg: 45.7559, loss: 1.3735
2021-08-14 04:07:47,382 - mmseg - INFO - Iter [14350/160000]	lr: 9.197e-03, eta: 2 days, 5:34:20, time: 1.262, data_time: 0.015, memory: 5723, decode.loss_seg: 1.3654, decode.acc_seg: 47.0598, loss: 1.3654
2021-08-14 04:08:50,136 - mmseg - INFO - Iter [14400/160000]	lr: 9.194e-03, eta: 2 days, 5:32:39, time: 1.256, data_time: 0.015, memory: 5723, decode.loss_seg: 1.3921, decode.acc_seg: 47.0178, loss: 1.3921
2021-08-14 04:09:54,262 - mmseg - INFO - Iter [14450/160000]	lr: 9.192e-03, eta: 2 days, 5:31:11, time: 1.282, data_time: 0.014, memory: 5723, decode.loss_seg: 1.3683, decode.acc_seg: 46.8935, loss: 1.3683
2021-08-14 04:10:58,148 - mmseg - INFO - Iter [14500/160000]	lr: 9.189e-03, eta: 2 days, 5:29:42, time: 1.278, data_time: 0.013, memory: 5723, decode.loss_seg: 1.3316, decode.acc_seg: 48.5756, loss: 1.3316
2021-08-14 04:12:36,443 - mmseg - INFO - Iter [14550/160000]	lr: 9.186e-03, eta: 2 days, 5:33:57, time: 1.966, data_time: 0.730, memory: 5723, decode.loss_seg: 1.4016, decode.acc_seg: 45.3496, loss: 1.4016
2021-08-14 04:13:37,844 - mmseg - INFO - Iter [14600/160000]	lr: 9.183e-03, eta: 2 days, 5:32:03, time: 1.228, data_time: 0.014, memory: 5723, decode.loss_seg: 1.3811, decode.acc_seg: 46.5458, loss: 1.3811
2021-08-14 04:14:42,184 - mmseg - INFO - Iter [14650/160000]	lr: 9.180e-03, eta: 2 days, 5:30:37, time: 1.287, data_time: 0.016, memory: 5723, decode.loss_seg: 1.3732, decode.acc_seg: 46.6356, loss: 1.3732
2021-08-14 04:15:43,328 - mmseg - INFO - Iter [14700/160000]	lr: 9.178e-03, eta: 2 days, 5:28:40, time: 1.222, data_time: 0.013, memory: 5723, decode.loss_seg: 1.3549, decode.acc_seg: 46.4579, loss: 1.3549
2021-08-14 04:16:44,306 - mmseg - INFO - Iter [14750/160000]	lr: 9.175e-03, eta: 2 days, 5:26:41, time: 1.219, data_time: 0.013, memory: 5723, decode.loss_seg: 1.3530, decode.acc_seg: 46.8327, loss: 1.3530
2021-08-14 04:17:45,666 - mmseg - INFO - Iter [14800/160000]	lr: 9.172e-03, eta: 2 days, 5:24:48, time: 1.228, data_time: 0.013, memory: 5723, decode.loss_seg: 1.3909, decode.acc_seg: 47.3071, loss: 1.3909
2021-08-14 04:18:45,033 - mmseg - INFO - Iter [14850/160000]	lr: 9.169e-03, eta: 2 days, 5:22:35, time: 1.187, data_time: 0.013, memory: 5723, decode.loss_seg: 1.3565, decode.acc_seg: 47.5030, loss: 1.3565
2021-08-14 04:19:46,049 - mmseg - INFO - Iter [14900/160000]	lr: 9.166e-03, eta: 2 days, 5:20:38, time: 1.221, data_time: 0.015, memory: 5723, decode.loss_seg: 1.3753, decode.acc_seg: 46.4856, loss: 1.3753
2021-08-14 04:20:48,146 - mmseg - INFO - Iter [14950/160000]	lr: 9.163e-03, eta: 2 days, 5:18:52, time: 1.241, data_time: 0.015, memory: 5723, decode.loss_seg: 1.3649, decode.acc_seg: 46.8192, loss: 1.3649
2021-08-14 04:21:47,758 - mmseg - INFO - Exp name: fcn_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 04:21:47,759 - mmseg - INFO - Iter [15000/160000]	lr: 9.161e-03, eta: 2 days, 5:16:43, time: 1.193, data_time: 0.013, memory: 5723, decode.loss_seg: 1.3876, decode.acc_seg: 46.4375, loss: 1.3876
2021-08-14 04:22:48,410 - mmseg - INFO - Iter [15050/160000]	lr: 9.158e-03, eta: 2 days, 5:14:44, time: 1.212, data_time: 0.014, memory: 5723, decode.loss_seg: 1.3221, decode.acc_seg: 47.5590, loss: 1.3221
2021-08-14 04:23:49,508 - mmseg - INFO - Iter [15100/160000]	lr: 9.155e-03, eta: 2 days, 5:12:49, time: 1.222, data_time: 0.014, memory: 5723, decode.loss_seg: 1.3591, decode.acc_seg: 46.8793, loss: 1.3591
2021-08-14 04:25:28,258 - mmseg - INFO - Iter [15150/160000]	lr: 9.152e-03, eta: 2 days, 5:16:55, time: 1.975, data_time: 0.723, memory: 5723, decode.loss_seg: 1.3331, decode.acc_seg: 47.8457, loss: 1.3331
2021-08-14 04:26:30,275 - mmseg - INFO - Iter [15200/160000]	lr: 9.149e-03, eta: 2 days, 5:15:10, time: 1.241, data_time: 0.013, memory: 5723, decode.loss_seg: 1.3554, decode.acc_seg: 46.2353, loss: 1.3554
2021-08-14 04:27:36,463 - mmseg - INFO - Iter [15250/160000]	lr: 9.147e-03, eta: 2 days, 5:14:03, time: 1.324, data_time: 0.014, memory: 5723, decode.loss_seg: 1.3789, decode.acc_seg: 46.5523, loss: 1.3789
2021-08-14 04:28:43,243 - mmseg - INFO - Iter [15300/160000]	lr: 9.144e-03, eta: 2 days, 5:13:03, time: 1.336, data_time: 0.015, memory: 5723, decode.loss_seg: 1.3781, decode.acc_seg: 47.9915, loss: 1.3781
2021-08-14 04:29:45,616 - mmseg - INFO - Iter [15350/160000]	lr: 9.141e-03, eta: 2 days, 5:11:20, time: 1.247, data_time: 0.013, memory: 5723, decode.loss_seg: 1.3576, decode.acc_seg: 46.6436, loss: 1.3576
2021-08-14 04:30:49,206 - mmseg - INFO - Iter [15400/160000]	lr: 9.138e-03, eta: 2 days, 5:09:49, time: 1.272, data_time: 0.014, memory: 5723, decode.loss_seg: 1.3754, decode.acc_seg: 47.5520, loss: 1.3754
2021-08-14 04:31:52,986 - mmseg - INFO - Iter [15450/160000]	lr: 9.135e-03, eta: 2 days, 5:08:21, time: 1.276, data_time: 0.014, memory: 5723, decode.loss_seg: 1.3696, decode.acc_seg: 47.8461, loss: 1.3696
2021-08-14 04:32:55,828 - mmseg - INFO - Iter [15500/160000]	lr: 9.133e-03, eta: 2 days, 5:06:44, time: 1.257, data_time: 0.015, memory: 5723, decode.loss_seg: 1.3568, decode.acc_seg: 46.0673, loss: 1.3568
2021-08-14 04:33:59,385 - mmseg - INFO - Iter [15550/160000]	lr: 9.130e-03, eta: 2 days, 5:05:13, time: 1.271, data_time: 0.013, memory: 5723, decode.loss_seg: 1.3661, decode.acc_seg: 46.2383, loss: 1.3661
2021-08-14 04:35:00,641 - mmseg - INFO - Iter [15600/160000]	lr: 9.127e-03, eta: 2 days, 5:03:22, time: 1.226, data_time: 0.014, memory: 5723, decode.loss_seg: 1.3645, decode.acc_seg: 46.0605, loss: 1.3645
2021-08-14 04:36:07,216 - mmseg - INFO - Iter [15650/160000]	lr: 9.124e-03, eta: 2 days, 5:02:20, time: 1.331, data_time: 0.015, memory: 5723, decode.loss_seg: 1.3638, decode.acc_seg: 47.1558, loss: 1.3638
2021-08-14 04:37:09,952 - mmseg - INFO - Iter [15700/160000]	lr: 9.121e-03, eta: 2 days, 5:00:42, time: 1.255, data_time: 0.013, memory: 5723, decode.loss_seg: 1.3710, decode.acc_seg: 47.2559, loss: 1.3710
2021-08-14 04:38:13,559 - mmseg - INFO - Iter [15750/160000]	lr: 9.118e-03, eta: 2 days, 4:59:13, time: 1.272, data_time: 0.014, memory: 5723, decode.loss_seg: 1.3153, decode.acc_seg: 46.8459, loss: 1.3153
2021-08-14 04:39:50,891 - mmseg - INFO - Iter [15800/160000]	lr: 9.116e-03, eta: 2 days, 5:02:52, time: 1.946, data_time: 0.682, memory: 5723, decode.loss_seg: 1.3521, decode.acc_seg: 47.3868, loss: 1.3521
2021-08-14 04:40:55,185 - mmseg - INFO - Iter [15850/160000]	lr: 9.113e-03, eta: 2 days, 5:01:28, time: 1.285, data_time: 0.013, memory: 5723, decode.loss_seg: 1.3272, decode.acc_seg: 46.6333, loss: 1.3272
2021-08-14 04:41:57,885 - mmseg - INFO - Iter [15900/160000]	lr: 9.110e-03, eta: 2 days, 4:59:50, time: 1.254, data_time: 0.013, memory: 5723, decode.loss_seg: 1.3260, decode.acc_seg: 48.6622, loss: 1.3260
2021-08-14 04:42:59,267 - mmseg - INFO - Iter [15950/160000]	lr: 9.107e-03, eta: 2 days, 4:58:00, time: 1.228, data_time: 0.014, memory: 5723, decode.loss_seg: 1.3245, decode.acc_seg: 47.0209, loss: 1.3245
2021-08-14 04:44:00,620 - mmseg - INFO - Saving checkpoint at 16000 iterations
2021-08-14 04:44:00,976 - mmseg - INFO - Exp name: fcn_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 04:44:00,979 - mmseg - INFO - Iter [16000/160000]	lr: 9.104e-03, eta: 2 days, 4:56:14, time: 1.235, data_time: 0.013, memory: 5723, decode.loss_seg: 1.3858, decode.acc_seg: 46.9956, loss: 1.3858
2021-08-14 04:46:41,360 - mmseg - INFO - per class results:
2021-08-14 04:46:41,377 - mmseg - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        | 47.92 | 82.33 |
|       building      | 56.49 | 70.68 |
|         sky         |  84.9 |  94.7 |
|        floor        | 48.36 | 83.17 |
|         tree        | 54.35 | 72.13 |
|       ceiling       | 55.56 | 85.41 |
|         road        | 57.09 | 69.28 |
|         bed         | 50.91 | 72.76 |
|      windowpane     | 37.24 | 58.42 |
|        grass        | 50.42 | 79.44 |
|       cabinet       | 26.39 | 34.14 |
|       sidewalk      | 16.47 | 19.37 |
|        person       | 30.58 | 42.37 |
|        earth        | 13.45 | 20.36 |
|         door        |  4.29 |  4.57 |
|        table        | 13.49 | 18.17 |
|       mountain      | 27.86 | 45.43 |
|        plant        |  9.93 | 10.28 |
|       curtain       | 26.86 |  36.3 |
|        chair        | 12.71 | 17.78 |
|         car         | 44.29 | 67.94 |
|        water        |  7.78 | 11.57 |
|       painting      |  37.9 | 53.98 |
|         sofa        | 21.14 | 37.35 |
|        shelf        |  9.9  |  14.1 |
|        house        | 13.27 | 15.88 |
|         sea         | 11.26 | 75.42 |
|        mirror       |  3.38 |  3.75 |
|         rug         |  4.96 |  5.07 |
|        field        | 13.58 | 28.87 |
|       armchair      |  0.16 |  0.16 |
|         seat        |  8.53 | 11.26 |
|        fence        |  2.36 |  2.5  |
|         desk        |  0.32 |  0.33 |
|         rock        |  3.22 |  3.6  |
|       wardrobe      |  0.0  |  0.0  |
|         lamp        |  9.16 |  9.85 |
|       bathtub       |  7.42 |  8.07 |
|       railing       |  0.0  |  0.0  |
|       cushion       |  8.08 |  9.87 |
|         base        |  0.0  |  0.0  |
|         box         |  0.0  |  0.0  |
|        column       |  0.0  |  0.0  |
|      signboard      |  0.0  |  0.0  |
|   chest of drawers  |  1.72 |  1.76 |
|       counter       |  0.0  |  0.0  |
|         sand        |  5.21 |  7.89 |
|         sink        | 13.56 | 22.11 |
|      skyscraper     | 30.65 | 60.21 |
|      fireplace      | 20.57 | 28.01 |
|     refrigerator    |  0.07 |  0.07 |
|      grandstand     |  0.17 |  0.21 |
|         path        |  0.0  |  0.0  |
|        stairs       |  0.69 |  0.69 |
|        runway       | 25.32 |  37.4 |
|         case        |  2.44 |  2.68 |
|      pool table     | 17.06 | 60.07 |
|        pillow       | 12.03 | 13.28 |
|     screen door     |  0.0  |  0.0  |
|       stairway      |  2.72 |  3.4  |
|        river        |  2.49 |  3.07 |
|        bridge       |  0.0  |  0.0  |
|       bookcase      |  0.0  |  0.0  |
|        blind        |  0.0  |  0.0  |
|     coffee table    |  4.71 |  5.12 |
|        toilet       | 22.99 |  36.9 |
|        flower       |  1.78 |  1.85 |
|         book        |  0.22 |  0.22 |
|         hill        |  1.72 |  2.13 |
|        bench        |  0.0  |  0.0  |
|      countertop     |  0.13 |  0.13 |
|        stove        |  3.69 |  4.1  |
|         palm        |  0.0  |  0.0  |
|    kitchen island   |  0.0  |  0.0  |
|       computer      |  3.8  |  4.01 |
|     swivel chair    |  0.0  |  0.0  |
|         boat        |  0.0  |  0.0  |
|         bar         |  0.0  |  0.0  |
|    arcade machine   |  0.0  |  0.0  |
|        hovel        |  0.0  |  0.0  |
|         bus         |  0.0  |  0.0  |
|        towel        |  0.0  |  0.0  |
|        light        |  0.06 |  0.06 |
|        truck        |  0.0  |  0.0  |
|        tower        |  0.0  |  0.0  |
|      chandelier     | 15.89 | 17.29 |
|        awning       |  0.0  |  0.0  |
|     streetlight     |  0.0  |  0.0  |
|        booth        |  0.0  |  0.0  |
| television receiver |  1.39 |  1.39 |
|       airplane      |  0.46 |  0.5  |
|      dirt track     |  0.0  |  0.0  |
|       apparel       |  0.0  |  0.0  |
|         pole        |  0.0  |  0.0  |
|         land        |  0.0  |  0.0  |
|      bannister      |  0.0  |  0.0  |
|      escalator      |  0.0  |  0.0  |
|       ottoman       |  0.0  |  0.0  |
|        bottle       |  0.0  |  0.0  |
|        buffet       |  0.0  |  0.0  |
|        poster       |  0.0  |  0.0  |
|        stage        |  0.0  |  0.0  |
|         van         |  0.0  |  0.0  |
|         ship        |  0.0  |  0.0  |
|       fountain      |  0.0  |  0.0  |
|    conveyer belt    |  0.0  |  0.0  |
|        canopy       |  0.0  |  0.0  |
|        washer       |  0.0  |  0.0  |
|      plaything      |  0.0  |  0.0  |
|    swimming pool    |  0.6  |  0.63 |
|        stool        |  0.0  |  0.0  |
|        barrel       |  0.0  |  0.0  |
|        basket       |  0.0  |  0.0  |
|      waterfall      | 36.79 | 52.79 |
|         tent        |  0.0  |  0.0  |
|         bag         |  0.0  |  0.0  |
|       minibike      |  0.0  |  0.0  |
|        cradle       |  0.0  |  0.0  |
|         oven        |  0.0  |  0.0  |
|         ball        |  0.0  |  0.0  |
|         food        |  0.0  |  0.0  |
|         step        |  0.0  |  0.0  |
|         tank        |  0.0  |  0.0  |
|      trade name     |  0.0  |  0.0  |
|      microwave      |  0.0  |  0.0  |
|         pot         |  0.0  |  0.0  |
|        animal       |  0.0  |  0.0  |
|       bicycle       |  0.0  |  0.0  |
|         lake        |  0.0  |  0.0  |
|      dishwasher     |  0.0  |  0.0  |
|        screen       |  0.0  |  0.0  |
|       blanket       |  0.0  |  0.0  |
|      sculpture      |  0.0  |  0.0  |
|         hood        |  0.0  |  0.0  |
|        sconce       |  0.0  |  0.0  |
|         vase        |  0.0  |  0.0  |
|    traffic light    |  0.0  |  0.0  |
|         tray        |  0.0  |  0.0  |
|        ashcan       |  0.0  |  0.0  |
|         fan         |  0.0  |  0.0  |
|         pier        |  0.0  |  0.0  |
|      crt screen     |  0.0  |  0.0  |
|        plate        |  0.0  |  0.0  |
|       monitor       |  0.0  |  0.0  |
|    bulletin board   |  0.0  |  0.0  |
|        shower       |  0.0  |  0.0  |
|       radiator      |  0.0  |  0.0  |
|        glass        |  0.0  |  0.0  |
|        clock        |  0.0  |  0.0  |
|         flag        |  0.0  |  0.0  |
+---------------------+-------+-------+
2021-08-14 04:46:41,377 - mmseg - INFO - Summary:
2021-08-14 04:46:41,377 - mmseg - INFO - 
+-------+------+-------+
|  aAcc | mIoU |  mAcc |
+-------+------+-------+
| 58.59 | 7.74 | 11.63 |
+-------+------+-------+
2021-08-14 04:46:41,485 - mmseg - INFO - Exp name: fcn_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 04:46:41,486 - mmseg - INFO - Iter(val) [250]	aAcc: 0.5859, mIoU: 0.0774, mAcc: 0.1163, IoU.wall: 0.4792, IoU.building: 0.5649, IoU.sky: 0.8490, IoU.floor: 0.4836, IoU.tree: 0.5435, IoU.ceiling: 0.5556, IoU.road: 0.5709, IoU.bed : 0.5091, IoU.windowpane: 0.3724, IoU.grass: 0.5042, IoU.cabinet: 0.2639, IoU.sidewalk: 0.1647, IoU.person: 0.3058, IoU.earth: 0.1345, IoU.door: 0.0429, IoU.table: 0.1349, IoU.mountain: 0.2786, IoU.plant: 0.0993, IoU.curtain: 0.2686, IoU.chair: 0.1271, IoU.car: 0.4429, IoU.water: 0.0778, IoU.painting: 0.3790, IoU.sofa: 0.2114, IoU.shelf: 0.0990, IoU.house: 0.1327, IoU.sea: 0.1126, IoU.mirror: 0.0338, IoU.rug: 0.0496, IoU.field: 0.1358, IoU.armchair: 0.0016, IoU.seat: 0.0853, IoU.fence: 0.0236, IoU.desk: 0.0032, IoU.rock: 0.0322, IoU.wardrobe: 0.0000, IoU.lamp: 0.0916, IoU.bathtub: 0.0742, IoU.railing: 0.0000, IoU.cushion: 0.0808, IoU.base: 0.0000, IoU.box: 0.0000, IoU.column: 0.0000, IoU.signboard: 0.0000, IoU.chest of drawers: 0.0172, IoU.counter: 0.0000, IoU.sand: 0.0521, IoU.sink: 0.1356, IoU.skyscraper: 0.3065, IoU.fireplace: 0.2057, IoU.refrigerator: 0.0007, IoU.grandstand: 0.0017, IoU.path: 0.0000, IoU.stairs: 0.0069, IoU.runway: 0.2532, IoU.case: 0.0244, IoU.pool table: 0.1706, IoU.pillow: 0.1203, IoU.screen door: 0.0000, IoU.stairway: 0.0272, IoU.river: 0.0249, IoU.bridge: 0.0000, IoU.bookcase: 0.0000, IoU.blind: 0.0000, IoU.coffee table: 0.0471, IoU.toilet: 0.2299, IoU.flower: 0.0178, IoU.book: 0.0022, IoU.hill: 0.0172, IoU.bench: 0.0000, IoU.countertop: 0.0013, IoU.stove: 0.0369, IoU.palm: 0.0000, IoU.kitchen island: 0.0000, IoU.computer: 0.0380, IoU.swivel chair: 0.0000, IoU.boat: 0.0000, IoU.bar: 0.0000, IoU.arcade machine: 0.0000, IoU.hovel: 0.0000, IoU.bus: 0.0000, IoU.towel: 0.0000, IoU.light: 0.0006, IoU.truck: 0.0000, IoU.tower: 0.0000, IoU.chandelier: 0.1589, IoU.awning: 0.0000, IoU.streetlight: 0.0000, IoU.booth: 0.0000, IoU.television receiver: 0.0139, IoU.airplane: 0.0046, IoU.dirt track: 0.0000, IoU.apparel: 0.0000, IoU.pole: 0.0000, IoU.land: 0.0000, IoU.bannister: 0.0000, IoU.escalator: 0.0000, IoU.ottoman: 0.0000, IoU.bottle: 0.0000, IoU.buffet: 0.0000, IoU.poster: 0.0000, IoU.stage: 0.0000, IoU.van: 0.0000, IoU.ship: 0.0000, IoU.fountain: 0.0000, IoU.conveyer belt: 0.0000, IoU.canopy: 0.0000, IoU.washer: 0.0000, IoU.plaything: 0.0000, IoU.swimming pool: 0.0060, IoU.stool: 0.0000, IoU.barrel: 0.0000, IoU.basket: 0.0000, IoU.waterfall: 0.3679, IoU.tent: 0.0000, IoU.bag: 0.0000, IoU.minibike: 0.0000, IoU.cradle: 0.0000, IoU.oven: 0.0000, IoU.ball: 0.0000, IoU.food: 0.0000, IoU.step: 0.0000, IoU.tank: 0.0000, IoU.trade name: 0.0000, IoU.microwave: 0.0000, IoU.pot: 0.0000, IoU.animal: 0.0000, IoU.bicycle: 0.0000, IoU.lake: 0.0000, IoU.dishwasher: 0.0000, IoU.screen: 0.0000, IoU.blanket: 0.0000, IoU.sculpture: 0.0000, IoU.hood: 0.0000, IoU.sconce: 0.0000, IoU.vase: 0.0000, IoU.traffic light: 0.0000, IoU.tray: 0.0000, IoU.ashcan: 0.0000, IoU.fan: 0.0000, IoU.pier: 0.0000, IoU.crt screen: 0.0000, IoU.plate: 0.0000, IoU.monitor: 0.0000, IoU.bulletin board: 0.0000, IoU.shower: 0.0000, IoU.radiator: 0.0000, IoU.glass: 0.0000, IoU.clock: 0.0000, IoU.flag: 0.0000, Acc.wall: 0.8233, Acc.building: 0.7068, Acc.sky: 0.9470, Acc.floor: 0.8317, Acc.tree: 0.7213, Acc.ceiling: 0.8541, Acc.road: 0.6928, Acc.bed : 0.7276, Acc.windowpane: 0.5842, Acc.grass: 0.7944, Acc.cabinet: 0.3414, Acc.sidewalk: 0.1937, Acc.person: 0.4237, Acc.earth: 0.2036, Acc.door: 0.0457, Acc.table: 0.1817, Acc.mountain: 0.4543, Acc.plant: 0.1028, Acc.curtain: 0.3630, Acc.chair: 0.1778, Acc.car: 0.6794, Acc.water: 0.1157, Acc.painting: 0.5398, Acc.sofa: 0.3735, Acc.shelf: 0.1410, Acc.house: 0.1588, Acc.sea: 0.7542, Acc.mirror: 0.0375, Acc.rug: 0.0507, Acc.field: 0.2887, Acc.armchair: 0.0016, Acc.seat: 0.1126, Acc.fence: 0.0250, Acc.desk: 0.0033, Acc.rock: 0.0360, Acc.wardrobe: 0.0000, Acc.lamp: 0.0985, Acc.bathtub: 0.0807, Acc.railing: 0.0000, Acc.cushion: 0.0987, Acc.base: 0.0000, Acc.box: 0.0000, Acc.column: 0.0000, Acc.signboard: 0.0000, Acc.chest of drawers: 0.0176, Acc.counter: 0.0000, Acc.sand: 0.0789, Acc.sink: 0.2211, Acc.skyscraper: 0.6021, Acc.fireplace: 0.2801, Acc.refrigerator: 0.0007, Acc.grandstand: 0.0021, Acc.path: 0.0000, Acc.stairs: 0.0069, Acc.runway: 0.3740, Acc.case: 0.0268, Acc.pool table: 0.6007, Acc.pillow: 0.1328, Acc.screen door: 0.0000, Acc.stairway: 0.0340, Acc.river: 0.0307, Acc.bridge: 0.0000, Acc.bookcase: 0.0000, Acc.blind: 0.0000, Acc.coffee table: 0.0512, Acc.toilet: 0.3690, Acc.flower: 0.0185, Acc.book: 0.0022, Acc.hill: 0.0213, Acc.bench: 0.0000, Acc.countertop: 0.0013, Acc.stove: 0.0410, Acc.palm: 0.0000, Acc.kitchen island: 0.0000, Acc.computer: 0.0401, Acc.swivel chair: 0.0000, Acc.boat: 0.0000, Acc.bar: 0.0000, Acc.arcade machine: 0.0000, Acc.hovel: 0.0000, Acc.bus: 0.0000, Acc.towel: 0.0000, Acc.light: 0.0006, Acc.truck: 0.0000, Acc.tower: 0.0000, Acc.chandelier: 0.1729, Acc.awning: 0.0000, Acc.streetlight: 0.0000, Acc.booth: 0.0000, Acc.television receiver: 0.0139, Acc.airplane: 0.0050, Acc.dirt track: 0.0000, Acc.apparel: 0.0000, Acc.pole: 0.0000, Acc.land: 0.0000, Acc.bannister: 0.0000, Acc.escalator: 0.0000, Acc.ottoman: 0.0000, Acc.bottle: 0.0000, Acc.buffet: 0.0000, Acc.poster: 0.0000, Acc.stage: 0.0000, Acc.van: 0.0000, Acc.ship: 0.0000, Acc.fountain: 0.0000, Acc.conveyer belt: 0.0000, Acc.canopy: 0.0000, Acc.washer: 0.0000, Acc.plaything: 0.0000, Acc.swimming pool: 0.0063, Acc.stool: 0.0000, Acc.barrel: 0.0000, Acc.basket: 0.0000, Acc.waterfall: 0.5279, Acc.tent: 0.0000, Acc.bag: 0.0000, Acc.minibike: 0.0000, Acc.cradle: 0.0000, Acc.oven: 0.0000, Acc.ball: 0.0000, Acc.food: 0.0000, Acc.step: 0.0000, Acc.tank: 0.0000, Acc.trade name: 0.0000, Acc.microwave: 0.0000, Acc.pot: 0.0000, Acc.animal: 0.0000, Acc.bicycle: 0.0000, Acc.lake: 0.0000, Acc.dishwasher: 0.0000, Acc.screen: 0.0000, Acc.blanket: 0.0000, Acc.sculpture: 0.0000, Acc.hood: 0.0000, Acc.sconce: 0.0000, Acc.vase: 0.0000, Acc.traffic light: 0.0000, Acc.tray: 0.0000, Acc.ashcan: 0.0000, Acc.fan: 0.0000, Acc.pier: 0.0000, Acc.crt screen: 0.0000, Acc.plate: 0.0000, Acc.monitor: 0.0000, Acc.bulletin board: 0.0000, Acc.shower: 0.0000, Acc.radiator: 0.0000, Acc.glass: 0.0000, Acc.clock: 0.0000, Acc.flag: 0.0000
2021-08-14 04:47:46,754 - mmseg - INFO - Iter [16050/160000]	lr: 9.102e-03, eta: 2 days, 5:18:59, time: 4.515, data_time: 3.225, memory: 5723, decode.loss_seg: 1.3463, decode.acc_seg: 47.4905, loss: 1.3463
2021-08-14 04:48:48,616 - mmseg - INFO - Iter [16100/160000]	lr: 9.099e-03, eta: 2 days, 5:17:10, time: 1.238, data_time: 0.013, memory: 5723, decode.loss_seg: 1.3715, decode.acc_seg: 46.0894, loss: 1.3715
2021-08-14 04:49:54,058 - mmseg - INFO - Iter [16150/160000]	lr: 9.096e-03, eta: 2 days, 5:15:52, time: 1.309, data_time: 0.015, memory: 5723, decode.loss_seg: 1.3480, decode.acc_seg: 46.7486, loss: 1.3480
2021-08-14 04:50:57,026 - mmseg - INFO - Iter [16200/160000]	lr: 9.093e-03, eta: 2 days, 5:14:13, time: 1.259, data_time: 0.013, memory: 5723, decode.loss_seg: 1.3728, decode.acc_seg: 46.8251, loss: 1.3728
2021-08-14 04:51:59,455 - mmseg - INFO - Iter [16250/160000]	lr: 9.090e-03, eta: 2 days, 5:12:29, time: 1.248, data_time: 0.015, memory: 5723, decode.loss_seg: 1.3709, decode.acc_seg: 46.0791, loss: 1.3709
2021-08-14 04:53:05,805 - mmseg - INFO - Iter [16300/160000]	lr: 9.088e-03, eta: 2 days, 5:11:20, time: 1.328, data_time: 0.016, memory: 5723, decode.loss_seg: 1.3395, decode.acc_seg: 48.0448, loss: 1.3395
2021-08-14 04:54:12,732 - mmseg - INFO - Iter [16350/160000]	lr: 9.085e-03, eta: 2 days, 5:10:16, time: 1.339, data_time: 0.015, memory: 5723, decode.loss_seg: 1.3297, decode.acc_seg: 48.1560, loss: 1.3297
2021-08-14 04:55:14,809 - mmseg - INFO - Iter [16400/160000]	lr: 9.082e-03, eta: 2 days, 5:08:30, time: 1.242, data_time: 0.013, memory: 5723, decode.loss_seg: 1.3437, decode.acc_seg: 47.2987, loss: 1.3437
2021-08-14 04:56:55,698 - mmseg - INFO - Iter [16450/160000]	lr: 9.079e-03, eta: 2 days, 5:12:21, time: 2.017, data_time: 0.725, memory: 5723, decode.loss_seg: 1.3367, decode.acc_seg: 47.1267, loss: 1.3367
2021-08-14 04:57:58,429 - mmseg - INFO - Iter [16500/160000]	lr: 9.076e-03, eta: 2 days, 5:10:41, time: 1.256, data_time: 0.014, memory: 5723, decode.loss_seg: 1.3417, decode.acc_seg: 48.9434, loss: 1.3417
2021-08-14 04:58:59,983 - mmseg - INFO - Iter [16550/160000]	lr: 9.073e-03, eta: 2 days, 5:08:49, time: 1.231, data_time: 0.013, memory: 5723, decode.loss_seg: 1.3536, decode.acc_seg: 47.0379, loss: 1.3536
2021-08-14 05:00:05,700 - mmseg - INFO - Iter [16600/160000]	lr: 9.071e-03, eta: 2 days, 5:07:34, time: 1.315, data_time: 0.015, memory: 5723, decode.loss_seg: 1.3314, decode.acc_seg: 48.0979, loss: 1.3314
2021-08-14 05:01:10,851 - mmseg - INFO - Iter [16650/160000]	lr: 9.068e-03, eta: 2 days, 5:06:14, time: 1.302, data_time: 0.014, memory: 5723, decode.loss_seg: 1.3493, decode.acc_seg: 46.6460, loss: 1.3493
2021-08-14 05:02:14,209 - mmseg - INFO - Iter [16700/160000]	lr: 9.065e-03, eta: 2 days, 5:04:39, time: 1.268, data_time: 0.014, memory: 5723, decode.loss_seg: 1.3671, decode.acc_seg: 47.5368, loss: 1.3671
2021-08-14 05:03:14,697 - mmseg - INFO - Iter [16750/160000]	lr: 9.062e-03, eta: 2 days, 5:02:40, time: 1.210, data_time: 0.014, memory: 5723, decode.loss_seg: 1.3574, decode.acc_seg: 46.0808, loss: 1.3574
2021-08-14 05:04:21,062 - mmseg - INFO - Iter [16800/160000]	lr: 9.059e-03, eta: 2 days, 5:01:30, time: 1.326, data_time: 0.013, memory: 5723, decode.loss_seg: 1.3652, decode.acc_seg: 46.6577, loss: 1.3652
2021-08-14 05:05:26,225 - mmseg - INFO - Iter [16850/160000]	lr: 9.057e-03, eta: 2 days, 5:00:11, time: 1.304, data_time: 0.015, memory: 5723, decode.loss_seg: 1.3359, decode.acc_seg: 47.4858, loss: 1.3359
2021-08-14 05:06:32,904 - mmseg - INFO - Iter [16900/160000]	lr: 9.054e-03, eta: 2 days, 4:59:04, time: 1.332, data_time: 0.013, memory: 5723, decode.loss_seg: 1.3166, decode.acc_seg: 47.9269, loss: 1.3166
2021-08-14 05:07:40,762 - mmseg - INFO - Iter [16950/160000]	lr: 9.051e-03, eta: 2 days, 4:58:08, time: 1.357, data_time: 0.014, memory: 5723, decode.loss_seg: 1.3224, decode.acc_seg: 48.9796, loss: 1.3224
2021-08-14 05:08:48,612 - mmseg - INFO - Exp name: fcn_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 05:08:48,612 - mmseg - INFO - Iter [17000/160000]	lr: 9.048e-03, eta: 2 days, 4:57:11, time: 1.357, data_time: 0.014, memory: 5723, decode.loss_seg: 1.3165, decode.acc_seg: 48.7802, loss: 1.3165
2021-08-14 05:10:26,246 - mmseg - INFO - Iter [17050/160000]	lr: 9.045e-03, eta: 2 days, 5:00:25, time: 1.954, data_time: 0.718, memory: 5723, decode.loss_seg: 1.3264, decode.acc_seg: 48.1219, loss: 1.3264
2021-08-14 05:11:30,065 - mmseg - INFO - Iter [17100/160000]	lr: 9.043e-03, eta: 2 days, 4:58:53, time: 1.276, data_time: 0.014, memory: 5723, decode.loss_seg: 1.3217, decode.acc_seg: 47.4248, loss: 1.3217
2021-08-14 05:12:32,766 - mmseg - INFO - Iter [17150/160000]	lr: 9.040e-03, eta: 2 days, 4:57:13, time: 1.254, data_time: 0.014, memory: 5723, decode.loss_seg: 1.3156, decode.acc_seg: 47.5281, loss: 1.3156
2021-08-14 05:13:36,109 - mmseg - INFO - Iter [17200/160000]	lr: 9.037e-03, eta: 2 days, 4:55:38, time: 1.266, data_time: 0.013, memory: 5723, decode.loss_seg: 1.3614, decode.acc_seg: 47.2327, loss: 1.3614
2021-08-14 05:14:40,467 - mmseg - INFO - Iter [17250/160000]	lr: 9.034e-03, eta: 2 days, 4:54:12, time: 1.287, data_time: 0.013, memory: 5723, decode.loss_seg: 1.3124, decode.acc_seg: 48.3038, loss: 1.3124
2021-08-14 05:15:44,311 - mmseg - INFO - Iter [17300/160000]	lr: 9.031e-03, eta: 2 days, 4:52:42, time: 1.277, data_time: 0.014, memory: 5723, decode.loss_seg: 1.3005, decode.acc_seg: 47.5709, loss: 1.3005
2021-08-14 05:16:46,256 - mmseg - INFO - Iter [17350/160000]	lr: 9.028e-03, eta: 2 days, 4:50:56, time: 1.239, data_time: 0.014, memory: 5723, decode.loss_seg: 1.3127, decode.acc_seg: 47.9633, loss: 1.3127
2021-08-14 05:17:48,036 - mmseg - INFO - Iter [17400/160000]	lr: 9.026e-03, eta: 2 days, 4:49:09, time: 1.236, data_time: 0.014, memory: 5723, decode.loss_seg: 1.3365, decode.acc_seg: 47.5475, loss: 1.3365
2021-08-14 05:18:50,157 - mmseg - INFO - Iter [17450/160000]	lr: 9.023e-03, eta: 2 days, 4:47:25, time: 1.243, data_time: 0.014, memory: 5723, decode.loss_seg: 1.2981, decode.acc_seg: 47.8910, loss: 1.2981
2021-08-14 05:19:54,624 - mmseg - INFO - Iter [17500/160000]	lr: 9.020e-03, eta: 2 days, 4:46:00, time: 1.288, data_time: 0.014, memory: 5723, decode.loss_seg: 1.3348, decode.acc_seg: 47.9473, loss: 1.3348
2021-08-14 05:21:02,383 - mmseg - INFO - Iter [17550/160000]	lr: 9.017e-03, eta: 2 days, 4:45:03, time: 1.356, data_time: 0.015, memory: 5723, decode.loss_seg: 1.3375, decode.acc_seg: 48.2431, loss: 1.3375
2021-08-14 05:22:08,947 - mmseg - INFO - Iter [17600/160000]	lr: 9.014e-03, eta: 2 days, 4:43:56, time: 1.331, data_time: 0.015, memory: 5723, decode.loss_seg: 1.2916, decode.acc_seg: 48.4567, loss: 1.2916
2021-08-14 05:23:11,952 - mmseg - INFO - Iter [17650/160000]	lr: 9.012e-03, eta: 2 days, 4:42:20, time: 1.260, data_time: 0.014, memory: 5723, decode.loss_seg: 1.3384, decode.acc_seg: 47.7094, loss: 1.3384
2021-08-14 05:24:50,910 - mmseg - INFO - Iter [17700/160000]	lr: 9.009e-03, eta: 2 days, 4:45:32, time: 1.978, data_time: 0.723, memory: 5723, decode.loss_seg: 1.3624, decode.acc_seg: 47.4383, loss: 1.3624
2021-08-14 05:25:58,069 - mmseg - INFO - Iter [17750/160000]	lr: 9.006e-03, eta: 2 days, 4:44:29, time: 1.343, data_time: 0.015, memory: 5723, decode.loss_seg: 1.3078, decode.acc_seg: 47.5475, loss: 1.3078
2021-08-14 05:27:04,875 - mmseg - INFO - Iter [17800/160000]	lr: 9.003e-03, eta: 2 days, 4:43:23, time: 1.336, data_time: 0.015, memory: 5723, decode.loss_seg: 1.3172, decode.acc_seg: 48.3025, loss: 1.3172
2021-08-14 05:28:06,782 - mmseg - INFO - Iter [17850/160000]	lr: 9.000e-03, eta: 2 days, 4:41:38, time: 1.239, data_time: 0.015, memory: 5723, decode.loss_seg: 1.3156, decode.acc_seg: 46.4333, loss: 1.3156
2021-08-14 05:29:09,880 - mmseg - INFO - Iter [17900/160000]	lr: 8.997e-03, eta: 2 days, 4:40:02, time: 1.262, data_time: 0.014, memory: 5723, decode.loss_seg: 1.3005, decode.acc_seg: 47.6138, loss: 1.3005
2021-08-14 05:30:14,570 - mmseg - INFO - Iter [17950/160000]	lr: 8.995e-03, eta: 2 days, 4:38:40, time: 1.294, data_time: 0.014, memory: 5723, decode.loss_seg: 1.3211, decode.acc_seg: 47.9389, loss: 1.3211
2021-08-14 05:31:16,205 - mmseg - INFO - Exp name: fcn_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 05:31:16,205 - mmseg - INFO - Iter [18000/160000]	lr: 8.992e-03, eta: 2 days, 4:36:53, time: 1.233, data_time: 0.014, memory: 5723, decode.loss_seg: 1.3091, decode.acc_seg: 47.6038, loss: 1.3091
2021-08-14 05:32:19,644 - mmseg - INFO - Iter [18050/160000]	lr: 8.989e-03, eta: 2 days, 4:35:20, time: 1.268, data_time: 0.014, memory: 5723, decode.loss_seg: 1.3218, decode.acc_seg: 47.5918, loss: 1.3218
2021-08-14 05:33:22,174 - mmseg - INFO - Iter [18100/160000]	lr: 8.986e-03, eta: 2 days, 4:33:41, time: 1.251, data_time: 0.015, memory: 5723, decode.loss_seg: 1.3109, decode.acc_seg: 48.5806, loss: 1.3109
2021-08-14 05:34:22,965 - mmseg - INFO - Iter [18150/160000]	lr: 8.983e-03, eta: 2 days, 4:31:49, time: 1.216, data_time: 0.014, memory: 5723, decode.loss_seg: 1.3111, decode.acc_seg: 46.8030, loss: 1.3111
2021-08-14 05:35:24,691 - mmseg - INFO - Iter [18200/160000]	lr: 8.981e-03, eta: 2 days, 4:30:03, time: 1.234, data_time: 0.013, memory: 5723, decode.loss_seg: 1.3306, decode.acc_seg: 48.1146, loss: 1.3306
2021-08-14 05:36:27,247 - mmseg - INFO - Iter [18250/160000]	lr: 8.978e-03, eta: 2 days, 4:28:25, time: 1.252, data_time: 0.014, memory: 5723, decode.loss_seg: 1.3136, decode.acc_seg: 48.6375, loss: 1.3136
2021-08-14 05:38:05,964 - mmseg - INFO - Iter [18300/160000]	lr: 8.975e-03, eta: 2 days, 4:31:27, time: 1.974, data_time: 0.697, memory: 5723, decode.loss_seg: 1.3257, decode.acc_seg: 47.2550, loss: 1.3257
2021-08-14 05:39:08,639 - mmseg - INFO - Iter [18350/160000]	lr: 8.972e-03, eta: 2 days, 4:29:49, time: 1.252, data_time: 0.014, memory: 5723, decode.loss_seg: 1.3148, decode.acc_seg: 47.0731, loss: 1.3148
2021-08-14 05:40:10,813 - mmseg - INFO - Iter [18400/160000]	lr: 8.969e-03, eta: 2 days, 4:28:07, time: 1.244, data_time: 0.014, memory: 5723, decode.loss_seg: 1.2979, decode.acc_seg: 48.0298, loss: 1.2979
2021-08-14 05:41:12,795 - mmseg - INFO - Iter [18450/160000]	lr: 8.966e-03, eta: 2 days, 4:26:24, time: 1.239, data_time: 0.013, memory: 5723, decode.loss_seg: 1.3090, decode.acc_seg: 47.4890, loss: 1.3090
2021-08-14 05:42:14,418 - mmseg - INFO - Iter [18500/160000]	lr: 8.964e-03, eta: 2 days, 4:24:39, time: 1.233, data_time: 0.013, memory: 5723, decode.loss_seg: 1.2971, decode.acc_seg: 47.2251, loss: 1.2971
2021-08-14 05:43:15,203 - mmseg - INFO - Iter [18550/160000]	lr: 8.961e-03, eta: 2 days, 4:22:47, time: 1.215, data_time: 0.013, memory: 5723, decode.loss_seg: 1.3261, decode.acc_seg: 48.0556, loss: 1.3261
2021-08-14 05:44:16,703 - mmseg - INFO - Iter [18600/160000]	lr: 8.958e-03, eta: 2 days, 4:21:02, time: 1.230, data_time: 0.014, memory: 5723, decode.loss_seg: 1.2937, decode.acc_seg: 47.9394, loss: 1.2937
2021-08-14 05:45:19,355 - mmseg - INFO - Iter [18650/160000]	lr: 8.955e-03, eta: 2 days, 4:19:25, time: 1.253, data_time: 0.013, memory: 5723, decode.loss_seg: 1.3209, decode.acc_seg: 48.2142, loss: 1.3209
2021-08-14 05:46:23,138 - mmseg - INFO - Iter [18700/160000]	lr: 8.952e-03, eta: 2 days, 4:17:56, time: 1.275, data_time: 0.012, memory: 5723, decode.loss_seg: 1.3095, decode.acc_seg: 48.3552, loss: 1.3095
2021-08-14 05:47:25,769 - mmseg - INFO - Iter [18750/160000]	lr: 8.950e-03, eta: 2 days, 4:16:20, time: 1.253, data_time: 0.014, memory: 5723, decode.loss_seg: 1.3240, decode.acc_seg: 48.6722, loss: 1.3240
2021-08-14 05:48:30,369 - mmseg - INFO - Iter [18800/160000]	lr: 8.947e-03, eta: 2 days, 4:14:58, time: 1.292, data_time: 0.014, memory: 5723, decode.loss_seg: 1.3269, decode.acc_seg: 47.4803, loss: 1.3269
2021-08-14 05:49:32,108 - mmseg - INFO - Iter [18850/160000]	lr: 8.944e-03, eta: 2 days, 4:13:15, time: 1.235, data_time: 0.015, memory: 5723, decode.loss_seg: 1.3216, decode.acc_seg: 47.7620, loss: 1.3216
2021-08-14 05:50:33,060 - mmseg - INFO - Iter [18900/160000]	lr: 8.941e-03, eta: 2 days, 4:11:26, time: 1.218, data_time: 0.013, memory: 5723, decode.loss_seg: 1.3407, decode.acc_seg: 47.8157, loss: 1.3407
2021-08-14 05:52:10,984 - mmseg - INFO - Iter [18950/160000]	lr: 8.938e-03, eta: 2 days, 4:14:13, time: 1.959, data_time: 0.737, memory: 5723, decode.loss_seg: 1.3352, decode.acc_seg: 46.7850, loss: 1.3352
2021-08-14 05:53:12,914 - mmseg - INFO - Exp name: fcn_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 05:53:12,915 - mmseg - INFO - Iter [19000/160000]	lr: 8.935e-03, eta: 2 days, 4:12:31, time: 1.239, data_time: 0.014, memory: 5723, decode.loss_seg: 1.2888, decode.acc_seg: 48.0835, loss: 1.2888
2021-08-14 05:54:14,000 - mmseg - INFO - Iter [19050/160000]	lr: 8.933e-03, eta: 2 days, 4:10:43, time: 1.221, data_time: 0.013, memory: 5723, decode.loss_seg: 1.3332, decode.acc_seg: 47.2831, loss: 1.3332
2021-08-14 05:55:15,474 - mmseg - INFO - Iter [19100/160000]	lr: 8.930e-03, eta: 2 days, 4:08:59, time: 1.230, data_time: 0.014, memory: 5723, decode.loss_seg: 1.3059, decode.acc_seg: 48.2477, loss: 1.3059
2021-08-14 05:56:15,943 - mmseg - INFO - Iter [19150/160000]	lr: 8.927e-03, eta: 2 days, 4:07:07, time: 1.209, data_time: 0.013, memory: 5723, decode.loss_seg: 1.2854, decode.acc_seg: 49.0743, loss: 1.2854
2021-08-14 05:57:16,757 - mmseg - INFO - Iter [19200/160000]	lr: 8.924e-03, eta: 2 days, 4:05:18, time: 1.216, data_time: 0.013, memory: 5723, decode.loss_seg: 1.2827, decode.acc_seg: 48.1373, loss: 1.2827
2021-08-14 05:58:19,542 - mmseg - INFO - Iter [19250/160000]	lr: 8.921e-03, eta: 2 days, 4:03:43, time: 1.256, data_time: 0.013, memory: 5723, decode.loss_seg: 1.3270, decode.acc_seg: 48.3102, loss: 1.3270
2021-08-14 05:59:23,016 - mmseg - INFO - Iter [19300/160000]	lr: 8.918e-03, eta: 2 days, 4:02:14, time: 1.269, data_time: 0.013, memory: 5723, decode.loss_seg: 1.3040, decode.acc_seg: 48.9082, loss: 1.3040
2021-08-14 06:00:27,472 - mmseg - INFO - Iter [19350/160000]	lr: 8.916e-03, eta: 2 days, 4:00:52, time: 1.288, data_time: 0.014, memory: 5723, decode.loss_seg: 1.2776, decode.acc_seg: 48.9659, loss: 1.2776
2021-08-14 06:01:30,102 - mmseg - INFO - Iter [19400/160000]	lr: 8.913e-03, eta: 2 days, 3:59:17, time: 1.254, data_time: 0.014, memory: 5723, decode.loss_seg: 1.2704, decode.acc_seg: 48.4276, loss: 1.2704
2021-08-14 06:02:34,030 - mmseg - INFO - Iter [19450/160000]	lr: 8.910e-03, eta: 2 days, 3:57:52, time: 1.279, data_time: 0.013, memory: 5723, decode.loss_seg: 1.2542, decode.acc_seg: 48.0268, loss: 1.2542
2021-08-14 06:03:37,635 - mmseg - INFO - Iter [19500/160000]	lr: 8.907e-03, eta: 2 days, 3:56:24, time: 1.271, data_time: 0.015, memory: 5723, decode.loss_seg: 1.2847, decode.acc_seg: 48.9239, loss: 1.2847
2021-08-14 06:04:40,119 - mmseg - INFO - Iter [19550/160000]	lr: 8.904e-03, eta: 2 days, 3:54:48, time: 1.250, data_time: 0.013, memory: 5723, decode.loss_seg: 1.3277, decode.acc_seg: 48.7987, loss: 1.3277
2021-08-14 06:06:31,345 - mmseg - INFO - Iter [19600/160000]	lr: 8.902e-03, eta: 2 days, 3:59:01, time: 2.223, data_time: 0.978, memory: 5723, decode.loss_seg: 1.2867, decode.acc_seg: 48.2573, loss: 1.2867
2021-08-14 06:07:33,999 - mmseg - INFO - Iter [19650/160000]	lr: 8.899e-03, eta: 2 days, 3:57:27, time: 1.254, data_time: 0.015, memory: 5723, decode.loss_seg: 1.3058, decode.acc_seg: 47.6284, loss: 1.3058
2021-08-14 06:08:38,357 - mmseg - INFO - Iter [19700/160000]	lr: 8.896e-03, eta: 2 days, 3:56:04, time: 1.287, data_time: 0.014, memory: 5723, decode.loss_seg: 1.2856, decode.acc_seg: 48.6196, loss: 1.2856
2021-08-14 06:09:40,158 - mmseg - INFO - Iter [19750/160000]	lr: 8.893e-03, eta: 2 days, 3:54:23, time: 1.236, data_time: 0.014, memory: 5723, decode.loss_seg: 1.3026, decode.acc_seg: 48.1808, loss: 1.3026
2021-08-14 06:10:42,688 - mmseg - INFO - Iter [19800/160000]	lr: 8.890e-03, eta: 2 days, 3:52:47, time: 1.250, data_time: 0.013, memory: 5723, decode.loss_seg: 1.2723, decode.acc_seg: 48.2795, loss: 1.2723
2021-08-14 06:11:45,215 - mmseg - INFO - Iter [19850/160000]	lr: 8.887e-03, eta: 2 days, 3:51:12, time: 1.251, data_time: 0.013, memory: 5723, decode.loss_seg: 1.3057, decode.acc_seg: 47.7198, loss: 1.3057
2021-08-14 06:12:46,602 - mmseg - INFO - Iter [19900/160000]	lr: 8.885e-03, eta: 2 days, 3:49:28, time: 1.227, data_time: 0.012, memory: 5723, decode.loss_seg: 1.3070, decode.acc_seg: 48.3898, loss: 1.3070
2021-08-14 06:13:48,860 - mmseg - INFO - Iter [19950/160000]	lr: 8.882e-03, eta: 2 days, 3:47:52, time: 1.245, data_time: 0.013, memory: 5723, decode.loss_seg: 1.2643, decode.acc_seg: 49.2082, loss: 1.2643
2021-08-14 06:14:52,675 - mmseg - INFO - Exp name: fcn_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 06:14:52,676 - mmseg - INFO - Iter [20000/160000]	lr: 8.879e-03, eta: 2 days, 3:46:26, time: 1.277, data_time: 0.012, memory: 5723, decode.loss_seg: 1.2883, decode.acc_seg: 47.9975, loss: 1.2883
2021-08-14 06:15:54,938 - mmseg - INFO - Iter [20050/160000]	lr: 8.876e-03, eta: 2 days, 3:44:49, time: 1.244, data_time: 0.013, memory: 5723, decode.loss_seg: 1.2565, decode.acc_seg: 49.5772, loss: 1.2565
2021-08-14 06:16:58,314 - mmseg - INFO - Iter [20100/160000]	lr: 8.873e-03, eta: 2 days, 3:43:20, time: 1.268, data_time: 0.015, memory: 5723, decode.loss_seg: 1.3076, decode.acc_seg: 48.7223, loss: 1.3076
2021-08-14 06:18:01,739 - mmseg - INFO - Iter [20150/160000]	lr: 8.871e-03, eta: 2 days, 3:41:52, time: 1.269, data_time: 0.014, memory: 5723, decode.loss_seg: 1.2906, decode.acc_seg: 49.0140, loss: 1.2906
2021-08-14 06:19:40,412 - mmseg - INFO - Iter [20200/160000]	lr: 8.868e-03, eta: 2 days, 3:44:28, time: 1.973, data_time: 0.694, memory: 5723, decode.loss_seg: 1.3024, decode.acc_seg: 48.7172, loss: 1.3024
2021-08-14 06:20:43,060 - mmseg - INFO - Iter [20250/160000]	lr: 8.865e-03, eta: 2 days, 3:42:54, time: 1.253, data_time: 0.014, memory: 5723, decode.loss_seg: 1.2453, decode.acc_seg: 49.2096, loss: 1.2453
2021-08-14 06:21:45,029 - mmseg - INFO - Iter [20300/160000]	lr: 8.862e-03, eta: 2 days, 3:41:15, time: 1.239, data_time: 0.012, memory: 5723, decode.loss_seg: 1.3138, decode.acc_seg: 48.3482, loss: 1.3138
2021-08-14 06:22:46,630 - mmseg - INFO - Iter [20350/160000]	lr: 8.859e-03, eta: 2 days, 3:39:34, time: 1.232, data_time: 0.014, memory: 5723, decode.loss_seg: 1.2406, decode.acc_seg: 49.1195, loss: 1.2406
2021-08-14 06:23:47,965 - mmseg - INFO - Iter [20400/160000]	lr: 8.856e-03, eta: 2 days, 3:37:52, time: 1.227, data_time: 0.013, memory: 5723, decode.loss_seg: 1.3087, decode.acc_seg: 47.9326, loss: 1.3087
2021-08-14 06:24:50,265 - mmseg - INFO - Iter [20450/160000]	lr: 8.854e-03, eta: 2 days, 3:36:16, time: 1.246, data_time: 0.013, memory: 5723, decode.loss_seg: 1.2770, decode.acc_seg: 49.0705, loss: 1.2770
2021-08-14 06:25:53,583 - mmseg - INFO - Iter [20500/160000]	lr: 8.851e-03, eta: 2 days, 3:34:47, time: 1.266, data_time: 0.013, memory: 5723, decode.loss_seg: 1.3086, decode.acc_seg: 48.6270, loss: 1.3086
2021-08-14 06:26:56,854 - mmseg - INFO - Iter [20550/160000]	lr: 8.848e-03, eta: 2 days, 3:33:19, time: 1.265, data_time: 0.013, memory: 5723, decode.loss_seg: 1.2641, decode.acc_seg: 48.3522, loss: 1.2641
2021-08-14 06:28:00,833 - mmseg - INFO - Iter [20600/160000]	lr: 8.845e-03, eta: 2 days, 3:31:55, time: 1.280, data_time: 0.015, memory: 5723, decode.loss_seg: 1.2919, decode.acc_seg: 48.5281, loss: 1.2919
2021-08-14 06:29:03,339 - mmseg - INFO - Iter [20650/160000]	lr: 8.842e-03, eta: 2 days, 3:30:21, time: 1.249, data_time: 0.013, memory: 5723, decode.loss_seg: 1.2692, decode.acc_seg: 47.9644, loss: 1.2692
2021-08-14 06:30:05,371 - mmseg - INFO - Iter [20700/160000]	lr: 8.839e-03, eta: 2 days, 3:28:44, time: 1.241, data_time: 0.014, memory: 5723, decode.loss_seg: 1.2815, decode.acc_seg: 48.7110, loss: 1.2815
2021-08-14 06:31:08,088 - mmseg - INFO - Iter [20750/160000]	lr: 8.837e-03, eta: 2 days, 3:27:12, time: 1.253, data_time: 0.013, memory: 5723, decode.loss_seg: 1.2799, decode.acc_seg: 48.5595, loss: 1.2799
2021-08-14 06:32:11,004 - mmseg - INFO - Iter [20800/160000]	lr: 8.834e-03, eta: 2 days, 3:25:41, time: 1.259, data_time: 0.014, memory: 5723, decode.loss_seg: 1.2746, decode.acc_seg: 48.5334, loss: 1.2746
2021-08-14 06:33:48,021 - mmseg - INFO - Iter [20850/160000]	lr: 8.831e-03, eta: 2 days, 3:27:59, time: 1.941, data_time: 0.705, memory: 5723, decode.loss_seg: 1.2625, decode.acc_seg: 49.4087, loss: 1.2625
2021-08-14 06:34:53,174 - mmseg - INFO - Iter [20900/160000]	lr: 8.828e-03, eta: 2 days, 3:26:42, time: 1.302, data_time: 0.013, memory: 5723, decode.loss_seg: 1.2371, decode.acc_seg: 48.5609, loss: 1.2371
2021-08-14 06:35:55,401 - mmseg - INFO - Iter [20950/160000]	lr: 8.825e-03, eta: 2 days, 3:25:07, time: 1.246, data_time: 0.015, memory: 5723, decode.loss_seg: 1.2253, decode.acc_seg: 50.2918, loss: 1.2253
2021-08-14 06:36:56,806 - mmseg - INFO - Exp name: fcn_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 06:36:56,807 - mmseg - INFO - Iter [21000/160000]	lr: 8.823e-03, eta: 2 days, 3:23:26, time: 1.227, data_time: 0.012, memory: 5723, decode.loss_seg: 1.2775, decode.acc_seg: 50.0181, loss: 1.2775
2021-08-14 06:37:59,220 - mmseg - INFO - Iter [21050/160000]	lr: 8.820e-03, eta: 2 days, 3:21:53, time: 1.249, data_time: 0.013, memory: 5723, decode.loss_seg: 1.2764, decode.acc_seg: 48.4542, loss: 1.2764
2021-08-14 06:39:03,181 - mmseg - INFO - Iter [21100/160000]	lr: 8.817e-03, eta: 2 days, 3:20:29, time: 1.279, data_time: 0.014, memory: 5723, decode.loss_seg: 1.2602, decode.acc_seg: 48.7320, loss: 1.2602
2021-08-14 06:40:06,045 - mmseg - INFO - Iter [21150/160000]	lr: 8.814e-03, eta: 2 days, 3:18:58, time: 1.257, data_time: 0.013, memory: 5723, decode.loss_seg: 1.3054, decode.acc_seg: 48.4620, loss: 1.3054
2021-08-14 06:41:08,508 - mmseg - INFO - Iter [21200/160000]	lr: 8.811e-03, eta: 2 days, 3:17:25, time: 1.250, data_time: 0.015, memory: 5723, decode.loss_seg: 1.2729, decode.acc_seg: 49.6290, loss: 1.2729
2021-08-14 06:42:10,033 - mmseg - INFO - Iter [21250/160000]	lr: 8.808e-03, eta: 2 days, 3:15:46, time: 1.230, data_time: 0.013, memory: 5723, decode.loss_seg: 1.2655, decode.acc_seg: 49.0110, loss: 1.2655
2021-08-14 06:43:10,694 - mmseg - INFO - Iter [21300/160000]	lr: 8.806e-03, eta: 2 days, 3:14:02, time: 1.214, data_time: 0.014, memory: 5723, decode.loss_seg: 1.2827, decode.acc_seg: 47.4236, loss: 1.2827
2021-08-14 06:44:13,774 - mmseg - INFO - Iter [21350/160000]	lr: 8.803e-03, eta: 2 days, 3:12:33, time: 1.261, data_time: 0.012, memory: 5723, decode.loss_seg: 1.3028, decode.acc_seg: 48.2151, loss: 1.3028
2021-08-14 06:45:15,132 - mmseg - INFO - Iter [21400/160000]	lr: 8.800e-03, eta: 2 days, 3:10:53, time: 1.227, data_time: 0.013, memory: 5723, decode.loss_seg: 1.2975, decode.acc_seg: 47.9102, loss: 1.2975
2021-08-14 06:46:15,964 - mmseg - INFO - Iter [21450/160000]	lr: 8.797e-03, eta: 2 days, 3:09:11, time: 1.217, data_time: 0.012, memory: 5723, decode.loss_seg: 1.2970, decode.acc_seg: 47.4478, loss: 1.2970
2021-08-14 06:47:52,942 - mmseg - INFO - Iter [21500/160000]	lr: 8.794e-03, eta: 2 days, 3:11:21, time: 1.939, data_time: 0.723, memory: 5723, decode.loss_seg: 1.2475, decode.acc_seg: 48.7502, loss: 1.2475
2021-08-14 06:48:57,116 - mmseg - INFO - Iter [21550/160000]	lr: 8.791e-03, eta: 2 days, 3:09:59, time: 1.283, data_time: 0.014, memory: 5723, decode.loss_seg: 1.2840, decode.acc_seg: 48.6018, loss: 1.2840
2021-08-14 06:50:00,386 - mmseg - INFO - Iter [21600/160000]	lr: 8.789e-03, eta: 2 days, 3:08:32, time: 1.266, data_time: 0.013, memory: 5723, decode.loss_seg: 1.2356, decode.acc_seg: 49.4039, loss: 1.2356
2021-08-14 06:51:05,827 - mmseg - INFO - Iter [21650/160000]	lr: 8.786e-03, eta: 2 days, 3:07:18, time: 1.309, data_time: 0.013, memory: 5723, decode.loss_seg: 1.2899, decode.acc_seg: 49.5400, loss: 1.2899
2021-08-14 06:52:07,468 - mmseg - INFO - Iter [21700/160000]	lr: 8.783e-03, eta: 2 days, 3:05:41, time: 1.232, data_time: 0.012, memory: 5723, decode.loss_seg: 1.2996, decode.acc_seg: 48.1553, loss: 1.2996
2021-08-14 06:53:09,550 - mmseg - INFO - Iter [21750/160000]	lr: 8.780e-03, eta: 2 days, 3:04:06, time: 1.242, data_time: 0.014, memory: 5723, decode.loss_seg: 1.2312, decode.acc_seg: 49.5353, loss: 1.2312
2021-08-14 06:54:14,967 - mmseg - INFO - Iter [21800/160000]	lr: 8.777e-03, eta: 2 days, 3:02:53, time: 1.307, data_time: 0.012, memory: 5723, decode.loss_seg: 1.2989, decode.acc_seg: 47.6787, loss: 1.2989
2021-08-14 06:55:19,913 - mmseg - INFO - Iter [21850/160000]	lr: 8.775e-03, eta: 2 days, 3:01:36, time: 1.299, data_time: 0.015, memory: 5723, decode.loss_seg: 1.2738, decode.acc_seg: 49.1546, loss: 1.2738
2021-08-14 06:56:22,670 - mmseg - INFO - Iter [21900/160000]	lr: 8.772e-03, eta: 2 days, 3:00:07, time: 1.256, data_time: 0.014, memory: 5723, decode.loss_seg: 1.2339, decode.acc_seg: 50.0762, loss: 1.2339
2021-08-14 06:57:24,447 - mmseg - INFO - Iter [21950/160000]	lr: 8.769e-03, eta: 2 days, 2:58:31, time: 1.236, data_time: 0.014, memory: 5723, decode.loss_seg: 1.2968, decode.acc_seg: 48.1109, loss: 1.2968
2021-08-14 06:58:27,981 - mmseg - INFO - Exp name: fcn_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 06:58:27,982 - mmseg - INFO - Iter [22000/160000]	lr: 8.766e-03, eta: 2 days, 2:57:06, time: 1.271, data_time: 0.013, memory: 5723, decode.loss_seg: 1.2662, decode.acc_seg: 49.1409, loss: 1.2662
2021-08-14 06:59:28,981 - mmseg - INFO - Iter [22050/160000]	lr: 8.763e-03, eta: 2 days, 2:55:25, time: 1.219, data_time: 0.012, memory: 5723, decode.loss_seg: 1.3153, decode.acc_seg: 49.1270, loss: 1.3153
2021-08-14 07:01:07,268 - mmseg - INFO - Iter [22100/160000]	lr: 8.760e-03, eta: 2 days, 2:57:37, time: 1.966, data_time: 0.720, memory: 5723, decode.loss_seg: 1.2765, decode.acc_seg: 48.1084, loss: 1.2765
2021-08-14 07:02:10,629 - mmseg - INFO - Iter [22150/160000]	lr: 8.758e-03, eta: 2 days, 2:56:11, time: 1.267, data_time: 0.016, memory: 5723, decode.loss_seg: 1.2404, decode.acc_seg: 49.1263, loss: 1.2404
2021-08-14 07:03:12,506 - mmseg - INFO - Iter [22200/160000]	lr: 8.755e-03, eta: 2 days, 2:54:36, time: 1.238, data_time: 0.014, memory: 5723, decode.loss_seg: 1.2539, decode.acc_seg: 50.1659, loss: 1.2539
2021-08-14 07:04:15,826 - mmseg - INFO - Iter [22250/160000]	lr: 8.752e-03, eta: 2 days, 2:53:10, time: 1.267, data_time: 0.014, memory: 5723, decode.loss_seg: 1.2227, decode.acc_seg: 49.3648, loss: 1.2227
2021-08-14 07:05:18,794 - mmseg - INFO - Iter [22300/160000]	lr: 8.749e-03, eta: 2 days, 2:51:41, time: 1.259, data_time: 0.013, memory: 5723, decode.loss_seg: 1.2532, decode.acc_seg: 49.0134, loss: 1.2532
2021-08-14 07:06:23,726 - mmseg - INFO - Iter [22350/160000]	lr: 8.746e-03, eta: 2 days, 2:50:25, time: 1.298, data_time: 0.013, memory: 5723, decode.loss_seg: 1.2049, decode.acc_seg: 49.2214, loss: 1.2049
2021-08-14 07:07:29,515 - mmseg - INFO - Iter [22400/160000]	lr: 8.743e-03, eta: 2 days, 2:49:15, time: 1.316, data_time: 0.013, memory: 5723, decode.loss_seg: 1.2449, decode.acc_seg: 49.4731, loss: 1.2449
2021-08-14 07:08:33,183 - mmseg - INFO - Iter [22450/160000]	lr: 8.741e-03, eta: 2 days, 2:47:51, time: 1.273, data_time: 0.014, memory: 5723, decode.loss_seg: 1.2361, decode.acc_seg: 49.7042, loss: 1.2361
2021-08-14 07:09:35,891 - mmseg - INFO - Iter [22500/160000]	lr: 8.738e-03, eta: 2 days, 2:46:21, time: 1.254, data_time: 0.015, memory: 5723, decode.loss_seg: 1.2635, decode.acc_seg: 48.9785, loss: 1.2635
2021-08-14 07:10:37,067 - mmseg - INFO - Iter [22550/160000]	lr: 8.735e-03, eta: 2 days, 2:44:43, time: 1.224, data_time: 0.013, memory: 5723, decode.loss_seg: 1.2884, decode.acc_seg: 48.9074, loss: 1.2884
2021-08-14 07:11:39,097 - mmseg - INFO - Iter [22600/160000]	lr: 8.732e-03, eta: 2 days, 2:43:09, time: 1.241, data_time: 0.014, memory: 5723, decode.loss_seg: 1.3089, decode.acc_seg: 49.4200, loss: 1.3089
2021-08-14 07:12:39,150 - mmseg - INFO - Iter [22650/160000]	lr: 8.729e-03, eta: 2 days, 2:41:24, time: 1.201, data_time: 0.013, memory: 5723, decode.loss_seg: 1.2458, decode.acc_seg: 49.4852, loss: 1.2458
2021-08-14 07:13:42,864 - mmseg - INFO - Iter [22700/160000]	lr: 8.726e-03, eta: 2 days, 2:40:01, time: 1.275, data_time: 0.015, memory: 5723, decode.loss_seg: 1.2505, decode.acc_seg: 47.8281, loss: 1.2505
2021-08-14 07:15:22,097 - mmseg - INFO - Iter [22750/160000]	lr: 8.724e-03, eta: 2 days, 2:42:13, time: 1.985, data_time: 0.746, memory: 5723, decode.loss_seg: 1.2515, decode.acc_seg: 48.6176, loss: 1.2515
2021-08-14 07:16:25,682 - mmseg - INFO - Iter [22800/160000]	lr: 8.721e-03, eta: 2 days, 2:40:49, time: 1.271, data_time: 0.013, memory: 5723, decode.loss_seg: 1.2200, decode.acc_seg: 48.8160, loss: 1.2200
2021-08-14 07:17:29,073 - mmseg - INFO - Iter [22850/160000]	lr: 8.718e-03, eta: 2 days, 2:39:24, time: 1.269, data_time: 0.015, memory: 5723, decode.loss_seg: 1.2765, decode.acc_seg: 48.6065, loss: 1.2765
2021-08-14 07:18:32,142 - mmseg - INFO - Iter [22900/160000]	lr: 8.715e-03, eta: 2 days, 2:37:57, time: 1.261, data_time: 0.015, memory: 5723, decode.loss_seg: 1.2557, decode.acc_seg: 49.8023, loss: 1.2557
2021-08-14 07:19:32,915 - mmseg - INFO - Iter [22950/160000]	lr: 8.712e-03, eta: 2 days, 2:36:16, time: 1.215, data_time: 0.013, memory: 5723, decode.loss_seg: 1.2372, decode.acc_seg: 47.9632, loss: 1.2372
2021-08-14 07:20:34,844 - mmseg - INFO - Exp name: fcn_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 07:20:34,844 - mmseg - INFO - Iter [23000/160000]	lr: 8.710e-03, eta: 2 days, 2:34:43, time: 1.239, data_time: 0.014, memory: 5723, decode.loss_seg: 1.2504, decode.acc_seg: 49.0154, loss: 1.2504
2021-08-14 07:21:39,067 - mmseg - INFO - Iter [23050/160000]	lr: 8.707e-03, eta: 2 days, 2:33:23, time: 1.284, data_time: 0.014, memory: 5723, decode.loss_seg: 1.2509, decode.acc_seg: 50.6962, loss: 1.2509
2021-08-14 07:22:43,900 - mmseg - INFO - Iter [23100/160000]	lr: 8.704e-03, eta: 2 days, 2:32:07, time: 1.297, data_time: 0.013, memory: 5723, decode.loss_seg: 1.2307, decode.acc_seg: 48.9739, loss: 1.2307
2021-08-14 07:23:49,229 - mmseg - INFO - Iter [23150/160000]	lr: 8.701e-03, eta: 2 days, 2:30:54, time: 1.307, data_time: 0.013, memory: 5723, decode.loss_seg: 1.2428, decode.acc_seg: 49.3454, loss: 1.2428
2021-08-14 07:24:52,652 - mmseg - INFO - Iter [23200/160000]	lr: 8.698e-03, eta: 2 days, 2:29:30, time: 1.268, data_time: 0.014, memory: 5723, decode.loss_seg: 1.2637, decode.acc_seg: 48.3189, loss: 1.2637
2021-08-14 07:25:54,371 - mmseg - INFO - Iter [23250/160000]	lr: 8.695e-03, eta: 2 days, 2:27:56, time: 1.235, data_time: 0.013, memory: 5723, decode.loss_seg: 1.2488, decode.acc_seg: 49.2342, loss: 1.2488
2021-08-14 07:26:57,590 - mmseg - INFO - Iter [23300/160000]	lr: 8.693e-03, eta: 2 days, 2:26:30, time: 1.264, data_time: 0.015, memory: 5723, decode.loss_seg: 1.2919, decode.acc_seg: 48.6603, loss: 1.2919
2021-08-14 07:28:33,879 - mmseg - INFO - Iter [23350/160000]	lr: 8.690e-03, eta: 2 days, 2:28:19, time: 1.925, data_time: 0.689, memory: 5723, decode.loss_seg: 1.2763, decode.acc_seg: 48.7040, loss: 1.2763
2021-08-14 07:29:37,186 - mmseg - INFO - Iter [23400/160000]	lr: 8.687e-03, eta: 2 days, 2:26:54, time: 1.267, data_time: 0.015, memory: 5723, decode.loss_seg: 1.2463, decode.acc_seg: 49.2790, loss: 1.2463
2021-08-14 07:30:38,596 - mmseg - INFO - Iter [23450/160000]	lr: 8.684e-03, eta: 2 days, 2:25:18, time: 1.228, data_time: 0.013, memory: 5723, decode.loss_seg: 1.2827, decode.acc_seg: 49.0951, loss: 1.2827
2021-08-14 07:31:40,733 - mmseg - INFO - Iter [23500/160000]	lr: 8.681e-03, eta: 2 days, 2:23:46, time: 1.243, data_time: 0.015, memory: 5723, decode.loss_seg: 1.2561, decode.acc_seg: 49.7808, loss: 1.2561
2021-08-14 07:32:43,687 - mmseg - INFO - Iter [23550/160000]	lr: 8.678e-03, eta: 2 days, 2:22:19, time: 1.259, data_time: 0.013, memory: 5723, decode.loss_seg: 1.2189, decode.acc_seg: 48.5555, loss: 1.2189
2021-08-14 07:33:48,029 - mmseg - INFO - Iter [23600/160000]	lr: 8.676e-03, eta: 2 days, 2:21:01, time: 1.288, data_time: 0.014, memory: 5723, decode.loss_seg: 1.2758, decode.acc_seg: 48.7006, loss: 1.2758
2021-08-14 07:34:49,787 - mmseg - INFO - Iter [23650/160000]	lr: 8.673e-03, eta: 2 days, 2:19:27, time: 1.235, data_time: 0.014, memory: 5723, decode.loss_seg: 1.2608, decode.acc_seg: 48.3342, loss: 1.2608
2021-08-14 07:35:53,661 - mmseg - INFO - Iter [23700/160000]	lr: 8.670e-03, eta: 2 days, 2:18:06, time: 1.278, data_time: 0.015, memory: 5723, decode.loss_seg: 1.2209, decode.acc_seg: 49.6567, loss: 1.2209
2021-08-14 07:36:58,703 - mmseg - INFO - Iter [23750/160000]	lr: 8.667e-03, eta: 2 days, 2:16:52, time: 1.300, data_time: 0.016, memory: 5723, decode.loss_seg: 1.2114, decode.acc_seg: 49.6740, loss: 1.2114
2021-08-14 07:38:01,426 - mmseg - INFO - Iter [23800/160000]	lr: 8.664e-03, eta: 2 days, 2:15:24, time: 1.255, data_time: 0.013, memory: 5723, decode.loss_seg: 1.2805, decode.acc_seg: 49.0669, loss: 1.2805
2021-08-14 07:39:02,815 - mmseg - INFO - Iter [23850/160000]	lr: 8.661e-03, eta: 2 days, 2:13:49, time: 1.227, data_time: 0.013, memory: 5723, decode.loss_seg: 1.2814, decode.acc_seg: 49.5303, loss: 1.2814
2021-08-14 07:40:06,805 - mmseg - INFO - Iter [23900/160000]	lr: 8.659e-03, eta: 2 days, 2:12:29, time: 1.280, data_time: 0.013, memory: 5723, decode.loss_seg: 1.2508, decode.acc_seg: 48.9152, loss: 1.2508
2021-08-14 07:41:09,112 - mmseg - INFO - Iter [23950/160000]	lr: 8.656e-03, eta: 2 days, 2:10:59, time: 1.247, data_time: 0.013, memory: 5723, decode.loss_seg: 1.2739, decode.acc_seg: 49.3201, loss: 1.2739
2021-08-14 07:42:46,093 - mmseg - INFO - Exp name: fcn_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 07:42:46,097 - mmseg - INFO - Iter [24000/160000]	lr: 8.653e-03, eta: 2 days, 2:12:46, time: 1.939, data_time: 0.726, memory: 5723, decode.loss_seg: 1.2288, decode.acc_seg: 49.6549, loss: 1.2288
2021-08-14 07:43:48,449 - mmseg - INFO - Iter [24050/160000]	lr: 8.650e-03, eta: 2 days, 2:11:16, time: 1.247, data_time: 0.015, memory: 5723, decode.loss_seg: 1.2217, decode.acc_seg: 49.6537, loss: 1.2217
2021-08-14 07:44:50,004 - mmseg - INFO - Iter [24100/160000]	lr: 8.647e-03, eta: 2 days, 2:09:42, time: 1.231, data_time: 0.013, memory: 5723, decode.loss_seg: 1.2279, decode.acc_seg: 49.1726, loss: 1.2279
2021-08-14 07:45:53,371 - mmseg - INFO - Iter [24150/160000]	lr: 8.644e-03, eta: 2 days, 2:08:19, time: 1.268, data_time: 0.016, memory: 5723, decode.loss_seg: 1.2291, decode.acc_seg: 49.4126, loss: 1.2291
2021-08-14 07:46:57,908 - mmseg - INFO - Iter [24200/160000]	lr: 8.642e-03, eta: 2 days, 2:07:01, time: 1.290, data_time: 0.016, memory: 5723, decode.loss_seg: 1.2488, decode.acc_seg: 49.7394, loss: 1.2488
2021-08-14 07:48:00,941 - mmseg - INFO - Iter [24250/160000]	lr: 8.639e-03, eta: 2 days, 2:05:36, time: 1.260, data_time: 0.015, memory: 5723, decode.loss_seg: 1.2297, decode.acc_seg: 49.7257, loss: 1.2297
2021-08-14 07:49:02,064 - mmseg - INFO - Iter [24300/160000]	lr: 8.636e-03, eta: 2 days, 2:04:00, time: 1.223, data_time: 0.014, memory: 5723, decode.loss_seg: 1.2512, decode.acc_seg: 48.2653, loss: 1.2512
2021-08-14 07:50:05,344 - mmseg - INFO - Iter [24350/160000]	lr: 8.633e-03, eta: 2 days, 2:02:36, time: 1.266, data_time: 0.013, memory: 5723, decode.loss_seg: 1.2460, decode.acc_seg: 49.5889, loss: 1.2460
2021-08-14 07:51:08,875 - mmseg - INFO - Iter [24400/160000]	lr: 8.630e-03, eta: 2 days, 2:01:14, time: 1.271, data_time: 0.013, memory: 5723, decode.loss_seg: 1.2164, decode.acc_seg: 49.8897, loss: 1.2164
2021-08-14 07:52:11,221 - mmseg - INFO - Iter [24450/160000]	lr: 8.627e-03, eta: 2 days, 1:59:45, time: 1.246, data_time: 0.014, memory: 5723, decode.loss_seg: 1.2763, decode.acc_seg: 48.7248, loss: 1.2763
2021-08-14 07:53:14,394 - mmseg - INFO - Iter [24500/160000]	lr: 8.625e-03, eta: 2 days, 1:58:21, time: 1.263, data_time: 0.015, memory: 5723, decode.loss_seg: 1.2475, decode.acc_seg: 49.2751, loss: 1.2475
2021-08-14 07:54:16,997 - mmseg - INFO - Iter [24550/160000]	lr: 8.622e-03, eta: 2 days, 1:56:54, time: 1.253, data_time: 0.016, memory: 5723, decode.loss_seg: 1.2560, decode.acc_seg: 49.5008, loss: 1.2560
2021-08-14 07:55:19,625 - mmseg - INFO - Iter [24600/160000]	lr: 8.619e-03, eta: 2 days, 1:55:27, time: 1.253, data_time: 0.014, memory: 5723, decode.loss_seg: 1.2745, decode.acc_seg: 48.6981, loss: 1.2745
2021-08-14 07:56:59,510 - mmseg - INFO - Iter [24650/160000]	lr: 8.616e-03, eta: 2 days, 1:57:24, time: 1.997, data_time: 0.742, memory: 5723, decode.loss_seg: 1.2611, decode.acc_seg: 49.6963, loss: 1.2611
2021-08-14 07:58:02,695 - mmseg - INFO - Iter [24700/160000]	lr: 8.613e-03, eta: 2 days, 1:56:00, time: 1.264, data_time: 0.016, memory: 5723, decode.loss_seg: 1.2225, decode.acc_seg: 48.9931, loss: 1.2225
2021-08-14 07:59:03,401 - mmseg - INFO - Iter [24750/160000]	lr: 8.610e-03, eta: 2 days, 1:54:22, time: 1.214, data_time: 0.013, memory: 5723, decode.loss_seg: 1.2098, decode.acc_seg: 50.0964, loss: 1.2098
2021-08-14 08:00:06,302 - mmseg - INFO - Iter [24800/160000]	lr: 8.608e-03, eta: 2 days, 1:52:57, time: 1.258, data_time: 0.014, memory: 5723, decode.loss_seg: 1.2141, decode.acc_seg: 50.1088, loss: 1.2141
2021-08-14 08:01:09,103 - mmseg - INFO - Iter [24850/160000]	lr: 8.605e-03, eta: 2 days, 1:51:30, time: 1.255, data_time: 0.013, memory: 5723, decode.loss_seg: 1.2194, decode.acc_seg: 49.3890, loss: 1.2194
2021-08-14 08:02:10,728 - mmseg - INFO - Iter [24900/160000]	lr: 8.602e-03, eta: 2 days, 1:49:58, time: 1.233, data_time: 0.014, memory: 5723, decode.loss_seg: 1.2413, decode.acc_seg: 48.8268, loss: 1.2413
2021-08-14 08:03:13,919 - mmseg - INFO - Iter [24950/160000]	lr: 8.599e-03, eta: 2 days, 1:48:34, time: 1.263, data_time: 0.014, memory: 5723, decode.loss_seg: 1.2269, decode.acc_seg: 50.4593, loss: 1.2269
2021-08-14 08:04:17,323 - mmseg - INFO - Exp name: fcn_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 08:04:17,324 - mmseg - INFO - Iter [25000/160000]	lr: 8.596e-03, eta: 2 days, 1:47:12, time: 1.268, data_time: 0.013, memory: 5723, decode.loss_seg: 1.2686, decode.acc_seg: 49.3475, loss: 1.2686
2021-08-14 08:05:18,285 - mmseg - INFO - Iter [25050/160000]	lr: 8.593e-03, eta: 2 days, 1:45:36, time: 1.220, data_time: 0.015, memory: 5723, decode.loss_seg: 1.2596, decode.acc_seg: 48.7178, loss: 1.2596
2021-08-14 08:06:19,647 - mmseg - INFO - Iter [25100/160000]	lr: 8.591e-03, eta: 2 days, 1:44:03, time: 1.227, data_time: 0.013, memory: 5723, decode.loss_seg: 1.2364, decode.acc_seg: 50.3219, loss: 1.2364
2021-08-14 08:07:22,909 - mmseg - INFO - Iter [25150/160000]	lr: 8.588e-03, eta: 2 days, 1:42:40, time: 1.266, data_time: 0.014, memory: 5723, decode.loss_seg: 1.2178, decode.acc_seg: 49.4724, loss: 1.2178
2021-08-14 08:08:27,725 - mmseg - INFO - Iter [25200/160000]	lr: 8.585e-03, eta: 2 days, 1:41:25, time: 1.296, data_time: 0.015, memory: 5723, decode.loss_seg: 1.2577, decode.acc_seg: 49.2829, loss: 1.2577
2021-08-14 08:10:05,918 - mmseg - INFO - Iter [25250/160000]	lr: 8.582e-03, eta: 2 days, 1:43:09, time: 1.964, data_time: 0.660, memory: 5723, decode.loss_seg: 1.2314, decode.acc_seg: 49.8367, loss: 1.2314
2021-08-14 08:11:11,573 - mmseg - INFO - Iter [25300/160000]	lr: 8.579e-03, eta: 2 days, 1:41:59, time: 1.313, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1954, decode.acc_seg: 50.4438, loss: 1.1954
2021-08-14 08:12:12,591 - mmseg - INFO - Iter [25350/160000]	lr: 8.576e-03, eta: 2 days, 1:40:23, time: 1.219, data_time: 0.013, memory: 5723, decode.loss_seg: 1.2124, decode.acc_seg: 49.6575, loss: 1.2124
2021-08-14 08:13:17,098 - mmseg - INFO - Iter [25400/160000]	lr: 8.574e-03, eta: 2 days, 1:39:07, time: 1.291, data_time: 0.016, memory: 5723, decode.loss_seg: 1.2210, decode.acc_seg: 50.0787, loss: 1.2210
2021-08-14 08:14:21,761 - mmseg - INFO - Iter [25450/160000]	lr: 8.571e-03, eta: 2 days, 1:37:51, time: 1.292, data_time: 0.013, memory: 5723, decode.loss_seg: 1.2583, decode.acc_seg: 49.8835, loss: 1.2583
2021-08-14 08:15:26,822 - mmseg - INFO - Iter [25500/160000]	lr: 8.568e-03, eta: 2 days, 1:36:38, time: 1.301, data_time: 0.013, memory: 5723, decode.loss_seg: 1.2634, decode.acc_seg: 50.0238, loss: 1.2634
2021-08-14 08:16:32,455 - mmseg - INFO - Iter [25550/160000]	lr: 8.565e-03, eta: 2 days, 1:35:28, time: 1.313, data_time: 0.013, memory: 5723, decode.loss_seg: 1.2337, decode.acc_seg: 48.8773, loss: 1.2337
2021-08-14 08:17:36,631 - mmseg - INFO - Iter [25600/160000]	lr: 8.562e-03, eta: 2 days, 1:34:09, time: 1.283, data_time: 0.013, memory: 5723, decode.loss_seg: 1.2745, decode.acc_seg: 48.1982, loss: 1.2745
2021-08-14 08:18:40,893 - mmseg - INFO - Iter [25650/160000]	lr: 8.559e-03, eta: 2 days, 1:32:52, time: 1.285, data_time: 0.014, memory: 5723, decode.loss_seg: 1.2148, decode.acc_seg: 50.1138, loss: 1.2148
2021-08-14 08:19:43,061 - mmseg - INFO - Iter [25700/160000]	lr: 8.557e-03, eta: 2 days, 1:31:24, time: 1.244, data_time: 0.015, memory: 5723, decode.loss_seg: 1.2296, decode.acc_seg: 48.9696, loss: 1.2296
2021-08-14 08:20:46,605 - mmseg - INFO - Iter [25750/160000]	lr: 8.554e-03, eta: 2 days, 1:30:03, time: 1.271, data_time: 0.014, memory: 5723, decode.loss_seg: 1.2459, decode.acc_seg: 48.9107, loss: 1.2459
2021-08-14 08:21:48,688 - mmseg - INFO - Iter [25800/160000]	lr: 8.551e-03, eta: 2 days, 1:28:34, time: 1.240, data_time: 0.013, memory: 5723, decode.loss_seg: 1.2220, decode.acc_seg: 49.2700, loss: 1.2220
2021-08-14 08:22:52,470 - mmseg - INFO - Iter [25850/160000]	lr: 8.548e-03, eta: 2 days, 1:27:14, time: 1.277, data_time: 0.015, memory: 5723, decode.loss_seg: 1.2219, decode.acc_seg: 50.5447, loss: 1.2219
2021-08-14 08:24:29,503 - mmseg - INFO - Iter [25900/160000]	lr: 8.545e-03, eta: 2 days, 1:28:47, time: 1.941, data_time: 0.721, memory: 5723, decode.loss_seg: 1.2036, decode.acc_seg: 50.2040, loss: 1.2036
2021-08-14 08:25:30,697 - mmseg - INFO - Iter [25950/160000]	lr: 8.542e-03, eta: 2 days, 1:27:13, time: 1.223, data_time: 0.013, memory: 5723, decode.loss_seg: 1.2127, decode.acc_seg: 49.5382, loss: 1.2127
2021-08-14 08:26:33,452 - mmseg - INFO - Exp name: fcn_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 08:26:33,452 - mmseg - INFO - Iter [26000/160000]	lr: 8.540e-03, eta: 2 days, 1:25:48, time: 1.256, data_time: 0.015, memory: 5723, decode.loss_seg: 1.1872, decode.acc_seg: 50.0331, loss: 1.1872
2021-08-14 08:27:36,093 - mmseg - INFO - Iter [26050/160000]	lr: 8.537e-03, eta: 2 days, 1:24:22, time: 1.253, data_time: 0.013, memory: 5723, decode.loss_seg: 1.2237, decode.acc_seg: 49.7698, loss: 1.2237
2021-08-14 08:28:37,284 - mmseg - INFO - Iter [26100/160000]	lr: 8.534e-03, eta: 2 days, 1:22:49, time: 1.224, data_time: 0.013, memory: 5723, decode.loss_seg: 1.2041, decode.acc_seg: 50.0446, loss: 1.2041
2021-08-14 08:29:42,477 - mmseg - INFO - Iter [26150/160000]	lr: 8.531e-03, eta: 2 days, 1:21:37, time: 1.304, data_time: 0.015, memory: 5723, decode.loss_seg: 1.2282, decode.acc_seg: 48.8312, loss: 1.2282
2021-08-14 08:30:44,977 - mmseg - INFO - Iter [26200/160000]	lr: 8.528e-03, eta: 2 days, 1:20:10, time: 1.249, data_time: 0.012, memory: 5723, decode.loss_seg: 1.2427, decode.acc_seg: 49.4426, loss: 1.2427
2021-08-14 08:31:46,981 - mmseg - INFO - Iter [26250/160000]	lr: 8.525e-03, eta: 2 days, 1:18:42, time: 1.241, data_time: 0.014, memory: 5723, decode.loss_seg: 1.2164, decode.acc_seg: 48.9266, loss: 1.2164
2021-08-14 08:32:49,379 - mmseg - INFO - Iter [26300/160000]	lr: 8.523e-03, eta: 2 days, 1:17:15, time: 1.248, data_time: 0.014, memory: 5723, decode.loss_seg: 1.2413, decode.acc_seg: 48.7360, loss: 1.2413
2021-08-14 08:33:55,548 - mmseg - INFO - Iter [26350/160000]	lr: 8.520e-03, eta: 2 days, 1:16:08, time: 1.322, data_time: 0.013, memory: 5723, decode.loss_seg: 1.2440, decode.acc_seg: 50.0873, loss: 1.2440
2021-08-14 08:34:59,728 - mmseg - INFO - Iter [26400/160000]	lr: 8.517e-03, eta: 2 days, 1:14:51, time: 1.285, data_time: 0.014, memory: 5723, decode.loss_seg: 1.2245, decode.acc_seg: 51.1892, loss: 1.2245
2021-08-14 08:36:03,350 - mmseg - INFO - Iter [26450/160000]	lr: 8.514e-03, eta: 2 days, 1:13:31, time: 1.272, data_time: 0.015, memory: 5723, decode.loss_seg: 1.2342, decode.acc_seg: 49.6143, loss: 1.2342
2021-08-14 08:37:04,713 - mmseg - INFO - Iter [26500/160000]	lr: 8.511e-03, eta: 2 days, 1:11:59, time: 1.227, data_time: 0.013, memory: 5723, decode.loss_seg: 1.2014, decode.acc_seg: 50.1286, loss: 1.2014
2021-08-14 08:38:43,625 - mmseg - INFO - Iter [26550/160000]	lr: 8.508e-03, eta: 2 days, 1:13:37, time: 1.978, data_time: 0.722, memory: 5723, decode.loss_seg: 1.1698, decode.acc_seg: 50.7130, loss: 1.1698
2021-08-14 08:39:46,483 - mmseg - INFO - Iter [26600/160000]	lr: 8.506e-03, eta: 2 days, 1:12:12, time: 1.257, data_time: 0.014, memory: 5723, decode.loss_seg: 1.2293, decode.acc_seg: 49.0658, loss: 1.2293
2021-08-14 08:40:48,716 - mmseg - INFO - Iter [26650/160000]	lr: 8.503e-03, eta: 2 days, 1:10:45, time: 1.245, data_time: 0.013, memory: 5723, decode.loss_seg: 1.2318, decode.acc_seg: 48.8605, loss: 1.2318
2021-08-14 08:41:52,508 - mmseg - INFO - Iter [26700/160000]	lr: 8.500e-03, eta: 2 days, 1:09:26, time: 1.275, data_time: 0.014, memory: 5723, decode.loss_seg: 1.2225, decode.acc_seg: 49.1692, loss: 1.2225
2021-08-14 08:42:55,382 - mmseg - INFO - Iter [26750/160000]	lr: 8.497e-03, eta: 2 days, 1:08:02, time: 1.259, data_time: 0.015, memory: 5723, decode.loss_seg: 1.1792, decode.acc_seg: 50.5945, loss: 1.1792
2021-08-14 08:43:57,942 - mmseg - INFO - Iter [26800/160000]	lr: 8.494e-03, eta: 2 days, 1:06:36, time: 1.250, data_time: 0.013, memory: 5723, decode.loss_seg: 1.2162, decode.acc_seg: 49.6414, loss: 1.2162
2021-08-14 08:44:59,122 - mmseg - INFO - Iter [26850/160000]	lr: 8.491e-03, eta: 2 days, 1:05:05, time: 1.224, data_time: 0.014, memory: 5723, decode.loss_seg: 1.2304, decode.acc_seg: 49.1245, loss: 1.2304
2021-08-14 08:46:01,076 - mmseg - INFO - Iter [26900/160000]	lr: 8.489e-03, eta: 2 days, 1:03:36, time: 1.239, data_time: 0.015, memory: 5723, decode.loss_seg: 1.2243, decode.acc_seg: 49.6555, loss: 1.2243
2021-08-14 08:47:03,597 - mmseg - INFO - Iter [26950/160000]	lr: 8.486e-03, eta: 2 days, 1:02:11, time: 1.251, data_time: 0.014, memory: 5723, decode.loss_seg: 1.1938, decode.acc_seg: 50.2842, loss: 1.1938
2021-08-14 08:48:05,598 - mmseg - INFO - Exp name: fcn_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 08:48:05,599 - mmseg - INFO - Iter [27000/160000]	lr: 8.483e-03, eta: 2 days, 1:00:43, time: 1.240, data_time: 0.013, memory: 5723, decode.loss_seg: 1.2243, decode.acc_seg: 50.1263, loss: 1.2243
2021-08-14 08:49:08,252 - mmseg - INFO - Iter [27050/160000]	lr: 8.480e-03, eta: 2 days, 0:59:19, time: 1.252, data_time: 0.013, memory: 5723, decode.loss_seg: 1.2245, decode.acc_seg: 49.5929, loss: 1.2245
2021-08-14 08:50:11,806 - mmseg - INFO - Iter [27100/160000]	lr: 8.477e-03, eta: 2 days, 0:57:59, time: 1.271, data_time: 0.013, memory: 5723, decode.loss_seg: 1.2377, decode.acc_seg: 49.7523, loss: 1.2377
2021-08-14 08:51:50,364 - mmseg - INFO - Iter [27150/160000]	lr: 8.474e-03, eta: 2 days, 0:59:30, time: 1.972, data_time: 0.707, memory: 5723, decode.loss_seg: 1.2312, decode.acc_seg: 50.2729, loss: 1.2312
2021-08-14 08:52:53,676 - mmseg - INFO - Iter [27200/160000]	lr: 8.472e-03, eta: 2 days, 0:58:09, time: 1.267, data_time: 0.014, memory: 5723, decode.loss_seg: 1.2502, decode.acc_seg: 48.3825, loss: 1.2502
2021-08-14 08:53:55,981 - mmseg - INFO - Iter [27250/160000]	lr: 8.469e-03, eta: 2 days, 0:56:43, time: 1.246, data_time: 0.013, memory: 5723, decode.loss_seg: 1.2031, decode.acc_seg: 50.5175, loss: 1.2031
2021-08-14 08:54:57,143 - mmseg - INFO - Iter [27300/160000]	lr: 8.466e-03, eta: 2 days, 0:55:11, time: 1.223, data_time: 0.013, memory: 5723, decode.loss_seg: 1.1976, decode.acc_seg: 51.1711, loss: 1.1976
2021-08-14 08:56:01,301 - mmseg - INFO - Iter [27350/160000]	lr: 8.463e-03, eta: 2 days, 0:53:54, time: 1.282, data_time: 0.014, memory: 5723, decode.loss_seg: 1.1869, decode.acc_seg: 50.2460, loss: 1.1869
2021-08-14 08:57:06,177 - mmseg - INFO - Iter [27400/160000]	lr: 8.460e-03, eta: 2 days, 0:52:41, time: 1.298, data_time: 0.014, memory: 5723, decode.loss_seg: 1.2702, decode.acc_seg: 48.8753, loss: 1.2702
2021-08-14 08:58:10,824 - mmseg - INFO - Iter [27450/160000]	lr: 8.457e-03, eta: 2 days, 0:51:26, time: 1.293, data_time: 0.013, memory: 5723, decode.loss_seg: 1.2306, decode.acc_seg: 49.7787, loss: 1.2306
2021-08-14 08:59:17,666 - mmseg - INFO - Iter [27500/160000]	lr: 8.455e-03, eta: 2 days, 0:50:22, time: 1.336, data_time: 0.013, memory: 5723, decode.loss_seg: 1.1901, decode.acc_seg: 51.3678, loss: 1.1901
2021-08-14 09:00:23,305 - mmseg - INFO - Iter [27550/160000]	lr: 8.452e-03, eta: 2 days, 0:49:12, time: 1.313, data_time: 0.013, memory: 5723, decode.loss_seg: 1.2525, decode.acc_seg: 48.9048, loss: 1.2525
2021-08-14 09:01:25,577 - mmseg - INFO - Iter [27600/160000]	lr: 8.449e-03, eta: 2 days, 0:47:46, time: 1.245, data_time: 0.014, memory: 5723, decode.loss_seg: 1.2203, decode.acc_seg: 50.0081, loss: 1.2203
2021-08-14 09:02:26,347 - mmseg - INFO - Iter [27650/160000]	lr: 8.446e-03, eta: 2 days, 0:46:14, time: 1.217, data_time: 0.014, memory: 5723, decode.loss_seg: 1.2079, decode.acc_seg: 49.8556, loss: 1.2079
2021-08-14 09:03:29,566 - mmseg - INFO - Iter [27700/160000]	lr: 8.443e-03, eta: 2 days, 0:44:52, time: 1.264, data_time: 0.014, memory: 5723, decode.loss_seg: 1.1999, decode.acc_seg: 51.1221, loss: 1.1999
2021-08-14 09:04:32,644 - mmseg - INFO - Iter [27750/160000]	lr: 8.440e-03, eta: 2 days, 0:43:30, time: 1.262, data_time: 0.014, memory: 5723, decode.loss_seg: 1.2349, decode.acc_seg: 49.1926, loss: 1.2349
2021-08-14 09:06:10,544 - mmseg - INFO - Iter [27800/160000]	lr: 8.438e-03, eta: 2 days, 0:44:54, time: 1.959, data_time: 0.741, memory: 5723, decode.loss_seg: 1.2557, decode.acc_seg: 49.3857, loss: 1.2557
2021-08-14 09:07:12,151 - mmseg - INFO - Iter [27850/160000]	lr: 8.435e-03, eta: 2 days, 0:43:25, time: 1.232, data_time: 0.014, memory: 5723, decode.loss_seg: 1.1705, decode.acc_seg: 50.9388, loss: 1.1705
2021-08-14 09:08:13,930 - mmseg - INFO - Iter [27900/160000]	lr: 8.432e-03, eta: 2 days, 0:41:57, time: 1.235, data_time: 0.013, memory: 5723, decode.loss_seg: 1.2069, decode.acc_seg: 50.0155, loss: 1.2069
2021-08-14 09:09:17,282 - mmseg - INFO - Iter [27950/160000]	lr: 8.429e-03, eta: 2 days, 0:40:37, time: 1.267, data_time: 0.014, memory: 5723, decode.loss_seg: 1.1971, decode.acc_seg: 50.3755, loss: 1.1971
2021-08-14 09:10:21,177 - mmseg - INFO - Exp name: fcn_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 09:10:21,177 - mmseg - INFO - Iter [28000/160000]	lr: 8.426e-03, eta: 2 days, 0:39:19, time: 1.279, data_time: 0.014, memory: 5723, decode.loss_seg: 1.1837, decode.acc_seg: 50.3372, loss: 1.1837
2021-08-14 09:11:22,887 - mmseg - INFO - Iter [28050/160000]	lr: 8.423e-03, eta: 2 days, 0:37:51, time: 1.234, data_time: 0.014, memory: 5723, decode.loss_seg: 1.1991, decode.acc_seg: 50.7843, loss: 1.1991
2021-08-14 09:12:24,456 - mmseg - INFO - Iter [28100/160000]	lr: 8.421e-03, eta: 2 days, 0:36:22, time: 1.231, data_time: 0.013, memory: 5723, decode.loss_seg: 1.2078, decode.acc_seg: 49.7021, loss: 1.2078
2021-08-14 09:13:27,214 - mmseg - INFO - Iter [28150/160000]	lr: 8.418e-03, eta: 2 days, 0:34:59, time: 1.255, data_time: 0.014, memory: 5723, decode.loss_seg: 1.1777, decode.acc_seg: 50.6799, loss: 1.1777
2021-08-14 09:14:32,006 - mmseg - INFO - Iter [28200/160000]	lr: 8.415e-03, eta: 2 days, 0:33:45, time: 1.295, data_time: 0.013, memory: 5723, decode.loss_seg: 1.1845, decode.acc_seg: 50.9337, loss: 1.1845
2021-08-14 09:15:38,445 - mmseg - INFO - Iter [28250/160000]	lr: 8.412e-03, eta: 2 days, 0:32:39, time: 1.329, data_time: 0.014, memory: 5723, decode.loss_seg: 1.2544, decode.acc_seg: 50.3380, loss: 1.2544
2021-08-14 09:16:43,460 - mmseg - INFO - Iter [28300/160000]	lr: 8.409e-03, eta: 2 days, 0:31:27, time: 1.301, data_time: 0.013, memory: 5723, decode.loss_seg: 1.1709, decode.acc_seg: 50.5114, loss: 1.1709
2021-08-14 09:17:47,237 - mmseg - INFO - Iter [28350/160000]	lr: 8.406e-03, eta: 2 days, 0:30:09, time: 1.275, data_time: 0.014, memory: 5723, decode.loss_seg: 1.2296, decode.acc_seg: 50.6599, loss: 1.2296
2021-08-14 09:19:25,645 - mmseg - INFO - Iter [28400/160000]	lr: 8.403e-03, eta: 2 days, 0:31:31, time: 1.969, data_time: 0.691, memory: 5723, decode.loss_seg: 1.2232, decode.acc_seg: 50.5886, loss: 1.2232
2021-08-14 09:20:27,851 - mmseg - INFO - Iter [28450/160000]	lr: 8.401e-03, eta: 2 days, 0:30:06, time: 1.244, data_time: 0.013, memory: 5723, decode.loss_seg: 1.2148, decode.acc_seg: 49.8973, loss: 1.2148
2021-08-14 09:21:32,024 - mmseg - INFO - Iter [28500/160000]	lr: 8.398e-03, eta: 2 days, 0:28:49, time: 1.284, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1899, decode.acc_seg: 50.3058, loss: 1.1899
2021-08-14 09:22:36,545 - mmseg - INFO - Iter [28550/160000]	lr: 8.395e-03, eta: 2 days, 0:27:35, time: 1.290, data_time: 0.016, memory: 5723, decode.loss_seg: 1.2057, decode.acc_seg: 49.7769, loss: 1.2057
2021-08-14 09:23:39,797 - mmseg - INFO - Iter [28600/160000]	lr: 8.392e-03, eta: 2 days, 0:26:14, time: 1.265, data_time: 0.014, memory: 5723, decode.loss_seg: 1.1547, decode.acc_seg: 50.9037, loss: 1.1547
2021-08-14 09:24:42,125 - mmseg - INFO - Iter [28650/160000]	lr: 8.389e-03, eta: 2 days, 0:24:49, time: 1.246, data_time: 0.013, memory: 5723, decode.loss_seg: 1.1936, decode.acc_seg: 50.6238, loss: 1.1936
2021-08-14 09:25:47,110 - mmseg - INFO - Iter [28700/160000]	lr: 8.386e-03, eta: 2 days, 0:23:36, time: 1.300, data_time: 0.013, memory: 5723, decode.loss_seg: 1.2317, decode.acc_seg: 49.6991, loss: 1.2317
2021-08-14 09:26:47,153 - mmseg - INFO - Iter [28750/160000]	lr: 8.384e-03, eta: 2 days, 0:22:01, time: 1.201, data_time: 0.013, memory: 5723, decode.loss_seg: 1.1787, decode.acc_seg: 50.3738, loss: 1.1787
2021-08-14 09:27:49,722 - mmseg - INFO - Iter [28800/160000]	lr: 8.381e-03, eta: 2 days, 0:20:38, time: 1.251, data_time: 0.013, memory: 5723, decode.loss_seg: 1.1613, decode.acc_seg: 50.0052, loss: 1.1613
2021-08-14 09:28:53,562 - mmseg - INFO - Iter [28850/160000]	lr: 8.378e-03, eta: 2 days, 0:19:20, time: 1.277, data_time: 0.014, memory: 5723, decode.loss_seg: 1.2042, decode.acc_seg: 50.8269, loss: 1.2042
2021-08-14 09:29:55,598 - mmseg - INFO - Iter [28900/160000]	lr: 8.375e-03, eta: 2 days, 0:17:54, time: 1.240, data_time: 0.012, memory: 5723, decode.loss_seg: 1.2167, decode.acc_seg: 49.2584, loss: 1.2167
2021-08-14 09:30:58,002 - mmseg - INFO - Iter [28950/160000]	lr: 8.372e-03, eta: 2 days, 0:16:30, time: 1.248, data_time: 0.014, memory: 5723, decode.loss_seg: 1.1867, decode.acc_seg: 50.2350, loss: 1.1867
2021-08-14 09:31:59,417 - mmseg - INFO - Exp name: fcn_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 09:31:59,417 - mmseg - INFO - Iter [29000/160000]	lr: 8.369e-03, eta: 2 days, 0:15:02, time: 1.228, data_time: 0.013, memory: 5723, decode.loss_seg: 1.1908, decode.acc_seg: 49.9015, loss: 1.1908
2021-08-14 09:33:36,848 - mmseg - INFO - Iter [29050/160000]	lr: 8.367e-03, eta: 2 days, 0:16:16, time: 1.949, data_time: 0.717, memory: 5723, decode.loss_seg: 1.2198, decode.acc_seg: 50.4142, loss: 1.2198
2021-08-14 09:34:38,802 - mmseg - INFO - Iter [29100/160000]	lr: 8.364e-03, eta: 2 days, 0:14:50, time: 1.238, data_time: 0.013, memory: 5723, decode.loss_seg: 1.1816, decode.acc_seg: 49.6271, loss: 1.1816
2021-08-14 09:35:42,393 - mmseg - INFO - Iter [29150/160000]	lr: 8.361e-03, eta: 2 days, 0:13:31, time: 1.272, data_time: 0.013, memory: 5723, decode.loss_seg: 1.1730, decode.acc_seg: 50.9302, loss: 1.1730
2021-08-14 09:36:49,052 - mmseg - INFO - Iter [29200/160000]	lr: 8.358e-03, eta: 2 days, 0:12:26, time: 1.333, data_time: 0.015, memory: 5723, decode.loss_seg: 1.2091, decode.acc_seg: 50.0339, loss: 1.2091
2021-08-14 09:37:54,730 - mmseg - INFO - Iter [29250/160000]	lr: 8.355e-03, eta: 2 days, 0:11:17, time: 1.314, data_time: 0.013, memory: 5723, decode.loss_seg: 1.1636, decode.acc_seg: 50.4966, loss: 1.1636
2021-08-14 09:38:59,910 - mmseg - INFO - Iter [29300/160000]	lr: 8.352e-03, eta: 2 days, 0:10:05, time: 1.303, data_time: 0.012, memory: 5723, decode.loss_seg: 1.1638, decode.acc_seg: 51.0077, loss: 1.1638
2021-08-14 09:40:06,052 - mmseg - INFO - Iter [29350/160000]	lr: 8.350e-03, eta: 2 days, 0:08:58, time: 1.322, data_time: 0.013, memory: 5723, decode.loss_seg: 1.1881, decode.acc_seg: 50.4622, loss: 1.1881
2021-08-14 09:41:10,685 - mmseg - INFO - Iter [29400/160000]	lr: 8.347e-03, eta: 2 days, 0:07:44, time: 1.294, data_time: 0.016, memory: 5723, decode.loss_seg: 1.2108, decode.acc_seg: 50.2249, loss: 1.2108
2021-08-14 09:42:14,816 - mmseg - INFO - Iter [29450/160000]	lr: 8.344e-03, eta: 2 days, 0:06:28, time: 1.282, data_time: 0.014, memory: 5723, decode.loss_seg: 1.2134, decode.acc_seg: 49.8702, loss: 1.2134
2021-08-14 09:43:15,955 - mmseg - INFO - Iter [29500/160000]	lr: 8.341e-03, eta: 2 days, 0:04:59, time: 1.222, data_time: 0.013, memory: 5723, decode.loss_seg: 1.2081, decode.acc_seg: 50.5424, loss: 1.2081
2021-08-14 09:44:20,712 - mmseg - INFO - Iter [29550/160000]	lr: 8.338e-03, eta: 2 days, 0:03:46, time: 1.294, data_time: 0.013, memory: 5723, decode.loss_seg: 1.2113, decode.acc_seg: 50.6059, loss: 1.2113
2021-08-14 09:45:27,659 - mmseg - INFO - Iter [29600/160000]	lr: 8.335e-03, eta: 2 days, 0:02:42, time: 1.340, data_time: 0.014, memory: 5723, decode.loss_seg: 1.2122, decode.acc_seg: 49.7296, loss: 1.2122
2021-08-14 09:46:28,054 - mmseg - INFO - Iter [29650/160000]	lr: 8.332e-03, eta: 2 days, 0:01:10, time: 1.208, data_time: 0.013, memory: 5723, decode.loss_seg: 1.1584, decode.acc_seg: 50.4724, loss: 1.1584
2021-08-14 09:48:05,379 - mmseg - INFO - Iter [29700/160000]	lr: 8.330e-03, eta: 2 days, 0:02:20, time: 1.947, data_time: 0.684, memory: 5723, decode.loss_seg: 1.1446, decode.acc_seg: 50.1012, loss: 1.1446
2021-08-14 09:49:10,251 - mmseg - INFO - Iter [29750/160000]	lr: 8.327e-03, eta: 2 days, 0:01:07, time: 1.297, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1761, decode.acc_seg: 50.5777, loss: 1.1761
2021-08-14 09:50:12,313 - mmseg - INFO - Iter [29800/160000]	lr: 8.324e-03, eta: 1 day, 23:59:41, time: 1.239, data_time: 0.013, memory: 5723, decode.loss_seg: 1.1817, decode.acc_seg: 50.5695, loss: 1.1817
2021-08-14 09:51:17,990 - mmseg - INFO - Iter [29850/160000]	lr: 8.321e-03, eta: 1 day, 23:58:32, time: 1.314, data_time: 0.014, memory: 5723, decode.loss_seg: 1.2506, decode.acc_seg: 50.0609, loss: 1.2506
2021-08-14 09:52:22,278 - mmseg - INFO - Iter [29900/160000]	lr: 8.318e-03, eta: 1 day, 23:57:17, time: 1.287, data_time: 0.015, memory: 5723, decode.loss_seg: 1.1822, decode.acc_seg: 50.2970, loss: 1.1822
2021-08-14 09:53:24,516 - mmseg - INFO - Iter [29950/160000]	lr: 8.315e-03, eta: 1 day, 23:55:53, time: 1.245, data_time: 0.013, memory: 5723, decode.loss_seg: 1.1604, decode.acc_seg: 51.0370, loss: 1.1604
2021-08-14 09:54:27,148 - mmseg - INFO - Exp name: fcn_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 09:54:27,149 - mmseg - INFO - Iter [30000/160000]	lr: 8.313e-03, eta: 1 day, 23:54:30, time: 1.253, data_time: 0.013, memory: 5723, decode.loss_seg: 1.1950, decode.acc_seg: 50.0326, loss: 1.1950
2021-08-14 09:55:29,043 - mmseg - INFO - Iter [30050/160000]	lr: 8.310e-03, eta: 1 day, 23:53:05, time: 1.238, data_time: 0.013, memory: 5723, decode.loss_seg: 1.1861, decode.acc_seg: 50.9952, loss: 1.1861
2021-08-14 09:56:31,373 - mmseg - INFO - Iter [30100/160000]	lr: 8.307e-03, eta: 1 day, 23:51:41, time: 1.246, data_time: 0.013, memory: 5723, decode.loss_seg: 1.1812, decode.acc_seg: 50.2911, loss: 1.1812
2021-08-14 09:57:37,964 - mmseg - INFO - Iter [30150/160000]	lr: 8.304e-03, eta: 1 day, 23:50:36, time: 1.331, data_time: 0.014, memory: 5723, decode.loss_seg: 1.1925, decode.acc_seg: 51.1334, loss: 1.1925
2021-08-14 09:58:39,440 - mmseg - INFO - Iter [30200/160000]	lr: 8.301e-03, eta: 1 day, 23:49:09, time: 1.231, data_time: 0.015, memory: 5723, decode.loss_seg: 1.2025, decode.acc_seg: 49.7591, loss: 1.2025
2021-08-14 09:59:42,130 - mmseg - INFO - Iter [30250/160000]	lr: 8.298e-03, eta: 1 day, 23:47:47, time: 1.253, data_time: 0.015, memory: 5723, decode.loss_seg: 1.1974, decode.acc_seg: 51.0601, loss: 1.1974
2021-08-14 10:01:18,913 - mmseg - INFO - Iter [30300/160000]	lr: 8.296e-03, eta: 1 day, 23:48:51, time: 1.936, data_time: 0.725, memory: 5723, decode.loss_seg: 1.2316, decode.acc_seg: 48.7272, loss: 1.2316
2021-08-14 10:02:24,912 - mmseg - INFO - Iter [30350/160000]	lr: 8.293e-03, eta: 1 day, 23:47:43, time: 1.319, data_time: 0.013, memory: 5723, decode.loss_seg: 1.1832, decode.acc_seg: 49.7832, loss: 1.1832
2021-08-14 10:03:26,288 - mmseg - INFO - Iter [30400/160000]	lr: 8.290e-03, eta: 1 day, 23:46:16, time: 1.229, data_time: 0.014, memory: 5723, decode.loss_seg: 1.1832, decode.acc_seg: 51.2208, loss: 1.1832
2021-08-14 10:04:27,730 - mmseg - INFO - Iter [30450/160000]	lr: 8.287e-03, eta: 1 day, 23:44:49, time: 1.229, data_time: 0.015, memory: 5723, decode.loss_seg: 1.1972, decode.acc_seg: 50.8408, loss: 1.1972
2021-08-14 10:05:30,342 - mmseg - INFO - Iter [30500/160000]	lr: 8.284e-03, eta: 1 day, 23:43:26, time: 1.251, data_time: 0.012, memory: 5723, decode.loss_seg: 1.1802, decode.acc_seg: 50.4633, loss: 1.1802
2021-08-14 10:06:30,797 - mmseg - INFO - Iter [30550/160000]	lr: 8.281e-03, eta: 1 day, 23:41:55, time: 1.209, data_time: 0.014, memory: 5723, decode.loss_seg: 1.1620, decode.acc_seg: 49.7145, loss: 1.1620
2021-08-14 10:07:33,359 - mmseg - INFO - Iter [30600/160000]	lr: 8.278e-03, eta: 1 day, 23:40:33, time: 1.251, data_time: 0.013, memory: 5723, decode.loss_seg: 1.1661, decode.acc_seg: 50.3332, loss: 1.1661
2021-08-14 10:08:34,823 - mmseg - INFO - Iter [30650/160000]	lr: 8.276e-03, eta: 1 day, 23:39:06, time: 1.230, data_time: 0.013, memory: 5723, decode.loss_seg: 1.1795, decode.acc_seg: 51.1813, loss: 1.1795
2021-08-14 10:09:39,091 - mmseg - INFO - Iter [30700/160000]	lr: 8.273e-03, eta: 1 day, 23:37:51, time: 1.285, data_time: 0.015, memory: 5723, decode.loss_seg: 1.1846, decode.acc_seg: 51.0044, loss: 1.1846
2021-08-14 10:10:41,574 - mmseg - INFO - Iter [30750/160000]	lr: 8.270e-03, eta: 1 day, 23:36:29, time: 1.250, data_time: 0.015, memory: 5723, decode.loss_seg: 1.2298, decode.acc_seg: 49.0908, loss: 1.2298
2021-08-14 10:11:44,035 - mmseg - INFO - Iter [30800/160000]	lr: 8.267e-03, eta: 1 day, 23:35:06, time: 1.248, data_time: 0.013, memory: 5723, decode.loss_seg: 1.1929, decode.acc_seg: 50.2875, loss: 1.1929
2021-08-14 10:12:47,035 - mmseg - INFO - Iter [30850/160000]	lr: 8.264e-03, eta: 1 day, 23:33:46, time: 1.261, data_time: 0.014, memory: 5723, decode.loss_seg: 1.1670, decode.acc_seg: 50.9648, loss: 1.1670
2021-08-14 10:13:49,862 - mmseg - INFO - Iter [30900/160000]	lr: 8.261e-03, eta: 1 day, 23:32:26, time: 1.257, data_time: 0.012, memory: 5723, decode.loss_seg: 1.2138, decode.acc_seg: 50.2627, loss: 1.2138
2021-08-14 10:15:29,157 - mmseg - INFO - Iter [30950/160000]	lr: 8.259e-03, eta: 1 day, 23:33:37, time: 1.985, data_time: 0.706, memory: 5723, decode.loss_seg: 1.1868, decode.acc_seg: 50.6539, loss: 1.1868
2021-08-14 10:16:30,733 - mmseg - INFO - Exp name: fcn_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 10:16:30,733 - mmseg - INFO - Iter [31000/160000]	lr: 8.256e-03, eta: 1 day, 23:32:10, time: 1.231, data_time: 0.013, memory: 5723, decode.loss_seg: 1.1528, decode.acc_seg: 51.4294, loss: 1.1528
2021-08-14 10:17:34,319 - mmseg - INFO - Iter [31050/160000]	lr: 8.253e-03, eta: 1 day, 23:30:53, time: 1.272, data_time: 0.015, memory: 5723, decode.loss_seg: 1.1718, decode.acc_seg: 50.6524, loss: 1.1718
2021-08-14 10:18:36,387 - mmseg - INFO - Iter [31100/160000]	lr: 8.250e-03, eta: 1 day, 23:29:29, time: 1.242, data_time: 0.015, memory: 5723, decode.loss_seg: 1.1488, decode.acc_seg: 50.9011, loss: 1.1488
2021-08-14 10:19:42,278 - mmseg - INFO - Iter [31150/160000]	lr: 8.247e-03, eta: 1 day, 23:28:21, time: 1.317, data_time: 0.012, memory: 5723, decode.loss_seg: 1.1818, decode.acc_seg: 49.9167, loss: 1.1818
2021-08-14 10:20:49,274 - mmseg - INFO - Iter [31200/160000]	lr: 8.244e-03, eta: 1 day, 23:27:17, time: 1.340, data_time: 0.014, memory: 5723, decode.loss_seg: 1.2266, decode.acc_seg: 49.6838, loss: 1.2266
2021-08-14 10:21:51,436 - mmseg - INFO - Iter [31250/160000]	lr: 8.241e-03, eta: 1 day, 23:25:54, time: 1.244, data_time: 0.013, memory: 5723, decode.loss_seg: 1.1893, decode.acc_seg: 50.8443, loss: 1.1893
2021-08-14 10:22:53,421 - mmseg - INFO - Iter [31300/160000]	lr: 8.239e-03, eta: 1 day, 23:24:30, time: 1.240, data_time: 0.014, memory: 5723, decode.loss_seg: 1.1730, decode.acc_seg: 51.0293, loss: 1.1730
2021-08-14 10:23:58,844 - mmseg - INFO - Iter [31350/160000]	lr: 8.236e-03, eta: 1 day, 23:23:20, time: 1.308, data_time: 0.014, memory: 5723, decode.loss_seg: 1.2088, decode.acc_seg: 50.7621, loss: 1.2088
2021-08-14 10:25:01,562 - mmseg - INFO - Iter [31400/160000]	lr: 8.233e-03, eta: 1 day, 23:21:59, time: 1.255, data_time: 0.015, memory: 5723, decode.loss_seg: 1.2011, decode.acc_seg: 50.8661, loss: 1.2011
2021-08-14 10:26:04,593 - mmseg - INFO - Iter [31450/160000]	lr: 8.230e-03, eta: 1 day, 23:20:39, time: 1.261, data_time: 0.014, memory: 5723, decode.loss_seg: 1.1951, decode.acc_seg: 50.2462, loss: 1.1951
2021-08-14 10:27:08,799 - mmseg - INFO - Iter [31500/160000]	lr: 8.227e-03, eta: 1 day, 23:19:24, time: 1.283, data_time: 0.014, memory: 5723, decode.loss_seg: 1.2001, decode.acc_seg: 49.3969, loss: 1.2001
2021-08-14 10:28:11,179 - mmseg - INFO - Iter [31550/160000]	lr: 8.224e-03, eta: 1 day, 23:18:02, time: 1.248, data_time: 0.013, memory: 5723, decode.loss_seg: 1.1805, decode.acc_seg: 50.6779, loss: 1.1805
2021-08-14 10:29:49,267 - mmseg - INFO - Iter [31600/160000]	lr: 8.222e-03, eta: 1 day, 23:19:05, time: 1.961, data_time: 0.725, memory: 5723, decode.loss_seg: 1.1451, decode.acc_seg: 51.1211, loss: 1.1451
2021-08-14 10:30:52,901 - mmseg - INFO - Iter [31650/160000]	lr: 8.219e-03, eta: 1 day, 23:17:48, time: 1.273, data_time: 0.015, memory: 5723, decode.loss_seg: 1.1532, decode.acc_seg: 52.0522, loss: 1.1532
2021-08-14 10:31:56,795 - mmseg - INFO - Iter [31700/160000]	lr: 8.216e-03, eta: 1 day, 23:16:32, time: 1.277, data_time: 0.015, memory: 5723, decode.loss_seg: 1.1757, decode.acc_seg: 50.9991, loss: 1.1757
2021-08-14 10:32:59,599 - mmseg - INFO - Iter [31750/160000]	lr: 8.213e-03, eta: 1 day, 23:15:11, time: 1.256, data_time: 0.014, memory: 5723, decode.loss_seg: 1.1448, decode.acc_seg: 51.1601, loss: 1.1448
2021-08-14 10:34:01,190 - mmseg - INFO - Iter [31800/160000]	lr: 8.210e-03, eta: 1 day, 23:13:46, time: 1.232, data_time: 0.014, memory: 5723, decode.loss_seg: 1.1853, decode.acc_seg: 50.5842, loss: 1.1853
2021-08-14 10:35:03,147 - mmseg - INFO - Iter [31850/160000]	lr: 8.207e-03, eta: 1 day, 23:12:22, time: 1.239, data_time: 0.013, memory: 5723, decode.loss_seg: 1.1781, decode.acc_seg: 49.4810, loss: 1.1781
2021-08-14 10:36:03,835 - mmseg - INFO - Iter [31900/160000]	lr: 8.204e-03, eta: 1 day, 23:10:53, time: 1.214, data_time: 0.012, memory: 5723, decode.loss_seg: 1.1978, decode.acc_seg: 49.9531, loss: 1.1978
2021-08-14 10:37:04,088 - mmseg - INFO - Iter [31950/160000]	lr: 8.202e-03, eta: 1 day, 23:09:22, time: 1.205, data_time: 0.013, memory: 5723, decode.loss_seg: 1.1598, decode.acc_seg: 51.0876, loss: 1.1598
2021-08-14 10:38:06,962 - mmseg - INFO - Saving checkpoint at 32000 iterations
2021-08-14 10:38:07,348 - mmseg - INFO - Exp name: fcn_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 10:38:07,351 - mmseg - INFO - Iter [32000/160000]	lr: 8.199e-03, eta: 1 day, 23:08:04, time: 1.265, data_time: 0.015, memory: 5723, decode.loss_seg: 1.2014, decode.acc_seg: 50.8039, loss: 1.2014
2021-08-14 10:40:42,352 - mmseg - INFO - per class results:
2021-08-14 10:40:42,362 - mmseg - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        | 52.17 | 82.51 |
|       building      | 63.69 | 75.12 |
|         sky         | 87.21 | 92.71 |
|        floor        | 52.97 | 81.85 |
|         tree        | 56.99 | 82.88 |
|       ceiling       | 64.15 | 76.75 |
|         road        | 60.35 | 85.04 |
|         bed         | 54.77 | 79.84 |
|      windowpane     | 39.76 | 64.35 |
|        grass        | 53.64 | 72.03 |
|       cabinet       | 33.08 | 64.97 |
|       sidewalk      | 24.32 | 28.75 |
|        person       | 35.31 | 43.74 |
|        earth        | 16.64 | 23.12 |
|         door        | 13.16 | 17.48 |
|        table        | 23.67 | 33.46 |
|       mountain      | 32.65 | 54.95 |
|        plant        | 22.57 | 26.26 |
|       curtain       | 35.74 | 53.73 |
|        chair        | 18.67 | 25.13 |
|         car         | 47.61 | 72.64 |
|        water        | 26.98 | 54.47 |
|       painting      | 44.93 | 58.44 |
|         sofa        | 22.39 | 29.04 |
|        shelf        | 15.97 | 32.28 |
|        house        | 29.91 | 44.05 |
|         sea         | 27.25 |  69.9 |
|        mirror       |  2.52 |  2.61 |
|         rug         | 11.62 | 12.04 |
|        field        | 19.61 | 45.16 |
|       armchair      |  3.78 |  4.03 |
|         seat        | 16.49 | 23.85 |
|        fence        | 13.79 | 19.67 |
|         desk        |  6.28 |  7.21 |
|         rock        |  5.66 |  7.19 |
|       wardrobe      |  0.33 |  0.33 |
|         lamp        | 21.41 | 25.67 |
|       bathtub       | 23.03 | 28.76 |
|       railing       |  7.15 |  7.98 |
|       cushion       | 11.75 | 15.23 |
|         base        |  0.05 |  0.05 |
|         box         |  0.01 |  0.01 |
|        column       |  0.0  |  0.0  |
|      signboard      |  4.02 |  4.28 |
|   chest of drawers  |  9.17 | 10.13 |
|       counter       |  4.59 |  4.92 |
|         sand        |  5.14 |  5.43 |
|         sink        | 13.92 | 16.26 |
|      skyscraper     | 35.67 | 73.68 |
|      fireplace      | 33.24 |  35.6 |
|     refrigerator    | 15.39 | 19.63 |
|      grandstand     | 11.95 | 31.57 |
|         path        |  1.65 |  1.68 |
|        stairs       |  1.75 |  1.76 |
|        runway       | 32.72 | 38.41 |
|         case        |  2.59 |  2.82 |
|      pool table     | 51.76 | 69.26 |
|        pillow       | 22.18 | 26.89 |
|     screen door     |  0.11 |  0.11 |
|       stairway      |  8.11 | 13.91 |
|        river        |  0.12 |  0.12 |
|        bridge       |  0.96 |  1.06 |
|       bookcase      |  7.19 |  7.74 |
|        blind        |  0.0  |  0.0  |
|     coffee table    | 12.76 |  15.2 |
|        toilet       | 35.64 | 42.17 |
|        flower       |  3.98 |  4.25 |
|         book        |  3.38 |  3.42 |
|         hill        |  0.88 |  0.95 |
|        bench        |  3.79 |  3.83 |
|      countertop     |  0.54 |  0.55 |
|        stove        | 17.53 | 21.76 |
|         palm        |  0.0  |  0.0  |
|    kitchen island   |  0.0  |  0.0  |
|       computer      | 15.04 | 17.18 |
|     swivel chair    |  0.68 |  0.68 |
|         boat        |  0.55 |  0.56 |
|         bar         |  0.0  |  0.0  |
|    arcade machine   |  0.11 |  0.13 |
|        hovel        |  0.7  |  0.7  |
|         bus         | 18.46 | 24.77 |
|        towel        |  0.0  |  0.0  |
|        light        |  2.25 |  2.3  |
|        truck        |  0.0  |  0.0  |
|        tower        |  0.0  |  0.0  |
|      chandelier     | 32.99 | 43.55 |
|        awning       |  0.0  |  0.0  |
|     streetlight     |  0.0  |  0.0  |
|        booth        |  0.0  |  0.0  |
| television receiver | 10.21 | 11.96 |
|       airplane      |  5.56 |  6.57 |
|      dirt track     |  0.0  |  0.0  |
|       apparel       |  0.0  |  0.0  |
|         pole        |  0.0  |  0.0  |
|         land        |  0.0  |  0.0  |
|      bannister      |  0.0  |  0.0  |
|      escalator      |  0.02 |  0.02 |
|       ottoman       |  0.0  |  0.0  |
|        bottle       |  0.0  |  0.0  |
|        buffet       |  0.0  |  0.0  |
|        poster       |  0.0  |  0.0  |
|        stage        |  0.0  |  0.0  |
|         van         |  0.0  |  0.0  |
|         ship        |  0.0  |  0.0  |
|       fountain      |  0.0  |  0.0  |
|    conveyer belt    |  0.0  |  0.0  |
|        canopy       |  0.0  |  0.0  |
|        washer       | 23.91 | 32.05 |
|      plaything      |  0.0  |  0.0  |
|    swimming pool    |  2.89 |  3.13 |
|        stool        |  0.0  |  0.0  |
|        barrel       |  0.0  |  0.0  |
|        basket       |  0.0  |  0.0  |
|      waterfall      | 27.91 |  47.4 |
|         tent        | 17.77 | 26.72 |
|         bag         |  0.0  |  0.0  |
|       minibike      |  0.0  |  0.0  |
|        cradle       | 33.63 | 37.92 |
|         oven        |  0.0  |  0.0  |
|         ball        |  6.3  | 11.44 |
|         food        |  1.6  |  1.77 |
|         step        |  0.0  |  0.0  |
|         tank        |  0.0  |  0.0  |
|      trade name     |  0.0  |  0.0  |
|      microwave      |  0.58 |  0.58 |
|         pot         |  0.0  |  0.0  |
|        animal       |  0.0  |  0.0  |
|       bicycle       |  0.0  |  0.0  |
|         lake        |  0.0  |  0.0  |
|      dishwasher     |  0.0  |  0.0  |
|        screen       | 32.39 | 37.77 |
|       blanket       |  0.0  |  0.0  |
|      sculpture      |  0.0  |  0.0  |
|         hood        |  0.0  |  0.0  |
|        sconce       |  0.0  |  0.0  |
|         vase        |  0.0  |  0.0  |
|    traffic light    |  0.0  |  0.0  |
|         tray        |  0.0  |  0.0  |
|        ashcan       |  0.0  |  0.0  |
|         fan         |  0.0  |  0.0  |
|         pier        |  0.0  |  0.0  |
|      crt screen     |  0.0  |  0.0  |
|        plate        |  0.0  |  0.0  |
|       monitor       |  0.0  |  0.0  |
|    bulletin board   |  0.0  |  0.0  |
|        shower       |  0.0  |  0.0  |
|       radiator      |  0.0  |  0.0  |
|        glass        |  0.0  |  0.0  |
|        clock        |  0.0  |  0.0  |
|         flag        |  0.0  |  0.0  |
+---------------------+-------+-------+
2021-08-14 10:40:42,363 - mmseg - INFO - Summary:
2021-08-14 10:40:42,363 - mmseg - INFO - 
+-------+-------+------+
|  aAcc |  mIoU | mAcc |
+-------+-------+------+
| 63.12 | 11.83 | 16.6 |
+-------+-------+------+
2021-08-14 10:40:42,583 - mmseg - INFO - Exp name: fcn_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 10:40:42,584 - mmseg - INFO - Iter(val) [250]	aAcc: 0.6312, mIoU: 0.1183, mAcc: 0.1660, IoU.wall: 0.5217, IoU.building: 0.6369, IoU.sky: 0.8721, IoU.floor: 0.5297, IoU.tree: 0.5699, IoU.ceiling: 0.6415, IoU.road: 0.6035, IoU.bed : 0.5477, IoU.windowpane: 0.3976, IoU.grass: 0.5364, IoU.cabinet: 0.3308, IoU.sidewalk: 0.2432, IoU.person: 0.3531, IoU.earth: 0.1664, IoU.door: 0.1316, IoU.table: 0.2367, IoU.mountain: 0.3265, IoU.plant: 0.2257, IoU.curtain: 0.3574, IoU.chair: 0.1867, IoU.car: 0.4761, IoU.water: 0.2698, IoU.painting: 0.4493, IoU.sofa: 0.2239, IoU.shelf: 0.1597, IoU.house: 0.2991, IoU.sea: 0.2725, IoU.mirror: 0.0252, IoU.rug: 0.1162, IoU.field: 0.1961, IoU.armchair: 0.0378, IoU.seat: 0.1649, IoU.fence: 0.1379, IoU.desk: 0.0628, IoU.rock: 0.0566, IoU.wardrobe: 0.0033, IoU.lamp: 0.2141, IoU.bathtub: 0.2303, IoU.railing: 0.0715, IoU.cushion: 0.1175, IoU.base: 0.0005, IoU.box: 0.0001, IoU.column: 0.0000, IoU.signboard: 0.0402, IoU.chest of drawers: 0.0917, IoU.counter: 0.0459, IoU.sand: 0.0514, IoU.sink: 0.1392, IoU.skyscraper: 0.3567, IoU.fireplace: 0.3324, IoU.refrigerator: 0.1539, IoU.grandstand: 0.1195, IoU.path: 0.0165, IoU.stairs: 0.0175, IoU.runway: 0.3272, IoU.case: 0.0259, IoU.pool table: 0.5176, IoU.pillow: 0.2218, IoU.screen door: 0.0011, IoU.stairway: 0.0811, IoU.river: 0.0012, IoU.bridge: 0.0096, IoU.bookcase: 0.0719, IoU.blind: 0.0000, IoU.coffee table: 0.1276, IoU.toilet: 0.3564, IoU.flower: 0.0398, IoU.book: 0.0338, IoU.hill: 0.0088, IoU.bench: 0.0379, IoU.countertop: 0.0054, IoU.stove: 0.1753, IoU.palm: 0.0000, IoU.kitchen island: 0.0000, IoU.computer: 0.1504, IoU.swivel chair: 0.0068, IoU.boat: 0.0055, IoU.bar: 0.0000, IoU.arcade machine: 0.0011, IoU.hovel: 0.0070, IoU.bus: 0.1846, IoU.towel: 0.0000, IoU.light: 0.0225, IoU.truck: 0.0000, IoU.tower: 0.0000, IoU.chandelier: 0.3299, IoU.awning: 0.0000, IoU.streetlight: 0.0000, IoU.booth: 0.0000, IoU.television receiver: 0.1021, IoU.airplane: 0.0556, IoU.dirt track: 0.0000, IoU.apparel: 0.0000, IoU.pole: 0.0000, IoU.land: 0.0000, IoU.bannister: 0.0000, IoU.escalator: 0.0002, IoU.ottoman: 0.0000, IoU.bottle: 0.0000, IoU.buffet: 0.0000, IoU.poster: 0.0000, IoU.stage: 0.0000, IoU.van: 0.0000, IoU.ship: 0.0000, IoU.fountain: 0.0000, IoU.conveyer belt: 0.0000, IoU.canopy: 0.0000, IoU.washer: 0.2391, IoU.plaything: 0.0000, IoU.swimming pool: 0.0289, IoU.stool: 0.0000, IoU.barrel: 0.0000, IoU.basket: 0.0000, IoU.waterfall: 0.2791, IoU.tent: 0.1777, IoU.bag: 0.0000, IoU.minibike: 0.0000, IoU.cradle: 0.3363, IoU.oven: 0.0000, IoU.ball: 0.0630, IoU.food: 0.0160, IoU.step: 0.0000, IoU.tank: 0.0000, IoU.trade name: 0.0000, IoU.microwave: 0.0058, IoU.pot: 0.0000, IoU.animal: 0.0000, IoU.bicycle: 0.0000, IoU.lake: 0.0000, IoU.dishwasher: 0.0000, IoU.screen: 0.3239, IoU.blanket: 0.0000, IoU.sculpture: 0.0000, IoU.hood: 0.0000, IoU.sconce: 0.0000, IoU.vase: 0.0000, IoU.traffic light: 0.0000, IoU.tray: 0.0000, IoU.ashcan: 0.0000, IoU.fan: 0.0000, IoU.pier: 0.0000, IoU.crt screen: 0.0000, IoU.plate: 0.0000, IoU.monitor: 0.0000, IoU.bulletin board: 0.0000, IoU.shower: 0.0000, IoU.radiator: 0.0000, IoU.glass: 0.0000, IoU.clock: 0.0000, IoU.flag: 0.0000, Acc.wall: 0.8251, Acc.building: 0.7512, Acc.sky: 0.9271, Acc.floor: 0.8185, Acc.tree: 0.8288, Acc.ceiling: 0.7675, Acc.road: 0.8504, Acc.bed : 0.7984, Acc.windowpane: 0.6435, Acc.grass: 0.7203, Acc.cabinet: 0.6497, Acc.sidewalk: 0.2875, Acc.person: 0.4374, Acc.earth: 0.2312, Acc.door: 0.1748, Acc.table: 0.3346, Acc.mountain: 0.5495, Acc.plant: 0.2626, Acc.curtain: 0.5373, Acc.chair: 0.2513, Acc.car: 0.7264, Acc.water: 0.5447, Acc.painting: 0.5844, Acc.sofa: 0.2904, Acc.shelf: 0.3228, Acc.house: 0.4405, Acc.sea: 0.6990, Acc.mirror: 0.0261, Acc.rug: 0.1204, Acc.field: 0.4516, Acc.armchair: 0.0403, Acc.seat: 0.2385, Acc.fence: 0.1967, Acc.desk: 0.0721, Acc.rock: 0.0719, Acc.wardrobe: 0.0033, Acc.lamp: 0.2567, Acc.bathtub: 0.2876, Acc.railing: 0.0798, Acc.cushion: 0.1523, Acc.base: 0.0005, Acc.box: 0.0001, Acc.column: 0.0000, Acc.signboard: 0.0428, Acc.chest of drawers: 0.1013, Acc.counter: 0.0492, Acc.sand: 0.0543, Acc.sink: 0.1626, Acc.skyscraper: 0.7368, Acc.fireplace: 0.3560, Acc.refrigerator: 0.1963, Acc.grandstand: 0.3157, Acc.path: 0.0168, Acc.stairs: 0.0176, Acc.runway: 0.3841, Acc.case: 0.0282, Acc.pool table: 0.6926, Acc.pillow: 0.2689, Acc.screen door: 0.0011, Acc.stairway: 0.1391, Acc.river: 0.0012, Acc.bridge: 0.0106, Acc.bookcase: 0.0774, Acc.blind: 0.0000, Acc.coffee table: 0.1520, Acc.toilet: 0.4217, Acc.flower: 0.0425, Acc.book: 0.0342, Acc.hill: 0.0095, Acc.bench: 0.0383, Acc.countertop: 0.0055, Acc.stove: 0.2176, Acc.palm: 0.0000, Acc.kitchen island: 0.0000, Acc.computer: 0.1718, Acc.swivel chair: 0.0068, Acc.boat: 0.0056, Acc.bar: 0.0000, Acc.arcade machine: 0.0013, Acc.hovel: 0.0070, Acc.bus: 0.2477, Acc.towel: 0.0000, Acc.light: 0.0230, Acc.truck: 0.0000, Acc.tower: 0.0000, Acc.chandelier: 0.4355, Acc.awning: 0.0000, Acc.streetlight: 0.0000, Acc.booth: 0.0000, Acc.television receiver: 0.1196, Acc.airplane: 0.0657, Acc.dirt track: 0.0000, Acc.apparel: 0.0000, Acc.pole: 0.0000, Acc.land: 0.0000, Acc.bannister: 0.0000, Acc.escalator: 0.0002, Acc.ottoman: 0.0000, Acc.bottle: 0.0000, Acc.buffet: 0.0000, Acc.poster: 0.0000, Acc.stage: 0.0000, Acc.van: 0.0000, Acc.ship: 0.0000, Acc.fountain: 0.0000, Acc.conveyer belt: 0.0000, Acc.canopy: 0.0000, Acc.washer: 0.3205, Acc.plaything: 0.0000, Acc.swimming pool: 0.0313, Acc.stool: 0.0000, Acc.barrel: 0.0000, Acc.basket: 0.0000, Acc.waterfall: 0.4740, Acc.tent: 0.2672, Acc.bag: 0.0000, Acc.minibike: 0.0000, Acc.cradle: 0.3792, Acc.oven: 0.0000, Acc.ball: 0.1144, Acc.food: 0.0177, Acc.step: 0.0000, Acc.tank: 0.0000, Acc.trade name: 0.0000, Acc.microwave: 0.0058, Acc.pot: 0.0000, Acc.animal: 0.0000, Acc.bicycle: 0.0000, Acc.lake: 0.0000, Acc.dishwasher: 0.0000, Acc.screen: 0.3777, Acc.blanket: 0.0000, Acc.sculpture: 0.0000, Acc.hood: 0.0000, Acc.sconce: 0.0000, Acc.vase: 0.0000, Acc.traffic light: 0.0000, Acc.tray: 0.0000, Acc.ashcan: 0.0000, Acc.fan: 0.0000, Acc.pier: 0.0000, Acc.crt screen: 0.0000, Acc.plate: 0.0000, Acc.monitor: 0.0000, Acc.bulletin board: 0.0000, Acc.shower: 0.0000, Acc.radiator: 0.0000, Acc.glass: 0.0000, Acc.clock: 0.0000, Acc.flag: 0.0000
2021-08-14 10:41:46,590 - mmseg - INFO - Iter [32050/160000]	lr: 8.196e-03, eta: 1 day, 23:17:08, time: 4.384, data_time: 3.119, memory: 5723, decode.loss_seg: 1.1711, decode.acc_seg: 50.9591, loss: 1.1711
2021-08-14 10:42:52,389 - mmseg - INFO - Iter [32100/160000]	lr: 8.193e-03, eta: 1 day, 23:15:59, time: 1.315, data_time: 0.013, memory: 5723, decode.loss_seg: 1.1809, decode.acc_seg: 50.5320, loss: 1.1809
2021-08-14 10:43:58,044 - mmseg - INFO - Iter [32150/160000]	lr: 8.190e-03, eta: 1 day, 23:14:49, time: 1.314, data_time: 0.017, memory: 5723, decode.loss_seg: 1.2021, decode.acc_seg: 50.7739, loss: 1.2021
2021-08-14 10:45:36,741 - mmseg - INFO - Iter [32200/160000]	lr: 8.187e-03, eta: 1 day, 23:15:50, time: 1.973, data_time: 0.726, memory: 5723, decode.loss_seg: 1.1442, decode.acc_seg: 50.5066, loss: 1.1442
2021-08-14 10:46:42,027 - mmseg - INFO - Iter [32250/160000]	lr: 8.185e-03, eta: 1 day, 23:14:38, time: 1.305, data_time: 0.017, memory: 5723, decode.loss_seg: 1.1429, decode.acc_seg: 52.1961, loss: 1.1429
2021-08-14 10:47:43,230 - mmseg - INFO - Iter [32300/160000]	lr: 8.182e-03, eta: 1 day, 23:13:11, time: 1.225, data_time: 0.016, memory: 5723, decode.loss_seg: 1.2015, decode.acc_seg: 51.1159, loss: 1.2015
2021-08-14 10:48:44,502 - mmseg - INFO - Iter [32350/160000]	lr: 8.179e-03, eta: 1 day, 23:11:43, time: 1.225, data_time: 0.015, memory: 5723, decode.loss_seg: 1.1621, decode.acc_seg: 50.5547, loss: 1.1621
2021-08-14 10:49:46,044 - mmseg - INFO - Iter [32400/160000]	lr: 8.176e-03, eta: 1 day, 23:10:17, time: 1.231, data_time: 0.015, memory: 5723, decode.loss_seg: 1.1806, decode.acc_seg: 50.1263, loss: 1.1806
2021-08-14 10:50:47,085 - mmseg - INFO - Iter [32450/160000]	lr: 8.173e-03, eta: 1 day, 23:08:49, time: 1.221, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1471, decode.acc_seg: 51.5140, loss: 1.1471
2021-08-14 10:51:47,704 - mmseg - INFO - Iter [32500/160000]	lr: 8.170e-03, eta: 1 day, 23:07:19, time: 1.212, data_time: 0.015, memory: 5723, decode.loss_seg: 1.1754, decode.acc_seg: 49.7934, loss: 1.1754
2021-08-14 10:52:51,848 - mmseg - INFO - Iter [32550/160000]	lr: 8.167e-03, eta: 1 day, 23:06:03, time: 1.282, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1984, decode.acc_seg: 50.8380, loss: 1.1984
2021-08-14 10:53:55,363 - mmseg - INFO - Iter [32600/160000]	lr: 8.165e-03, eta: 1 day, 23:04:45, time: 1.270, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1618, decode.acc_seg: 50.2907, loss: 1.1618
2021-08-14 10:54:58,129 - mmseg - INFO - Iter [32650/160000]	lr: 8.162e-03, eta: 1 day, 23:03:24, time: 1.256, data_time: 0.017, memory: 5723, decode.loss_seg: 1.1960, decode.acc_seg: 50.2756, loss: 1.1960
2021-08-14 10:56:00,841 - mmseg - INFO - Iter [32700/160000]	lr: 8.159e-03, eta: 1 day, 23:02:02, time: 1.253, data_time: 0.015, memory: 5723, decode.loss_seg: 1.1602, decode.acc_seg: 51.7753, loss: 1.1602
2021-08-14 10:57:02,637 - mmseg - INFO - Iter [32750/160000]	lr: 8.156e-03, eta: 1 day, 23:00:38, time: 1.236, data_time: 0.017, memory: 5723, decode.loss_seg: 1.1573, decode.acc_seg: 50.4965, loss: 1.1573
2021-08-14 10:58:06,336 - mmseg - INFO - Iter [32800/160000]	lr: 8.153e-03, eta: 1 day, 22:59:20, time: 1.274, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1812, decode.acc_seg: 50.7196, loss: 1.1812
2021-08-14 10:59:44,027 - mmseg - INFO - Iter [32850/160000]	lr: 8.150e-03, eta: 1 day, 23:00:15, time: 1.954, data_time: 0.722, memory: 5723, decode.loss_seg: 1.1699, decode.acc_seg: 50.6842, loss: 1.1699
2021-08-14 11:00:45,790 - mmseg - INFO - Iter [32900/160000]	lr: 8.148e-03, eta: 1 day, 22:58:50, time: 1.235, data_time: 0.017, memory: 5723, decode.loss_seg: 1.1582, decode.acc_seg: 50.6282, loss: 1.1582
2021-08-14 11:01:47,154 - mmseg - INFO - Iter [32950/160000]	lr: 8.145e-03, eta: 1 day, 22:57:23, time: 1.227, data_time: 0.015, memory: 5723, decode.loss_seg: 1.1736, decode.acc_seg: 50.3547, loss: 1.1736
2021-08-14 11:02:50,316 - mmseg - INFO - Exp name: fcn_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 11:02:50,316 - mmseg - INFO - Iter [33000/160000]	lr: 8.142e-03, eta: 1 day, 22:56:04, time: 1.264, data_time: 0.015, memory: 5723, decode.loss_seg: 1.1694, decode.acc_seg: 51.0898, loss: 1.1694
2021-08-14 11:03:55,987 - mmseg - INFO - Iter [33050/160000]	lr: 8.139e-03, eta: 1 day, 22:54:54, time: 1.312, data_time: 0.014, memory: 5723, decode.loss_seg: 1.1660, decode.acc_seg: 49.5642, loss: 1.1660
2021-08-14 11:05:04,270 - mmseg - INFO - Iter [33100/160000]	lr: 8.136e-03, eta: 1 day, 22:53:54, time: 1.366, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1517, decode.acc_seg: 51.4696, loss: 1.1517
2021-08-14 11:06:08,999 - mmseg - INFO - Iter [33150/160000]	lr: 8.133e-03, eta: 1 day, 22:52:41, time: 1.296, data_time: 0.015, memory: 5723, decode.loss_seg: 1.1564, decode.acc_seg: 51.3682, loss: 1.1564
2021-08-14 11:07:12,240 - mmseg - INFO - Iter [33200/160000]	lr: 8.130e-03, eta: 1 day, 22:51:22, time: 1.264, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1471, decode.acc_seg: 50.9612, loss: 1.1471
2021-08-14 11:08:17,845 - mmseg - INFO - Iter [33250/160000]	lr: 8.128e-03, eta: 1 day, 22:50:12, time: 1.312, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1720, decode.acc_seg: 50.5587, loss: 1.1720
2021-08-14 11:09:21,006 - mmseg - INFO - Iter [33300/160000]	lr: 8.125e-03, eta: 1 day, 22:48:52, time: 1.264, data_time: 0.016, memory: 5723, decode.loss_seg: 1.2190, decode.acc_seg: 49.7058, loss: 1.2190
2021-08-14 11:10:27,571 - mmseg - INFO - Iter [33350/160000]	lr: 8.122e-03, eta: 1 day, 22:47:46, time: 1.331, data_time: 0.015, memory: 5723, decode.loss_seg: 1.1963, decode.acc_seg: 50.6598, loss: 1.1963
2021-08-14 11:11:28,909 - mmseg - INFO - Iter [33400/160000]	lr: 8.119e-03, eta: 1 day, 22:46:20, time: 1.227, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1606, decode.acc_seg: 51.3235, loss: 1.1606
2021-08-14 11:13:04,656 - mmseg - INFO - Iter [33450/160000]	lr: 8.116e-03, eta: 1 day, 22:47:04, time: 1.915, data_time: 0.684, memory: 5723, decode.loss_seg: 1.1747, decode.acc_seg: 51.3956, loss: 1.1747
2021-08-14 11:14:09,181 - mmseg - INFO - Iter [33500/160000]	lr: 8.113e-03, eta: 1 day, 22:45:50, time: 1.289, data_time: 0.015, memory: 5723, decode.loss_seg: 1.1364, decode.acc_seg: 50.5628, loss: 1.1364
2021-08-14 11:15:14,667 - mmseg - INFO - Iter [33550/160000]	lr: 8.110e-03, eta: 1 day, 22:44:39, time: 1.310, data_time: 0.015, memory: 5723, decode.loss_seg: 1.1694, decode.acc_seg: 51.5697, loss: 1.1694
2021-08-14 11:16:16,244 - mmseg - INFO - Iter [33600/160000]	lr: 8.108e-03, eta: 1 day, 22:43:14, time: 1.232, data_time: 0.018, memory: 5723, decode.loss_seg: 1.2060, decode.acc_seg: 50.8386, loss: 1.2060
2021-08-14 11:17:18,361 - mmseg - INFO - Iter [33650/160000]	lr: 8.105e-03, eta: 1 day, 22:41:51, time: 1.242, data_time: 0.015, memory: 5723, decode.loss_seg: 1.1730, decode.acc_seg: 50.7099, loss: 1.1730
2021-08-14 11:18:21,209 - mmseg - INFO - Iter [33700/160000]	lr: 8.102e-03, eta: 1 day, 22:40:31, time: 1.257, data_time: 0.015, memory: 5723, decode.loss_seg: 1.1324, decode.acc_seg: 51.1775, loss: 1.1324
2021-08-14 11:19:24,918 - mmseg - INFO - Iter [33750/160000]	lr: 8.099e-03, eta: 1 day, 22:39:14, time: 1.274, data_time: 0.014, memory: 5723, decode.loss_seg: 1.1830, decode.acc_seg: 50.6175, loss: 1.1830
2021-08-14 11:20:30,016 - mmseg - INFO - Iter [33800/160000]	lr: 8.096e-03, eta: 1 day, 22:38:02, time: 1.302, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1535, decode.acc_seg: 51.5138, loss: 1.1535
2021-08-14 11:21:35,097 - mmseg - INFO - Iter [33850/160000]	lr: 8.093e-03, eta: 1 day, 22:36:50, time: 1.302, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1850, decode.acc_seg: 50.2919, loss: 1.1850
2021-08-14 11:22:38,227 - mmseg - INFO - Iter [33900/160000]	lr: 8.090e-03, eta: 1 day, 22:35:31, time: 1.263, data_time: 0.015, memory: 5723, decode.loss_seg: 1.1744, decode.acc_seg: 51.5375, loss: 1.1744
2021-08-14 11:23:39,888 - mmseg - INFO - Iter [33950/160000]	lr: 8.088e-03, eta: 1 day, 22:34:07, time: 1.233, data_time: 0.015, memory: 5723, decode.loss_seg: 1.1912, decode.acc_seg: 51.1796, loss: 1.1912
2021-08-14 11:24:41,470 - mmseg - INFO - Exp name: fcn_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 11:24:41,471 - mmseg - INFO - Iter [34000/160000]	lr: 8.085e-03, eta: 1 day, 22:32:42, time: 1.231, data_time: 0.015, memory: 5723, decode.loss_seg: 1.1707, decode.acc_seg: 50.4489, loss: 1.1707
2021-08-14 11:25:45,062 - mmseg - INFO - Iter [34050/160000]	lr: 8.082e-03, eta: 1 day, 22:31:25, time: 1.272, data_time: 0.015, memory: 5723, decode.loss_seg: 1.1389, decode.acc_seg: 51.3516, loss: 1.1389
2021-08-14 11:27:21,971 - mmseg - INFO - Iter [34100/160000]	lr: 8.079e-03, eta: 1 day, 22:32:10, time: 1.938, data_time: 0.721, memory: 5723, decode.loss_seg: 1.1648, decode.acc_seg: 50.2111, loss: 1.1648
2021-08-14 11:28:26,730 - mmseg - INFO - Iter [34150/160000]	lr: 8.076e-03, eta: 1 day, 22:30:57, time: 1.295, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1491, decode.acc_seg: 49.9895, loss: 1.1491
2021-08-14 11:29:33,629 - mmseg - INFO - Iter [34200/160000]	lr: 8.073e-03, eta: 1 day, 22:29:52, time: 1.338, data_time: 0.015, memory: 5723, decode.loss_seg: 1.1471, decode.acc_seg: 51.3609, loss: 1.1471
2021-08-14 11:30:36,766 - mmseg - INFO - Iter [34250/160000]	lr: 8.071e-03, eta: 1 day, 22:28:33, time: 1.262, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1572, decode.acc_seg: 50.9912, loss: 1.1572
2021-08-14 11:31:38,696 - mmseg - INFO - Iter [34300/160000]	lr: 8.068e-03, eta: 1 day, 22:27:10, time: 1.239, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1395, decode.acc_seg: 51.9206, loss: 1.1395
2021-08-14 11:32:42,544 - mmseg - INFO - Iter [34350/160000]	lr: 8.065e-03, eta: 1 day, 22:25:53, time: 1.276, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1775, decode.acc_seg: 50.3939, loss: 1.1775
2021-08-14 11:33:49,160 - mmseg - INFO - Iter [34400/160000]	lr: 8.062e-03, eta: 1 day, 22:24:47, time: 1.333, data_time: 0.017, memory: 5723, decode.loss_seg: 1.1613, decode.acc_seg: 51.1377, loss: 1.1613
2021-08-14 11:34:52,646 - mmseg - INFO - Iter [34450/160000]	lr: 8.059e-03, eta: 1 day, 22:23:30, time: 1.269, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1580, decode.acc_seg: 50.4827, loss: 1.1580
2021-08-14 11:35:55,508 - mmseg - INFO - Iter [34500/160000]	lr: 8.056e-03, eta: 1 day, 22:22:10, time: 1.258, data_time: 0.016, memory: 5723, decode.loss_seg: 1.2134, decode.acc_seg: 50.0334, loss: 1.2134
2021-08-14 11:36:57,184 - mmseg - INFO - Iter [34550/160000]	lr: 8.053e-03, eta: 1 day, 22:20:46, time: 1.234, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1736, decode.acc_seg: 50.7510, loss: 1.1736
2021-08-14 11:38:00,554 - mmseg - INFO - Iter [34600/160000]	lr: 8.051e-03, eta: 1 day, 22:19:28, time: 1.266, data_time: 0.015, memory: 5723, decode.loss_seg: 1.1632, decode.acc_seg: 51.4093, loss: 1.1632
2021-08-14 11:39:06,246 - mmseg - INFO - Iter [34650/160000]	lr: 8.048e-03, eta: 1 day, 22:18:19, time: 1.315, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0926, decode.acc_seg: 52.1003, loss: 1.0926
2021-08-14 11:40:08,788 - mmseg - INFO - Iter [34700/160000]	lr: 8.045e-03, eta: 1 day, 22:16:58, time: 1.250, data_time: 0.015, memory: 5723, decode.loss_seg: 1.1990, decode.acc_seg: 50.0806, loss: 1.1990
2021-08-14 11:41:50,540 - mmseg - INFO - Iter [34750/160000]	lr: 8.042e-03, eta: 1 day, 22:17:59, time: 2.035, data_time: 0.748, memory: 5723, decode.loss_seg: 1.1354, decode.acc_seg: 50.9567, loss: 1.1354
2021-08-14 11:42:55,080 - mmseg - INFO - Iter [34800/160000]	lr: 8.039e-03, eta: 1 day, 22:16:45, time: 1.291, data_time: 0.017, memory: 5723, decode.loss_seg: 1.1462, decode.acc_seg: 51.7836, loss: 1.1462
2021-08-14 11:43:55,679 - mmseg - INFO - Iter [34850/160000]	lr: 8.036e-03, eta: 1 day, 22:15:17, time: 1.212, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1408, decode.acc_seg: 50.5223, loss: 1.1408
2021-08-14 11:44:55,610 - mmseg - INFO - Iter [34900/160000]	lr: 8.033e-03, eta: 1 day, 22:13:47, time: 1.199, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1640, decode.acc_seg: 51.7482, loss: 1.1640
2021-08-14 11:45:57,444 - mmseg - INFO - Iter [34950/160000]	lr: 8.031e-03, eta: 1 day, 22:12:24, time: 1.236, data_time: 0.015, memory: 5723, decode.loss_seg: 1.1359, decode.acc_seg: 51.2642, loss: 1.1359
2021-08-14 11:47:00,403 - mmseg - INFO - Exp name: fcn_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 11:47:00,403 - mmseg - INFO - Iter [35000/160000]	lr: 8.028e-03, eta: 1 day, 22:11:04, time: 1.259, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1558, decode.acc_seg: 51.3774, loss: 1.1558
2021-08-14 11:48:01,258 - mmseg - INFO - Iter [35050/160000]	lr: 8.025e-03, eta: 1 day, 22:09:38, time: 1.217, data_time: 0.015, memory: 5723, decode.loss_seg: 1.1705, decode.acc_seg: 49.7256, loss: 1.1705
2021-08-14 11:49:06,027 - mmseg - INFO - Iter [35100/160000]	lr: 8.022e-03, eta: 1 day, 22:08:25, time: 1.295, data_time: 0.015, memory: 5723, decode.loss_seg: 1.1480, decode.acc_seg: 51.1593, loss: 1.1480
2021-08-14 11:50:10,166 - mmseg - INFO - Iter [35150/160000]	lr: 8.019e-03, eta: 1 day, 22:07:10, time: 1.283, data_time: 0.017, memory: 5723, decode.loss_seg: 1.1954, decode.acc_seg: 50.9863, loss: 1.1954
2021-08-14 11:51:12,264 - mmseg - INFO - Iter [35200/160000]	lr: 8.016e-03, eta: 1 day, 22:05:48, time: 1.243, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1828, decode.acc_seg: 51.5285, loss: 1.1828
2021-08-14 11:52:16,343 - mmseg - INFO - Iter [35250/160000]	lr: 8.013e-03, eta: 1 day, 22:04:33, time: 1.281, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1516, decode.acc_seg: 51.6345, loss: 1.1516
2021-08-14 11:53:22,359 - mmseg - INFO - Iter [35300/160000]	lr: 8.011e-03, eta: 1 day, 22:03:25, time: 1.320, data_time: 0.017, memory: 5723, decode.loss_seg: 1.1718, decode.acc_seg: 50.1658, loss: 1.1718
2021-08-14 11:55:02,148 - mmseg - INFO - Iter [35350/160000]	lr: 8.008e-03, eta: 1 day, 22:04:16, time: 1.997, data_time: 0.723, memory: 5723, decode.loss_seg: 1.1831, decode.acc_seg: 50.3486, loss: 1.1831
2021-08-14 11:56:08,336 - mmseg - INFO - Iter [35400/160000]	lr: 8.005e-03, eta: 1 day, 22:03:08, time: 1.324, data_time: 0.015, memory: 5723, decode.loss_seg: 1.1424, decode.acc_seg: 51.7419, loss: 1.1424
2021-08-14 11:57:10,436 - mmseg - INFO - Iter [35450/160000]	lr: 8.002e-03, eta: 1 day, 22:01:46, time: 1.241, data_time: 0.015, memory: 5723, decode.loss_seg: 1.1720, decode.acc_seg: 50.3394, loss: 1.1720
2021-08-14 11:58:11,709 - mmseg - INFO - Iter [35500/160000]	lr: 7.999e-03, eta: 1 day, 22:00:21, time: 1.226, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1684, decode.acc_seg: 51.2206, loss: 1.1684
2021-08-14 11:59:14,700 - mmseg - INFO - Iter [35550/160000]	lr: 7.996e-03, eta: 1 day, 21:59:02, time: 1.260, data_time: 0.015, memory: 5723, decode.loss_seg: 1.1219, decode.acc_seg: 51.3006, loss: 1.1219
2021-08-14 12:00:20,816 - mmseg - INFO - Iter [35600/160000]	lr: 7.993e-03, eta: 1 day, 21:57:54, time: 1.322, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1891, decode.acc_seg: 49.8123, loss: 1.1891
2021-08-14 12:01:28,771 - mmseg - INFO - Iter [35650/160000]	lr: 7.991e-03, eta: 1 day, 21:56:53, time: 1.359, data_time: 0.018, memory: 5723, decode.loss_seg: 1.1742, decode.acc_seg: 50.6726, loss: 1.1742
2021-08-14 12:02:31,741 - mmseg - INFO - Iter [35700/160000]	lr: 7.988e-03, eta: 1 day, 21:55:34, time: 1.260, data_time: 0.017, memory: 5723, decode.loss_seg: 1.1274, decode.acc_seg: 51.5757, loss: 1.1274
2021-08-14 12:03:35,473 - mmseg - INFO - Iter [35750/160000]	lr: 7.985e-03, eta: 1 day, 21:54:18, time: 1.275, data_time: 0.017, memory: 5723, decode.loss_seg: 1.1361, decode.acc_seg: 51.0333, loss: 1.1361
2021-08-14 12:04:36,986 - mmseg - INFO - Iter [35800/160000]	lr: 7.982e-03, eta: 1 day, 21:52:54, time: 1.231, data_time: 0.018, memory: 5723, decode.loss_seg: 1.1541, decode.acc_seg: 51.5275, loss: 1.1541
2021-08-14 12:05:37,682 - mmseg - INFO - Iter [35850/160000]	lr: 7.979e-03, eta: 1 day, 21:51:28, time: 1.214, data_time: 0.017, memory: 5723, decode.loss_seg: 1.1645, decode.acc_seg: 51.1867, loss: 1.1645
2021-08-14 12:06:39,294 - mmseg - INFO - Iter [35900/160000]	lr: 7.976e-03, eta: 1 day, 21:50:04, time: 1.232, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1509, decode.acc_seg: 50.9669, loss: 1.1509
2021-08-14 12:07:41,969 - mmseg - INFO - Iter [35950/160000]	lr: 7.973e-03, eta: 1 day, 21:48:45, time: 1.253, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1634, decode.acc_seg: 50.6123, loss: 1.1634
2021-08-14 12:09:31,266 - mmseg - INFO - Exp name: fcn_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 12:09:31,270 - mmseg - INFO - Iter [36000/160000]	lr: 7.971e-03, eta: 1 day, 21:50:06, time: 2.185, data_time: 0.910, memory: 5723, decode.loss_seg: 1.1386, decode.acc_seg: 50.2958, loss: 1.1386
2021-08-14 12:10:35,363 - mmseg - INFO - Iter [36050/160000]	lr: 7.968e-03, eta: 1 day, 21:48:51, time: 1.283, data_time: 0.017, memory: 5723, decode.loss_seg: 1.1971, decode.acc_seg: 51.1043, loss: 1.1971
2021-08-14 12:11:38,003 - mmseg - INFO - Iter [36100/160000]	lr: 7.965e-03, eta: 1 day, 21:47:31, time: 1.252, data_time: 0.014, memory: 5723, decode.loss_seg: 1.1203, decode.acc_seg: 52.5840, loss: 1.1203
2021-08-14 12:12:41,158 - mmseg - INFO - Iter [36150/160000]	lr: 7.962e-03, eta: 1 day, 21:46:13, time: 1.264, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1178, decode.acc_seg: 51.8867, loss: 1.1178
2021-08-14 12:13:44,162 - mmseg - INFO - Iter [36200/160000]	lr: 7.959e-03, eta: 1 day, 21:44:54, time: 1.260, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1140, decode.acc_seg: 51.5492, loss: 1.1140
2021-08-14 12:14:45,831 - mmseg - INFO - Iter [36250/160000]	lr: 7.956e-03, eta: 1 day, 21:43:31, time: 1.232, data_time: 0.015, memory: 5723, decode.loss_seg: 1.1385, decode.acc_seg: 51.4242, loss: 1.1385
2021-08-14 12:15:52,735 - mmseg - INFO - Iter [36300/160000]	lr: 7.953e-03, eta: 1 day, 21:42:26, time: 1.339, data_time: 0.016, memory: 5723, decode.loss_seg: 1.2229, decode.acc_seg: 50.4788, loss: 1.2229
2021-08-14 12:16:55,332 - mmseg - INFO - Iter [36350/160000]	lr: 7.951e-03, eta: 1 day, 21:41:06, time: 1.251, data_time: 0.015, memory: 5723, decode.loss_seg: 1.1804, decode.acc_seg: 51.1813, loss: 1.1804
2021-08-14 12:17:56,195 - mmseg - INFO - Iter [36400/160000]	lr: 7.948e-03, eta: 1 day, 21:39:40, time: 1.218, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1235, decode.acc_seg: 51.0227, loss: 1.1235
2021-08-14 12:18:58,337 - mmseg - INFO - Iter [36450/160000]	lr: 7.945e-03, eta: 1 day, 21:38:19, time: 1.243, data_time: 0.017, memory: 5723, decode.loss_seg: 1.1320, decode.acc_seg: 51.0329, loss: 1.1320
2021-08-14 12:20:02,389 - mmseg - INFO - Iter [36500/160000]	lr: 7.942e-03, eta: 1 day, 21:37:04, time: 1.280, data_time: 0.017, memory: 5723, decode.loss_seg: 1.1610, decode.acc_seg: 50.9054, loss: 1.1610
2021-08-14 12:21:07,017 - mmseg - INFO - Iter [36550/160000]	lr: 7.939e-03, eta: 1 day, 21:35:51, time: 1.292, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1638, decode.acc_seg: 50.9947, loss: 1.1638
2021-08-14 12:22:45,313 - mmseg - INFO - Iter [36600/160000]	lr: 7.936e-03, eta: 1 day, 21:36:32, time: 1.967, data_time: 0.731, memory: 5723, decode.loss_seg: 1.1628, decode.acc_seg: 51.3906, loss: 1.1628
2021-08-14 12:23:46,621 - mmseg - INFO - Iter [36650/160000]	lr: 7.933e-03, eta: 1 day, 21:35:08, time: 1.226, data_time: 0.017, memory: 5723, decode.loss_seg: 1.1238, decode.acc_seg: 51.7312, loss: 1.1238
2021-08-14 12:24:49,418 - mmseg - INFO - Iter [36700/160000]	lr: 7.931e-03, eta: 1 day, 21:33:49, time: 1.256, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1384, decode.acc_seg: 51.8045, loss: 1.1384
2021-08-14 12:25:50,735 - mmseg - INFO - Iter [36750/160000]	lr: 7.928e-03, eta: 1 day, 21:32:25, time: 1.227, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1033, decode.acc_seg: 52.1065, loss: 1.1033
2021-08-14 12:26:52,448 - mmseg - INFO - Iter [36800/160000]	lr: 7.925e-03, eta: 1 day, 21:31:03, time: 1.235, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1870, decode.acc_seg: 51.5498, loss: 1.1870
2021-08-14 12:27:54,866 - mmseg - INFO - Iter [36850/160000]	lr: 7.922e-03, eta: 1 day, 21:29:43, time: 1.248, data_time: 0.015, memory: 5723, decode.loss_seg: 1.1747, decode.acc_seg: 50.6570, loss: 1.1747
2021-08-14 12:28:57,483 - mmseg - INFO - Iter [36900/160000]	lr: 7.919e-03, eta: 1 day, 21:28:23, time: 1.253, data_time: 0.017, memory: 5723, decode.loss_seg: 1.1614, decode.acc_seg: 50.6588, loss: 1.1614
2021-08-14 12:29:59,906 - mmseg - INFO - Iter [36950/160000]	lr: 7.916e-03, eta: 1 day, 21:27:03, time: 1.248, data_time: 0.015, memory: 5723, decode.loss_seg: 1.1392, decode.acc_seg: 52.1038, loss: 1.1392
2021-08-14 12:31:00,758 - mmseg - INFO - Exp name: fcn_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 12:31:00,759 - mmseg - INFO - Iter [37000/160000]	lr: 7.913e-03, eta: 1 day, 21:25:38, time: 1.217, data_time: 0.015, memory: 5723, decode.loss_seg: 1.1426, decode.acc_seg: 50.9852, loss: 1.1426
2021-08-14 12:32:00,911 - mmseg - INFO - Iter [37050/160000]	lr: 7.911e-03, eta: 1 day, 21:24:10, time: 1.203, data_time: 0.015, memory: 5723, decode.loss_seg: 1.1553, decode.acc_seg: 50.6480, loss: 1.1553
2021-08-14 12:33:01,298 - mmseg - INFO - Iter [37100/160000]	lr: 7.908e-03, eta: 1 day, 21:22:44, time: 1.208, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1455, decode.acc_seg: 51.5134, loss: 1.1455
2021-08-14 12:34:04,101 - mmseg - INFO - Iter [37150/160000]	lr: 7.905e-03, eta: 1 day, 21:21:25, time: 1.256, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1254, decode.acc_seg: 50.5358, loss: 1.1254
2021-08-14 12:35:10,406 - mmseg - INFO - Iter [37200/160000]	lr: 7.902e-03, eta: 1 day, 21:20:18, time: 1.325, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1916, decode.acc_seg: 51.2236, loss: 1.1916
2021-08-14 12:36:49,259 - mmseg - INFO - Iter [37250/160000]	lr: 7.899e-03, eta: 1 day, 21:20:59, time: 1.978, data_time: 0.687, memory: 5723, decode.loss_seg: 1.1393, decode.acc_seg: 51.0269, loss: 1.1393
2021-08-14 12:37:52,277 - mmseg - INFO - Iter [37300/160000]	lr: 7.896e-03, eta: 1 day, 21:19:41, time: 1.259, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1217, decode.acc_seg: 51.3211, loss: 1.1217
2021-08-14 12:38:55,604 - mmseg - INFO - Iter [37350/160000]	lr: 7.893e-03, eta: 1 day, 21:18:24, time: 1.267, data_time: 0.017, memory: 5723, decode.loss_seg: 1.1244, decode.acc_seg: 51.9659, loss: 1.1244
2021-08-14 12:39:56,557 - mmseg - INFO - Iter [37400/160000]	lr: 7.891e-03, eta: 1 day, 21:16:59, time: 1.219, data_time: 0.017, memory: 5723, decode.loss_seg: 1.1552, decode.acc_seg: 52.3535, loss: 1.1552
2021-08-14 12:40:59,817 - mmseg - INFO - Iter [37450/160000]	lr: 7.888e-03, eta: 1 day, 21:15:42, time: 1.265, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1821, decode.acc_seg: 51.2700, loss: 1.1821
2021-08-14 12:42:04,039 - mmseg - INFO - Iter [37500/160000]	lr: 7.885e-03, eta: 1 day, 21:14:28, time: 1.284, data_time: 0.017, memory: 5723, decode.loss_seg: 1.1269, decode.acc_seg: 51.3456, loss: 1.1269
2021-08-14 12:43:06,276 - mmseg - INFO - Iter [37550/160000]	lr: 7.882e-03, eta: 1 day, 21:13:08, time: 1.245, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1097, decode.acc_seg: 52.2712, loss: 1.1097
2021-08-14 12:44:10,531 - mmseg - INFO - Iter [37600/160000]	lr: 7.879e-03, eta: 1 day, 21:11:54, time: 1.284, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1407, decode.acc_seg: 51.2797, loss: 1.1407
2021-08-14 12:45:15,675 - mmseg - INFO - Iter [37650/160000]	lr: 7.876e-03, eta: 1 day, 21:10:43, time: 1.303, data_time: 0.017, memory: 5723, decode.loss_seg: 1.1462, decode.acc_seg: 50.8272, loss: 1.1462
2021-08-14 12:46:19,688 - mmseg - INFO - Iter [37700/160000]	lr: 7.873e-03, eta: 1 day, 21:09:29, time: 1.280, data_time: 0.017, memory: 5723, decode.loss_seg: 1.1342, decode.acc_seg: 51.3057, loss: 1.1342
2021-08-14 12:47:20,019 - mmseg - INFO - Iter [37750/160000]	lr: 7.871e-03, eta: 1 day, 21:08:03, time: 1.207, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1664, decode.acc_seg: 51.3154, loss: 1.1664
2021-08-14 12:48:20,235 - mmseg - INFO - Iter [37800/160000]	lr: 7.868e-03, eta: 1 day, 21:06:36, time: 1.204, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1329, decode.acc_seg: 52.2586, loss: 1.1329
2021-08-14 12:49:24,073 - mmseg - INFO - Iter [37850/160000]	lr: 7.865e-03, eta: 1 day, 21:05:21, time: 1.276, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1576, decode.acc_seg: 50.5481, loss: 1.1576
2021-08-14 12:51:03,052 - mmseg - INFO - Iter [37900/160000]	lr: 7.862e-03, eta: 1 day, 21:06:00, time: 1.980, data_time: 0.726, memory: 5723, decode.loss_seg: 1.0989, decode.acc_seg: 51.3010, loss: 1.0989
2021-08-14 12:52:05,438 - mmseg - INFO - Iter [37950/160000]	lr: 7.859e-03, eta: 1 day, 21:04:40, time: 1.248, data_time: 0.017, memory: 5723, decode.loss_seg: 1.1237, decode.acc_seg: 50.9440, loss: 1.1237
2021-08-14 12:53:07,711 - mmseg - INFO - Exp name: fcn_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 12:53:07,712 - mmseg - INFO - Iter [38000/160000]	lr: 7.856e-03, eta: 1 day, 21:03:20, time: 1.245, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1369, decode.acc_seg: 51.7765, loss: 1.1369
2021-08-14 12:54:12,522 - mmseg - INFO - Iter [38050/160000]	lr: 7.853e-03, eta: 1 day, 21:02:08, time: 1.296, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1245, decode.acc_seg: 52.7629, loss: 1.1245
2021-08-14 12:55:17,534 - mmseg - INFO - Iter [38100/160000]	lr: 7.851e-03, eta: 1 day, 21:00:57, time: 1.301, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1115, decode.acc_seg: 52.4773, loss: 1.1115
2021-08-14 12:56:18,489 - mmseg - INFO - Iter [38150/160000]	lr: 7.848e-03, eta: 1 day, 20:59:33, time: 1.219, data_time: 0.018, memory: 5723, decode.loss_seg: 1.1328, decode.acc_seg: 52.2464, loss: 1.1328
2021-08-14 12:57:19,919 - mmseg - INFO - Iter [38200/160000]	lr: 7.845e-03, eta: 1 day, 20:58:10, time: 1.228, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1589, decode.acc_seg: 50.8314, loss: 1.1589
2021-08-14 12:58:21,469 - mmseg - INFO - Iter [38250/160000]	lr: 7.842e-03, eta: 1 day, 20:56:48, time: 1.231, data_time: 0.019, memory: 5723, decode.loss_seg: 1.1271, decode.acc_seg: 50.7114, loss: 1.1271
2021-08-14 12:59:24,274 - mmseg - INFO - Iter [38300/160000]	lr: 7.839e-03, eta: 1 day, 20:55:30, time: 1.256, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1370, decode.acc_seg: 51.9731, loss: 1.1370
2021-08-14 13:00:26,938 - mmseg - INFO - Iter [38350/160000]	lr: 7.836e-03, eta: 1 day, 20:54:12, time: 1.253, data_time: 0.017, memory: 5723, decode.loss_seg: 1.1507, decode.acc_seg: 51.9595, loss: 1.1507
2021-08-14 13:01:32,145 - mmseg - INFO - Iter [38400/160000]	lr: 7.833e-03, eta: 1 day, 20:53:01, time: 1.304, data_time: 0.017, memory: 5723, decode.loss_seg: 1.1482, decode.acc_seg: 51.3158, loss: 1.1482
2021-08-14 13:02:33,398 - mmseg - INFO - Iter [38450/160000]	lr: 7.831e-03, eta: 1 day, 20:51:39, time: 1.225, data_time: 0.017, memory: 5723, decode.loss_seg: 1.1346, decode.acc_seg: 52.4321, loss: 1.1346
2021-08-14 13:04:10,457 - mmseg - INFO - Iter [38500/160000]	lr: 7.828e-03, eta: 1 day, 20:52:09, time: 1.941, data_time: 0.673, memory: 5723, decode.loss_seg: 1.1729, decode.acc_seg: 49.9834, loss: 1.1729
2021-08-14 13:05:12,733 - mmseg - INFO - Iter [38550/160000]	lr: 7.825e-03, eta: 1 day, 20:50:49, time: 1.246, data_time: 0.017, memory: 5723, decode.loss_seg: 1.0705, decode.acc_seg: 52.2404, loss: 1.0705
2021-08-14 13:06:14,163 - mmseg - INFO - Iter [38600/160000]	lr: 7.822e-03, eta: 1 day, 20:49:27, time: 1.229, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1257, decode.acc_seg: 51.1052, loss: 1.1257
2021-08-14 13:07:16,416 - mmseg - INFO - Iter [38650/160000]	lr: 7.819e-03, eta: 1 day, 20:48:07, time: 1.245, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0921, decode.acc_seg: 52.0176, loss: 1.0921
2021-08-14 13:08:19,610 - mmseg - INFO - Iter [38700/160000]	lr: 7.816e-03, eta: 1 day, 20:46:50, time: 1.263, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1541, decode.acc_seg: 51.4750, loss: 1.1541
2021-08-14 13:09:23,974 - mmseg - INFO - Iter [38750/160000]	lr: 7.813e-03, eta: 1 day, 20:45:37, time: 1.288, data_time: 0.017, memory: 5723, decode.loss_seg: 1.1453, decode.acc_seg: 51.5135, loss: 1.1453
2021-08-14 13:10:24,919 - mmseg - INFO - Iter [38800/160000]	lr: 7.811e-03, eta: 1 day, 20:44:14, time: 1.219, data_time: 0.018, memory: 5723, decode.loss_seg: 1.1725, decode.acc_seg: 51.4112, loss: 1.1725
2021-08-14 13:11:27,925 - mmseg - INFO - Iter [38850/160000]	lr: 7.808e-03, eta: 1 day, 20:42:57, time: 1.260, data_time: 0.018, memory: 5723, decode.loss_seg: 1.1604, decode.acc_seg: 51.5132, loss: 1.1604
2021-08-14 13:12:33,220 - mmseg - INFO - Iter [38900/160000]	lr: 7.805e-03, eta: 1 day, 20:41:46, time: 1.305, data_time: 0.017, memory: 5723, decode.loss_seg: 1.1656, decode.acc_seg: 50.4756, loss: 1.1656
2021-08-14 13:13:39,072 - mmseg - INFO - Iter [38950/160000]	lr: 7.802e-03, eta: 1 day, 20:40:38, time: 1.318, data_time: 0.017, memory: 5723, decode.loss_seg: 1.1778, decode.acc_seg: 50.4103, loss: 1.1778
2021-08-14 13:14:40,650 - mmseg - INFO - Exp name: fcn_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 13:14:40,650 - mmseg - INFO - Iter [39000/160000]	lr: 7.799e-03, eta: 1 day, 20:39:17, time: 1.232, data_time: 0.017, memory: 5723, decode.loss_seg: 1.1259, decode.acc_seg: 51.3062, loss: 1.1259
2021-08-14 13:15:44,091 - mmseg - INFO - Iter [39050/160000]	lr: 7.796e-03, eta: 1 day, 20:38:01, time: 1.268, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1206, decode.acc_seg: 50.8793, loss: 1.1206
2021-08-14 13:16:48,342 - mmseg - INFO - Iter [39100/160000]	lr: 7.793e-03, eta: 1 day, 20:36:48, time: 1.286, data_time: 0.018, memory: 5723, decode.loss_seg: 1.1450, decode.acc_seg: 50.8574, loss: 1.1450
2021-08-14 13:18:26,361 - mmseg - INFO - Iter [39150/160000]	lr: 7.790e-03, eta: 1 day, 20:37:19, time: 1.960, data_time: 0.744, memory: 5723, decode.loss_seg: 1.1328, decode.acc_seg: 50.5877, loss: 1.1328
2021-08-14 13:19:29,123 - mmseg - INFO - Iter [39200/160000]	lr: 7.788e-03, eta: 1 day, 20:36:01, time: 1.255, data_time: 0.017, memory: 5723, decode.loss_seg: 1.1613, decode.acc_seg: 51.4793, loss: 1.1613
2021-08-14 13:20:31,229 - mmseg - INFO - Iter [39250/160000]	lr: 7.785e-03, eta: 1 day, 20:34:41, time: 1.242, data_time: 0.017, memory: 5723, decode.loss_seg: 1.1007, decode.acc_seg: 52.3680, loss: 1.1007
2021-08-14 13:21:34,477 - mmseg - INFO - Iter [39300/160000]	lr: 7.782e-03, eta: 1 day, 20:33:25, time: 1.265, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1244, decode.acc_seg: 51.8515, loss: 1.1244
2021-08-14 13:22:35,989 - mmseg - INFO - Iter [39350/160000]	lr: 7.779e-03, eta: 1 day, 20:32:04, time: 1.231, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1171, decode.acc_seg: 51.8621, loss: 1.1171
2021-08-14 13:23:38,154 - mmseg - INFO - Iter [39400/160000]	lr: 7.776e-03, eta: 1 day, 20:30:44, time: 1.243, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1440, decode.acc_seg: 52.0187, loss: 1.1440
2021-08-14 13:24:43,785 - mmseg - INFO - Iter [39450/160000]	lr: 7.773e-03, eta: 1 day, 20:29:35, time: 1.312, data_time: 0.015, memory: 5723, decode.loss_seg: 1.1378, decode.acc_seg: 52.1740, loss: 1.1378
2021-08-14 13:25:51,511 - mmseg - INFO - Iter [39500/160000]	lr: 7.770e-03, eta: 1 day, 20:28:33, time: 1.355, data_time: 0.015, memory: 5723, decode.loss_seg: 1.1364, decode.acc_seg: 50.8916, loss: 1.1364
2021-08-14 13:26:57,247 - mmseg - INFO - Iter [39550/160000]	lr: 7.768e-03, eta: 1 day, 20:27:24, time: 1.314, data_time: 0.015, memory: 5723, decode.loss_seg: 1.1622, decode.acc_seg: 50.5480, loss: 1.1622
2021-08-14 13:28:00,973 - mmseg - INFO - Iter [39600/160000]	lr: 7.765e-03, eta: 1 day, 20:26:09, time: 1.276, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1158, decode.acc_seg: 52.1595, loss: 1.1158
2021-08-14 13:29:04,088 - mmseg - INFO - Iter [39650/160000]	lr: 7.762e-03, eta: 1 day, 20:24:53, time: 1.262, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1295, decode.acc_seg: 51.9650, loss: 1.1295
2021-08-14 13:30:07,286 - mmseg - INFO - Iter [39700/160000]	lr: 7.759e-03, eta: 1 day, 20:23:37, time: 1.264, data_time: 0.017, memory: 5723, decode.loss_seg: 1.1575, decode.acc_seg: 51.4383, loss: 1.1575
2021-08-14 13:31:09,078 - mmseg - INFO - Iter [39750/160000]	lr: 7.756e-03, eta: 1 day, 20:22:16, time: 1.236, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1378, decode.acc_seg: 50.6828, loss: 1.1378
2021-08-14 13:32:50,005 - mmseg - INFO - Iter [39800/160000]	lr: 7.753e-03, eta: 1 day, 20:22:54, time: 2.018, data_time: 0.716, memory: 5723, decode.loss_seg: 1.1093, decode.acc_seg: 52.0911, loss: 1.1093
2021-08-14 13:33:56,414 - mmseg - INFO - Iter [39850/160000]	lr: 7.750e-03, eta: 1 day, 20:21:47, time: 1.329, data_time: 0.017, memory: 5723, decode.loss_seg: 1.1337, decode.acc_seg: 51.2139, loss: 1.1337
2021-08-14 13:34:57,145 - mmseg - INFO - Iter [39900/160000]	lr: 7.747e-03, eta: 1 day, 20:20:24, time: 1.215, data_time: 0.015, memory: 5723, decode.loss_seg: 1.1339, decode.acc_seg: 51.8003, loss: 1.1339
2021-08-14 13:35:58,725 - mmseg - INFO - Iter [39950/160000]	lr: 7.745e-03, eta: 1 day, 20:19:03, time: 1.232, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1474, decode.acc_seg: 51.5195, loss: 1.1474
2021-08-14 13:37:00,327 - mmseg - INFO - Exp name: fcn_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 13:37:00,329 - mmseg - INFO - Iter [40000/160000]	lr: 7.742e-03, eta: 1 day, 20:17:41, time: 1.231, data_time: 0.015, memory: 5723, decode.loss_seg: 1.1516, decode.acc_seg: 51.6216, loss: 1.1516
2021-08-14 13:38:05,050 - mmseg - INFO - Iter [40050/160000]	lr: 7.739e-03, eta: 1 day, 20:16:30, time: 1.294, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1187, decode.acc_seg: 52.2744, loss: 1.1187
2021-08-14 13:39:11,422 - mmseg - INFO - Iter [40100/160000]	lr: 7.736e-03, eta: 1 day, 20:15:23, time: 1.328, data_time: 0.014, memory: 5723, decode.loss_seg: 1.1321, decode.acc_seg: 51.5444, loss: 1.1321
2021-08-14 13:40:13,050 - mmseg - INFO - Iter [40150/160000]	lr: 7.733e-03, eta: 1 day, 20:14:03, time: 1.233, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1458, decode.acc_seg: 51.4449, loss: 1.1458
2021-08-14 13:41:15,261 - mmseg - INFO - Iter [40200/160000]	lr: 7.730e-03, eta: 1 day, 20:12:43, time: 1.244, data_time: 0.015, memory: 5723, decode.loss_seg: 1.0962, decode.acc_seg: 51.5876, loss: 1.0962
2021-08-14 13:42:16,451 - mmseg - INFO - Iter [40250/160000]	lr: 7.727e-03, eta: 1 day, 20:11:21, time: 1.224, data_time: 0.015, memory: 5723, decode.loss_seg: 1.1534, decode.acc_seg: 51.5470, loss: 1.1534
2021-08-14 13:43:18,762 - mmseg - INFO - Iter [40300/160000]	lr: 7.725e-03, eta: 1 day, 20:10:03, time: 1.246, data_time: 0.015, memory: 5723, decode.loss_seg: 1.1627, decode.acc_seg: 51.1279, loss: 1.1627
2021-08-14 13:44:19,110 - mmseg - INFO - Iter [40350/160000]	lr: 7.722e-03, eta: 1 day, 20:08:38, time: 1.207, data_time: 0.014, memory: 5723, decode.loss_seg: 1.1062, decode.acc_seg: 51.8861, loss: 1.1062
2021-08-14 13:45:56,423 - mmseg - INFO - Iter [40400/160000]	lr: 7.719e-03, eta: 1 day, 20:09:03, time: 1.946, data_time: 0.725, memory: 5723, decode.loss_seg: 1.1339, decode.acc_seg: 50.9056, loss: 1.1339
2021-08-14 13:47:00,584 - mmseg - INFO - Iter [40450/160000]	lr: 7.716e-03, eta: 1 day, 20:07:50, time: 1.283, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1350, decode.acc_seg: 51.6658, loss: 1.1350
2021-08-14 13:48:03,328 - mmseg - INFO - Iter [40500/160000]	lr: 7.713e-03, eta: 1 day, 20:06:33, time: 1.254, data_time: 0.015, memory: 5723, decode.loss_seg: 1.1227, decode.acc_seg: 51.6683, loss: 1.1227
2021-08-14 13:49:04,701 - mmseg - INFO - Iter [40550/160000]	lr: 7.710e-03, eta: 1 day, 20:05:12, time: 1.228, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1523, decode.acc_seg: 51.6890, loss: 1.1523
2021-08-14 13:50:05,863 - mmseg - INFO - Iter [40600/160000]	lr: 7.707e-03, eta: 1 day, 20:03:50, time: 1.223, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1199, decode.acc_seg: 51.3334, loss: 1.1199
2021-08-14 13:51:10,287 - mmseg - INFO - Iter [40650/160000]	lr: 7.705e-03, eta: 1 day, 20:02:37, time: 1.288, data_time: 0.015, memory: 5723, decode.loss_seg: 1.1232, decode.acc_seg: 51.3547, loss: 1.1232
2021-08-14 13:52:12,323 - mmseg - INFO - Iter [40700/160000]	lr: 7.702e-03, eta: 1 day, 20:01:18, time: 1.241, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1269, decode.acc_seg: 51.4224, loss: 1.1269
2021-08-14 13:53:14,845 - mmseg - INFO - Iter [40750/160000]	lr: 7.699e-03, eta: 1 day, 20:00:00, time: 1.250, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1208, decode.acc_seg: 52.3730, loss: 1.1208
2021-08-14 13:54:17,042 - mmseg - INFO - Iter [40800/160000]	lr: 7.696e-03, eta: 1 day, 19:58:41, time: 1.245, data_time: 0.015, memory: 5723, decode.loss_seg: 1.1506, decode.acc_seg: 51.3955, loss: 1.1506
2021-08-14 13:55:21,608 - mmseg - INFO - Iter [40850/160000]	lr: 7.693e-03, eta: 1 day, 19:57:30, time: 1.291, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1395, decode.acc_seg: 51.0099, loss: 1.1395
2021-08-14 13:56:27,869 - mmseg - INFO - Iter [40900/160000]	lr: 7.690e-03, eta: 1 day, 19:56:23, time: 1.325, data_time: 0.015, memory: 5723, decode.loss_seg: 1.1690, decode.acc_seg: 51.7678, loss: 1.1690
2021-08-14 13:57:29,536 - mmseg - INFO - Iter [40950/160000]	lr: 7.687e-03, eta: 1 day, 19:55:03, time: 1.234, data_time: 0.017, memory: 5723, decode.loss_seg: 1.1214, decode.acc_seg: 52.7499, loss: 1.1214
2021-08-14 13:58:31,791 - mmseg - INFO - Exp name: fcn_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 13:58:31,792 - mmseg - INFO - Iter [41000/160000]	lr: 7.684e-03, eta: 1 day, 19:53:44, time: 1.245, data_time: 0.017, memory: 5723, decode.loss_seg: 1.0992, decode.acc_seg: 52.0623, loss: 1.0992
2021-08-14 14:00:10,321 - mmseg - INFO - Iter [41050/160000]	lr: 7.682e-03, eta: 1 day, 19:54:11, time: 1.971, data_time: 0.735, memory: 5723, decode.loss_seg: 1.0971, decode.acc_seg: 53.2216, loss: 1.0971
2021-08-14 14:01:14,164 - mmseg - INFO - Iter [41100/160000]	lr: 7.679e-03, eta: 1 day, 19:52:57, time: 1.277, data_time: 0.017, memory: 5723, decode.loss_seg: 1.0898, decode.acc_seg: 52.3477, loss: 1.0898
2021-08-14 14:02:16,923 - mmseg - INFO - Iter [41150/160000]	lr: 7.676e-03, eta: 1 day, 19:51:40, time: 1.255, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1402, decode.acc_seg: 51.9394, loss: 1.1402
2021-08-14 14:03:20,202 - mmseg - INFO - Iter [41200/160000]	lr: 7.673e-03, eta: 1 day, 19:50:24, time: 1.265, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1159, decode.acc_seg: 52.6497, loss: 1.1159
2021-08-14 14:04:26,932 - mmseg - INFO - Iter [41250/160000]	lr: 7.670e-03, eta: 1 day, 19:49:19, time: 1.335, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1473, decode.acc_seg: 51.8194, loss: 1.1473
2021-08-14 14:05:30,720 - mmseg - INFO - Iter [41300/160000]	lr: 7.667e-03, eta: 1 day, 19:48:05, time: 1.276, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0859, decode.acc_seg: 52.2097, loss: 1.0859
2021-08-14 14:06:34,263 - mmseg - INFO - Iter [41350/160000]	lr: 7.664e-03, eta: 1 day, 19:46:50, time: 1.270, data_time: 0.015, memory: 5723, decode.loss_seg: 1.1266, decode.acc_seg: 51.8288, loss: 1.1266
2021-08-14 14:07:36,486 - mmseg - INFO - Iter [41400/160000]	lr: 7.661e-03, eta: 1 day, 19:45:32, time: 1.245, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1496, decode.acc_seg: 50.9016, loss: 1.1496
2021-08-14 14:08:38,491 - mmseg - INFO - Iter [41450/160000]	lr: 7.659e-03, eta: 1 day, 19:44:13, time: 1.240, data_time: 0.015, memory: 5723, decode.loss_seg: 1.1565, decode.acc_seg: 50.5893, loss: 1.1565
2021-08-14 14:09:41,327 - mmseg - INFO - Iter [41500/160000]	lr: 7.656e-03, eta: 1 day, 19:42:56, time: 1.257, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1426, decode.acc_seg: 51.4926, loss: 1.1426
2021-08-14 14:10:44,205 - mmseg - INFO - Iter [41550/160000]	lr: 7.653e-03, eta: 1 day, 19:41:40, time: 1.257, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1136, decode.acc_seg: 51.3527, loss: 1.1136
2021-08-14 14:11:46,882 - mmseg - INFO - Iter [41600/160000]	lr: 7.650e-03, eta: 1 day, 19:40:23, time: 1.254, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1259, decode.acc_seg: 52.2088, loss: 1.1259
2021-08-14 14:13:25,589 - mmseg - INFO - Iter [41650/160000]	lr: 7.647e-03, eta: 1 day, 19:40:48, time: 1.974, data_time: 0.724, memory: 5723, decode.loss_seg: 1.1383, decode.acc_seg: 51.3901, loss: 1.1383
2021-08-14 14:14:30,369 - mmseg - INFO - Iter [41700/160000]	lr: 7.644e-03, eta: 1 day, 19:39:37, time: 1.295, data_time: 0.015, memory: 5723, decode.loss_seg: 1.0920, decode.acc_seg: 51.7333, loss: 1.0920
2021-08-14 14:15:35,014 - mmseg - INFO - Iter [41750/160000]	lr: 7.641e-03, eta: 1 day, 19:38:25, time: 1.293, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0860, decode.acc_seg: 53.4999, loss: 1.0860
2021-08-14 14:16:39,798 - mmseg - INFO - Iter [41800/160000]	lr: 7.639e-03, eta: 1 day, 19:37:14, time: 1.296, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0789, decode.acc_seg: 52.8110, loss: 1.0789
2021-08-14 14:17:45,300 - mmseg - INFO - Iter [41850/160000]	lr: 7.636e-03, eta: 1 day, 19:36:05, time: 1.310, data_time: 0.015, memory: 5723, decode.loss_seg: 1.1536, decode.acc_seg: 51.7488, loss: 1.1536
2021-08-14 14:18:48,568 - mmseg - INFO - Iter [41900/160000]	lr: 7.633e-03, eta: 1 day, 19:34:50, time: 1.266, data_time: 0.015, memory: 5723, decode.loss_seg: 1.1524, decode.acc_seg: 50.6840, loss: 1.1524
2021-08-14 14:19:51,187 - mmseg - INFO - Iter [41950/160000]	lr: 7.630e-03, eta: 1 day, 19:33:33, time: 1.252, data_time: 0.015, memory: 5723, decode.loss_seg: 1.1540, decode.acc_seg: 50.9214, loss: 1.1540
2021-08-14 14:20:54,212 - mmseg - INFO - Exp name: fcn_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 14:20:54,212 - mmseg - INFO - Iter [42000/160000]	lr: 7.627e-03, eta: 1 day, 19:32:17, time: 1.260, data_time: 0.015, memory: 5723, decode.loss_seg: 1.1178, decode.acc_seg: 51.5820, loss: 1.1178
2021-08-14 14:21:58,249 - mmseg - INFO - Iter [42050/160000]	lr: 7.624e-03, eta: 1 day, 19:31:04, time: 1.280, data_time: 0.015, memory: 5723, decode.loss_seg: 1.0948, decode.acc_seg: 51.4399, loss: 1.0948
2021-08-14 14:23:01,778 - mmseg - INFO - Iter [42100/160000]	lr: 7.621e-03, eta: 1 day, 19:29:49, time: 1.271, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1336, decode.acc_seg: 50.6523, loss: 1.1336
2021-08-14 14:24:03,608 - mmseg - INFO - Iter [42150/160000]	lr: 7.618e-03, eta: 1 day, 19:28:30, time: 1.237, data_time: 0.017, memory: 5723, decode.loss_seg: 1.1250, decode.acc_seg: 51.3460, loss: 1.1250
2021-08-14 14:25:09,002 - mmseg - INFO - Iter [42200/160000]	lr: 7.616e-03, eta: 1 day, 19:27:21, time: 1.307, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1377, decode.acc_seg: 50.6483, loss: 1.1377
2021-08-14 14:26:14,296 - mmseg - INFO - Iter [42250/160000]	lr: 7.613e-03, eta: 1 day, 19:26:11, time: 1.306, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1717, decode.acc_seg: 50.5693, loss: 1.1717
2021-08-14 14:27:51,686 - mmseg - INFO - Iter [42300/160000]	lr: 7.610e-03, eta: 1 day, 19:26:31, time: 1.949, data_time: 0.727, memory: 5723, decode.loss_seg: 1.1129, decode.acc_seg: 51.4892, loss: 1.1129
2021-08-14 14:28:53,772 - mmseg - INFO - Iter [42350/160000]	lr: 7.607e-03, eta: 1 day, 19:25:13, time: 1.241, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0865, decode.acc_seg: 51.9247, loss: 1.0865
2021-08-14 14:29:54,829 - mmseg - INFO - Iter [42400/160000]	lr: 7.604e-03, eta: 1 day, 19:23:51, time: 1.222, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1107, decode.acc_seg: 51.5835, loss: 1.1107
2021-08-14 14:30:58,679 - mmseg - INFO - Iter [42450/160000]	lr: 7.601e-03, eta: 1 day, 19:22:38, time: 1.276, data_time: 0.015, memory: 5723, decode.loss_seg: 1.1503, decode.acc_seg: 50.5705, loss: 1.1503
2021-08-14 14:32:04,032 - mmseg - INFO - Iter [42500/160000]	lr: 7.598e-03, eta: 1 day, 19:21:28, time: 1.307, data_time: 0.015, memory: 5723, decode.loss_seg: 1.1233, decode.acc_seg: 52.4672, loss: 1.1233
2021-08-14 14:33:05,851 - mmseg - INFO - Iter [42550/160000]	lr: 7.595e-03, eta: 1 day, 19:20:09, time: 1.237, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1102, decode.acc_seg: 51.9918, loss: 1.1102
2021-08-14 14:34:10,024 - mmseg - INFO - Iter [42600/160000]	lr: 7.593e-03, eta: 1 day, 19:18:57, time: 1.284, data_time: 0.015, memory: 5723, decode.loss_seg: 1.1339, decode.acc_seg: 52.1768, loss: 1.1339
2021-08-14 14:35:12,129 - mmseg - INFO - Iter [42650/160000]	lr: 7.590e-03, eta: 1 day, 19:17:38, time: 1.242, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1244, decode.acc_seg: 51.3346, loss: 1.1244
2021-08-14 14:36:13,735 - mmseg - INFO - Iter [42700/160000]	lr: 7.587e-03, eta: 1 day, 19:16:19, time: 1.232, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1159, decode.acc_seg: 51.3629, loss: 1.1159
2021-08-14 14:37:16,483 - mmseg - INFO - Iter [42750/160000]	lr: 7.584e-03, eta: 1 day, 19:15:02, time: 1.255, data_time: 0.015, memory: 5723, decode.loss_seg: 1.1107, decode.acc_seg: 52.5830, loss: 1.1107
2021-08-14 14:38:19,462 - mmseg - INFO - Iter [42800/160000]	lr: 7.581e-03, eta: 1 day, 19:13:47, time: 1.259, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0701, decode.acc_seg: 53.8937, loss: 1.0701
2021-08-14 14:39:23,835 - mmseg - INFO - Iter [42850/160000]	lr: 7.578e-03, eta: 1 day, 19:12:35, time: 1.288, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1290, decode.acc_seg: 52.0955, loss: 1.1290
2021-08-14 14:40:30,556 - mmseg - INFO - Iter [42900/160000]	lr: 7.575e-03, eta: 1 day, 19:11:29, time: 1.333, data_time: 0.014, memory: 5723, decode.loss_seg: 1.1380, decode.acc_seg: 51.2729, loss: 1.1380
2021-08-14 14:42:09,287 - mmseg - INFO - Iter [42950/160000]	lr: 7.572e-03, eta: 1 day, 19:11:51, time: 1.975, data_time: 0.729, memory: 5723, decode.loss_seg: 1.0897, decode.acc_seg: 51.7486, loss: 1.0897
2021-08-14 14:43:11,862 - mmseg - INFO - Exp name: fcn_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 14:43:11,863 - mmseg - INFO - Iter [43000/160000]	lr: 7.570e-03, eta: 1 day, 19:10:34, time: 1.251, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0669, decode.acc_seg: 52.9022, loss: 1.0669
2021-08-14 14:44:19,050 - mmseg - INFO - Iter [43050/160000]	lr: 7.567e-03, eta: 1 day, 19:09:30, time: 1.343, data_time: 0.015, memory: 5723, decode.loss_seg: 1.1028, decode.acc_seg: 52.9409, loss: 1.1028
2021-08-14 14:45:22,570 - mmseg - INFO - Iter [43100/160000]	lr: 7.564e-03, eta: 1 day, 19:08:15, time: 1.271, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1358, decode.acc_seg: 50.8268, loss: 1.1358
2021-08-14 14:46:23,633 - mmseg - INFO - Iter [43150/160000]	lr: 7.561e-03, eta: 1 day, 19:06:54, time: 1.220, data_time: 0.015, memory: 5723, decode.loss_seg: 1.0873, decode.acc_seg: 52.3849, loss: 1.0873
2021-08-14 14:47:25,897 - mmseg - INFO - Iter [43200/160000]	lr: 7.558e-03, eta: 1 day, 19:05:37, time: 1.246, data_time: 0.017, memory: 5723, decode.loss_seg: 1.1125, decode.acc_seg: 52.8168, loss: 1.1125
2021-08-14 14:48:27,513 - mmseg - INFO - Iter [43250/160000]	lr: 7.555e-03, eta: 1 day, 19:04:17, time: 1.232, data_time: 0.015, memory: 5723, decode.loss_seg: 1.1585, decode.acc_seg: 50.5554, loss: 1.1585
2021-08-14 14:49:28,705 - mmseg - INFO - Iter [43300/160000]	lr: 7.552e-03, eta: 1 day, 19:02:57, time: 1.224, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1465, decode.acc_seg: 51.8696, loss: 1.1465
2021-08-14 14:50:29,775 - mmseg - INFO - Iter [43350/160000]	lr: 7.549e-03, eta: 1 day, 19:01:36, time: 1.222, data_time: 0.015, memory: 5723, decode.loss_seg: 1.1243, decode.acc_seg: 51.3328, loss: 1.1243
2021-08-14 14:51:32,734 - mmseg - INFO - Iter [43400/160000]	lr: 7.547e-03, eta: 1 day, 19:00:21, time: 1.258, data_time: 0.015, memory: 5723, decode.loss_seg: 1.1549, decode.acc_seg: 51.2802, loss: 1.1549
2021-08-14 14:52:35,287 - mmseg - INFO - Iter [43450/160000]	lr: 7.544e-03, eta: 1 day, 18:59:04, time: 1.251, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1214, decode.acc_seg: 52.1922, loss: 1.1214
2021-08-14 14:53:40,994 - mmseg - INFO - Iter [43500/160000]	lr: 7.541e-03, eta: 1 day, 18:57:56, time: 1.315, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1088, decode.acc_seg: 52.5747, loss: 1.1088
2021-08-14 14:55:20,280 - mmseg - INFO - Iter [43550/160000]	lr: 7.538e-03, eta: 1 day, 18:58:17, time: 1.986, data_time: 0.733, memory: 5723, decode.loss_seg: 1.1136, decode.acc_seg: 52.1627, loss: 1.1136
2021-08-14 14:56:20,837 - mmseg - INFO - Iter [43600/160000]	lr: 7.535e-03, eta: 1 day, 18:56:55, time: 1.211, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0698, decode.acc_seg: 52.4662, loss: 1.0698
2021-08-14 14:57:22,062 - mmseg - INFO - Iter [43650/160000]	lr: 7.532e-03, eta: 1 day, 18:55:35, time: 1.225, data_time: 0.017, memory: 5723, decode.loss_seg: 1.1245, decode.acc_seg: 51.5408, loss: 1.1245
2021-08-14 14:58:24,581 - mmseg - INFO - Iter [43700/160000]	lr: 7.529e-03, eta: 1 day, 18:54:18, time: 1.249, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0837, decode.acc_seg: 52.8250, loss: 1.0837
2021-08-14 14:59:29,891 - mmseg - INFO - Iter [43750/160000]	lr: 7.527e-03, eta: 1 day, 18:53:09, time: 1.307, data_time: 0.017, memory: 5723, decode.loss_seg: 1.0963, decode.acc_seg: 52.9144, loss: 1.0963
2021-08-14 15:00:33,467 - mmseg - INFO - Iter [43800/160000]	lr: 7.524e-03, eta: 1 day, 18:51:55, time: 1.272, data_time: 0.018, memory: 5723, decode.loss_seg: 1.1427, decode.acc_seg: 50.8548, loss: 1.1427
2021-08-14 15:01:34,472 - mmseg - INFO - Iter [43850/160000]	lr: 7.521e-03, eta: 1 day, 18:50:34, time: 1.220, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0615, decode.acc_seg: 53.4443, loss: 1.0615
2021-08-14 15:02:34,799 - mmseg - INFO - Iter [43900/160000]	lr: 7.518e-03, eta: 1 day, 18:49:12, time: 1.207, data_time: 0.018, memory: 5723, decode.loss_seg: 1.1006, decode.acc_seg: 52.2544, loss: 1.1006
2021-08-14 15:03:37,882 - mmseg - INFO - Iter [43950/160000]	lr: 7.515e-03, eta: 1 day, 18:47:57, time: 1.262, data_time: 0.016, memory: 5723, decode.loss_seg: 1.2015, decode.acc_seg: 50.8546, loss: 1.2015
2021-08-14 15:04:39,860 - mmseg - INFO - Exp name: fcn_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 15:04:39,860 - mmseg - INFO - Iter [44000/160000]	lr: 7.512e-03, eta: 1 day, 18:46:39, time: 1.239, data_time: 0.017, memory: 5723, decode.loss_seg: 1.0984, decode.acc_seg: 51.4903, loss: 1.0984
2021-08-14 15:05:44,065 - mmseg - INFO - Iter [44050/160000]	lr: 7.509e-03, eta: 1 day, 18:45:27, time: 1.284, data_time: 0.017, memory: 5723, decode.loss_seg: 1.1165, decode.acc_seg: 51.7931, loss: 1.1165
2021-08-14 15:06:47,222 - mmseg - INFO - Iter [44100/160000]	lr: 7.506e-03, eta: 1 day, 18:44:12, time: 1.264, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1396, decode.acc_seg: 51.3467, loss: 1.1396
2021-08-14 15:07:48,790 - mmseg - INFO - Iter [44150/160000]	lr: 7.503e-03, eta: 1 day, 18:42:53, time: 1.231, data_time: 0.018, memory: 5723, decode.loss_seg: 1.0966, decode.acc_seg: 52.8986, loss: 1.0966
2021-08-14 15:09:28,762 - mmseg - INFO - Iter [44200/160000]	lr: 7.501e-03, eta: 1 day, 18:43:14, time: 1.999, data_time: 0.697, memory: 5723, decode.loss_seg: 1.1007, decode.acc_seg: 52.7480, loss: 1.1007
2021-08-14 15:10:32,980 - mmseg - INFO - Iter [44250/160000]	lr: 7.498e-03, eta: 1 day, 18:42:02, time: 1.285, data_time: 0.018, memory: 5723, decode.loss_seg: 1.0829, decode.acc_seg: 52.4693, loss: 1.0829
2021-08-14 15:11:38,333 - mmseg - INFO - Iter [44300/160000]	lr: 7.495e-03, eta: 1 day, 18:40:53, time: 1.307, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1750, decode.acc_seg: 52.1725, loss: 1.1750
2021-08-14 15:12:39,150 - mmseg - INFO - Iter [44350/160000]	lr: 7.492e-03, eta: 1 day, 18:39:32, time: 1.217, data_time: 0.018, memory: 5723, decode.loss_seg: 1.1095, decode.acc_seg: 52.0774, loss: 1.1095
2021-08-14 15:13:42,688 - mmseg - INFO - Iter [44400/160000]	lr: 7.489e-03, eta: 1 day, 18:38:18, time: 1.271, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1231, decode.acc_seg: 51.8371, loss: 1.1231
2021-08-14 15:14:45,850 - mmseg - INFO - Iter [44450/160000]	lr: 7.486e-03, eta: 1 day, 18:37:03, time: 1.262, data_time: 0.017, memory: 5723, decode.loss_seg: 1.1083, decode.acc_seg: 51.8697, loss: 1.1083
2021-08-14 15:15:52,662 - mmseg - INFO - Iter [44500/160000]	lr: 7.483e-03, eta: 1 day, 18:35:58, time: 1.337, data_time: 0.018, memory: 5723, decode.loss_seg: 1.1085, decode.acc_seg: 52.4692, loss: 1.1085
2021-08-14 15:16:54,383 - mmseg - INFO - Iter [44550/160000]	lr: 7.480e-03, eta: 1 day, 18:34:40, time: 1.234, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0622, decode.acc_seg: 52.9740, loss: 1.0622
2021-08-14 15:17:55,717 - mmseg - INFO - Iter [44600/160000]	lr: 7.478e-03, eta: 1 day, 18:33:20, time: 1.226, data_time: 0.017, memory: 5723, decode.loss_seg: 1.1151, decode.acc_seg: 51.7616, loss: 1.1151
2021-08-14 15:18:58,849 - mmseg - INFO - Iter [44650/160000]	lr: 7.475e-03, eta: 1 day, 18:32:06, time: 1.263, data_time: 0.018, memory: 5723, decode.loss_seg: 1.1260, decode.acc_seg: 51.8153, loss: 1.1260
2021-08-14 15:20:04,494 - mmseg - INFO - Iter [44700/160000]	lr: 7.472e-03, eta: 1 day, 18:30:57, time: 1.313, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1201, decode.acc_seg: 52.6962, loss: 1.1201
2021-08-14 15:21:09,676 - mmseg - INFO - Iter [44750/160000]	lr: 7.469e-03, eta: 1 day, 18:29:48, time: 1.304, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1520, decode.acc_seg: 51.5387, loss: 1.1520
2021-08-14 15:22:13,881 - mmseg - INFO - Iter [44800/160000]	lr: 7.466e-03, eta: 1 day, 18:28:36, time: 1.284, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1054, decode.acc_seg: 52.4442, loss: 1.1054
2021-08-14 15:23:53,769 - mmseg - INFO - Iter [44850/160000]	lr: 7.463e-03, eta: 1 day, 18:28:56, time: 1.998, data_time: 0.719, memory: 5723, decode.loss_seg: 1.0822, decode.acc_seg: 52.4029, loss: 1.0822
2021-08-14 15:24:57,210 - mmseg - INFO - Iter [44900/160000]	lr: 7.460e-03, eta: 1 day, 18:27:42, time: 1.269, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0927, decode.acc_seg: 52.8242, loss: 1.0927
2021-08-14 15:26:01,684 - mmseg - INFO - Iter [44950/160000]	lr: 7.457e-03, eta: 1 day, 18:26:30, time: 1.289, data_time: 0.015, memory: 5723, decode.loss_seg: 1.0914, decode.acc_seg: 52.8448, loss: 1.0914
2021-08-14 15:27:03,879 - mmseg - INFO - Exp name: fcn_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 15:27:03,880 - mmseg - INFO - Iter [45000/160000]	lr: 7.455e-03, eta: 1 day, 18:25:13, time: 1.244, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0978, decode.acc_seg: 52.7195, loss: 1.0978
2021-08-14 15:28:06,952 - mmseg - INFO - Iter [45050/160000]	lr: 7.452e-03, eta: 1 day, 18:23:58, time: 1.261, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0923, decode.acc_seg: 51.5491, loss: 1.0923
2021-08-14 15:29:12,192 - mmseg - INFO - Iter [45100/160000]	lr: 7.449e-03, eta: 1 day, 18:22:49, time: 1.304, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0944, decode.acc_seg: 51.7964, loss: 1.0944
2021-08-14 15:30:13,870 - mmseg - INFO - Iter [45150/160000]	lr: 7.446e-03, eta: 1 day, 18:21:30, time: 1.234, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0823, decode.acc_seg: 52.3024, loss: 1.0823
2021-08-14 15:31:16,838 - mmseg - INFO - Iter [45200/160000]	lr: 7.443e-03, eta: 1 day, 18:20:15, time: 1.260, data_time: 0.017, memory: 5723, decode.loss_seg: 1.0892, decode.acc_seg: 52.0942, loss: 1.0892
2021-08-14 15:32:19,447 - mmseg - INFO - Iter [45250/160000]	lr: 7.440e-03, eta: 1 day, 18:19:00, time: 1.252, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1486, decode.acc_seg: 51.2553, loss: 1.1486
2021-08-14 15:33:22,979 - mmseg - INFO - Iter [45300/160000]	lr: 7.437e-03, eta: 1 day, 18:17:46, time: 1.271, data_time: 0.015, memory: 5723, decode.loss_seg: 1.1324, decode.acc_seg: 52.2258, loss: 1.1324
2021-08-14 15:34:27,067 - mmseg - INFO - Iter [45350/160000]	lr: 7.434e-03, eta: 1 day, 18:16:34, time: 1.281, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1182, decode.acc_seg: 51.6330, loss: 1.1182
2021-08-14 15:35:29,901 - mmseg - INFO - Iter [45400/160000]	lr: 7.432e-03, eta: 1 day, 18:15:18, time: 1.257, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0988, decode.acc_seg: 52.8978, loss: 1.0988
2021-08-14 15:37:09,484 - mmseg - INFO - Iter [45450/160000]	lr: 7.429e-03, eta: 1 day, 18:15:36, time: 1.992, data_time: 0.741, memory: 5723, decode.loss_seg: 1.1325, decode.acc_seg: 51.9864, loss: 1.1325
2021-08-14 15:38:12,802 - mmseg - INFO - Iter [45500/160000]	lr: 7.426e-03, eta: 1 day, 18:14:22, time: 1.266, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0623, decode.acc_seg: 52.2862, loss: 1.0623
2021-08-14 15:39:14,853 - mmseg - INFO - Iter [45550/160000]	lr: 7.423e-03, eta: 1 day, 18:13:04, time: 1.241, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0865, decode.acc_seg: 52.8951, loss: 1.0865
2021-08-14 15:40:18,093 - mmseg - INFO - Iter [45600/160000]	lr: 7.420e-03, eta: 1 day, 18:11:50, time: 1.264, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1157, decode.acc_seg: 52.6530, loss: 1.1157
2021-08-14 15:41:19,585 - mmseg - INFO - Iter [45650/160000]	lr: 7.417e-03, eta: 1 day, 18:10:31, time: 1.231, data_time: 0.017, memory: 5723, decode.loss_seg: 1.0799, decode.acc_seg: 52.5827, loss: 1.0799
2021-08-14 15:42:21,479 - mmseg - INFO - Iter [45700/160000]	lr: 7.414e-03, eta: 1 day, 18:09:14, time: 1.237, data_time: 0.018, memory: 5723, decode.loss_seg: 1.1142, decode.acc_seg: 52.0184, loss: 1.1142
2021-08-14 15:43:22,837 - mmseg - INFO - Iter [45750/160000]	lr: 7.411e-03, eta: 1 day, 18:07:55, time: 1.228, data_time: 0.017, memory: 5723, decode.loss_seg: 1.1422, decode.acc_seg: 51.6174, loss: 1.1422
2021-08-14 15:44:24,335 - mmseg - INFO - Iter [45800/160000]	lr: 7.409e-03, eta: 1 day, 18:06:36, time: 1.230, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1031, decode.acc_seg: 52.3081, loss: 1.1031
2021-08-14 15:45:29,199 - mmseg - INFO - Iter [45850/160000]	lr: 7.406e-03, eta: 1 day, 18:05:26, time: 1.296, data_time: 0.015, memory: 5723, decode.loss_seg: 1.1214, decode.acc_seg: 52.3654, loss: 1.1214
2021-08-14 15:46:36,055 - mmseg - INFO - Iter [45900/160000]	lr: 7.403e-03, eta: 1 day, 18:04:21, time: 1.338, data_time: 0.017, memory: 5723, decode.loss_seg: 1.1124, decode.acc_seg: 51.9630, loss: 1.1124
2021-08-14 15:47:41,253 - mmseg - INFO - Iter [45950/160000]	lr: 7.400e-03, eta: 1 day, 18:03:11, time: 1.304, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0821, decode.acc_seg: 52.8110, loss: 1.0821
2021-08-14 15:48:46,938 - mmseg - INFO - Exp name: fcn_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 15:48:46,938 - mmseg - INFO - Iter [46000/160000]	lr: 7.397e-03, eta: 1 day, 18:02:03, time: 1.314, data_time: 0.017, memory: 5723, decode.loss_seg: 1.1364, decode.acc_seg: 52.5817, loss: 1.1364
2021-08-14 15:49:52,532 - mmseg - INFO - Iter [46050/160000]	lr: 7.394e-03, eta: 1 day, 18:00:55, time: 1.312, data_time: 0.015, memory: 5723, decode.loss_seg: 1.0976, decode.acc_seg: 52.1696, loss: 1.0976
2021-08-14 15:51:31,767 - mmseg - INFO - Iter [46100/160000]	lr: 7.391e-03, eta: 1 day, 18:01:10, time: 1.986, data_time: 0.712, memory: 5723, decode.loss_seg: 1.0809, decode.acc_seg: 52.6650, loss: 1.0809
2021-08-14 15:52:33,679 - mmseg - INFO - Iter [46150/160000]	lr: 7.388e-03, eta: 1 day, 17:59:53, time: 1.238, data_time: 0.017, memory: 5723, decode.loss_seg: 1.0863, decode.acc_seg: 52.7991, loss: 1.0863
2021-08-14 15:53:35,109 - mmseg - INFO - Iter [46200/160000]	lr: 7.385e-03, eta: 1 day, 17:58:34, time: 1.229, data_time: 0.015, memory: 5723, decode.loss_seg: 1.1154, decode.acc_seg: 52.5316, loss: 1.1154
2021-08-14 15:54:37,090 - mmseg - INFO - Iter [46250/160000]	lr: 7.383e-03, eta: 1 day, 17:57:17, time: 1.239, data_time: 0.015, memory: 5723, decode.loss_seg: 1.1057, decode.acc_seg: 52.3553, loss: 1.1057
2021-08-14 15:55:39,530 - mmseg - INFO - Iter [46300/160000]	lr: 7.380e-03, eta: 1 day, 17:56:01, time: 1.249, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0826, decode.acc_seg: 52.0177, loss: 1.0826
2021-08-14 15:56:41,705 - mmseg - INFO - Iter [46350/160000]	lr: 7.377e-03, eta: 1 day, 17:54:44, time: 1.243, data_time: 0.017, memory: 5723, decode.loss_seg: 1.1205, decode.acc_seg: 50.8388, loss: 1.1205
2021-08-14 15:57:43,778 - mmseg - INFO - Iter [46400/160000]	lr: 7.374e-03, eta: 1 day, 17:53:27, time: 1.241, data_time: 0.017, memory: 5723, decode.loss_seg: 1.1179, decode.acc_seg: 51.3391, loss: 1.1179
2021-08-14 15:58:48,615 - mmseg - INFO - Iter [46450/160000]	lr: 7.371e-03, eta: 1 day, 17:52:17, time: 1.297, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1022, decode.acc_seg: 52.5614, loss: 1.1022
2021-08-14 15:59:50,156 - mmseg - INFO - Iter [46500/160000]	lr: 7.368e-03, eta: 1 day, 17:50:59, time: 1.231, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0958, decode.acc_seg: 52.2933, loss: 1.0958
2021-08-14 16:00:51,309 - mmseg - INFO - Iter [46550/160000]	lr: 7.365e-03, eta: 1 day, 17:49:39, time: 1.223, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0631, decode.acc_seg: 53.1978, loss: 1.0631
2021-08-14 16:01:55,109 - mmseg - INFO - Iter [46600/160000]	lr: 7.362e-03, eta: 1 day, 17:48:27, time: 1.276, data_time: 0.015, memory: 5723, decode.loss_seg: 1.0960, decode.acc_seg: 52.5477, loss: 1.0960
2021-08-14 16:02:57,570 - mmseg - INFO - Iter [46650/160000]	lr: 7.360e-03, eta: 1 day, 17:47:11, time: 1.249, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1332, decode.acc_seg: 52.0389, loss: 1.1332
2021-08-14 16:04:34,912 - mmseg - INFO - Iter [46700/160000]	lr: 7.357e-03, eta: 1 day, 17:47:20, time: 1.948, data_time: 0.740, memory: 5723, decode.loss_seg: 1.1205, decode.acc_seg: 52.5555, loss: 1.1205
2021-08-14 16:05:38,215 - mmseg - INFO - Iter [46750/160000]	lr: 7.354e-03, eta: 1 day, 17:46:06, time: 1.265, data_time: 0.015, memory: 5723, decode.loss_seg: 1.0932, decode.acc_seg: 52.6567, loss: 1.0932
2021-08-14 16:06:44,170 - mmseg - INFO - Iter [46800/160000]	lr: 7.351e-03, eta: 1 day, 17:44:59, time: 1.320, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0778, decode.acc_seg: 51.8896, loss: 1.0778
2021-08-14 16:07:47,474 - mmseg - INFO - Iter [46850/160000]	lr: 7.348e-03, eta: 1 day, 17:43:45, time: 1.265, data_time: 0.015, memory: 5723, decode.loss_seg: 1.0504, decode.acc_seg: 52.5849, loss: 1.0504
2021-08-14 16:08:49,246 - mmseg - INFO - Iter [46900/160000]	lr: 7.345e-03, eta: 1 day, 17:42:27, time: 1.236, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1193, decode.acc_seg: 52.5089, loss: 1.1193
2021-08-14 16:09:55,792 - mmseg - INFO - Iter [46950/160000]	lr: 7.342e-03, eta: 1 day, 17:41:21, time: 1.330, data_time: 0.015, memory: 5723, decode.loss_seg: 1.0888, decode.acc_seg: 53.8117, loss: 1.0888
2021-08-14 16:11:03,028 - mmseg - INFO - Exp name: fcn_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 16:11:03,028 - mmseg - INFO - Iter [47000/160000]	lr: 7.339e-03, eta: 1 day, 17:40:17, time: 1.345, data_time: 0.015, memory: 5723, decode.loss_seg: 1.0777, decode.acc_seg: 53.1223, loss: 1.0777
2021-08-14 16:12:07,205 - mmseg - INFO - Iter [47050/160000]	lr: 7.336e-03, eta: 1 day, 17:39:05, time: 1.284, data_time: 0.014, memory: 5723, decode.loss_seg: 1.1192, decode.acc_seg: 51.6648, loss: 1.1192
2021-08-14 16:13:09,530 - mmseg - INFO - Iter [47100/160000]	lr: 7.334e-03, eta: 1 day, 17:37:49, time: 1.247, data_time: 0.015, memory: 5723, decode.loss_seg: 1.0709, decode.acc_seg: 52.2225, loss: 1.0709
2021-08-14 16:14:14,543 - mmseg - INFO - Iter [47150/160000]	lr: 7.331e-03, eta: 1 day, 17:36:40, time: 1.300, data_time: 0.015, memory: 5723, decode.loss_seg: 1.0875, decode.acc_seg: 53.0349, loss: 1.0875
2021-08-14 16:15:18,227 - mmseg - INFO - Iter [47200/160000]	lr: 7.328e-03, eta: 1 day, 17:35:27, time: 1.273, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1291, decode.acc_seg: 52.0465, loss: 1.1291
2021-08-14 16:16:21,792 - mmseg - INFO - Iter [47250/160000]	lr: 7.325e-03, eta: 1 day, 17:34:14, time: 1.272, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1261, decode.acc_seg: 51.7782, loss: 1.1261
2021-08-14 16:17:23,979 - mmseg - INFO - Iter [47300/160000]	lr: 7.322e-03, eta: 1 day, 17:32:57, time: 1.244, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1595, decode.acc_seg: 51.4721, loss: 1.1595
2021-08-14 16:19:02,165 - mmseg - INFO - Iter [47350/160000]	lr: 7.319e-03, eta: 1 day, 17:33:07, time: 1.963, data_time: 0.720, memory: 5723, decode.loss_seg: 1.0956, decode.acc_seg: 52.3292, loss: 1.0956
2021-08-14 16:20:04,997 - mmseg - INFO - Iter [47400/160000]	lr: 7.316e-03, eta: 1 day, 17:31:52, time: 1.257, data_time: 0.017, memory: 5723, decode.loss_seg: 1.0938, decode.acc_seg: 51.4426, loss: 1.0938
2021-08-14 16:21:09,548 - mmseg - INFO - Iter [47450/160000]	lr: 7.313e-03, eta: 1 day, 17:30:41, time: 1.291, data_time: 0.015, memory: 5723, decode.loss_seg: 1.0914, decode.acc_seg: 52.3565, loss: 1.0914
2021-08-14 16:22:11,523 - mmseg - INFO - Iter [47500/160000]	lr: 7.311e-03, eta: 1 day, 17:29:24, time: 1.238, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1037, decode.acc_seg: 52.8397, loss: 1.1037
2021-08-14 16:23:13,049 - mmseg - INFO - Iter [47550/160000]	lr: 7.308e-03, eta: 1 day, 17:28:06, time: 1.232, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1022, decode.acc_seg: 52.0835, loss: 1.1022
2021-08-14 16:24:15,176 - mmseg - INFO - Iter [47600/160000]	lr: 7.305e-03, eta: 1 day, 17:26:50, time: 1.242, data_time: 0.015, memory: 5723, decode.loss_seg: 1.0711, decode.acc_seg: 53.0833, loss: 1.0711
2021-08-14 16:25:18,955 - mmseg - INFO - Iter [47650/160000]	lr: 7.302e-03, eta: 1 day, 17:25:37, time: 1.276, data_time: 0.015, memory: 5723, decode.loss_seg: 1.1473, decode.acc_seg: 52.4948, loss: 1.1473
2021-08-14 16:26:22,219 - mmseg - INFO - Iter [47700/160000]	lr: 7.299e-03, eta: 1 day, 17:24:24, time: 1.265, data_time: 0.015, memory: 5723, decode.loss_seg: 1.0726, decode.acc_seg: 54.1515, loss: 1.0726
2021-08-14 16:27:27,573 - mmseg - INFO - Iter [47750/160000]	lr: 7.296e-03, eta: 1 day, 17:23:15, time: 1.308, data_time: 0.015, memory: 5723, decode.loss_seg: 1.1197, decode.acc_seg: 51.2007, loss: 1.1197
2021-08-14 16:28:28,959 - mmseg - INFO - Iter [47800/160000]	lr: 7.293e-03, eta: 1 day, 17:21:57, time: 1.227, data_time: 0.015, memory: 5723, decode.loss_seg: 1.0690, decode.acc_seg: 53.3578, loss: 1.0690
2021-08-14 16:29:30,975 - mmseg - INFO - Iter [47850/160000]	lr: 7.290e-03, eta: 1 day, 17:20:40, time: 1.240, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1124, decode.acc_seg: 52.6108, loss: 1.1124
2021-08-14 16:30:33,304 - mmseg - INFO - Iter [47900/160000]	lr: 7.287e-03, eta: 1 day, 17:19:25, time: 1.247, data_time: 0.015, memory: 5723, decode.loss_seg: 1.0917, decode.acc_seg: 52.4707, loss: 1.0917
2021-08-14 16:31:35,028 - mmseg - INFO - Iter [47950/160000]	lr: 7.285e-03, eta: 1 day, 17:18:07, time: 1.234, data_time: 0.015, memory: 5723, decode.loss_seg: 1.0997, decode.acc_seg: 53.3408, loss: 1.0997
2021-08-14 16:33:13,200 - mmseg - INFO - Saving checkpoint at 48000 iterations
2021-08-14 16:33:13,691 - mmseg - INFO - Exp name: fcn_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 16:33:13,691 - mmseg - INFO - Iter [48000/160000]	lr: 7.282e-03, eta: 1 day, 17:18:17, time: 1.974, data_time: 0.735, memory: 5723, decode.loss_seg: 1.0511, decode.acc_seg: 52.9966, loss: 1.0511
2021-08-14 16:35:16,207 - mmseg - INFO - per class results:
2021-08-14 16:35:16,218 - mmseg - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        |  55.1 | 82.59 |
|       building      |  66.1 | 87.11 |
|         sky         | 88.31 | 95.66 |
|        floor        | 56.85 | 83.28 |
|         tree        |  58.4 | 77.88 |
|       ceiling       | 68.03 | 82.74 |
|         road        | 66.87 | 82.74 |
|         bed         |  60.1 | 83.66 |
|      windowpane     | 40.05 | 67.85 |
|        grass        | 51.81 | 70.32 |
|       cabinet       | 36.11 | 44.99 |
|       sidewalk      | 36.12 | 45.63 |
|        person       | 40.45 | 56.44 |
|        earth        | 20.25 | 30.09 |
|         door        | 12.79 | 17.69 |
|        table        | 28.24 | 39.49 |
|       mountain      | 34.64 | 44.17 |
|        plant        | 34.18 | 49.45 |
|       curtain       | 35.71 | 47.72 |
|        chair        | 22.95 | 31.51 |
|         car         | 57.75 | 75.81 |
|        water        | 29.18 | 43.44 |
|       painting      | 46.59 |  55.4 |
|         sofa        | 31.75 | 48.64 |
|        shelf        |  15.3 | 21.07 |
|        house        | 13.72 | 15.26 |
|         sea         | 35.35 | 87.04 |
|        mirror       | 15.02 | 16.76 |
|         rug         | 23.09 | 25.51 |
|        field        | 18.61 | 52.82 |
|       armchair      |  6.38 |  7.1  |
|         seat        |  18.8 | 29.07 |
|        fence        |  8.15 | 12.91 |
|         desk        |  7.15 |  7.98 |
|         rock        | 10.16 | 12.72 |
|       wardrobe      | 12.98 | 14.75 |
|         lamp        | 26.24 |  32.4 |
|       bathtub       | 19.56 | 21.38 |
|       railing       |  9.77 | 10.59 |
|       cushion       | 17.81 | 24.56 |
|         base        |  2.55 |  2.93 |
|         box         |  0.0  |  0.0  |
|        column       |  0.69 |  0.71 |
|      signboard      |  4.62 |  4.71 |
|   chest of drawers  | 15.41 | 19.55 |
|       counter       |  8.77 | 12.28 |
|         sand        |  9.96 |  15.3 |
|         sink        | 18.77 | 21.66 |
|      skyscraper     | 42.19 | 64.07 |
|      fireplace      | 41.37 | 47.43 |
|     refrigerator    | 25.76 | 29.07 |
|      grandstand     | 12.15 | 34.84 |
|         path        |  7.39 |  8.47 |
|        stairs       |  6.02 |  6.61 |
|        runway       | 39.16 | 44.79 |
|         case        | 12.07 | 21.93 |
|      pool table     | 67.14 | 79.32 |
|        pillow       | 11.95 | 12.91 |
|     screen door     |  1.25 |  1.26 |
|       stairway      | 10.25 | 22.49 |
|        river        |  2.17 |  2.75 |
|        bridge       |  4.82 |  5.98 |
|       bookcase      | 20.55 | 45.17 |
|        blind        |  0.0  |  0.0  |
|     coffee table    | 22.89 | 33.53 |
|        toilet       | 34.02 | 38.06 |
|        flower       |  1.2  |  1.21 |
|         book        |  7.68 |  8.34 |
|         hill        |  0.03 |  0.03 |
|        bench        |  5.05 |  5.3  |
|      countertop     |  9.4  | 10.27 |
|        stove        | 26.49 | 35.11 |
|         palm        |  1.64 |  1.64 |
|    kitchen island   |  1.55 |  1.56 |
|       computer      | 14.34 | 15.44 |
|     swivel chair    |  5.41 |  5.64 |
|         boat        |  2.39 |  2.57 |
|         bar         |  1.18 |  1.21 |
|    arcade machine   |  1.39 |  1.8  |
|        hovel        |  0.92 |  0.94 |
|         bus         | 13.94 | 14.87 |
|        towel        |  0.84 |  0.85 |
|        light        |  4.96 |  5.1  |
|        truck        |  0.0  |  0.0  |
|        tower        |  0.34 |  0.34 |
|      chandelier     | 35.48 | 44.67 |
|        awning       |  0.0  |  0.0  |
|     streetlight     |  0.0  |  0.0  |
|        booth        |  0.0  |  0.0  |
| television receiver |  20.8 |  22.1 |
|       airplane      |  20.1 | 27.26 |
|      dirt track     |  0.0  |  0.0  |
|       apparel       |  0.94 |  1.41 |
|         pole        |  0.02 |  0.02 |
|         land        |  0.0  |  0.0  |
|      bannister      |  0.0  |  0.0  |
|      escalator      |  1.61 |  1.92 |
|       ottoman       |  0.0  |  0.0  |
|        bottle       |  0.0  |  0.0  |
|        buffet       |  0.0  |  0.0  |
|        poster       |  0.0  |  0.0  |
|        stage        |  0.0  |  0.0  |
|         van         |  0.0  |  0.0  |
|         ship        |  0.0  |  0.0  |
|       fountain      |  0.0  |  0.0  |
|    conveyer belt    |  0.0  |  0.0  |
|        canopy       |  0.0  |  0.0  |
|        washer       | 25.35 | 26.13 |
|      plaything      |  0.0  |  0.0  |
|    swimming pool    |  7.53 | 11.13 |
|        stool        |  0.0  |  0.0  |
|        barrel       |  0.0  |  0.0  |
|        basket       |  0.0  |  0.0  |
|      waterfall      | 34.55 | 54.57 |
|         tent        | 23.67 | 32.24 |
|         bag         |  0.0  |  0.0  |
|       minibike      |  0.0  |  0.0  |
|        cradle       | 39.92 | 48.53 |
|         oven        |  0.0  |  0.0  |
|         ball        |  0.0  |  0.0  |
|         food        |  1.46 |  1.48 |
|         step        |  0.0  |  0.0  |
|         tank        |  0.0  |  0.0  |
|      trade name     |  0.26 |  0.26 |
|      microwave      |  4.4  |  4.56 |
|         pot         |  0.0  |  0.0  |
|        animal       |  0.0  |  0.0  |
|       bicycle       |  0.0  |  0.0  |
|         lake        |  0.0  |  0.0  |
|      dishwasher     |  0.0  |  0.0  |
|        screen       |  41.5 | 55.79 |
|       blanket       |  0.0  |  0.0  |
|      sculpture      |  0.0  |  0.0  |
|         hood        |  1.97 |  1.98 |
|        sconce       |  0.0  |  0.0  |
|         vase        |  0.02 |  0.02 |
|    traffic light    |  0.0  |  0.0  |
|         tray        |  0.0  |  0.0  |
|        ashcan       |  0.0  |  0.0  |
|         fan         |  0.0  |  0.0  |
|         pier        |  0.0  |  0.0  |
|      crt screen     |  0.0  |  0.0  |
|        plate        |  0.0  |  0.0  |
|       monitor       |  0.0  |  0.0  |
|    bulletin board   |  0.0  |  0.0  |
|        shower       |  0.0  |  0.0  |
|       radiator      |  0.0  |  0.0  |
|        glass        |  0.0  |  0.0  |
|        clock        |  0.0  |  0.0  |
|         flag        |  0.0  |  0.0  |
+---------------------+-------+-------+
2021-08-14 16:35:16,218 - mmseg - INFO - Summary:
2021-08-14 16:35:16,218 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 65.97 | 14.11 | 19.06 |
+-------+-------+-------+
2021-08-14 16:35:16,389 - mmseg - INFO - Exp name: fcn_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 16:35:16,390 - mmseg - INFO - Iter(val) [250]	aAcc: 0.6597, mIoU: 0.1411, mAcc: 0.1906, IoU.wall: 0.5510, IoU.building: 0.6610, IoU.sky: 0.8831, IoU.floor: 0.5685, IoU.tree: 0.5840, IoU.ceiling: 0.6803, IoU.road: 0.6687, IoU.bed : 0.6010, IoU.windowpane: 0.4005, IoU.grass: 0.5181, IoU.cabinet: 0.3611, IoU.sidewalk: 0.3612, IoU.person: 0.4045, IoU.earth: 0.2025, IoU.door: 0.1279, IoU.table: 0.2824, IoU.mountain: 0.3464, IoU.plant: 0.3418, IoU.curtain: 0.3571, IoU.chair: 0.2295, IoU.car: 0.5775, IoU.water: 0.2918, IoU.painting: 0.4659, IoU.sofa: 0.3175, IoU.shelf: 0.1530, IoU.house: 0.1372, IoU.sea: 0.3535, IoU.mirror: 0.1502, IoU.rug: 0.2309, IoU.field: 0.1861, IoU.armchair: 0.0638, IoU.seat: 0.1880, IoU.fence: 0.0815, IoU.desk: 0.0715, IoU.rock: 0.1016, IoU.wardrobe: 0.1298, IoU.lamp: 0.2624, IoU.bathtub: 0.1956, IoU.railing: 0.0977, IoU.cushion: 0.1781, IoU.base: 0.0255, IoU.box: 0.0000, IoU.column: 0.0069, IoU.signboard: 0.0462, IoU.chest of drawers: 0.1541, IoU.counter: 0.0877, IoU.sand: 0.0996, IoU.sink: 0.1877, IoU.skyscraper: 0.4219, IoU.fireplace: 0.4137, IoU.refrigerator: 0.2576, IoU.grandstand: 0.1215, IoU.path: 0.0739, IoU.stairs: 0.0602, IoU.runway: 0.3916, IoU.case: 0.1207, IoU.pool table: 0.6714, IoU.pillow: 0.1195, IoU.screen door: 0.0125, IoU.stairway: 0.1025, IoU.river: 0.0217, IoU.bridge: 0.0482, IoU.bookcase: 0.2055, IoU.blind: 0.0000, IoU.coffee table: 0.2289, IoU.toilet: 0.3402, IoU.flower: 0.0120, IoU.book: 0.0768, IoU.hill: 0.0003, IoU.bench: 0.0505, IoU.countertop: 0.0940, IoU.stove: 0.2649, IoU.palm: 0.0164, IoU.kitchen island: 0.0155, IoU.computer: 0.1434, IoU.swivel chair: 0.0541, IoU.boat: 0.0239, IoU.bar: 0.0118, IoU.arcade machine: 0.0139, IoU.hovel: 0.0092, IoU.bus: 0.1394, IoU.towel: 0.0084, IoU.light: 0.0496, IoU.truck: 0.0000, IoU.tower: 0.0034, IoU.chandelier: 0.3548, IoU.awning: 0.0000, IoU.streetlight: 0.0000, IoU.booth: 0.0000, IoU.television receiver: 0.2080, IoU.airplane: 0.2010, IoU.dirt track: 0.0000, IoU.apparel: 0.0094, IoU.pole: 0.0002, IoU.land: 0.0000, IoU.bannister: 0.0000, IoU.escalator: 0.0161, IoU.ottoman: 0.0000, IoU.bottle: 0.0000, IoU.buffet: 0.0000, IoU.poster: 0.0000, IoU.stage: 0.0000, IoU.van: 0.0000, IoU.ship: 0.0000, IoU.fountain: 0.0000, IoU.conveyer belt: 0.0000, IoU.canopy: 0.0000, IoU.washer: 0.2535, IoU.plaything: 0.0000, IoU.swimming pool: 0.0753, IoU.stool: 0.0000, IoU.barrel: 0.0000, IoU.basket: 0.0000, IoU.waterfall: 0.3455, IoU.tent: 0.2367, IoU.bag: 0.0000, IoU.minibike: 0.0000, IoU.cradle: 0.3992, IoU.oven: 0.0000, IoU.ball: 0.0000, IoU.food: 0.0146, IoU.step: 0.0000, IoU.tank: 0.0000, IoU.trade name: 0.0026, IoU.microwave: 0.0440, IoU.pot: 0.0000, IoU.animal: 0.0000, IoU.bicycle: 0.0000, IoU.lake: 0.0000, IoU.dishwasher: 0.0000, IoU.screen: 0.4150, IoU.blanket: 0.0000, IoU.sculpture: 0.0000, IoU.hood: 0.0197, IoU.sconce: 0.0000, IoU.vase: 0.0002, IoU.traffic light: 0.0000, IoU.tray: 0.0000, IoU.ashcan: 0.0000, IoU.fan: 0.0000, IoU.pier: 0.0000, IoU.crt screen: 0.0000, IoU.plate: 0.0000, IoU.monitor: 0.0000, IoU.bulletin board: 0.0000, IoU.shower: 0.0000, IoU.radiator: 0.0000, IoU.glass: 0.0000, IoU.clock: 0.0000, IoU.flag: 0.0000, Acc.wall: 0.8259, Acc.building: 0.8711, Acc.sky: 0.9566, Acc.floor: 0.8328, Acc.tree: 0.7788, Acc.ceiling: 0.8274, Acc.road: 0.8274, Acc.bed : 0.8366, Acc.windowpane: 0.6785, Acc.grass: 0.7032, Acc.cabinet: 0.4499, Acc.sidewalk: 0.4563, Acc.person: 0.5644, Acc.earth: 0.3009, Acc.door: 0.1769, Acc.table: 0.3949, Acc.mountain: 0.4417, Acc.plant: 0.4945, Acc.curtain: 0.4772, Acc.chair: 0.3151, Acc.car: 0.7581, Acc.water: 0.4344, Acc.painting: 0.5540, Acc.sofa: 0.4864, Acc.shelf: 0.2107, Acc.house: 0.1526, Acc.sea: 0.8704, Acc.mirror: 0.1676, Acc.rug: 0.2551, Acc.field: 0.5282, Acc.armchair: 0.0710, Acc.seat: 0.2907, Acc.fence: 0.1291, Acc.desk: 0.0798, Acc.rock: 0.1272, Acc.wardrobe: 0.1475, Acc.lamp: 0.3240, Acc.bathtub: 0.2138, Acc.railing: 0.1059, Acc.cushion: 0.2456, Acc.base: 0.0293, Acc.box: 0.0000, Acc.column: 0.0071, Acc.signboard: 0.0471, Acc.chest of drawers: 0.1955, Acc.counter: 0.1228, Acc.sand: 0.1530, Acc.sink: 0.2166, Acc.skyscraper: 0.6407, Acc.fireplace: 0.4743, Acc.refrigerator: 0.2907, Acc.grandstand: 0.3484, Acc.path: 0.0847, Acc.stairs: 0.0661, Acc.runway: 0.4479, Acc.case: 0.2193, Acc.pool table: 0.7932, Acc.pillow: 0.1291, Acc.screen door: 0.0126, Acc.stairway: 0.2249, Acc.river: 0.0275, Acc.bridge: 0.0598, Acc.bookcase: 0.4517, Acc.blind: 0.0000, Acc.coffee table: 0.3353, Acc.toilet: 0.3806, Acc.flower: 0.0121, Acc.book: 0.0834, Acc.hill: 0.0003, Acc.bench: 0.0530, Acc.countertop: 0.1027, Acc.stove: 0.3511, Acc.palm: 0.0164, Acc.kitchen island: 0.0156, Acc.computer: 0.1544, Acc.swivel chair: 0.0564, Acc.boat: 0.0257, Acc.bar: 0.0121, Acc.arcade machine: 0.0180, Acc.hovel: 0.0094, Acc.bus: 0.1487, Acc.towel: 0.0085, Acc.light: 0.0510, Acc.truck: 0.0000, Acc.tower: 0.0034, Acc.chandelier: 0.4467, Acc.awning: 0.0000, Acc.streetlight: 0.0000, Acc.booth: 0.0000, Acc.television receiver: 0.2210, Acc.airplane: 0.2726, Acc.dirt track: 0.0000, Acc.apparel: 0.0141, Acc.pole: 0.0002, Acc.land: 0.0000, Acc.bannister: 0.0000, Acc.escalator: 0.0192, Acc.ottoman: 0.0000, Acc.bottle: 0.0000, Acc.buffet: 0.0000, Acc.poster: 0.0000, Acc.stage: 0.0000, Acc.van: 0.0000, Acc.ship: 0.0000, Acc.fountain: 0.0000, Acc.conveyer belt: 0.0000, Acc.canopy: 0.0000, Acc.washer: 0.2613, Acc.plaything: 0.0000, Acc.swimming pool: 0.1113, Acc.stool: 0.0000, Acc.barrel: 0.0000, Acc.basket: 0.0000, Acc.waterfall: 0.5457, Acc.tent: 0.3224, Acc.bag: 0.0000, Acc.minibike: 0.0000, Acc.cradle: 0.4853, Acc.oven: 0.0000, Acc.ball: 0.0000, Acc.food: 0.0148, Acc.step: 0.0000, Acc.tank: 0.0000, Acc.trade name: 0.0026, Acc.microwave: 0.0456, Acc.pot: 0.0000, Acc.animal: 0.0000, Acc.bicycle: 0.0000, Acc.lake: 0.0000, Acc.dishwasher: 0.0000, Acc.screen: 0.5579, Acc.blanket: 0.0000, Acc.sculpture: 0.0000, Acc.hood: 0.0198, Acc.sconce: 0.0000, Acc.vase: 0.0002, Acc.traffic light: 0.0000, Acc.tray: 0.0000, Acc.ashcan: 0.0000, Acc.fan: 0.0000, Acc.pier: 0.0000, Acc.crt screen: 0.0000, Acc.plate: 0.0000, Acc.monitor: 0.0000, Acc.bulletin board: 0.0000, Acc.shower: 0.0000, Acc.radiator: 0.0000, Acc.glass: 0.0000, Acc.clock: 0.0000, Acc.flag: 0.0000
2021-08-14 16:36:20,045 - mmseg - INFO - Iter [48050/160000]	lr: 7.279e-03, eta: 1 day, 17:21:50, time: 3.727, data_time: 2.471, memory: 5723, decode.loss_seg: 1.0771, decode.acc_seg: 52.6806, loss: 1.0771
2021-08-14 16:37:25,285 - mmseg - INFO - Iter [48100/160000]	lr: 7.276e-03, eta: 1 day, 17:20:40, time: 1.304, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0765, decode.acc_seg: 53.7555, loss: 1.0765
2021-08-14 16:38:30,992 - mmseg - INFO - Iter [48150/160000]	lr: 7.273e-03, eta: 1 day, 17:19:32, time: 1.314, data_time: 0.015, memory: 5723, decode.loss_seg: 1.0848, decode.acc_seg: 52.4880, loss: 1.0848
2021-08-14 16:39:33,107 - mmseg - INFO - Iter [48200/160000]	lr: 7.270e-03, eta: 1 day, 17:18:15, time: 1.243, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0724, decode.acc_seg: 52.9523, loss: 1.0724
2021-08-14 16:40:37,356 - mmseg - INFO - Iter [48250/160000]	lr: 7.267e-03, eta: 1 day, 17:17:03, time: 1.285, data_time: 0.017, memory: 5723, decode.loss_seg: 1.1032, decode.acc_seg: 52.2062, loss: 1.1032
2021-08-14 16:41:42,534 - mmseg - INFO - Iter [48300/160000]	lr: 7.264e-03, eta: 1 day, 17:15:54, time: 1.303, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0884, decode.acc_seg: 52.5783, loss: 1.0884
2021-08-14 16:42:44,120 - mmseg - INFO - Iter [48350/160000]	lr: 7.261e-03, eta: 1 day, 17:14:36, time: 1.232, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0946, decode.acc_seg: 52.5474, loss: 1.0946
2021-08-14 16:43:46,342 - mmseg - INFO - Iter [48400/160000]	lr: 7.259e-03, eta: 1 day, 17:13:20, time: 1.243, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1425, decode.acc_seg: 51.6550, loss: 1.1425
2021-08-14 16:44:49,309 - mmseg - INFO - Iter [48450/160000]	lr: 7.256e-03, eta: 1 day, 17:12:05, time: 1.260, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0993, decode.acc_seg: 52.1855, loss: 1.0993
2021-08-14 16:45:50,866 - mmseg - INFO - Iter [48500/160000]	lr: 7.253e-03, eta: 1 day, 17:10:47, time: 1.231, data_time: 0.017, memory: 5723, decode.loss_seg: 1.0785, decode.acc_seg: 52.7289, loss: 1.0785
2021-08-14 16:46:53,757 - mmseg - INFO - Iter [48550/160000]	lr: 7.250e-03, eta: 1 day, 17:09:32, time: 1.257, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0942, decode.acc_seg: 52.1831, loss: 1.0942
2021-08-14 16:48:33,671 - mmseg - INFO - Iter [48600/160000]	lr: 7.247e-03, eta: 1 day, 17:09:43, time: 1.998, data_time: 0.722, memory: 5723, decode.loss_seg: 1.1026, decode.acc_seg: 52.1978, loss: 1.1026
2021-08-14 16:49:36,013 - mmseg - INFO - Iter [48650/160000]	lr: 7.244e-03, eta: 1 day, 17:08:27, time: 1.247, data_time: 0.018, memory: 5723, decode.loss_seg: 1.0969, decode.acc_seg: 53.0337, loss: 1.0969
2021-08-14 16:50:38,762 - mmseg - INFO - Iter [48700/160000]	lr: 7.241e-03, eta: 1 day, 17:07:12, time: 1.255, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0799, decode.acc_seg: 52.2262, loss: 1.0799
2021-08-14 16:51:41,983 - mmseg - INFO - Iter [48750/160000]	lr: 7.238e-03, eta: 1 day, 17:05:57, time: 1.264, data_time: 0.015, memory: 5723, decode.loss_seg: 1.0837, decode.acc_seg: 51.8638, loss: 1.0837
2021-08-14 16:52:45,400 - mmseg - INFO - Iter [48800/160000]	lr: 7.236e-03, eta: 1 day, 17:04:44, time: 1.269, data_time: 0.017, memory: 5723, decode.loss_seg: 1.1149, decode.acc_seg: 52.4714, loss: 1.1149
2021-08-14 16:53:48,448 - mmseg - INFO - Iter [48850/160000]	lr: 7.233e-03, eta: 1 day, 17:03:30, time: 1.261, data_time: 0.015, memory: 5723, decode.loss_seg: 1.0889, decode.acc_seg: 52.9970, loss: 1.0889
2021-08-14 16:54:50,791 - mmseg - INFO - Iter [48900/160000]	lr: 7.230e-03, eta: 1 day, 17:02:14, time: 1.247, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0846, decode.acc_seg: 51.9764, loss: 1.0846
2021-08-14 16:55:53,998 - mmseg - INFO - Iter [48950/160000]	lr: 7.227e-03, eta: 1 day, 17:01:00, time: 1.264, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1013, decode.acc_seg: 52.6149, loss: 1.1013
2021-08-14 16:56:56,211 - mmseg - INFO - Exp name: fcn_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 16:56:56,211 - mmseg - INFO - Iter [49000/160000]	lr: 7.224e-03, eta: 1 day, 16:59:44, time: 1.244, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1380, decode.acc_seg: 51.5403, loss: 1.1380
2021-08-14 16:57:58,147 - mmseg - INFO - Iter [49050/160000]	lr: 7.221e-03, eta: 1 day, 16:58:27, time: 1.240, data_time: 0.017, memory: 5723, decode.loss_seg: 1.0943, decode.acc_seg: 51.2947, loss: 1.0943
2021-08-14 16:58:58,656 - mmseg - INFO - Iter [49100/160000]	lr: 7.218e-03, eta: 1 day, 16:57:07, time: 1.210, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1089, decode.acc_seg: 52.5601, loss: 1.1089
2021-08-14 17:00:00,803 - mmseg - INFO - Iter [49150/160000]	lr: 7.215e-03, eta: 1 day, 16:55:51, time: 1.243, data_time: 0.017, memory: 5723, decode.loss_seg: 1.0947, decode.acc_seg: 52.2760, loss: 1.0947
2021-08-14 17:01:03,610 - mmseg - INFO - Iter [49200/160000]	lr: 7.212e-03, eta: 1 day, 16:54:36, time: 1.256, data_time: 0.017, memory: 5723, decode.loss_seg: 1.0788, decode.acc_seg: 52.7037, loss: 1.0788
2021-08-14 17:02:41,639 - mmseg - INFO - Iter [49250/160000]	lr: 7.210e-03, eta: 1 day, 16:54:41, time: 1.961, data_time: 0.745, memory: 5723, decode.loss_seg: 1.0807, decode.acc_seg: 53.7645, loss: 1.0807
2021-08-14 17:03:43,663 - mmseg - INFO - Iter [49300/160000]	lr: 7.207e-03, eta: 1 day, 16:53:24, time: 1.240, data_time: 0.017, memory: 5723, decode.loss_seg: 1.0648, decode.acc_seg: 52.1690, loss: 1.0648
2021-08-14 17:04:46,903 - mmseg - INFO - Iter [49350/160000]	lr: 7.204e-03, eta: 1 day, 16:52:10, time: 1.266, data_time: 0.017, memory: 5723, decode.loss_seg: 1.0529, decode.acc_seg: 53.7268, loss: 1.0529
2021-08-14 17:05:48,819 - mmseg - INFO - Iter [49400/160000]	lr: 7.201e-03, eta: 1 day, 16:50:54, time: 1.238, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1379, decode.acc_seg: 51.3334, loss: 1.1379
2021-08-14 17:06:52,998 - mmseg - INFO - Iter [49450/160000]	lr: 7.198e-03, eta: 1 day, 16:49:42, time: 1.282, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0680, decode.acc_seg: 52.6620, loss: 1.0680
2021-08-14 17:07:58,577 - mmseg - INFO - Iter [49500/160000]	lr: 7.195e-03, eta: 1 day, 16:48:33, time: 1.313, data_time: 0.018, memory: 5723, decode.loss_seg: 1.1150, decode.acc_seg: 52.5445, loss: 1.1150
2021-08-14 17:09:03,690 - mmseg - INFO - Iter [49550/160000]	lr: 7.192e-03, eta: 1 day, 16:47:24, time: 1.302, data_time: 0.018, memory: 5723, decode.loss_seg: 1.1102, decode.acc_seg: 52.5012, loss: 1.1102
2021-08-14 17:10:05,322 - mmseg - INFO - Iter [49600/160000]	lr: 7.189e-03, eta: 1 day, 16:46:07, time: 1.233, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0786, decode.acc_seg: 52.4142, loss: 1.0786
2021-08-14 17:11:08,060 - mmseg - INFO - Iter [49650/160000]	lr: 7.186e-03, eta: 1 day, 16:44:52, time: 1.255, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0806, decode.acc_seg: 51.6350, loss: 1.0806
2021-08-14 17:12:10,897 - mmseg - INFO - Iter [49700/160000]	lr: 7.184e-03, eta: 1 day, 16:43:37, time: 1.256, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0809, decode.acc_seg: 52.8731, loss: 1.0809
2021-08-14 17:13:14,687 - mmseg - INFO - Iter [49750/160000]	lr: 7.181e-03, eta: 1 day, 16:42:25, time: 1.276, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0838, decode.acc_seg: 52.4603, loss: 1.0838
2021-08-14 17:14:20,781 - mmseg - INFO - Iter [49800/160000]	lr: 7.178e-03, eta: 1 day, 16:41:18, time: 1.321, data_time: 0.017, memory: 5723, decode.loss_seg: 1.0904, decode.acc_seg: 53.2986, loss: 1.0904
2021-08-14 17:16:02,912 - mmseg - INFO - Iter [49850/160000]	lr: 7.175e-03, eta: 1 day, 16:41:30, time: 2.044, data_time: 0.698, memory: 5723, decode.loss_seg: 1.0974, decode.acc_seg: 52.3076, loss: 1.0974
2021-08-14 17:17:05,975 - mmseg - INFO - Iter [49900/160000]	lr: 7.172e-03, eta: 1 day, 16:40:16, time: 1.261, data_time: 0.017, memory: 5723, decode.loss_seg: 1.0946, decode.acc_seg: 52.0254, loss: 1.0946
2021-08-14 17:18:08,581 - mmseg - INFO - Iter [49950/160000]	lr: 7.169e-03, eta: 1 day, 16:39:01, time: 1.252, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0707, decode.acc_seg: 52.2509, loss: 1.0707
2021-08-14 17:19:09,507 - mmseg - INFO - Exp name: fcn_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 17:19:09,508 - mmseg - INFO - Iter [50000/160000]	lr: 7.166e-03, eta: 1 day, 16:37:42, time: 1.219, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0472, decode.acc_seg: 53.8206, loss: 1.0472
2021-08-14 17:20:11,910 - mmseg - INFO - Iter [50050/160000]	lr: 7.163e-03, eta: 1 day, 16:36:27, time: 1.248, data_time: 0.015, memory: 5723, decode.loss_seg: 1.0959, decode.acc_seg: 52.2502, loss: 1.0959
2021-08-14 17:21:12,549 - mmseg - INFO - Iter [50100/160000]	lr: 7.160e-03, eta: 1 day, 16:35:08, time: 1.213, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0620, decode.acc_seg: 52.6271, loss: 1.0620
2021-08-14 17:22:15,354 - mmseg - INFO - Iter [50150/160000]	lr: 7.157e-03, eta: 1 day, 16:33:53, time: 1.255, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1086, decode.acc_seg: 52.5845, loss: 1.1086
2021-08-14 17:23:18,002 - mmseg - INFO - Iter [50200/160000]	lr: 7.155e-03, eta: 1 day, 16:32:38, time: 1.253, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0927, decode.acc_seg: 52.7916, loss: 1.0927
2021-08-14 17:24:21,111 - mmseg - INFO - Iter [50250/160000]	lr: 7.152e-03, eta: 1 day, 16:31:24, time: 1.262, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0720, decode.acc_seg: 52.8226, loss: 1.0720
2021-08-14 17:25:23,661 - mmseg - INFO - Iter [50300/160000]	lr: 7.149e-03, eta: 1 day, 16:30:09, time: 1.252, data_time: 0.020, memory: 5723, decode.loss_seg: 1.0954, decode.acc_seg: 51.9221, loss: 1.0954
2021-08-14 17:26:27,031 - mmseg - INFO - Iter [50350/160000]	lr: 7.146e-03, eta: 1 day, 16:28:56, time: 1.267, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0706, decode.acc_seg: 51.9176, loss: 1.0706
2021-08-14 17:27:31,547 - mmseg - INFO - Iter [50400/160000]	lr: 7.143e-03, eta: 1 day, 16:27:45, time: 1.290, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0965, decode.acc_seg: 52.5489, loss: 1.0965
2021-08-14 17:28:33,926 - mmseg - INFO - Iter [50450/160000]	lr: 7.140e-03, eta: 1 day, 16:26:30, time: 1.248, data_time: 0.017, memory: 5723, decode.loss_seg: 1.0730, decode.acc_seg: 53.2906, loss: 1.0730
2021-08-14 17:30:12,291 - mmseg - INFO - Iter [50500/160000]	lr: 7.137e-03, eta: 1 day, 16:26:33, time: 1.967, data_time: 0.741, memory: 5723, decode.loss_seg: 1.1053, decode.acc_seg: 53.1561, loss: 1.1053
2021-08-14 17:31:15,052 - mmseg - INFO - Iter [50550/160000]	lr: 7.134e-03, eta: 1 day, 16:25:18, time: 1.256, data_time: 0.017, memory: 5723, decode.loss_seg: 1.0723, decode.acc_seg: 52.6497, loss: 1.0723
2021-08-14 17:32:17,104 - mmseg - INFO - Iter [50600/160000]	lr: 7.131e-03, eta: 1 day, 16:24:02, time: 1.241, data_time: 0.015, memory: 5723, decode.loss_seg: 1.0411, decode.acc_seg: 53.4226, loss: 1.0411
2021-08-14 17:33:22,969 - mmseg - INFO - Iter [50650/160000]	lr: 7.129e-03, eta: 1 day, 16:22:55, time: 1.317, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0731, decode.acc_seg: 53.5838, loss: 1.0731
2021-08-14 17:34:29,815 - mmseg - INFO - Iter [50700/160000]	lr: 7.126e-03, eta: 1 day, 16:21:49, time: 1.337, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0863, decode.acc_seg: 53.1572, loss: 1.0863
2021-08-14 17:35:37,524 - mmseg - INFO - Iter [50750/160000]	lr: 7.123e-03, eta: 1 day, 16:20:45, time: 1.354, data_time: 0.015, memory: 5723, decode.loss_seg: 1.0427, decode.acc_seg: 53.6219, loss: 1.0427
2021-08-14 17:36:45,073 - mmseg - INFO - Iter [50800/160000]	lr: 7.120e-03, eta: 1 day, 16:19:41, time: 1.351, data_time: 0.015, memory: 5723, decode.loss_seg: 1.0823, decode.acc_seg: 53.3107, loss: 1.0823
2021-08-14 17:37:47,570 - mmseg - INFO - Iter [50850/160000]	lr: 7.117e-03, eta: 1 day, 16:18:26, time: 1.250, data_time: 0.015, memory: 5723, decode.loss_seg: 1.0983, decode.acc_seg: 52.1658, loss: 1.0983
2021-08-14 17:38:50,933 - mmseg - INFO - Iter [50900/160000]	lr: 7.114e-03, eta: 1 day, 16:17:13, time: 1.268, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0892, decode.acc_seg: 51.9548, loss: 1.0892
2021-08-14 17:39:50,862 - mmseg - INFO - Iter [50950/160000]	lr: 7.111e-03, eta: 1 day, 16:15:52, time: 1.198, data_time: 0.017, memory: 5723, decode.loss_seg: 1.0786, decode.acc_seg: 52.8432, loss: 1.0786
2021-08-14 17:40:52,688 - mmseg - INFO - Exp name: fcn_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 17:40:52,688 - mmseg - INFO - Iter [51000/160000]	lr: 7.108e-03, eta: 1 day, 16:14:36, time: 1.237, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0821, decode.acc_seg: 53.2496, loss: 1.0821
2021-08-14 17:41:58,460 - mmseg - INFO - Iter [51050/160000]	lr: 7.105e-03, eta: 1 day, 16:13:28, time: 1.314, data_time: 0.015, memory: 5723, decode.loss_seg: 1.0836, decode.acc_seg: 51.5976, loss: 1.0836
2021-08-14 17:43:06,140 - mmseg - INFO - Iter [51100/160000]	lr: 7.103e-03, eta: 1 day, 16:12:24, time: 1.354, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1198, decode.acc_seg: 52.7042, loss: 1.1198
2021-08-14 17:44:46,281 - mmseg - INFO - Iter [51150/160000]	lr: 7.100e-03, eta: 1 day, 16:12:29, time: 2.004, data_time: 0.727, memory: 5723, decode.loss_seg: 1.0380, decode.acc_seg: 53.1599, loss: 1.0380
2021-08-14 17:45:52,805 - mmseg - INFO - Iter [51200/160000]	lr: 7.097e-03, eta: 1 day, 16:11:23, time: 1.330, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1020, decode.acc_seg: 52.8352, loss: 1.1020
2021-08-14 17:46:58,161 - mmseg - INFO - Iter [51250/160000]	lr: 7.094e-03, eta: 1 day, 16:10:14, time: 1.307, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0676, decode.acc_seg: 53.4637, loss: 1.0676
2021-08-14 17:48:03,431 - mmseg - INFO - Iter [51300/160000]	lr: 7.091e-03, eta: 1 day, 16:09:05, time: 1.306, data_time: 0.017, memory: 5723, decode.loss_seg: 1.0675, decode.acc_seg: 53.9004, loss: 1.0675
2021-08-14 17:49:09,758 - mmseg - INFO - Iter [51350/160000]	lr: 7.088e-03, eta: 1 day, 16:07:58, time: 1.326, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0459, decode.acc_seg: 53.3005, loss: 1.0459
2021-08-14 17:50:14,830 - mmseg - INFO - Iter [51400/160000]	lr: 7.085e-03, eta: 1 day, 16:06:49, time: 1.302, data_time: 0.017, memory: 5723, decode.loss_seg: 1.0582, decode.acc_seg: 52.3310, loss: 1.0582
2021-08-14 17:51:18,410 - mmseg - INFO - Iter [51450/160000]	lr: 7.082e-03, eta: 1 day, 16:05:36, time: 1.271, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1008, decode.acc_seg: 51.6696, loss: 1.1008
2021-08-14 17:52:22,190 - mmseg - INFO - Iter [51500/160000]	lr: 7.079e-03, eta: 1 day, 16:04:24, time: 1.276, data_time: 0.015, memory: 5723, decode.loss_seg: 1.0804, decode.acc_seg: 52.1163, loss: 1.0804
2021-08-14 17:53:24,413 - mmseg - INFO - Iter [51550/160000]	lr: 7.076e-03, eta: 1 day, 16:03:08, time: 1.245, data_time: 0.015, memory: 5723, decode.loss_seg: 1.1082, decode.acc_seg: 52.2452, loss: 1.1082
2021-08-14 17:54:26,554 - mmseg - INFO - Iter [51600/160000]	lr: 7.074e-03, eta: 1 day, 16:01:53, time: 1.243, data_time: 0.015, memory: 5723, decode.loss_seg: 1.0757, decode.acc_seg: 53.3896, loss: 1.0757
2021-08-14 17:55:28,171 - mmseg - INFO - Iter [51650/160000]	lr: 7.071e-03, eta: 1 day, 16:00:36, time: 1.232, data_time: 0.015, memory: 5723, decode.loss_seg: 1.1164, decode.acc_seg: 51.8180, loss: 1.1164
2021-08-14 17:56:32,867 - mmseg - INFO - Iter [51700/160000]	lr: 7.068e-03, eta: 1 day, 15:59:26, time: 1.293, data_time: 0.015, memory: 5723, decode.loss_seg: 1.1180, decode.acc_seg: 52.6607, loss: 1.1180
2021-08-14 17:58:14,644 - mmseg - INFO - Iter [51750/160000]	lr: 7.065e-03, eta: 1 day, 15:59:33, time: 2.036, data_time: 0.718, memory: 5723, decode.loss_seg: 1.1113, decode.acc_seg: 52.2099, loss: 1.1113
2021-08-14 17:59:18,184 - mmseg - INFO - Iter [51800/160000]	lr: 7.062e-03, eta: 1 day, 15:58:21, time: 1.270, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0702, decode.acc_seg: 52.1089, loss: 1.0702
2021-08-14 18:00:25,337 - mmseg - INFO - Iter [51850/160000]	lr: 7.059e-03, eta: 1 day, 15:57:15, time: 1.343, data_time: 0.015, memory: 5723, decode.loss_seg: 1.0582, decode.acc_seg: 52.2520, loss: 1.0582
2021-08-14 18:01:29,275 - mmseg - INFO - Iter [51900/160000]	lr: 7.056e-03, eta: 1 day, 15:56:04, time: 1.279, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0978, decode.acc_seg: 52.4116, loss: 1.0978
2021-08-14 18:02:31,816 - mmseg - INFO - Iter [51950/160000]	lr: 7.053e-03, eta: 1 day, 15:54:49, time: 1.252, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0575, decode.acc_seg: 53.5427, loss: 1.0575
2021-08-14 18:03:34,479 - mmseg - INFO - Exp name: fcn_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 18:03:34,479 - mmseg - INFO - Iter [52000/160000]	lr: 7.050e-03, eta: 1 day, 15:53:35, time: 1.253, data_time: 0.015, memory: 5723, decode.loss_seg: 1.0871, decode.acc_seg: 53.6441, loss: 1.0871
2021-08-14 18:04:36,517 - mmseg - INFO - Iter [52050/160000]	lr: 7.048e-03, eta: 1 day, 15:52:19, time: 1.241, data_time: 0.015, memory: 5723, decode.loss_seg: 1.0870, decode.acc_seg: 52.4847, loss: 1.0870
2021-08-14 18:05:38,994 - mmseg - INFO - Iter [52100/160000]	lr: 7.045e-03, eta: 1 day, 15:51:04, time: 1.249, data_time: 0.014, memory: 5723, decode.loss_seg: 1.1184, decode.acc_seg: 52.8304, loss: 1.1184
2021-08-14 18:06:42,491 - mmseg - INFO - Iter [52150/160000]	lr: 7.042e-03, eta: 1 day, 15:49:51, time: 1.270, data_time: 0.015, memory: 5723, decode.loss_seg: 1.1005, decode.acc_seg: 52.7386, loss: 1.1005
2021-08-14 18:07:47,726 - mmseg - INFO - Iter [52200/160000]	lr: 7.039e-03, eta: 1 day, 15:48:42, time: 1.304, data_time: 0.015, memory: 5723, decode.loss_seg: 1.1187, decode.acc_seg: 51.3319, loss: 1.1187
2021-08-14 18:08:51,406 - mmseg - INFO - Iter [52250/160000]	lr: 7.036e-03, eta: 1 day, 15:47:30, time: 1.274, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0924, decode.acc_seg: 52.8590, loss: 1.0924
2021-08-14 18:09:54,836 - mmseg - INFO - Iter [52300/160000]	lr: 7.033e-03, eta: 1 day, 15:46:17, time: 1.269, data_time: 0.014, memory: 5723, decode.loss_seg: 1.0886, decode.acc_seg: 52.2853, loss: 1.0886
2021-08-14 18:10:56,681 - mmseg - INFO - Iter [52350/160000]	lr: 7.030e-03, eta: 1 day, 15:45:01, time: 1.237, data_time: 0.014, memory: 5723, decode.loss_seg: 1.0654, decode.acc_seg: 53.3699, loss: 1.0654
2021-08-14 18:12:39,096 - mmseg - INFO - Iter [52400/160000]	lr: 7.027e-03, eta: 1 day, 15:45:09, time: 2.048, data_time: 0.772, memory: 5723, decode.loss_seg: 1.0935, decode.acc_seg: 52.4806, loss: 1.0935
2021-08-14 18:13:41,324 - mmseg - INFO - Iter [52450/160000]	lr: 7.024e-03, eta: 1 day, 15:43:54, time: 1.244, data_time: 0.017, memory: 5723, decode.loss_seg: 1.0594, decode.acc_seg: 52.8914, loss: 1.0594
2021-08-14 18:14:43,500 - mmseg - INFO - Iter [52500/160000]	lr: 7.021e-03, eta: 1 day, 15:42:38, time: 1.243, data_time: 0.015, memory: 5723, decode.loss_seg: 1.0523, decode.acc_seg: 53.2787, loss: 1.0523
2021-08-14 18:15:45,151 - mmseg - INFO - Iter [52550/160000]	lr: 7.019e-03, eta: 1 day, 15:41:22, time: 1.233, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0845, decode.acc_seg: 52.7764, loss: 1.0845
2021-08-14 18:16:48,411 - mmseg - INFO - Iter [52600/160000]	lr: 7.016e-03, eta: 1 day, 15:40:09, time: 1.265, data_time: 0.017, memory: 5723, decode.loss_seg: 1.0659, decode.acc_seg: 52.5954, loss: 1.0659
2021-08-14 18:17:49,543 - mmseg - INFO - Iter [52650/160000]	lr: 7.013e-03, eta: 1 day, 15:38:51, time: 1.223, data_time: 0.017, memory: 5723, decode.loss_seg: 1.0493, decode.acc_seg: 53.4080, loss: 1.0493
2021-08-14 18:18:52,201 - mmseg - INFO - Iter [52700/160000]	lr: 7.010e-03, eta: 1 day, 15:37:37, time: 1.253, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0707, decode.acc_seg: 53.0290, loss: 1.0707
2021-08-14 18:19:55,918 - mmseg - INFO - Iter [52750/160000]	lr: 7.007e-03, eta: 1 day, 15:36:25, time: 1.273, data_time: 0.017, memory: 5723, decode.loss_seg: 1.1211, decode.acc_seg: 50.9175, loss: 1.1211
2021-08-14 18:20:58,234 - mmseg - INFO - Iter [52800/160000]	lr: 7.004e-03, eta: 1 day, 15:35:10, time: 1.247, data_time: 0.017, memory: 5723, decode.loss_seg: 1.1021, decode.acc_seg: 53.2354, loss: 1.1021
2021-08-14 18:22:00,382 - mmseg - INFO - Iter [52850/160000]	lr: 7.001e-03, eta: 1 day, 15:33:55, time: 1.243, data_time: 0.017, memory: 5723, decode.loss_seg: 1.0686, decode.acc_seg: 52.7443, loss: 1.0686
2021-08-14 18:23:01,417 - mmseg - INFO - Iter [52900/160000]	lr: 6.998e-03, eta: 1 day, 15:32:37, time: 1.220, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0992, decode.acc_seg: 52.6392, loss: 1.0992
2021-08-14 18:24:04,616 - mmseg - INFO - Iter [52950/160000]	lr: 6.995e-03, eta: 1 day, 15:31:24, time: 1.265, data_time: 0.017, memory: 5723, decode.loss_seg: 1.0717, decode.acc_seg: 52.7097, loss: 1.0717
2021-08-14 18:25:06,322 - mmseg - INFO - Exp name: fcn_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 18:25:06,323 - mmseg - INFO - Iter [53000/160000]	lr: 6.992e-03, eta: 1 day, 15:30:08, time: 1.234, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1090, decode.acc_seg: 51.8183, loss: 1.1090
2021-08-14 18:26:42,852 - mmseg - INFO - Iter [53050/160000]	lr: 6.990e-03, eta: 1 day, 15:30:02, time: 1.930, data_time: 0.721, memory: 5723, decode.loss_seg: 1.0639, decode.acc_seg: 52.5891, loss: 1.0639
2021-08-14 18:27:46,512 - mmseg - INFO - Iter [53100/160000]	lr: 6.987e-03, eta: 1 day, 15:28:50, time: 1.274, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0716, decode.acc_seg: 53.6590, loss: 1.0716
2021-08-14 18:28:48,652 - mmseg - INFO - Iter [53150/160000]	lr: 6.984e-03, eta: 1 day, 15:27:35, time: 1.243, data_time: 0.015, memory: 5723, decode.loss_seg: 1.1109, decode.acc_seg: 52.8175, loss: 1.1109
2021-08-14 18:29:51,977 - mmseg - INFO - Iter [53200/160000]	lr: 6.981e-03, eta: 1 day, 15:26:22, time: 1.267, data_time: 0.017, memory: 5723, decode.loss_seg: 1.0780, decode.acc_seg: 53.0714, loss: 1.0780
2021-08-14 18:30:56,400 - mmseg - INFO - Iter [53250/160000]	lr: 6.978e-03, eta: 1 day, 15:25:12, time: 1.288, data_time: 0.015, memory: 5723, decode.loss_seg: 1.0661, decode.acc_seg: 51.9447, loss: 1.0661
2021-08-14 18:32:00,068 - mmseg - INFO - Iter [53300/160000]	lr: 6.975e-03, eta: 1 day, 15:24:00, time: 1.274, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0853, decode.acc_seg: 52.7349, loss: 1.0853
2021-08-14 18:33:01,631 - mmseg - INFO - Iter [53350/160000]	lr: 6.972e-03, eta: 1 day, 15:22:43, time: 1.232, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0620, decode.acc_seg: 53.9373, loss: 1.0620
2021-08-14 18:34:02,353 - mmseg - INFO - Iter [53400/160000]	lr: 6.969e-03, eta: 1 day, 15:21:25, time: 1.215, data_time: 0.015, memory: 5723, decode.loss_seg: 1.0721, decode.acc_seg: 52.7059, loss: 1.0721
2021-08-14 18:35:03,494 - mmseg - INFO - Iter [53450/160000]	lr: 6.966e-03, eta: 1 day, 15:20:08, time: 1.223, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0584, decode.acc_seg: 52.9426, loss: 1.0584
2021-08-14 18:36:05,069 - mmseg - INFO - Iter [53500/160000]	lr: 6.963e-03, eta: 1 day, 15:18:52, time: 1.231, data_time: 0.017, memory: 5723, decode.loss_seg: 1.1050, decode.acc_seg: 52.7048, loss: 1.1050
2021-08-14 18:37:05,613 - mmseg - INFO - Iter [53550/160000]	lr: 6.961e-03, eta: 1 day, 15:17:34, time: 1.211, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0588, decode.acc_seg: 52.7377, loss: 1.0588
2021-08-14 18:38:08,815 - mmseg - INFO - Iter [53600/160000]	lr: 6.958e-03, eta: 1 day, 15:16:21, time: 1.263, data_time: 0.018, memory: 5723, decode.loss_seg: 1.1091, decode.acc_seg: 51.9056, loss: 1.1091
2021-08-14 18:39:46,933 - mmseg - INFO - Iter [53650/160000]	lr: 6.955e-03, eta: 1 day, 15:16:18, time: 1.963, data_time: 0.739, memory: 5723, decode.loss_seg: 1.0800, decode.acc_seg: 51.8097, loss: 1.0800
2021-08-14 18:40:48,872 - mmseg - INFO - Iter [53700/160000]	lr: 6.952e-03, eta: 1 day, 15:15:02, time: 1.238, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0722, decode.acc_seg: 53.1608, loss: 1.0722
2021-08-14 18:41:50,370 - mmseg - INFO - Iter [53750/160000]	lr: 6.949e-03, eta: 1 day, 15:13:46, time: 1.230, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0956, decode.acc_seg: 53.0406, loss: 1.0956
2021-08-14 18:42:52,185 - mmseg - INFO - Iter [53800/160000]	lr: 6.946e-03, eta: 1 day, 15:12:30, time: 1.236, data_time: 0.018, memory: 5723, decode.loss_seg: 1.0847, decode.acc_seg: 52.3508, loss: 1.0847
2021-08-14 18:43:56,390 - mmseg - INFO - Iter [53850/160000]	lr: 6.943e-03, eta: 1 day, 15:11:19, time: 1.284, data_time: 0.017, memory: 5723, decode.loss_seg: 1.0711, decode.acc_seg: 52.9680, loss: 1.0711
2021-08-14 18:44:59,268 - mmseg - INFO - Iter [53900/160000]	lr: 6.940e-03, eta: 1 day, 15:10:06, time: 1.258, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0351, decode.acc_seg: 53.2368, loss: 1.0351
2021-08-14 18:46:00,644 - mmseg - INFO - Iter [53950/160000]	lr: 6.937e-03, eta: 1 day, 15:08:49, time: 1.227, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0149, decode.acc_seg: 53.6800, loss: 1.0149
2021-08-14 18:47:01,318 - mmseg - INFO - Exp name: fcn_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 18:47:01,319 - mmseg - INFO - Iter [54000/160000]	lr: 6.934e-03, eta: 1 day, 15:07:32, time: 1.214, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1299, decode.acc_seg: 53.1015, loss: 1.1299
2021-08-14 18:48:04,297 - mmseg - INFO - Iter [54050/160000]	lr: 6.932e-03, eta: 1 day, 15:06:18, time: 1.259, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0829, decode.acc_seg: 52.5781, loss: 1.0829
2021-08-14 18:49:05,782 - mmseg - INFO - Iter [54100/160000]	lr: 6.929e-03, eta: 1 day, 15:05:02, time: 1.229, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0882, decode.acc_seg: 52.8891, loss: 1.0882
2021-08-14 18:50:07,486 - mmseg - INFO - Iter [54150/160000]	lr: 6.926e-03, eta: 1 day, 15:03:46, time: 1.234, data_time: 0.017, memory: 5723, decode.loss_seg: 1.0863, decode.acc_seg: 53.6503, loss: 1.0863
2021-08-14 18:51:10,598 - mmseg - INFO - Iter [54200/160000]	lr: 6.923e-03, eta: 1 day, 15:02:34, time: 1.262, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0809, decode.acc_seg: 53.2554, loss: 1.0809
2021-08-14 18:52:13,998 - mmseg - INFO - Iter [54250/160000]	lr: 6.920e-03, eta: 1 day, 15:01:21, time: 1.268, data_time: 0.017, memory: 5723, decode.loss_seg: 1.0681, decode.acc_seg: 53.4209, loss: 1.0681
2021-08-14 18:53:51,588 - mmseg - INFO - Iter [54300/160000]	lr: 6.917e-03, eta: 1 day, 15:01:16, time: 1.952, data_time: 0.695, memory: 5723, decode.loss_seg: 1.0607, decode.acc_seg: 52.9587, loss: 1.0607
2021-08-14 18:54:53,565 - mmseg - INFO - Iter [54350/160000]	lr: 6.914e-03, eta: 1 day, 15:00:00, time: 1.240, data_time: 0.018, memory: 5723, decode.loss_seg: 1.0641, decode.acc_seg: 53.9112, loss: 1.0641
2021-08-14 18:55:56,108 - mmseg - INFO - Iter [54400/160000]	lr: 6.911e-03, eta: 1 day, 14:58:46, time: 1.251, data_time: 0.017, memory: 5723, decode.loss_seg: 1.0908, decode.acc_seg: 52.4231, loss: 1.0908
2021-08-14 18:57:00,083 - mmseg - INFO - Iter [54450/160000]	lr: 6.908e-03, eta: 1 day, 14:57:35, time: 1.279, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0716, decode.acc_seg: 52.6090, loss: 1.0716
2021-08-14 18:58:02,027 - mmseg - INFO - Iter [54500/160000]	lr: 6.905e-03, eta: 1 day, 14:56:20, time: 1.239, data_time: 0.017, memory: 5723, decode.loss_seg: 1.0623, decode.acc_seg: 53.6204, loss: 1.0623
2021-08-14 18:59:07,167 - mmseg - INFO - Iter [54550/160000]	lr: 6.903e-03, eta: 1 day, 14:55:11, time: 1.303, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0907, decode.acc_seg: 53.5868, loss: 1.0907
2021-08-14 19:00:09,334 - mmseg - INFO - Iter [54600/160000]	lr: 6.900e-03, eta: 1 day, 14:53:56, time: 1.243, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0838, decode.acc_seg: 53.2681, loss: 1.0838
2021-08-14 19:01:13,444 - mmseg - INFO - Iter [54650/160000]	lr: 6.897e-03, eta: 1 day, 14:52:45, time: 1.282, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0657, decode.acc_seg: 52.4626, loss: 1.0657
2021-08-14 19:02:15,202 - mmseg - INFO - Iter [54700/160000]	lr: 6.894e-03, eta: 1 day, 14:51:30, time: 1.236, data_time: 0.017, memory: 5723, decode.loss_seg: 1.0729, decode.acc_seg: 51.9740, loss: 1.0729
2021-08-14 19:03:17,274 - mmseg - INFO - Iter [54750/160000]	lr: 6.891e-03, eta: 1 day, 14:50:15, time: 1.241, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0401, decode.acc_seg: 53.6823, loss: 1.0401
2021-08-14 19:04:18,774 - mmseg - INFO - Iter [54800/160000]	lr: 6.888e-03, eta: 1 day, 14:48:59, time: 1.230, data_time: 0.015, memory: 5723, decode.loss_seg: 1.0869, decode.acc_seg: 53.0989, loss: 1.0869
2021-08-14 19:05:21,605 - mmseg - INFO - Iter [54850/160000]	lr: 6.885e-03, eta: 1 day, 14:47:46, time: 1.257, data_time: 0.015, memory: 5723, decode.loss_seg: 1.0771, decode.acc_seg: 52.7484, loss: 1.0771
2021-08-14 19:06:59,900 - mmseg - INFO - Iter [54900/160000]	lr: 6.882e-03, eta: 1 day, 14:47:41, time: 1.966, data_time: 0.722, memory: 5723, decode.loss_seg: 1.0609, decode.acc_seg: 53.2826, loss: 1.0609
2021-08-14 19:08:01,760 - mmseg - INFO - Iter [54950/160000]	lr: 6.879e-03, eta: 1 day, 14:46:26, time: 1.237, data_time: 0.017, memory: 5723, decode.loss_seg: 1.0628, decode.acc_seg: 52.4864, loss: 1.0628
2021-08-14 19:09:03,295 - mmseg - INFO - Exp name: fcn_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 19:09:03,295 - mmseg - INFO - Iter [55000/160000]	lr: 6.876e-03, eta: 1 day, 14:45:10, time: 1.231, data_time: 0.015, memory: 5723, decode.loss_seg: 1.0443, decode.acc_seg: 53.8972, loss: 1.0443
2021-08-14 19:10:04,443 - mmseg - INFO - Iter [55050/160000]	lr: 6.874e-03, eta: 1 day, 14:43:53, time: 1.223, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0765, decode.acc_seg: 52.6408, loss: 1.0765
2021-08-14 19:11:11,199 - mmseg - INFO - Iter [55100/160000]	lr: 6.871e-03, eta: 1 day, 14:42:47, time: 1.334, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0626, decode.acc_seg: 53.9080, loss: 1.0626
2021-08-14 19:12:19,396 - mmseg - INFO - Iter [55150/160000]	lr: 6.868e-03, eta: 1 day, 14:41:44, time: 1.364, data_time: 0.018, memory: 5723, decode.loss_seg: 1.0918, decode.acc_seg: 53.3846, loss: 1.0918
2021-08-14 19:13:27,567 - mmseg - INFO - Iter [55200/160000]	lr: 6.865e-03, eta: 1 day, 14:40:41, time: 1.364, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0825, decode.acc_seg: 52.9044, loss: 1.0825
2021-08-14 19:14:31,264 - mmseg - INFO - Iter [55250/160000]	lr: 6.862e-03, eta: 1 day, 14:39:30, time: 1.274, data_time: 0.019, memory: 5723, decode.loss_seg: 1.0970, decode.acc_seg: 53.1009, loss: 1.0970
2021-08-14 19:15:34,589 - mmseg - INFO - Iter [55300/160000]	lr: 6.859e-03, eta: 1 day, 14:38:17, time: 1.267, data_time: 0.017, memory: 5723, decode.loss_seg: 1.0664, decode.acc_seg: 53.6336, loss: 1.0664
2021-08-14 19:16:36,373 - mmseg - INFO - Iter [55350/160000]	lr: 6.856e-03, eta: 1 day, 14:37:02, time: 1.235, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0844, decode.acc_seg: 51.8511, loss: 1.0844
2021-08-14 19:17:40,634 - mmseg - INFO - Iter [55400/160000]	lr: 6.853e-03, eta: 1 day, 14:35:52, time: 1.286, data_time: 0.017, memory: 5723, decode.loss_seg: 1.0851, decode.acc_seg: 52.5966, loss: 1.0851
2021-08-14 19:18:40,960 - mmseg - INFO - Iter [55450/160000]	lr: 6.850e-03, eta: 1 day, 14:34:34, time: 1.207, data_time: 0.018, memory: 5723, decode.loss_seg: 1.0548, decode.acc_seg: 53.2645, loss: 1.0548
2021-08-14 19:19:45,020 - mmseg - INFO - Iter [55500/160000]	lr: 6.847e-03, eta: 1 day, 14:33:23, time: 1.282, data_time: 0.017, memory: 5723, decode.loss_seg: 1.0771, decode.acc_seg: 53.1760, loss: 1.0771
2021-08-14 19:21:21,710 - mmseg - INFO - Iter [55550/160000]	lr: 6.844e-03, eta: 1 day, 14:33:13, time: 1.934, data_time: 0.760, memory: 5723, decode.loss_seg: 1.0600, decode.acc_seg: 52.8136, loss: 1.0600
2021-08-14 19:22:22,634 - mmseg - INFO - Iter [55600/160000]	lr: 6.842e-03, eta: 1 day, 14:31:56, time: 1.218, data_time: 0.017, memory: 5723, decode.loss_seg: 1.0710, decode.acc_seg: 52.9337, loss: 1.0710
2021-08-14 19:23:24,321 - mmseg - INFO - Iter [55650/160000]	lr: 6.839e-03, eta: 1 day, 14:30:41, time: 1.234, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0785, decode.acc_seg: 52.8683, loss: 1.0785
2021-08-14 19:24:25,704 - mmseg - INFO - Iter [55700/160000]	lr: 6.836e-03, eta: 1 day, 14:29:25, time: 1.228, data_time: 0.018, memory: 5723, decode.loss_seg: 1.0510, decode.acc_seg: 53.2984, loss: 1.0510
2021-08-14 19:25:28,031 - mmseg - INFO - Iter [55750/160000]	lr: 6.833e-03, eta: 1 day, 14:28:11, time: 1.246, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0558, decode.acc_seg: 53.3778, loss: 1.0558
2021-08-14 19:26:28,638 - mmseg - INFO - Iter [55800/160000]	lr: 6.830e-03, eta: 1 day, 14:26:54, time: 1.213, data_time: 0.018, memory: 5723, decode.loss_seg: 1.1193, decode.acc_seg: 51.9348, loss: 1.1193
2021-08-14 19:27:29,853 - mmseg - INFO - Iter [55850/160000]	lr: 6.827e-03, eta: 1 day, 14:25:38, time: 1.224, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0854, decode.acc_seg: 52.6828, loss: 1.0854
2021-08-14 19:28:32,987 - mmseg - INFO - Iter [55900/160000]	lr: 6.824e-03, eta: 1 day, 14:24:25, time: 1.262, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0870, decode.acc_seg: 52.9563, loss: 1.0870
2021-08-14 19:29:35,883 - mmseg - INFO - Iter [55950/160000]	lr: 6.821e-03, eta: 1 day, 14:23:12, time: 1.258, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0941, decode.acc_seg: 52.8524, loss: 1.0941
2021-08-14 19:30:38,116 - mmseg - INFO - Exp name: fcn_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 19:30:38,116 - mmseg - INFO - Iter [56000/160000]	lr: 6.818e-03, eta: 1 day, 14:21:58, time: 1.245, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0419, decode.acc_seg: 53.0412, loss: 1.0419
2021-08-14 19:31:40,905 - mmseg - INFO - Iter [56050/160000]	lr: 6.815e-03, eta: 1 day, 14:20:45, time: 1.256, data_time: 0.017, memory: 5723, decode.loss_seg: 1.0719, decode.acc_seg: 53.4606, loss: 1.0719
2021-08-14 19:32:45,016 - mmseg - INFO - Iter [56100/160000]	lr: 6.813e-03, eta: 1 day, 14:19:34, time: 1.283, data_time: 0.017, memory: 5723, decode.loss_seg: 1.0826, decode.acc_seg: 53.2431, loss: 1.0826
2021-08-14 19:33:47,275 - mmseg - INFO - Iter [56150/160000]	lr: 6.810e-03, eta: 1 day, 14:18:20, time: 1.245, data_time: 0.017, memory: 5723, decode.loss_seg: 1.0510, decode.acc_seg: 53.4110, loss: 1.0510
2021-08-14 19:35:25,864 - mmseg - INFO - Iter [56200/160000]	lr: 6.807e-03, eta: 1 day, 14:18:13, time: 1.972, data_time: 0.729, memory: 5723, decode.loss_seg: 1.0899, decode.acc_seg: 52.4583, loss: 1.0899
2021-08-14 19:36:27,697 - mmseg - INFO - Iter [56250/160000]	lr: 6.804e-03, eta: 1 day, 14:16:59, time: 1.237, data_time: 0.017, memory: 5723, decode.loss_seg: 1.0809, decode.acc_seg: 52.1246, loss: 1.0809
2021-08-14 19:37:29,709 - mmseg - INFO - Iter [56300/160000]	lr: 6.801e-03, eta: 1 day, 14:15:44, time: 1.241, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0349, decode.acc_seg: 53.7626, loss: 1.0349
2021-08-14 19:38:33,414 - mmseg - INFO - Iter [56350/160000]	lr: 6.798e-03, eta: 1 day, 14:14:33, time: 1.274, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0380, decode.acc_seg: 53.6156, loss: 1.0380
2021-08-14 19:39:35,613 - mmseg - INFO - Iter [56400/160000]	lr: 6.795e-03, eta: 1 day, 14:13:18, time: 1.244, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0774, decode.acc_seg: 52.4420, loss: 1.0774
2021-08-14 19:40:38,034 - mmseg - INFO - Iter [56450/160000]	lr: 6.792e-03, eta: 1 day, 14:12:05, time: 1.248, data_time: 0.017, memory: 5723, decode.loss_seg: 1.0745, decode.acc_seg: 52.6934, loss: 1.0745
2021-08-14 19:41:40,898 - mmseg - INFO - Iter [56500/160000]	lr: 6.789e-03, eta: 1 day, 14:10:52, time: 1.257, data_time: 0.017, memory: 5723, decode.loss_seg: 1.0490, decode.acc_seg: 53.0189, loss: 1.0490
2021-08-14 19:42:45,554 - mmseg - INFO - Iter [56550/160000]	lr: 6.786e-03, eta: 1 day, 14:09:42, time: 1.294, data_time: 0.017, memory: 5723, decode.loss_seg: 1.0788, decode.acc_seg: 53.5478, loss: 1.0788
2021-08-14 19:43:48,596 - mmseg - INFO - Iter [56600/160000]	lr: 6.783e-03, eta: 1 day, 14:08:30, time: 1.261, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0500, decode.acc_seg: 53.3852, loss: 1.0500
2021-08-14 19:44:52,015 - mmseg - INFO - Iter [56650/160000]	lr: 6.781e-03, eta: 1 day, 14:07:18, time: 1.268, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0882, decode.acc_seg: 52.8145, loss: 1.0882
2021-08-14 19:45:53,032 - mmseg - INFO - Iter [56700/160000]	lr: 6.778e-03, eta: 1 day, 14:06:02, time: 1.221, data_time: 0.017, memory: 5723, decode.loss_seg: 1.0474, decode.acc_seg: 54.0413, loss: 1.0474
2021-08-14 19:46:54,855 - mmseg - INFO - Iter [56750/160000]	lr: 6.775e-03, eta: 1 day, 14:04:47, time: 1.236, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0815, decode.acc_seg: 53.3171, loss: 1.0815
2021-08-14 19:48:34,186 - mmseg - INFO - Iter [56800/160000]	lr: 6.772e-03, eta: 1 day, 14:04:40, time: 1.987, data_time: 0.737, memory: 5723, decode.loss_seg: 1.0745, decode.acc_seg: 53.3385, loss: 1.0745
2021-08-14 19:49:36,664 - mmseg - INFO - Iter [56850/160000]	lr: 6.769e-03, eta: 1 day, 14:03:27, time: 1.249, data_time: 0.017, memory: 5723, decode.loss_seg: 1.0287, decode.acc_seg: 52.9234, loss: 1.0287
2021-08-14 19:50:37,728 - mmseg - INFO - Iter [56900/160000]	lr: 6.766e-03, eta: 1 day, 14:02:11, time: 1.222, data_time: 0.017, memory: 5723, decode.loss_seg: 1.0342, decode.acc_seg: 53.6004, loss: 1.0342
2021-08-14 19:51:40,270 - mmseg - INFO - Iter [56950/160000]	lr: 6.763e-03, eta: 1 day, 14:00:57, time: 1.251, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0543, decode.acc_seg: 53.6867, loss: 1.0543
2021-08-14 19:52:42,107 - mmseg - INFO - Exp name: fcn_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 19:52:42,107 - mmseg - INFO - Iter [57000/160000]	lr: 6.760e-03, eta: 1 day, 13:59:43, time: 1.236, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0591, decode.acc_seg: 53.1199, loss: 1.0591
2021-08-14 19:53:45,906 - mmseg - INFO - Iter [57050/160000]	lr: 6.757e-03, eta: 1 day, 13:58:32, time: 1.276, data_time: 0.017, memory: 5723, decode.loss_seg: 1.0409, decode.acc_seg: 53.8351, loss: 1.0409
2021-08-14 19:54:46,673 - mmseg - INFO - Iter [57100/160000]	lr: 6.754e-03, eta: 1 day, 13:57:15, time: 1.216, data_time: 0.017, memory: 5723, decode.loss_seg: 1.0615, decode.acc_seg: 53.4884, loss: 1.0615
2021-08-14 19:55:48,530 - mmseg - INFO - Iter [57150/160000]	lr: 6.751e-03, eta: 1 day, 13:56:01, time: 1.237, data_time: 0.017, memory: 5723, decode.loss_seg: 1.0457, decode.acc_seg: 53.3268, loss: 1.0457
2021-08-14 19:56:50,573 - mmseg - INFO - Iter [57200/160000]	lr: 6.749e-03, eta: 1 day, 13:54:46, time: 1.241, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0580, decode.acc_seg: 53.0499, loss: 1.0580
2021-08-14 19:57:55,384 - mmseg - INFO - Iter [57250/160000]	lr: 6.746e-03, eta: 1 day, 13:53:37, time: 1.296, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0772, decode.acc_seg: 52.5330, loss: 1.0772
2021-08-14 19:58:57,576 - mmseg - INFO - Iter [57300/160000]	lr: 6.743e-03, eta: 1 day, 13:52:23, time: 1.244, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0674, decode.acc_seg: 52.9074, loss: 1.0674
2021-08-14 19:59:59,012 - mmseg - INFO - Iter [57350/160000]	lr: 6.740e-03, eta: 1 day, 13:51:08, time: 1.228, data_time: 0.017, memory: 5723, decode.loss_seg: 1.0725, decode.acc_seg: 52.5780, loss: 1.0725
2021-08-14 20:01:03,121 - mmseg - INFO - Iter [57400/160000]	lr: 6.737e-03, eta: 1 day, 13:49:58, time: 1.283, data_time: 0.017, memory: 5723, decode.loss_seg: 1.0949, decode.acc_seg: 52.3329, loss: 1.0949
2021-08-14 20:02:41,991 - mmseg - INFO - Iter [57450/160000]	lr: 6.734e-03, eta: 1 day, 13:49:49, time: 1.977, data_time: 0.724, memory: 5723, decode.loss_seg: 1.0385, decode.acc_seg: 53.7022, loss: 1.0385
2021-08-14 20:03:46,334 - mmseg - INFO - Iter [57500/160000]	lr: 6.731e-03, eta: 1 day, 13:48:39, time: 1.288, data_time: 0.014, memory: 5723, decode.loss_seg: 1.0199, decode.acc_seg: 53.5987, loss: 1.0199
2021-08-14 20:04:48,508 - mmseg - INFO - Iter [57550/160000]	lr: 6.728e-03, eta: 1 day, 13:47:25, time: 1.243, data_time: 0.014, memory: 5723, decode.loss_seg: 1.0885, decode.acc_seg: 53.4213, loss: 1.0885
2021-08-14 20:05:49,036 - mmseg - INFO - Iter [57600/160000]	lr: 6.725e-03, eta: 1 day, 13:46:08, time: 1.211, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0503, decode.acc_seg: 54.3060, loss: 1.0503
2021-08-14 20:06:50,066 - mmseg - INFO - Iter [57650/160000]	lr: 6.722e-03, eta: 1 day, 13:44:52, time: 1.220, data_time: 0.017, memory: 5723, decode.loss_seg: 1.0617, decode.acc_seg: 52.5851, loss: 1.0617
2021-08-14 20:07:53,992 - mmseg - INFO - Iter [57700/160000]	lr: 6.719e-03, eta: 1 day, 13:43:42, time: 1.278, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0627, decode.acc_seg: 52.9091, loss: 1.0627
2021-08-14 20:08:59,289 - mmseg - INFO - Iter [57750/160000]	lr: 6.716e-03, eta: 1 day, 13:42:33, time: 1.307, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0829, decode.acc_seg: 52.8072, loss: 1.0829
2021-08-14 20:09:59,979 - mmseg - INFO - Iter [57800/160000]	lr: 6.714e-03, eta: 1 day, 13:41:17, time: 1.213, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0837, decode.acc_seg: 52.8799, loss: 1.0837
2021-08-14 20:11:00,342 - mmseg - INFO - Iter [57850/160000]	lr: 6.711e-03, eta: 1 day, 13:40:00, time: 1.208, data_time: 0.015, memory: 5723, decode.loss_seg: 1.0357, decode.acc_seg: 51.9995, loss: 1.0357
2021-08-14 20:12:02,141 - mmseg - INFO - Iter [57900/160000]	lr: 6.708e-03, eta: 1 day, 13:38:46, time: 1.236, data_time: 0.017, memory: 5723, decode.loss_seg: 1.0231, decode.acc_seg: 53.9518, loss: 1.0231
2021-08-14 20:13:03,973 - mmseg - INFO - Iter [57950/160000]	lr: 6.705e-03, eta: 1 day, 13:37:31, time: 1.237, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0738, decode.acc_seg: 52.9077, loss: 1.0738
2021-08-14 20:14:04,721 - mmseg - INFO - Exp name: fcn_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 20:14:04,722 - mmseg - INFO - Iter [58000/160000]	lr: 6.702e-03, eta: 1 day, 13:36:15, time: 1.215, data_time: 0.018, memory: 5723, decode.loss_seg: 1.0475, decode.acc_seg: 53.0336, loss: 1.0475
2021-08-14 20:15:06,925 - mmseg - INFO - Iter [58050/160000]	lr: 6.699e-03, eta: 1 day, 13:35:01, time: 1.244, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0643, decode.acc_seg: 53.5908, loss: 1.0643
2021-08-14 20:16:45,265 - mmseg - INFO - Iter [58100/160000]	lr: 6.696e-03, eta: 1 day, 13:34:51, time: 1.966, data_time: 0.713, memory: 5723, decode.loss_seg: 1.0532, decode.acc_seg: 53.4418, loss: 1.0532
2021-08-14 20:17:50,577 - mmseg - INFO - Iter [58150/160000]	lr: 6.693e-03, eta: 1 day, 13:33:43, time: 1.306, data_time: 0.017, memory: 5723, decode.loss_seg: 1.0573, decode.acc_seg: 53.2041, loss: 1.0573
2021-08-14 20:18:53,370 - mmseg - INFO - Iter [58200/160000]	lr: 6.690e-03, eta: 1 day, 13:32:30, time: 1.256, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0304, decode.acc_seg: 53.6857, loss: 1.0304
2021-08-14 20:19:55,445 - mmseg - INFO - Iter [58250/160000]	lr: 6.687e-03, eta: 1 day, 13:31:16, time: 1.242, data_time: 0.019, memory: 5723, decode.loss_seg: 1.0651, decode.acc_seg: 52.0199, loss: 1.0651
2021-08-14 20:20:58,789 - mmseg - INFO - Iter [58300/160000]	lr: 6.684e-03, eta: 1 day, 13:30:04, time: 1.266, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0612, decode.acc_seg: 52.8158, loss: 1.0612
2021-08-14 20:21:59,391 - mmseg - INFO - Iter [58350/160000]	lr: 6.682e-03, eta: 1 day, 13:28:48, time: 1.212, data_time: 0.017, memory: 5723, decode.loss_seg: 1.0331, decode.acc_seg: 53.2718, loss: 1.0331
2021-08-14 20:23:02,679 - mmseg - INFO - Iter [58400/160000]	lr: 6.679e-03, eta: 1 day, 13:27:36, time: 1.266, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1012, decode.acc_seg: 52.8194, loss: 1.1012
2021-08-14 20:24:06,822 - mmseg - INFO - Iter [58450/160000]	lr: 6.676e-03, eta: 1 day, 13:26:26, time: 1.283, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0496, decode.acc_seg: 53.2331, loss: 1.0496
2021-08-14 20:25:09,858 - mmseg - INFO - Iter [58500/160000]	lr: 6.673e-03, eta: 1 day, 13:25:14, time: 1.259, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0602, decode.acc_seg: 52.8026, loss: 1.0602
2021-08-14 20:26:13,068 - mmseg - INFO - Iter [58550/160000]	lr: 6.670e-03, eta: 1 day, 13:24:02, time: 1.265, data_time: 0.019, memory: 5723, decode.loss_seg: 1.0411, decode.acc_seg: 54.1007, loss: 1.0411
2021-08-14 20:27:14,650 - mmseg - INFO - Iter [58600/160000]	lr: 6.667e-03, eta: 1 day, 13:22:47, time: 1.231, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0685, decode.acc_seg: 53.4841, loss: 1.0685
2021-08-14 20:28:16,935 - mmseg - INFO - Iter [58650/160000]	lr: 6.664e-03, eta: 1 day, 13:21:34, time: 1.246, data_time: 0.017, memory: 5723, decode.loss_seg: 1.0519, decode.acc_seg: 52.3865, loss: 1.0519
2021-08-14 20:29:56,384 - mmseg - INFO - Iter [58700/160000]	lr: 6.661e-03, eta: 1 day, 13:21:25, time: 1.989, data_time: 0.730, memory: 5723, decode.loss_seg: 1.0724, decode.acc_seg: 53.3139, loss: 1.0724
2021-08-14 20:30:58,808 - mmseg - INFO - Iter [58750/160000]	lr: 6.658e-03, eta: 1 day, 13:20:12, time: 1.248, data_time: 0.017, memory: 5723, decode.loss_seg: 1.0399, decode.acc_seg: 53.4760, loss: 1.0399
2021-08-14 20:32:03,524 - mmseg - INFO - Iter [58800/160000]	lr: 6.655e-03, eta: 1 day, 13:19:02, time: 1.294, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0181, decode.acc_seg: 54.4676, loss: 1.0181
2021-08-14 20:33:05,186 - mmseg - INFO - Iter [58850/160000]	lr: 6.652e-03, eta: 1 day, 13:17:48, time: 1.233, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0412, decode.acc_seg: 52.6737, loss: 1.0412
2021-08-14 20:34:08,445 - mmseg - INFO - Iter [58900/160000]	lr: 6.649e-03, eta: 1 day, 13:16:36, time: 1.265, data_time: 0.017, memory: 5723, decode.loss_seg: 1.0591, decode.acc_seg: 52.4290, loss: 1.0591
2021-08-14 20:35:11,218 - mmseg - INFO - Iter [58950/160000]	lr: 6.647e-03, eta: 1 day, 13:15:24, time: 1.256, data_time: 0.017, memory: 5723, decode.loss_seg: 1.0532, decode.acc_seg: 53.9499, loss: 1.0532
2021-08-14 20:36:13,346 - mmseg - INFO - Exp name: fcn_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 20:36:13,347 - mmseg - INFO - Iter [59000/160000]	lr: 6.644e-03, eta: 1 day, 13:14:10, time: 1.243, data_time: 0.017, memory: 5723, decode.loss_seg: 1.1114, decode.acc_seg: 53.1322, loss: 1.1114
2021-08-14 20:37:15,253 - mmseg - INFO - Iter [59050/160000]	lr: 6.641e-03, eta: 1 day, 13:12:56, time: 1.238, data_time: 0.017, memory: 5723, decode.loss_seg: 1.0710, decode.acc_seg: 52.3301, loss: 1.0710
2021-08-14 20:38:19,123 - mmseg - INFO - Iter [59100/160000]	lr: 6.638e-03, eta: 1 day, 13:11:46, time: 1.278, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0427, decode.acc_seg: 53.1322, loss: 1.0427
2021-08-14 20:39:20,264 - mmseg - INFO - Iter [59150/160000]	lr: 6.635e-03, eta: 1 day, 13:10:30, time: 1.223, data_time: 0.017, memory: 5723, decode.loss_seg: 1.0981, decode.acc_seg: 52.3795, loss: 1.0981
2021-08-14 20:40:22,701 - mmseg - INFO - Iter [59200/160000]	lr: 6.632e-03, eta: 1 day, 13:09:17, time: 1.248, data_time: 0.017, memory: 5723, decode.loss_seg: 1.0528, decode.acc_seg: 53.7227, loss: 1.0528
2021-08-14 20:41:26,791 - mmseg - INFO - Iter [59250/160000]	lr: 6.629e-03, eta: 1 day, 13:08:07, time: 1.282, data_time: 0.018, memory: 5723, decode.loss_seg: 1.0160, decode.acc_seg: 53.5357, loss: 1.0160
2021-08-14 20:42:32,618 - mmseg - INFO - Iter [59300/160000]	lr: 6.626e-03, eta: 1 day, 13:07:00, time: 1.316, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0577, decode.acc_seg: 53.3189, loss: 1.0577
2021-08-14 20:44:13,916 - mmseg - INFO - Iter [59350/160000]	lr: 6.623e-03, eta: 1 day, 13:06:53, time: 2.027, data_time: 0.728, memory: 5723, decode.loss_seg: 1.0640, decode.acc_seg: 52.8115, loss: 1.0640
2021-08-14 20:45:18,594 - mmseg - INFO - Iter [59400/160000]	lr: 6.620e-03, eta: 1 day, 13:05:43, time: 1.293, data_time: 0.018, memory: 5723, decode.loss_seg: 1.0452, decode.acc_seg: 53.5367, loss: 1.0452
2021-08-14 20:46:20,533 - mmseg - INFO - Iter [59450/160000]	lr: 6.617e-03, eta: 1 day, 13:04:30, time: 1.239, data_time: 0.018, memory: 5723, decode.loss_seg: 1.0582, decode.acc_seg: 53.2035, loss: 1.0582
2021-08-14 20:47:25,321 - mmseg - INFO - Iter [59500/160000]	lr: 6.614e-03, eta: 1 day, 13:03:21, time: 1.296, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0705, decode.acc_seg: 52.4862, loss: 1.0705
2021-08-14 20:48:27,043 - mmseg - INFO - Iter [59550/160000]	lr: 6.612e-03, eta: 1 day, 13:02:06, time: 1.234, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0652, decode.acc_seg: 52.6056, loss: 1.0652
2021-08-14 20:49:34,467 - mmseg - INFO - Iter [59600/160000]	lr: 6.609e-03, eta: 1 day, 13:01:02, time: 1.348, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0246, decode.acc_seg: 52.7972, loss: 1.0246
2021-08-14 20:50:40,259 - mmseg - INFO - Iter [59650/160000]	lr: 6.606e-03, eta: 1 day, 12:59:54, time: 1.317, data_time: 0.018, memory: 5723, decode.loss_seg: 1.0340, decode.acc_seg: 54.6135, loss: 1.0340
2021-08-14 20:51:43,592 - mmseg - INFO - Iter [59700/160000]	lr: 6.603e-03, eta: 1 day, 12:58:43, time: 1.266, data_time: 0.017, memory: 5723, decode.loss_seg: 1.0779, decode.acc_seg: 52.7980, loss: 1.0779
2021-08-14 20:52:45,874 - mmseg - INFO - Iter [59750/160000]	lr: 6.600e-03, eta: 1 day, 12:57:30, time: 1.245, data_time: 0.017, memory: 5723, decode.loss_seg: 1.0754, decode.acc_seg: 53.7762, loss: 1.0754
2021-08-14 20:53:49,046 - mmseg - INFO - Iter [59800/160000]	lr: 6.597e-03, eta: 1 day, 12:56:18, time: 1.264, data_time: 0.017, memory: 5723, decode.loss_seg: 1.0242, decode.acc_seg: 54.2544, loss: 1.0242
2021-08-14 20:54:54,061 - mmseg - INFO - Iter [59850/160000]	lr: 6.594e-03, eta: 1 day, 12:55:09, time: 1.300, data_time: 0.017, memory: 5723, decode.loss_seg: 1.0581, decode.acc_seg: 52.8506, loss: 1.0581
2021-08-14 20:56:00,954 - mmseg - INFO - Iter [59900/160000]	lr: 6.591e-03, eta: 1 day, 12:54:04, time: 1.337, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0183, decode.acc_seg: 54.0067, loss: 1.0183
2021-08-14 20:57:41,502 - mmseg - INFO - Iter [59950/160000]	lr: 6.588e-03, eta: 1 day, 12:53:55, time: 2.011, data_time: 0.735, memory: 5723, decode.loss_seg: 1.0901, decode.acc_seg: 52.7691, loss: 1.0901
2021-08-14 20:58:43,461 - mmseg - INFO - Exp name: fcn_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 20:58:43,461 - mmseg - INFO - Iter [60000/160000]	lr: 6.585e-03, eta: 1 day, 12:52:41, time: 1.240, data_time: 0.017, memory: 5723, decode.loss_seg: 1.0378, decode.acc_seg: 53.4672, loss: 1.0378
2021-08-14 20:59:45,408 - mmseg - INFO - Iter [60050/160000]	lr: 6.582e-03, eta: 1 day, 12:51:27, time: 1.239, data_time: 0.017, memory: 5723, decode.loss_seg: 1.0228, decode.acc_seg: 54.4039, loss: 1.0228
2021-08-14 21:00:47,916 - mmseg - INFO - Iter [60100/160000]	lr: 6.579e-03, eta: 1 day, 12:50:14, time: 1.250, data_time: 0.017, memory: 5723, decode.loss_seg: 1.0457, decode.acc_seg: 53.6949, loss: 1.0457
2021-08-14 21:01:48,885 - mmseg - INFO - Iter [60150/160000]	lr: 6.577e-03, eta: 1 day, 12:48:59, time: 1.220, data_time: 0.017, memory: 5723, decode.loss_seg: 1.0565, decode.acc_seg: 52.2882, loss: 1.0565
2021-08-14 21:02:51,395 - mmseg - INFO - Iter [60200/160000]	lr: 6.574e-03, eta: 1 day, 12:47:46, time: 1.250, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0409, decode.acc_seg: 53.6345, loss: 1.0409
2021-08-14 21:03:53,030 - mmseg - INFO - Iter [60250/160000]	lr: 6.571e-03, eta: 1 day, 12:46:32, time: 1.232, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0776, decode.acc_seg: 52.6279, loss: 1.0776
2021-08-14 21:04:55,913 - mmseg - INFO - Iter [60300/160000]	lr: 6.568e-03, eta: 1 day, 12:45:20, time: 1.258, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0554, decode.acc_seg: 53.3603, loss: 1.0554
2021-08-14 21:05:58,087 - mmseg - INFO - Iter [60350/160000]	lr: 6.565e-03, eta: 1 day, 12:44:07, time: 1.243, data_time: 0.017, memory: 5723, decode.loss_seg: 1.0155, decode.acc_seg: 53.3960, loss: 1.0155
2021-08-14 21:07:01,818 - mmseg - INFO - Iter [60400/160000]	lr: 6.562e-03, eta: 1 day, 12:42:56, time: 1.274, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0298, decode.acc_seg: 53.0136, loss: 1.0298
2021-08-14 21:08:07,609 - mmseg - INFO - Iter [60450/160000]	lr: 6.559e-03, eta: 1 day, 12:41:49, time: 1.317, data_time: 0.017, memory: 5723, decode.loss_seg: 1.0583, decode.acc_seg: 53.0673, loss: 1.0583
2021-08-14 21:09:11,930 - mmseg - INFO - Iter [60500/160000]	lr: 6.556e-03, eta: 1 day, 12:40:39, time: 1.286, data_time: 0.016, memory: 5723, decode.loss_seg: 1.1068, decode.acc_seg: 52.6951, loss: 1.1068
2021-08-14 21:10:15,860 - mmseg - INFO - Iter [60550/160000]	lr: 6.553e-03, eta: 1 day, 12:39:29, time: 1.278, data_time: 0.015, memory: 5723, decode.loss_seg: 1.0499, decode.acc_seg: 53.7157, loss: 1.0499
2021-08-14 21:11:54,671 - mmseg - INFO - Iter [60600/160000]	lr: 6.550e-03, eta: 1 day, 12:39:16, time: 1.977, data_time: 0.722, memory: 5723, decode.loss_seg: 1.0541, decode.acc_seg: 53.9210, loss: 1.0541
2021-08-14 21:12:58,607 - mmseg - INFO - Iter [60650/160000]	lr: 6.547e-03, eta: 1 day, 12:38:05, time: 1.278, data_time: 0.015, memory: 5723, decode.loss_seg: 1.0537, decode.acc_seg: 54.0774, loss: 1.0537
2021-08-14 21:14:06,968 - mmseg - INFO - Iter [60700/160000]	lr: 6.544e-03, eta: 1 day, 12:37:02, time: 1.367, data_time: 0.014, memory: 5723, decode.loss_seg: 1.0378, decode.acc_seg: 53.4336, loss: 1.0378
2021-08-14 21:15:15,078 - mmseg - INFO - Iter [60750/160000]	lr: 6.542e-03, eta: 1 day, 12:35:58, time: 1.362, data_time: 0.015, memory: 5723, decode.loss_seg: 1.0573, decode.acc_seg: 53.6729, loss: 1.0573
2021-08-14 21:16:18,699 - mmseg - INFO - Iter [60800/160000]	lr: 6.539e-03, eta: 1 day, 12:34:48, time: 1.273, data_time: 0.015, memory: 5723, decode.loss_seg: 1.0371, decode.acc_seg: 53.4208, loss: 1.0371
2021-08-14 21:17:21,339 - mmseg - INFO - Iter [60850/160000]	lr: 6.536e-03, eta: 1 day, 12:33:35, time: 1.253, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0327, decode.acc_seg: 53.9892, loss: 1.0327
2021-08-14 21:18:24,092 - mmseg - INFO - Iter [60900/160000]	lr: 6.533e-03, eta: 1 day, 12:32:23, time: 1.255, data_time: 0.015, memory: 5723, decode.loss_seg: 1.0205, decode.acc_seg: 54.1740, loss: 1.0205
2021-08-14 21:19:25,901 - mmseg - INFO - Iter [60950/160000]	lr: 6.530e-03, eta: 1 day, 12:31:09, time: 1.236, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0360, decode.acc_seg: 54.6401, loss: 1.0360
2021-08-14 21:20:28,146 - mmseg - INFO - Exp name: fcn_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 21:20:28,147 - mmseg - INFO - Iter [61000/160000]	lr: 6.527e-03, eta: 1 day, 12:29:56, time: 1.245, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0850, decode.acc_seg: 52.9491, loss: 1.0850
2021-08-14 21:21:32,850 - mmseg - INFO - Iter [61050/160000]	lr: 6.524e-03, eta: 1 day, 12:28:47, time: 1.294, data_time: 0.017, memory: 5723, decode.loss_seg: 1.0591, decode.acc_seg: 53.6161, loss: 1.0591
2021-08-14 21:22:35,197 - mmseg - INFO - Iter [61100/160000]	lr: 6.521e-03, eta: 1 day, 12:27:34, time: 1.247, data_time: 0.017, memory: 5723, decode.loss_seg: 1.0582, decode.acc_seg: 54.0122, loss: 1.0582
2021-08-14 21:23:38,596 - mmseg - INFO - Iter [61150/160000]	lr: 6.518e-03, eta: 1 day, 12:26:23, time: 1.268, data_time: 0.017, memory: 5723, decode.loss_seg: 1.0394, decode.acc_seg: 53.6575, loss: 1.0394
2021-08-14 21:24:44,472 - mmseg - INFO - Iter [61200/160000]	lr: 6.515e-03, eta: 1 day, 12:25:16, time: 1.317, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0746, decode.acc_seg: 52.8370, loss: 1.0746
2021-08-14 21:26:22,961 - mmseg - INFO - Iter [61250/160000]	lr: 6.512e-03, eta: 1 day, 12:25:01, time: 1.971, data_time: 0.681, memory: 5723, decode.loss_seg: 1.0764, decode.acc_seg: 52.0352, loss: 1.0764
2021-08-14 21:27:23,424 - mmseg - INFO - Iter [61300/160000]	lr: 6.509e-03, eta: 1 day, 12:23:46, time: 1.209, data_time: 0.017, memory: 5723, decode.loss_seg: 1.0456, decode.acc_seg: 52.8117, loss: 1.0456
2021-08-14 21:28:25,757 - mmseg - INFO - Iter [61350/160000]	lr: 6.506e-03, eta: 1 day, 12:22:33, time: 1.247, data_time: 0.015, memory: 5723, decode.loss_seg: 1.0361, decode.acc_seg: 53.2283, loss: 1.0361
2021-08-14 21:29:26,473 - mmseg - INFO - Iter [61400/160000]	lr: 6.504e-03, eta: 1 day, 12:21:17, time: 1.214, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0408, decode.acc_seg: 53.5639, loss: 1.0408
2021-08-14 21:30:32,995 - mmseg - INFO - Iter [61450/160000]	lr: 6.501e-03, eta: 1 day, 12:20:11, time: 1.329, data_time: 0.015, memory: 5723, decode.loss_seg: 1.0601, decode.acc_seg: 53.1291, loss: 1.0601
2021-08-14 21:31:37,392 - mmseg - INFO - Iter [61500/160000]	lr: 6.498e-03, eta: 1 day, 12:19:02, time: 1.289, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0391, decode.acc_seg: 53.4722, loss: 1.0391
2021-08-14 21:32:39,333 - mmseg - INFO - Iter [61550/160000]	lr: 6.495e-03, eta: 1 day, 12:17:48, time: 1.238, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0406, decode.acc_seg: 53.1497, loss: 1.0406
2021-08-14 21:33:42,628 - mmseg - INFO - Iter [61600/160000]	lr: 6.492e-03, eta: 1 day, 12:16:37, time: 1.266, data_time: 0.015, memory: 5723, decode.loss_seg: 1.0410, decode.acc_seg: 53.3382, loss: 1.0410
2021-08-14 21:34:43,891 - mmseg - INFO - Iter [61650/160000]	lr: 6.489e-03, eta: 1 day, 12:15:22, time: 1.225, data_time: 0.015, memory: 5723, decode.loss_seg: 1.0193, decode.acc_seg: 53.6138, loss: 1.0193
2021-08-14 21:35:49,407 - mmseg - INFO - Iter [61700/160000]	lr: 6.486e-03, eta: 1 day, 12:14:15, time: 1.309, data_time: 0.015, memory: 5723, decode.loss_seg: 1.0902, decode.acc_seg: 54.0224, loss: 1.0902
2021-08-14 21:36:52,732 - mmseg - INFO - Iter [61750/160000]	lr: 6.483e-03, eta: 1 day, 12:13:03, time: 1.267, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0431, decode.acc_seg: 53.3994, loss: 1.0431
2021-08-14 21:37:53,856 - mmseg - INFO - Iter [61800/160000]	lr: 6.480e-03, eta: 1 day, 12:11:49, time: 1.223, data_time: 0.017, memory: 5723, decode.loss_seg: 1.0296, decode.acc_seg: 54.2146, loss: 1.0296
2021-08-14 21:39:32,842 - mmseg - INFO - Iter [61850/160000]	lr: 6.477e-03, eta: 1 day, 12:11:34, time: 1.980, data_time: 0.747, memory: 5723, decode.loss_seg: 1.0613, decode.acc_seg: 53.8386, loss: 1.0613
2021-08-14 21:40:38,597 - mmseg - INFO - Iter [61900/160000]	lr: 6.474e-03, eta: 1 day, 12:10:27, time: 1.315, data_time: 0.015, memory: 5723, decode.loss_seg: 1.0277, decode.acc_seg: 53.2710, loss: 1.0277
2021-08-14 21:41:40,795 - mmseg - INFO - Iter [61950/160000]	lr: 6.471e-03, eta: 1 day, 12:09:14, time: 1.244, data_time: 0.015, memory: 5723, decode.loss_seg: 1.0604, decode.acc_seg: 52.5457, loss: 1.0604
2021-08-14 21:42:41,931 - mmseg - INFO - Exp name: fcn_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 21:42:41,932 - mmseg - INFO - Iter [62000/160000]	lr: 6.468e-03, eta: 1 day, 12:07:59, time: 1.223, data_time: 0.015, memory: 5723, decode.loss_seg: 1.0187, decode.acc_seg: 54.4524, loss: 1.0187
2021-08-14 21:43:43,737 - mmseg - INFO - Iter [62050/160000]	lr: 6.466e-03, eta: 1 day, 12:06:46, time: 1.235, data_time: 0.014, memory: 5723, decode.loss_seg: 1.0777, decode.acc_seg: 53.0984, loss: 1.0777
2021-08-14 21:44:48,041 - mmseg - INFO - Iter [62100/160000]	lr: 6.463e-03, eta: 1 day, 12:05:36, time: 1.286, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0322, decode.acc_seg: 52.4701, loss: 1.0322
2021-08-14 21:45:49,820 - mmseg - INFO - Iter [62150/160000]	lr: 6.460e-03, eta: 1 day, 12:04:22, time: 1.236, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0209, decode.acc_seg: 53.7809, loss: 1.0209
2021-08-14 21:46:52,280 - mmseg - INFO - Iter [62200/160000]	lr: 6.457e-03, eta: 1 day, 12:03:10, time: 1.249, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0563, decode.acc_seg: 53.3433, loss: 1.0563
2021-08-14 21:47:56,161 - mmseg - INFO - Iter [62250/160000]	lr: 6.454e-03, eta: 1 day, 12:02:00, time: 1.277, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0661, decode.acc_seg: 51.9117, loss: 1.0661
2021-08-14 21:48:58,700 - mmseg - INFO - Iter [62300/160000]	lr: 6.451e-03, eta: 1 day, 12:00:47, time: 1.251, data_time: 0.017, memory: 5723, decode.loss_seg: 1.0506, decode.acc_seg: 52.9461, loss: 1.0506
2021-08-14 21:50:00,577 - mmseg - INFO - Iter [62350/160000]	lr: 6.448e-03, eta: 1 day, 11:59:34, time: 1.238, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0912, decode.acc_seg: 53.0866, loss: 1.0912
2021-08-14 21:51:01,947 - mmseg - INFO - Iter [62400/160000]	lr: 6.445e-03, eta: 1 day, 11:58:20, time: 1.227, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0506, decode.acc_seg: 53.3504, loss: 1.0506
2021-08-14 21:52:02,500 - mmseg - INFO - Iter [62450/160000]	lr: 6.442e-03, eta: 1 day, 11:57:04, time: 1.211, data_time: 0.017, memory: 5723, decode.loss_seg: 1.0616, decode.acc_seg: 54.1665, loss: 1.0616
2021-08-14 21:53:42,665 - mmseg - INFO - Iter [62500/160000]	lr: 6.439e-03, eta: 1 day, 11:56:51, time: 2.003, data_time: 0.684, memory: 5723, decode.loss_seg: 1.0585, decode.acc_seg: 53.8901, loss: 1.0585
2021-08-14 21:54:48,324 - mmseg - INFO - Iter [62550/160000]	lr: 6.436e-03, eta: 1 day, 11:55:43, time: 1.314, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0187, decode.acc_seg: 53.2562, loss: 1.0187
2021-08-14 21:55:53,718 - mmseg - INFO - Iter [62600/160000]	lr: 6.433e-03, eta: 1 day, 11:54:36, time: 1.308, data_time: 0.014, memory: 5723, decode.loss_seg: 1.0206, decode.acc_seg: 54.4065, loss: 1.0206
2021-08-14 21:56:58,002 - mmseg - INFO - Iter [62650/160000]	lr: 6.430e-03, eta: 1 day, 11:53:26, time: 1.286, data_time: 0.015, memory: 5723, decode.loss_seg: 1.0210, decode.acc_seg: 53.8593, loss: 1.0210
2021-08-14 21:58:00,472 - mmseg - INFO - Iter [62700/160000]	lr: 6.428e-03, eta: 1 day, 11:52:14, time: 1.250, data_time: 0.017, memory: 5723, decode.loss_seg: 1.0629, decode.acc_seg: 53.3919, loss: 1.0629
2021-08-14 21:59:01,611 - mmseg - INFO - Iter [62750/160000]	lr: 6.425e-03, eta: 1 day, 11:50:59, time: 1.223, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0484, decode.acc_seg: 53.8865, loss: 1.0484
2021-08-14 22:00:04,311 - mmseg - INFO - Iter [62800/160000]	lr: 6.422e-03, eta: 1 day, 11:49:47, time: 1.254, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0562, decode.acc_seg: 52.9820, loss: 1.0562
2021-08-14 22:01:10,548 - mmseg - INFO - Iter [62850/160000]	lr: 6.419e-03, eta: 1 day, 11:48:41, time: 1.324, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0947, decode.acc_seg: 52.4068, loss: 1.0947
2021-08-14 22:02:13,507 - mmseg - INFO - Iter [62900/160000]	lr: 6.416e-03, eta: 1 day, 11:47:29, time: 1.260, data_time: 0.015, memory: 5723, decode.loss_seg: 1.0527, decode.acc_seg: 53.2474, loss: 1.0527
2021-08-14 22:03:15,151 - mmseg - INFO - Iter [62950/160000]	lr: 6.413e-03, eta: 1 day, 11:46:15, time: 1.233, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0683, decode.acc_seg: 53.7243, loss: 1.0683
2021-08-14 22:04:17,639 - mmseg - INFO - Exp name: fcn_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 22:04:17,640 - mmseg - INFO - Iter [63000/160000]	lr: 6.410e-03, eta: 1 day, 11:45:03, time: 1.250, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0324, decode.acc_seg: 53.5831, loss: 1.0324
2021-08-14 22:05:19,066 - mmseg - INFO - Iter [63050/160000]	lr: 6.407e-03, eta: 1 day, 11:43:49, time: 1.229, data_time: 0.017, memory: 5723, decode.loss_seg: 1.0910, decode.acc_seg: 53.2002, loss: 1.0910
2021-08-14 22:06:20,379 - mmseg - INFO - Iter [63100/160000]	lr: 6.404e-03, eta: 1 day, 11:42:35, time: 1.226, data_time: 0.015, memory: 5723, decode.loss_seg: 1.0254, decode.acc_seg: 53.1922, loss: 1.0254
2021-08-14 22:07:59,588 - mmseg - INFO - Iter [63150/160000]	lr: 6.401e-03, eta: 1 day, 11:42:19, time: 1.984, data_time: 0.708, memory: 5723, decode.loss_seg: 1.0432, decode.acc_seg: 52.7834, loss: 1.0432
2021-08-14 22:09:01,818 - mmseg - INFO - Iter [63200/160000]	lr: 6.398e-03, eta: 1 day, 11:41:06, time: 1.244, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0256, decode.acc_seg: 54.0403, loss: 1.0256
2021-08-14 22:10:07,089 - mmseg - INFO - Iter [63250/160000]	lr: 6.395e-03, eta: 1 day, 11:39:59, time: 1.306, data_time: 0.017, memory: 5723, decode.loss_seg: 1.0084, decode.acc_seg: 54.8619, loss: 1.0084
2021-08-14 22:11:13,151 - mmseg - INFO - Iter [63300/160000]	lr: 6.392e-03, eta: 1 day, 11:38:52, time: 1.321, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0456, decode.acc_seg: 53.1828, loss: 1.0456
2021-08-14 22:12:17,606 - mmseg - INFO - Iter [63350/160000]	lr: 6.389e-03, eta: 1 day, 11:37:42, time: 1.290, data_time: 0.017, memory: 5723, decode.loss_seg: 1.0403, decode.acc_seg: 53.2897, loss: 1.0403
2021-08-14 22:13:23,097 - mmseg - INFO - Iter [63400/160000]	lr: 6.387e-03, eta: 1 day, 11:36:35, time: 1.310, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0624, decode.acc_seg: 52.7466, loss: 1.0624
2021-08-14 22:14:26,269 - mmseg - INFO - Iter [63450/160000]	lr: 6.384e-03, eta: 1 day, 11:35:24, time: 1.264, data_time: 0.017, memory: 5723, decode.loss_seg: 1.0501, decode.acc_seg: 53.7612, loss: 1.0501
2021-08-14 22:15:29,495 - mmseg - INFO - Iter [63500/160000]	lr: 6.381e-03, eta: 1 day, 11:34:12, time: 1.264, data_time: 0.015, memory: 5723, decode.loss_seg: 1.0345, decode.acc_seg: 54.1363, loss: 1.0345
2021-08-14 22:16:32,746 - mmseg - INFO - Iter [63550/160000]	lr: 6.378e-03, eta: 1 day, 11:33:01, time: 1.266, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0672, decode.acc_seg: 53.2588, loss: 1.0672
2021-08-14 22:17:36,027 - mmseg - INFO - Iter [63600/160000]	lr: 6.375e-03, eta: 1 day, 11:31:50, time: 1.265, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0359, decode.acc_seg: 54.4200, loss: 1.0359
2021-08-14 22:18:38,320 - mmseg - INFO - Iter [63650/160000]	lr: 6.372e-03, eta: 1 day, 11:30:38, time: 1.245, data_time: 0.015, memory: 5723, decode.loss_seg: 1.0531, decode.acc_seg: 53.3871, loss: 1.0531
2021-08-14 22:19:42,357 - mmseg - INFO - Iter [63700/160000]	lr: 6.369e-03, eta: 1 day, 11:29:28, time: 1.282, data_time: 0.015, memory: 5723, decode.loss_seg: 1.0571, decode.acc_seg: 53.1119, loss: 1.0571
2021-08-14 22:21:19,896 - mmseg - INFO - Iter [63750/160000]	lr: 6.366e-03, eta: 1 day, 11:29:09, time: 1.951, data_time: 0.740, memory: 5723, decode.loss_seg: 1.0290, decode.acc_seg: 52.7720, loss: 1.0290
2021-08-14 22:22:23,549 - mmseg - INFO - Iter [63800/160000]	lr: 6.363e-03, eta: 1 day, 11:27:58, time: 1.273, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0236, decode.acc_seg: 53.7410, loss: 1.0236
2021-08-14 22:23:26,168 - mmseg - INFO - Iter [63850/160000]	lr: 6.360e-03, eta: 1 day, 11:26:46, time: 1.252, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0012, decode.acc_seg: 54.0528, loss: 1.0012
2021-08-14 22:24:27,773 - mmseg - INFO - Iter [63900/160000]	lr: 6.357e-03, eta: 1 day, 11:25:33, time: 1.232, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0259, decode.acc_seg: 53.5972, loss: 1.0259
2021-08-14 22:25:29,603 - mmseg - INFO - Iter [63950/160000]	lr: 6.354e-03, eta: 1 day, 11:24:20, time: 1.236, data_time: 0.015, memory: 5723, decode.loss_seg: 1.0605, decode.acc_seg: 53.6884, loss: 1.0605
2021-08-14 22:26:32,523 - mmseg - INFO - Saving checkpoint at 64000 iterations
2021-08-14 22:26:32,987 - mmseg - INFO - Exp name: fcn_litehr30-with-head_512x512_160k_ade20k.py
2021-08-14 22:26:32,990 - mmseg - INFO - Iter [64000/160000]	lr: 6.351e-03, eta: 1 day, 11:23:09, time: 1.269, data_time: 0.016, memory: 5723, decode.loss_seg: 1.0398, decode.acc_seg: 52.5229, loss: 1.0398
