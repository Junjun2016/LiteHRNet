2021-08-14 02:13:59,750 - mmseg - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.7.6 (default, Jan  8 2020, 19:59:22) [GCC 7.3.0]
CUDA available: True
GPU 0,1,2,3,4,5,6,7: TITAN Xp
CUDA_HOME: /mnt/lustre/share/polaris/dep/cuda-9.0-cudnn7.6.5
NVCC: Cuda compilation tools, release 9.0, V9.0.176
GCC: gcc (GCC) 5.4.0
PyTorch: 1.5.0
PyTorch compiling details: PyTorch built with:
  - GCC 5.4
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.1 Product Build 20200208 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v0.21.1 (Git Hash 912ce228837d1ce28e1a61806118835de03f5751)
  - OpenMP 201307 (a.k.a. OpenMP 4.0)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 9.0
  - NVCC architecture flags: -gencode;arch=compute_52,code=sm_52;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_70,code=compute_70
  - CuDNN 7.6.5
  - Magma 2.5.0
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_INTERNAL_THREADPOOL_IMPL -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=ON, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

TorchVision: 0.6.0
OpenCV: 4.2.0
MMCV: 1.3.11
MMCV Compiler: n/a
MMCV CUDA Compiler: n/a
MMSegmentation: 0.16.0+2bb6f37
------------------------------------------------------------

2021-08-14 02:13:59,751 - mmseg - INFO - Distributed training: True
2021-08-14 02:14:00,138 - mmseg - INFO - Config:
norm_cfg = dict(type='SyncBN', requires_grad=True)
model = dict(
    type='EncoderDecoder',
    backbone=dict(
        type='LiteHRNet',
        norm_cfg=dict(type='SyncBN', requires_grad=True),
        norm_eval=False,
        extra=dict(
            stem=dict(stem_channels=32, out_channels=32, expand_ratio=1),
            num_stages=3,
            stages_spec=dict(
                num_modules=(3, 8, 3),
                num_branches=(2, 3, 4),
                num_blocks=(2, 2, 2),
                module_type=('LITE', 'LITE', 'LITE'),
                with_fuse=(True, True, True),
                reduce_ratios=(8, 8, 8),
                num_channels=((40, 80), (40, 80, 160), (40, 80, 160, 320))),
            with_head=False)),
    decode_head=dict(
        type='FCNHead',
        in_channels=40,
        in_index=0,
        channels=40,
        input_transform=None,
        kernel_size=3,
        num_convs=2,
        concat_input=True,
        dropout_ratio=0.1,
        num_classes=150,
        norm_cfg=dict(type='SyncBN', requires_grad=True),
        align_corners=False,
        loss_decode=dict(
            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0)),
    train_cfg=dict(),
    test_cfg=dict(mode='whole'))
dataset_type = 'ADE20KDataset'
data_root = 'data/ade/ADEChallengeData2016'
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
crop_size = (512, 512)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations', reduce_zero_label=True),
    dict(type='Resize', img_scale=(2048, 512), ratio_range=(0.5, 2.0)),
    dict(type='RandomCrop', crop_size=(512, 512), cat_max_ratio=0.75),
    dict(type='RandomFlip', prob=0.5),
    dict(type='PhotoMetricDistortion'),
    dict(
        type='Normalize',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='Pad', size=(512, 512), pad_val=0, seg_pad_val=255),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_semantic_seg'])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(2048, 512),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
data = dict(
    samples_per_gpu=4,
    workers_per_gpu=4,
    train=dict(
        type='ADE20KDataset',
        data_root='data/ade/ADEChallengeData2016',
        img_dir='images/training',
        ann_dir='annotations/training',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations', reduce_zero_label=True),
            dict(type='Resize', img_scale=(2048, 512), ratio_range=(0.5, 2.0)),
            dict(type='RandomCrop', crop_size=(512, 512), cat_max_ratio=0.75),
            dict(type='RandomFlip', prob=0.5),
            dict(type='PhotoMetricDistortion'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='Pad', size=(512, 512), pad_val=0, seg_pad_val=255),
            dict(type='DefaultFormatBundle'),
            dict(type='Collect', keys=['img', 'gt_semantic_seg'])
        ]),
    val=dict(
        type='ADE20KDataset',
        data_root='data/ade/ADEChallengeData2016',
        img_dir='images/validation',
        ann_dir='annotations/validation',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(2048, 512),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]),
    test=dict(
        type='ADE20KDataset',
        data_root='data/ade/ADEChallengeData2016',
        img_dir='images/validation',
        ann_dir='annotations/validation',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(2048, 512),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]))
log_config = dict(
    interval=50, hooks=[dict(type='TextLoggerHook', by_epoch=False)])
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]
cudnn_benchmark = True
optimizer = dict(type='SGD', lr=0.01, momentum=0.9, weight_decay=0.0005)
optimizer_config = dict()
lr_config = dict(policy='poly', power=0.9, min_lr=0.0001, by_epoch=False)
runner = dict(type='IterBasedRunner', max_iters=160000)
checkpoint_config = dict(by_epoch=False, interval=16000)
evaluation = dict(interval=16000, metric='mIoU')
find_unused_parameters = True
work_dir = './work_dirs/fcn_litehr30-without-head_512x512_160k_ade20k'
gpu_ids = range(0, 1)

2021-08-14 02:14:00,139 - mmseg - INFO - Set random seed to 0, deterministic: False
2021-08-14 02:14:00,665 - mmseg - INFO - initialize LiteHRNet with init_cfg [{'type': 'Normal', 'std': 0.001, 'layer': 'Conv2d'}, {'type': 'Constant', 'val': 1, 'layer': ['_BatchNorm', 'GroupNorm']}]
2021-08-14 02:14:01,158 - mmseg - INFO - initialize FCNHead with init_cfg {'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
Name of parameter - Initialization information

backbone.stem.conv1.conv.weight - torch.Size([32, 3, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.stem.conv1.bn.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stem.conv1.bn.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stem.branch1.0.conv.weight - torch.Size([16, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stem.branch1.0.bn.weight - torch.Size([16]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stem.branch1.0.bn.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stem.branch1.1.conv.weight - torch.Size([16, 16, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stem.branch1.1.bn.weight - torch.Size([16]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stem.branch1.1.bn.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stem.expand_conv.conv.weight - torch.Size([32, 16, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.stem.expand_conv.bn.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stem.expand_conv.bn.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stem.depthwise_conv.conv.weight - torch.Size([32, 1, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.stem.depthwise_conv.bn.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stem.depthwise_conv.bn.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stem.linear_conv.conv.weight - torch.Size([16, 32, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.stem.linear_conv.bn.weight - torch.Size([16]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stem.linear_conv.bn.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.transition0.0.0.weight - torch.Size([32, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.transition0.0.1.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.transition0.0.1.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.transition0.0.2.weight - torch.Size([40, 32, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.transition0.0.3.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.transition0.0.3.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.transition0.1.0.0.weight - torch.Size([32, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.transition0.1.0.1.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.transition0.1.0.1.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.transition0.1.0.2.weight - torch.Size([80, 32, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.transition0.1.0.3.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.transition0.1.0.3.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.0.cross_resolution_weighting.conv1.conv.weight - torch.Size([7, 60, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.layers.0.cross_resolution_weighting.conv1.bn.weight - torch.Size([7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.0.cross_resolution_weighting.conv1.bn.bias - torch.Size([7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.0.cross_resolution_weighting.conv2.conv.weight - torch.Size([60, 7, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.layers.0.cross_resolution_weighting.conv2.bn.weight - torch.Size([60]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.0.cross_resolution_weighting.conv2.bn.bias - torch.Size([60]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.0.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.layers.0.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.0.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.0.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.layers.0.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.0.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.0.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.layers.0.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.0.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.layers.0.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.0.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.layers.0.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.0.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.layers.0.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.1.cross_resolution_weighting.conv1.conv.weight - torch.Size([7, 60, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.layers.1.cross_resolution_weighting.conv1.bn.weight - torch.Size([7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.1.cross_resolution_weighting.conv1.bn.bias - torch.Size([7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.1.cross_resolution_weighting.conv2.conv.weight - torch.Size([60, 7, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.layers.1.cross_resolution_weighting.conv2.bn.weight - torch.Size([60]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.1.cross_resolution_weighting.conv2.bn.bias - torch.Size([60]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.1.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.layers.1.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.1.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.1.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.layers.1.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.1.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.1.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.layers.1.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.1.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.layers.1.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.1.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.layers.1.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.layers.1.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.layers.1.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.fuse_layers.0.1.0.weight - torch.Size([40, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.fuse_layers.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.fuse_layers.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.fuse_layers.1.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.fuse_layers.1.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.fuse_layers.1.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.fuse_layers.1.0.0.2.weight - torch.Size([80, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.0.fuse_layers.1.0.0.3.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.0.fuse_layers.1.0.0.3.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.0.cross_resolution_weighting.conv1.conv.weight - torch.Size([7, 60, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.layers.0.cross_resolution_weighting.conv1.bn.weight - torch.Size([7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.0.cross_resolution_weighting.conv1.bn.bias - torch.Size([7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.0.cross_resolution_weighting.conv2.conv.weight - torch.Size([60, 7, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.layers.0.cross_resolution_weighting.conv2.bn.weight - torch.Size([60]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.0.cross_resolution_weighting.conv2.bn.bias - torch.Size([60]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.0.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.layers.0.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.0.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.0.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.layers.0.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.0.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.0.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.layers.0.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.0.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.layers.0.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.0.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.layers.0.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.0.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.layers.0.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.1.cross_resolution_weighting.conv1.conv.weight - torch.Size([7, 60, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.layers.1.cross_resolution_weighting.conv1.bn.weight - torch.Size([7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.1.cross_resolution_weighting.conv1.bn.bias - torch.Size([7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.1.cross_resolution_weighting.conv2.conv.weight - torch.Size([60, 7, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.layers.1.cross_resolution_weighting.conv2.bn.weight - torch.Size([60]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.1.cross_resolution_weighting.conv2.bn.bias - torch.Size([60]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.1.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.layers.1.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.1.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.1.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.layers.1.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.1.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.1.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.layers.1.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.1.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.layers.1.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.1.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.layers.1.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.layers.1.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.layers.1.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.fuse_layers.0.1.0.weight - torch.Size([40, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.fuse_layers.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.fuse_layers.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.fuse_layers.1.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.fuse_layers.1.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.fuse_layers.1.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.fuse_layers.1.0.0.2.weight - torch.Size([80, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.1.fuse_layers.1.0.0.3.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.1.fuse_layers.1.0.0.3.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.0.cross_resolution_weighting.conv1.conv.weight - torch.Size([7, 60, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.2.layers.0.cross_resolution_weighting.conv1.bn.weight - torch.Size([7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.0.cross_resolution_weighting.conv1.bn.bias - torch.Size([7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.0.cross_resolution_weighting.conv2.conv.weight - torch.Size([60, 7, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.2.layers.0.cross_resolution_weighting.conv2.bn.weight - torch.Size([60]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.0.cross_resolution_weighting.conv2.bn.bias - torch.Size([60]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.0.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.2.layers.0.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.0.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.0.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.2.layers.0.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.0.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.0.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.2.layers.0.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.0.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.2.layers.0.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.0.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.2.layers.0.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.0.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.2.layers.0.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.1.cross_resolution_weighting.conv1.conv.weight - torch.Size([7, 60, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.2.layers.1.cross_resolution_weighting.conv1.bn.weight - torch.Size([7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.1.cross_resolution_weighting.conv1.bn.bias - torch.Size([7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.1.cross_resolution_weighting.conv2.conv.weight - torch.Size([60, 7, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.2.layers.1.cross_resolution_weighting.conv2.bn.weight - torch.Size([60]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.1.cross_resolution_weighting.conv2.bn.bias - torch.Size([60]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.1.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.2.layers.1.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.1.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.1.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.2.layers.1.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.1.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.1.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.2.layers.1.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.1.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.2.layers.1.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.1.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.2.layers.1.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.layers.1.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.2.layers.1.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.fuse_layers.0.1.0.weight - torch.Size([40, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.2.fuse_layers.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.fuse_layers.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.fuse_layers.1.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.2.fuse_layers.1.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.fuse_layers.1.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.fuse_layers.1.0.0.2.weight - torch.Size([80, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage0.2.fuse_layers.1.0.0.3.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage0.2.fuse_layers.1.0.0.3.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.transition1.2.0.0.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.transition1.2.0.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.transition1.2.0.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.transition1.2.0.2.weight - torch.Size([160, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.transition1.2.0.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.transition1.2.0.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.0.cross_resolution_weighting.conv1.conv.weight - torch.Size([17, 140, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.0.cross_resolution_weighting.conv1.bn.weight - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.0.cross_resolution_weighting.conv1.bn.bias - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.0.cross_resolution_weighting.conv2.conv.weight - torch.Size([140, 17, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.0.cross_resolution_weighting.conv2.bn.weight - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.0.cross_resolution_weighting.conv2.bn.bias - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.0.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.0.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.0.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.0.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.0.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.0.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.0.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.0.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.0.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.0.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.0.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.0.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.0.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.0.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.0.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.0.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.0.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.0.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.0.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.0.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.0.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.1.cross_resolution_weighting.conv1.conv.weight - torch.Size([17, 140, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.1.cross_resolution_weighting.conv1.bn.weight - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.1.cross_resolution_weighting.conv1.bn.bias - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.1.cross_resolution_weighting.conv2.conv.weight - torch.Size([140, 17, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.1.cross_resolution_weighting.conv2.bn.weight - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.1.cross_resolution_weighting.conv2.bn.bias - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.1.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.1.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.1.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.1.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.1.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.1.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.1.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.1.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.1.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.1.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.1.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.1.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.1.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.1.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.1.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.1.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.1.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.1.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.1.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.layers.1.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.layers.1.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.0.1.0.weight - torch.Size([40, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.fuse_layers.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.0.2.0.weight - torch.Size([40, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.fuse_layers.0.2.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.0.2.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.1.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.fuse_layers.1.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.1.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.1.0.0.2.weight - torch.Size([80, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.fuse_layers.1.0.0.3.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.1.0.0.3.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.1.2.0.weight - torch.Size([80, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.fuse_layers.1.2.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.1.2.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.2.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.fuse_layers.2.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.2.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.2.0.0.2.weight - torch.Size([40, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.fuse_layers.2.0.0.3.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.2.0.0.3.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.2.0.1.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.fuse_layers.2.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.2.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.2.0.1.2.weight - torch.Size([160, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.fuse_layers.2.0.1.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.2.0.1.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.2.1.0.0.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.fuse_layers.2.1.0.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.2.1.0.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.2.1.0.2.weight - torch.Size([160, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.0.fuse_layers.2.1.0.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.0.fuse_layers.2.1.0.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.0.cross_resolution_weighting.conv1.conv.weight - torch.Size([17, 140, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.0.cross_resolution_weighting.conv1.bn.weight - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.0.cross_resolution_weighting.conv1.bn.bias - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.0.cross_resolution_weighting.conv2.conv.weight - torch.Size([140, 17, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.0.cross_resolution_weighting.conv2.bn.weight - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.0.cross_resolution_weighting.conv2.bn.bias - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.0.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.0.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.0.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.0.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.0.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.0.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.0.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.0.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.0.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.0.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.0.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.0.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.0.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.0.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.0.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.0.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.0.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.0.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.0.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.0.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.0.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.1.cross_resolution_weighting.conv1.conv.weight - torch.Size([17, 140, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.1.cross_resolution_weighting.conv1.bn.weight - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.1.cross_resolution_weighting.conv1.bn.bias - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.1.cross_resolution_weighting.conv2.conv.weight - torch.Size([140, 17, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.1.cross_resolution_weighting.conv2.bn.weight - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.1.cross_resolution_weighting.conv2.bn.bias - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.1.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.1.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.1.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.1.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.1.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.1.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.1.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.1.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.1.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.1.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.1.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.1.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.1.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.1.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.1.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.1.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.1.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.1.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.1.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.layers.1.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.layers.1.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.0.1.0.weight - torch.Size([40, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.fuse_layers.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.0.2.0.weight - torch.Size([40, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.fuse_layers.0.2.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.0.2.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.1.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.fuse_layers.1.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.1.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.1.0.0.2.weight - torch.Size([80, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.fuse_layers.1.0.0.3.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.1.0.0.3.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.1.2.0.weight - torch.Size([80, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.fuse_layers.1.2.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.1.2.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.2.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.fuse_layers.2.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.2.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.2.0.0.2.weight - torch.Size([40, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.fuse_layers.2.0.0.3.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.2.0.0.3.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.2.0.1.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.fuse_layers.2.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.2.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.2.0.1.2.weight - torch.Size([160, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.fuse_layers.2.0.1.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.2.0.1.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.2.1.0.0.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.fuse_layers.2.1.0.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.2.1.0.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.2.1.0.2.weight - torch.Size([160, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.1.fuse_layers.2.1.0.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.1.fuse_layers.2.1.0.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.0.cross_resolution_weighting.conv1.conv.weight - torch.Size([17, 140, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.0.cross_resolution_weighting.conv1.bn.weight - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.0.cross_resolution_weighting.conv1.bn.bias - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.0.cross_resolution_weighting.conv2.conv.weight - torch.Size([140, 17, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.0.cross_resolution_weighting.conv2.bn.weight - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.0.cross_resolution_weighting.conv2.bn.bias - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.0.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.0.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.0.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.0.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.0.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.0.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.0.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.0.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.0.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.0.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.0.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.0.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.0.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.0.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.0.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.0.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.0.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.0.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.0.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.0.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.0.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.1.cross_resolution_weighting.conv1.conv.weight - torch.Size([17, 140, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.1.cross_resolution_weighting.conv1.bn.weight - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.1.cross_resolution_weighting.conv1.bn.bias - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.1.cross_resolution_weighting.conv2.conv.weight - torch.Size([140, 17, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.1.cross_resolution_weighting.conv2.bn.weight - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.1.cross_resolution_weighting.conv2.bn.bias - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.1.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.1.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.1.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.1.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.1.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.1.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.1.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.1.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.1.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.1.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.1.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.1.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.1.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.1.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.1.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.1.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.1.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.1.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.1.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.layers.1.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.layers.1.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.0.1.0.weight - torch.Size([40, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.fuse_layers.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.0.2.0.weight - torch.Size([40, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.fuse_layers.0.2.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.0.2.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.1.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.fuse_layers.1.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.1.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.1.0.0.2.weight - torch.Size([80, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.fuse_layers.1.0.0.3.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.1.0.0.3.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.1.2.0.weight - torch.Size([80, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.fuse_layers.1.2.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.1.2.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.2.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.fuse_layers.2.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.2.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.2.0.0.2.weight - torch.Size([40, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.fuse_layers.2.0.0.3.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.2.0.0.3.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.2.0.1.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.fuse_layers.2.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.2.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.2.0.1.2.weight - torch.Size([160, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.fuse_layers.2.0.1.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.2.0.1.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.2.1.0.0.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.fuse_layers.2.1.0.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.2.1.0.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.2.1.0.2.weight - torch.Size([160, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.2.fuse_layers.2.1.0.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.2.fuse_layers.2.1.0.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.0.cross_resolution_weighting.conv1.conv.weight - torch.Size([17, 140, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.0.cross_resolution_weighting.conv1.bn.weight - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.0.cross_resolution_weighting.conv1.bn.bias - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.0.cross_resolution_weighting.conv2.conv.weight - torch.Size([140, 17, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.0.cross_resolution_weighting.conv2.bn.weight - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.0.cross_resolution_weighting.conv2.bn.bias - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.0.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.0.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.0.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.0.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.0.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.0.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.0.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.0.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.0.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.0.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.0.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.0.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.0.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.0.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.0.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.0.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.0.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.0.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.0.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.0.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.0.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.1.cross_resolution_weighting.conv1.conv.weight - torch.Size([17, 140, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.1.cross_resolution_weighting.conv1.bn.weight - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.1.cross_resolution_weighting.conv1.bn.bias - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.1.cross_resolution_weighting.conv2.conv.weight - torch.Size([140, 17, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.1.cross_resolution_weighting.conv2.bn.weight - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.1.cross_resolution_weighting.conv2.bn.bias - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.1.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.1.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.1.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.1.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.1.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.1.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.1.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.1.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.1.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.1.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.1.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.1.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.1.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.1.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.1.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.1.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.1.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.1.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.1.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.layers.1.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.layers.1.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.0.1.0.weight - torch.Size([40, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.fuse_layers.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.0.2.0.weight - torch.Size([40, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.fuse_layers.0.2.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.0.2.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.1.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.fuse_layers.1.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.1.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.1.0.0.2.weight - torch.Size([80, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.fuse_layers.1.0.0.3.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.1.0.0.3.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.1.2.0.weight - torch.Size([80, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.fuse_layers.1.2.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.1.2.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.2.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.fuse_layers.2.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.2.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.2.0.0.2.weight - torch.Size([40, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.fuse_layers.2.0.0.3.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.2.0.0.3.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.2.0.1.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.fuse_layers.2.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.2.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.2.0.1.2.weight - torch.Size([160, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.fuse_layers.2.0.1.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.2.0.1.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.2.1.0.0.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.fuse_layers.2.1.0.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.2.1.0.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.2.1.0.2.weight - torch.Size([160, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.3.fuse_layers.2.1.0.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.3.fuse_layers.2.1.0.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.0.cross_resolution_weighting.conv1.conv.weight - torch.Size([17, 140, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.layers.0.cross_resolution_weighting.conv1.bn.weight - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.0.cross_resolution_weighting.conv1.bn.bias - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.0.cross_resolution_weighting.conv2.conv.weight - torch.Size([140, 17, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.layers.0.cross_resolution_weighting.conv2.bn.weight - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.0.cross_resolution_weighting.conv2.bn.bias - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.0.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.layers.0.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.0.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.0.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.layers.0.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.0.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.0.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.layers.0.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.0.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.0.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.layers.0.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.0.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.layers.0.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.0.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.layers.0.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.0.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.layers.0.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.0.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.layers.0.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.0.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.layers.0.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.1.cross_resolution_weighting.conv1.conv.weight - torch.Size([17, 140, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.layers.1.cross_resolution_weighting.conv1.bn.weight - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.1.cross_resolution_weighting.conv1.bn.bias - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.1.cross_resolution_weighting.conv2.conv.weight - torch.Size([140, 17, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.layers.1.cross_resolution_weighting.conv2.bn.weight - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.1.cross_resolution_weighting.conv2.bn.bias - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.1.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.layers.1.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.1.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.1.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.layers.1.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.1.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.1.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.layers.1.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.1.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.1.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.layers.1.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.1.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.layers.1.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.1.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.layers.1.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.1.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.layers.1.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.1.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.layers.1.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.layers.1.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.layers.1.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.fuse_layers.0.1.0.weight - torch.Size([40, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.fuse_layers.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.fuse_layers.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.fuse_layers.0.2.0.weight - torch.Size([40, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.fuse_layers.0.2.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.fuse_layers.0.2.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.fuse_layers.1.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.fuse_layers.1.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.fuse_layers.1.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.fuse_layers.1.0.0.2.weight - torch.Size([80, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.fuse_layers.1.0.0.3.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.fuse_layers.1.0.0.3.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.fuse_layers.1.2.0.weight - torch.Size([80, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.fuse_layers.1.2.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.fuse_layers.1.2.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.fuse_layers.2.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.fuse_layers.2.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.fuse_layers.2.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.fuse_layers.2.0.0.2.weight - torch.Size([40, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.fuse_layers.2.0.0.3.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.fuse_layers.2.0.0.3.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.fuse_layers.2.0.1.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.fuse_layers.2.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.fuse_layers.2.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.fuse_layers.2.0.1.2.weight - torch.Size([160, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.fuse_layers.2.0.1.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.fuse_layers.2.0.1.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.fuse_layers.2.1.0.0.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.fuse_layers.2.1.0.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.fuse_layers.2.1.0.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.fuse_layers.2.1.0.2.weight - torch.Size([160, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.4.fuse_layers.2.1.0.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.4.fuse_layers.2.1.0.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.0.cross_resolution_weighting.conv1.conv.weight - torch.Size([17, 140, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.layers.0.cross_resolution_weighting.conv1.bn.weight - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.0.cross_resolution_weighting.conv1.bn.bias - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.0.cross_resolution_weighting.conv2.conv.weight - torch.Size([140, 17, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.layers.0.cross_resolution_weighting.conv2.bn.weight - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.0.cross_resolution_weighting.conv2.bn.bias - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.0.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.layers.0.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.0.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.0.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.layers.0.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.0.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.0.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.layers.0.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.0.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.0.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.layers.0.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.0.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.layers.0.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.0.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.layers.0.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.0.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.layers.0.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.0.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.layers.0.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.0.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.layers.0.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.1.cross_resolution_weighting.conv1.conv.weight - torch.Size([17, 140, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.layers.1.cross_resolution_weighting.conv1.bn.weight - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.1.cross_resolution_weighting.conv1.bn.bias - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.1.cross_resolution_weighting.conv2.conv.weight - torch.Size([140, 17, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.layers.1.cross_resolution_weighting.conv2.bn.weight - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.1.cross_resolution_weighting.conv2.bn.bias - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.1.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.layers.1.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.1.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.1.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.layers.1.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.1.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.1.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.layers.1.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.1.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.1.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.layers.1.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.1.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.layers.1.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.1.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.layers.1.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.1.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.layers.1.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.1.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.layers.1.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.layers.1.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.layers.1.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.fuse_layers.0.1.0.weight - torch.Size([40, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.fuse_layers.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.fuse_layers.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.fuse_layers.0.2.0.weight - torch.Size([40, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.fuse_layers.0.2.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.fuse_layers.0.2.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.fuse_layers.1.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.fuse_layers.1.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.fuse_layers.1.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.fuse_layers.1.0.0.2.weight - torch.Size([80, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.fuse_layers.1.0.0.3.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.fuse_layers.1.0.0.3.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.fuse_layers.1.2.0.weight - torch.Size([80, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.fuse_layers.1.2.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.fuse_layers.1.2.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.fuse_layers.2.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.fuse_layers.2.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.fuse_layers.2.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.fuse_layers.2.0.0.2.weight - torch.Size([40, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.fuse_layers.2.0.0.3.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.fuse_layers.2.0.0.3.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.fuse_layers.2.0.1.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.fuse_layers.2.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.fuse_layers.2.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.fuse_layers.2.0.1.2.weight - torch.Size([160, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.fuse_layers.2.0.1.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.fuse_layers.2.0.1.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.fuse_layers.2.1.0.0.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.fuse_layers.2.1.0.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.fuse_layers.2.1.0.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.fuse_layers.2.1.0.2.weight - torch.Size([160, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.5.fuse_layers.2.1.0.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.5.fuse_layers.2.1.0.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.0.cross_resolution_weighting.conv1.conv.weight - torch.Size([17, 140, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.layers.0.cross_resolution_weighting.conv1.bn.weight - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.0.cross_resolution_weighting.conv1.bn.bias - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.0.cross_resolution_weighting.conv2.conv.weight - torch.Size([140, 17, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.layers.0.cross_resolution_weighting.conv2.bn.weight - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.0.cross_resolution_weighting.conv2.bn.bias - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.0.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.layers.0.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.0.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.0.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.layers.0.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.0.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.0.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.layers.0.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.0.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.0.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.layers.0.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.0.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.layers.0.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.0.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.layers.0.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.0.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.layers.0.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.0.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.layers.0.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.0.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.layers.0.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.1.cross_resolution_weighting.conv1.conv.weight - torch.Size([17, 140, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.layers.1.cross_resolution_weighting.conv1.bn.weight - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.1.cross_resolution_weighting.conv1.bn.bias - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.1.cross_resolution_weighting.conv2.conv.weight - torch.Size([140, 17, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.layers.1.cross_resolution_weighting.conv2.bn.weight - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.1.cross_resolution_weighting.conv2.bn.bias - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.1.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.layers.1.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.1.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.1.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.layers.1.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.1.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.1.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.layers.1.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.1.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.1.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.layers.1.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.1.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.layers.1.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.1.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.layers.1.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.1.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.layers.1.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.1.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.layers.1.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.layers.1.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.layers.1.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.fuse_layers.0.1.0.weight - torch.Size([40, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.fuse_layers.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.fuse_layers.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.fuse_layers.0.2.0.weight - torch.Size([40, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.fuse_layers.0.2.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.fuse_layers.0.2.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.fuse_layers.1.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.fuse_layers.1.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.fuse_layers.1.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.fuse_layers.1.0.0.2.weight - torch.Size([80, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.fuse_layers.1.0.0.3.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.fuse_layers.1.0.0.3.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.fuse_layers.1.2.0.weight - torch.Size([80, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.fuse_layers.1.2.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.fuse_layers.1.2.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.fuse_layers.2.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.fuse_layers.2.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.fuse_layers.2.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.fuse_layers.2.0.0.2.weight - torch.Size([40, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.fuse_layers.2.0.0.3.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.fuse_layers.2.0.0.3.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.fuse_layers.2.0.1.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.fuse_layers.2.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.fuse_layers.2.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.fuse_layers.2.0.1.2.weight - torch.Size([160, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.fuse_layers.2.0.1.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.fuse_layers.2.0.1.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.fuse_layers.2.1.0.0.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.fuse_layers.2.1.0.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.fuse_layers.2.1.0.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.fuse_layers.2.1.0.2.weight - torch.Size([160, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.6.fuse_layers.2.1.0.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.6.fuse_layers.2.1.0.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.0.cross_resolution_weighting.conv1.conv.weight - torch.Size([17, 140, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.layers.0.cross_resolution_weighting.conv1.bn.weight - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.0.cross_resolution_weighting.conv1.bn.bias - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.0.cross_resolution_weighting.conv2.conv.weight - torch.Size([140, 17, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.layers.0.cross_resolution_weighting.conv2.bn.weight - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.0.cross_resolution_weighting.conv2.bn.bias - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.0.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.layers.0.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.0.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.0.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.layers.0.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.0.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.0.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.layers.0.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.0.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.0.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.layers.0.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.0.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.layers.0.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.0.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.layers.0.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.0.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.layers.0.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.0.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.layers.0.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.0.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.layers.0.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.1.cross_resolution_weighting.conv1.conv.weight - torch.Size([17, 140, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.layers.1.cross_resolution_weighting.conv1.bn.weight - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.1.cross_resolution_weighting.conv1.bn.bias - torch.Size([17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.1.cross_resolution_weighting.conv2.conv.weight - torch.Size([140, 17, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.layers.1.cross_resolution_weighting.conv2.bn.weight - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.1.cross_resolution_weighting.conv2.bn.bias - torch.Size([140]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.1.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.layers.1.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.1.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.1.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.layers.1.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.1.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.1.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.layers.1.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.1.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.1.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.layers.1.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.1.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.layers.1.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.1.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.layers.1.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.1.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.layers.1.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.1.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.layers.1.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.layers.1.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.layers.1.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.fuse_layers.0.1.0.weight - torch.Size([40, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.fuse_layers.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.fuse_layers.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.fuse_layers.0.2.0.weight - torch.Size([40, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.fuse_layers.0.2.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.fuse_layers.0.2.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.fuse_layers.1.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.fuse_layers.1.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.fuse_layers.1.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.fuse_layers.1.0.0.2.weight - torch.Size([80, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.fuse_layers.1.0.0.3.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.fuse_layers.1.0.0.3.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.fuse_layers.1.2.0.weight - torch.Size([80, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.fuse_layers.1.2.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.fuse_layers.1.2.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.fuse_layers.2.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.fuse_layers.2.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.fuse_layers.2.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.fuse_layers.2.0.0.2.weight - torch.Size([40, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.fuse_layers.2.0.0.3.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.fuse_layers.2.0.0.3.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.fuse_layers.2.0.1.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.fuse_layers.2.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.fuse_layers.2.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.fuse_layers.2.0.1.2.weight - torch.Size([160, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.fuse_layers.2.0.1.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.fuse_layers.2.0.1.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.fuse_layers.2.1.0.0.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.fuse_layers.2.1.0.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.fuse_layers.2.1.0.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.fuse_layers.2.1.0.2.weight - torch.Size([160, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage1.7.fuse_layers.2.1.0.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage1.7.fuse_layers.2.1.0.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.transition2.3.0.0.weight - torch.Size([160, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.transition2.3.0.1.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.transition2.3.0.1.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.transition2.3.0.2.weight - torch.Size([320, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.transition2.3.0.3.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.transition2.3.0.3.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.cross_resolution_weighting.conv1.conv.weight - torch.Size([37, 300, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.0.cross_resolution_weighting.conv1.bn.weight - torch.Size([37]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.cross_resolution_weighting.conv1.bn.bias - torch.Size([37]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.cross_resolution_weighting.conv2.conv.weight - torch.Size([300, 37, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.0.cross_resolution_weighting.conv2.bn.weight - torch.Size([300]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.cross_resolution_weighting.conv2.bn.bias - torch.Size([300]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.0.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.0.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.0.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.depthwise_convs.3.conv.weight - torch.Size([160, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.0.depthwise_convs.3.bn.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.depthwise_convs.3.bn.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.0.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.0.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.0.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.0.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.0.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.0.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.spatial_weighting.3.conv1.conv.weight - torch.Size([40, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.0.spatial_weighting.3.conv1.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.0.spatial_weighting.3.conv2.conv.weight - torch.Size([160, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.0.spatial_weighting.3.conv2.conv.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.cross_resolution_weighting.conv1.conv.weight - torch.Size([37, 300, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.1.cross_resolution_weighting.conv1.bn.weight - torch.Size([37]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.cross_resolution_weighting.conv1.bn.bias - torch.Size([37]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.cross_resolution_weighting.conv2.conv.weight - torch.Size([300, 37, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.1.cross_resolution_weighting.conv2.bn.weight - torch.Size([300]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.cross_resolution_weighting.conv2.bn.bias - torch.Size([300]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.1.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.1.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.1.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.depthwise_convs.3.conv.weight - torch.Size([160, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.1.depthwise_convs.3.bn.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.depthwise_convs.3.bn.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.1.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.1.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.1.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.1.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.1.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.1.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.spatial_weighting.3.conv1.conv.weight - torch.Size([40, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.1.spatial_weighting.3.conv1.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.layers.1.spatial_weighting.3.conv2.conv.weight - torch.Size([160, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.layers.1.spatial_weighting.3.conv2.conv.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.0.1.0.weight - torch.Size([40, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.0.2.0.weight - torch.Size([40, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.0.2.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.0.2.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.0.3.0.weight - torch.Size([40, 320, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.0.3.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.0.3.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.1.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.1.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.1.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.1.0.0.2.weight - torch.Size([80, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.1.0.0.3.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.1.0.0.3.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.1.2.0.weight - torch.Size([80, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.1.2.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.1.2.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.1.3.0.weight - torch.Size([80, 320, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.1.3.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.1.3.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.2.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.2.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.2.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.2.0.0.2.weight - torch.Size([40, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.2.0.0.3.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.2.0.0.3.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.2.0.1.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.2.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.2.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.2.0.1.2.weight - torch.Size([160, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.2.0.1.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.2.0.1.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.2.1.0.0.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.2.1.0.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.2.1.0.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.2.1.0.2.weight - torch.Size([160, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.2.1.0.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.2.1.0.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.2.3.0.weight - torch.Size([160, 320, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.2.3.1.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.2.3.1.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.3.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.0.0.2.weight - torch.Size([40, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.3.0.0.3.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.0.0.3.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.0.1.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.3.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.0.1.2.weight - torch.Size([40, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.3.0.1.3.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.0.1.3.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.0.2.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.3.0.2.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.0.2.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.0.2.2.weight - torch.Size([320, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.3.0.2.3.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.0.2.3.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.1.0.0.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.3.1.0.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.1.0.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.1.0.2.weight - torch.Size([80, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.3.1.0.3.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.1.0.3.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.1.1.0.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.3.1.1.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.1.1.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.1.1.2.weight - torch.Size([320, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.3.1.1.3.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.1.1.3.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.2.0.0.weight - torch.Size([160, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.3.2.0.1.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.2.0.1.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.2.0.2.weight - torch.Size([320, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.0.fuse_layers.3.2.0.3.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.0.fuse_layers.3.2.0.3.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.cross_resolution_weighting.conv1.conv.weight - torch.Size([37, 300, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.0.cross_resolution_weighting.conv1.bn.weight - torch.Size([37]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.cross_resolution_weighting.conv1.bn.bias - torch.Size([37]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.cross_resolution_weighting.conv2.conv.weight - torch.Size([300, 37, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.0.cross_resolution_weighting.conv2.bn.weight - torch.Size([300]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.cross_resolution_weighting.conv2.bn.bias - torch.Size([300]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.0.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.0.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.0.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.depthwise_convs.3.conv.weight - torch.Size([160, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.0.depthwise_convs.3.bn.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.depthwise_convs.3.bn.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.0.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.0.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.0.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.0.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.0.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.0.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.spatial_weighting.3.conv1.conv.weight - torch.Size([40, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.0.spatial_weighting.3.conv1.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.0.spatial_weighting.3.conv2.conv.weight - torch.Size([160, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.0.spatial_weighting.3.conv2.conv.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.cross_resolution_weighting.conv1.conv.weight - torch.Size([37, 300, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.1.cross_resolution_weighting.conv1.bn.weight - torch.Size([37]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.cross_resolution_weighting.conv1.bn.bias - torch.Size([37]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.cross_resolution_weighting.conv2.conv.weight - torch.Size([300, 37, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.1.cross_resolution_weighting.conv2.bn.weight - torch.Size([300]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.cross_resolution_weighting.conv2.bn.bias - torch.Size([300]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.1.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.1.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.1.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.depthwise_convs.3.conv.weight - torch.Size([160, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.1.depthwise_convs.3.bn.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.depthwise_convs.3.bn.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.1.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.1.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.1.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.1.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.1.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.1.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.spatial_weighting.3.conv1.conv.weight - torch.Size([40, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.1.spatial_weighting.3.conv1.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.layers.1.spatial_weighting.3.conv2.conv.weight - torch.Size([160, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.layers.1.spatial_weighting.3.conv2.conv.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.0.1.0.weight - torch.Size([40, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.0.2.0.weight - torch.Size([40, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.0.2.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.0.2.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.0.3.0.weight - torch.Size([40, 320, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.0.3.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.0.3.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.1.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.1.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.1.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.1.0.0.2.weight - torch.Size([80, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.1.0.0.3.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.1.0.0.3.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.1.2.0.weight - torch.Size([80, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.1.2.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.1.2.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.1.3.0.weight - torch.Size([80, 320, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.1.3.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.1.3.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.2.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.2.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.2.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.2.0.0.2.weight - torch.Size([40, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.2.0.0.3.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.2.0.0.3.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.2.0.1.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.2.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.2.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.2.0.1.2.weight - torch.Size([160, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.2.0.1.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.2.0.1.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.2.1.0.0.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.2.1.0.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.2.1.0.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.2.1.0.2.weight - torch.Size([160, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.2.1.0.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.2.1.0.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.2.3.0.weight - torch.Size([160, 320, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.2.3.1.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.2.3.1.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.3.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.0.0.2.weight - torch.Size([40, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.3.0.0.3.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.0.0.3.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.0.1.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.3.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.0.1.2.weight - torch.Size([40, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.3.0.1.3.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.0.1.3.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.0.2.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.3.0.2.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.0.2.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.0.2.2.weight - torch.Size([320, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.3.0.2.3.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.0.2.3.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.1.0.0.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.3.1.0.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.1.0.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.1.0.2.weight - torch.Size([80, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.3.1.0.3.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.1.0.3.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.1.1.0.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.3.1.1.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.1.1.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.1.1.2.weight - torch.Size([320, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.3.1.1.3.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.1.1.3.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.2.0.0.weight - torch.Size([160, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.3.2.0.1.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.2.0.1.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.2.0.2.weight - torch.Size([320, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.1.fuse_layers.3.2.0.3.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.1.fuse_layers.3.2.0.3.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.0.cross_resolution_weighting.conv1.conv.weight - torch.Size([37, 300, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.0.cross_resolution_weighting.conv1.bn.weight - torch.Size([37]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.0.cross_resolution_weighting.conv1.bn.bias - torch.Size([37]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.0.cross_resolution_weighting.conv2.conv.weight - torch.Size([300, 37, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.0.cross_resolution_weighting.conv2.bn.weight - torch.Size([300]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.0.cross_resolution_weighting.conv2.bn.bias - torch.Size([300]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.0.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.0.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.0.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.0.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.0.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.0.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.0.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.0.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.0.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.0.depthwise_convs.3.conv.weight - torch.Size([160, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.0.depthwise_convs.3.bn.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.0.depthwise_convs.3.bn.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.0.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.0.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.0.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.0.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.0.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.0.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.0.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.0.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.0.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.0.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.0.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.0.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.0.spatial_weighting.3.conv1.conv.weight - torch.Size([40, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.0.spatial_weighting.3.conv1.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.0.spatial_weighting.3.conv2.conv.weight - torch.Size([160, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.0.spatial_weighting.3.conv2.conv.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.1.cross_resolution_weighting.conv1.conv.weight - torch.Size([37, 300, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.1.cross_resolution_weighting.conv1.bn.weight - torch.Size([37]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.1.cross_resolution_weighting.conv1.bn.bias - torch.Size([37]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.1.cross_resolution_weighting.conv2.conv.weight - torch.Size([300, 37, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.1.cross_resolution_weighting.conv2.bn.weight - torch.Size([300]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.1.cross_resolution_weighting.conv2.bn.bias - torch.Size([300]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.1.depthwise_convs.0.conv.weight - torch.Size([20, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.1.depthwise_convs.0.bn.weight - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.1.depthwise_convs.0.bn.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.1.depthwise_convs.1.conv.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.1.depthwise_convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.1.depthwise_convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.1.depthwise_convs.2.conv.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.1.depthwise_convs.2.bn.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.1.depthwise_convs.2.bn.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.1.depthwise_convs.3.conv.weight - torch.Size([160, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.1.depthwise_convs.3.bn.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.1.depthwise_convs.3.bn.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.1.spatial_weighting.0.conv1.conv.weight - torch.Size([5, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.1.spatial_weighting.0.conv1.conv.bias - torch.Size([5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.1.spatial_weighting.0.conv2.conv.weight - torch.Size([20, 5, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.1.spatial_weighting.0.conv2.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.1.spatial_weighting.1.conv1.conv.weight - torch.Size([10, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.1.spatial_weighting.1.conv1.conv.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.1.spatial_weighting.1.conv2.conv.weight - torch.Size([40, 10, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.1.spatial_weighting.1.conv2.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.1.spatial_weighting.2.conv1.conv.weight - torch.Size([20, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.1.spatial_weighting.2.conv1.conv.bias - torch.Size([20]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.1.spatial_weighting.2.conv2.conv.weight - torch.Size([80, 20, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.1.spatial_weighting.2.conv2.conv.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.1.spatial_weighting.3.conv1.conv.weight - torch.Size([40, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.1.spatial_weighting.3.conv1.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.layers.1.spatial_weighting.3.conv2.conv.weight - torch.Size([160, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.layers.1.spatial_weighting.3.conv2.conv.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.0.1.0.weight - torch.Size([40, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.0.2.0.weight - torch.Size([40, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.0.2.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.0.2.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.0.3.0.weight - torch.Size([40, 320, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.0.3.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.0.3.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.1.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.1.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.1.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.1.0.0.2.weight - torch.Size([80, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.1.0.0.3.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.1.0.0.3.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.1.2.0.weight - torch.Size([80, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.1.2.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.1.2.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.1.3.0.weight - torch.Size([80, 320, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.1.3.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.1.3.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.2.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.2.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.2.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.2.0.0.2.weight - torch.Size([40, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.2.0.0.3.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.2.0.0.3.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.2.0.1.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.2.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.2.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.2.0.1.2.weight - torch.Size([160, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.2.0.1.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.2.0.1.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.2.1.0.0.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.2.1.0.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.2.1.0.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.2.1.0.2.weight - torch.Size([160, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.2.1.0.3.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.2.1.0.3.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.2.3.0.weight - torch.Size([160, 320, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.2.3.1.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.2.3.1.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.0.0.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.3.0.0.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.0.0.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.0.0.2.weight - torch.Size([40, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.3.0.0.3.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.0.0.3.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.0.1.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.3.0.1.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.0.1.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.0.1.2.weight - torch.Size([40, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.3.0.1.3.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.0.1.3.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.0.2.0.weight - torch.Size([40, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.3.0.2.1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.0.2.1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.0.2.2.weight - torch.Size([320, 40, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.3.0.2.3.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.0.2.3.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.1.0.0.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.3.1.0.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.1.0.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.1.0.2.weight - torch.Size([80, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.3.1.0.3.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.1.0.3.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.1.1.0.weight - torch.Size([80, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.3.1.1.1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.1.1.1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.1.1.2.weight - torch.Size([320, 80, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.3.1.1.3.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.1.1.3.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.2.0.0.weight - torch.Size([160, 1, 3, 3]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.3.2.0.1.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.2.0.1.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.2.0.2.weight - torch.Size([320, 160, 1, 1]): 
NormalInit: mean=0, std=0.001, bias=0 

backbone.stage2.2.fuse_layers.3.2.0.3.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stage2.2.fuse_layers.3.2.0.3.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.conv_seg.weight - torch.Size([150, 40, 1, 1]): 
NormalInit: mean=0, std=0.01, bias=0 

decode_head.conv_seg.bias - torch.Size([150]): 
NormalInit: mean=0, std=0.01, bias=0 

decode_head.convs.0.conv.weight - torch.Size([40, 40, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.convs.0.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.convs.0.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.convs.1.conv.weight - torch.Size([40, 40, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.convs.1.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.convs.1.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.conv_cat.conv.weight - torch.Size([40, 80, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

decode_head.conv_cat.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.conv_cat.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  
2021-08-14 02:14:01,177 - mmseg - INFO - EncoderDecoder(
  (backbone): LiteHRNet(
    (stem): Stem(
      (conv1): ConvModule(
        (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (branch1): Sequential(
        (0): ConvModule(
          (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)
          (bn): SyncBatchNorm(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): ConvModule(
          (conv): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): SyncBatchNorm(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (expand_conv): ConvModule(
        (conv): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (depthwise_conv): ConvModule(
        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)
        (bn): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (linear_conv): ConvModule(
        (conv): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): SyncBatchNorm(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (transition0): ModuleList(
      (0): Sequential(
        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
        (1): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Conv2d(32, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (3): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (4): ReLU()
      )
      (1): Sequential(
        (0): Sequential(
          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)
          (1): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Conv2d(32, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU()
        )
      )
    )
    (stage0): Sequential(
      (0): LiteHRModule(
        (layers): Sequential(
          (0): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(60, 7, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(7, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
          (1): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(60, 7, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(7, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
        )
        (fuse_layers): ModuleList(
          (0): ModuleList(
            (0): None
            (1): Sequential(
              (0): Conv2d(80, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
          )
          (1): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): None
          )
        )
        (relu): ReLU()
      )
      (1): LiteHRModule(
        (layers): Sequential(
          (0): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(60, 7, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(7, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
          (1): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(60, 7, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(7, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
        )
        (fuse_layers): ModuleList(
          (0): ModuleList(
            (0): None
            (1): Sequential(
              (0): Conv2d(80, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
          )
          (1): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): None
          )
        )
        (relu): ReLU()
      )
      (2): LiteHRModule(
        (layers): Sequential(
          (0): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(60, 7, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(7, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
          (1): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(60, 7, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(7, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
        )
        (fuse_layers): ModuleList(
          (0): ModuleList(
            (0): None
            (1): Sequential(
              (0): Conv2d(80, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
          )
          (1): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): None
          )
        )
        (relu): ReLU()
      )
    )
    (transition1): ModuleList(
      (0): None
      (1): None
      (2): Sequential(
        (0): Sequential(
          (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=80, bias=False)
          (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Conv2d(80, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU()
        )
      )
    )
    (stage1): Sequential(
      (0): LiteHRModule(
        (layers): Sequential(
          (0): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(140, 17, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(17, 140, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
          (1): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(140, 17, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(17, 140, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
        )
        (fuse_layers): ModuleList(
          (0): ModuleList(
            (0): None
            (1): Sequential(
              (0): Conv2d(80, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
            (2): Sequential(
              (0): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=4.0, mode=nearest)
            )
          )
          (1): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): None
            (2): Sequential(
              (0): Conv2d(160, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
          )
          (2): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (1): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=80, bias=False)
                (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(80, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): None
          )
        )
        (relu): ReLU()
      )
      (1): LiteHRModule(
        (layers): Sequential(
          (0): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(140, 17, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(17, 140, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
          (1): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(140, 17, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(17, 140, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
        )
        (fuse_layers): ModuleList(
          (0): ModuleList(
            (0): None
            (1): Sequential(
              (0): Conv2d(80, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
            (2): Sequential(
              (0): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=4.0, mode=nearest)
            )
          )
          (1): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): None
            (2): Sequential(
              (0): Conv2d(160, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
          )
          (2): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (1): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=80, bias=False)
                (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(80, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): None
          )
        )
        (relu): ReLU()
      )
      (2): LiteHRModule(
        (layers): Sequential(
          (0): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(140, 17, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(17, 140, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
          (1): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(140, 17, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(17, 140, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
        )
        (fuse_layers): ModuleList(
          (0): ModuleList(
            (0): None
            (1): Sequential(
              (0): Conv2d(80, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
            (2): Sequential(
              (0): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=4.0, mode=nearest)
            )
          )
          (1): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): None
            (2): Sequential(
              (0): Conv2d(160, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
          )
          (2): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (1): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=80, bias=False)
                (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(80, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): None
          )
        )
        (relu): ReLU()
      )
      (3): LiteHRModule(
        (layers): Sequential(
          (0): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(140, 17, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(17, 140, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
          (1): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(140, 17, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(17, 140, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
        )
        (fuse_layers): ModuleList(
          (0): ModuleList(
            (0): None
            (1): Sequential(
              (0): Conv2d(80, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
            (2): Sequential(
              (0): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=4.0, mode=nearest)
            )
          )
          (1): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): None
            (2): Sequential(
              (0): Conv2d(160, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
          )
          (2): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (1): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=80, bias=False)
                (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(80, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): None
          )
        )
        (relu): ReLU()
      )
      (4): LiteHRModule(
        (layers): Sequential(
          (0): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(140, 17, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(17, 140, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
          (1): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(140, 17, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(17, 140, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
        )
        (fuse_layers): ModuleList(
          (0): ModuleList(
            (0): None
            (1): Sequential(
              (0): Conv2d(80, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
            (2): Sequential(
              (0): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=4.0, mode=nearest)
            )
          )
          (1): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): None
            (2): Sequential(
              (0): Conv2d(160, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
          )
          (2): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (1): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=80, bias=False)
                (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(80, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): None
          )
        )
        (relu): ReLU()
      )
      (5): LiteHRModule(
        (layers): Sequential(
          (0): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(140, 17, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(17, 140, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
          (1): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(140, 17, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(17, 140, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
        )
        (fuse_layers): ModuleList(
          (0): ModuleList(
            (0): None
            (1): Sequential(
              (0): Conv2d(80, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
            (2): Sequential(
              (0): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=4.0, mode=nearest)
            )
          )
          (1): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): None
            (2): Sequential(
              (0): Conv2d(160, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
          )
          (2): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (1): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=80, bias=False)
                (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(80, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): None
          )
        )
        (relu): ReLU()
      )
      (6): LiteHRModule(
        (layers): Sequential(
          (0): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(140, 17, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(17, 140, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
          (1): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(140, 17, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(17, 140, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
        )
        (fuse_layers): ModuleList(
          (0): ModuleList(
            (0): None
            (1): Sequential(
              (0): Conv2d(80, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
            (2): Sequential(
              (0): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=4.0, mode=nearest)
            )
          )
          (1): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): None
            (2): Sequential(
              (0): Conv2d(160, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
          )
          (2): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (1): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=80, bias=False)
                (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(80, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): None
          )
        )
        (relu): ReLU()
      )
      (7): LiteHRModule(
        (layers): Sequential(
          (0): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(140, 17, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(17, 140, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
          (1): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(140, 17, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(17, 140, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
        )
        (fuse_layers): ModuleList(
          (0): ModuleList(
            (0): None
            (1): Sequential(
              (0): Conv2d(80, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
            (2): Sequential(
              (0): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=4.0, mode=nearest)
            )
          )
          (1): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): None
            (2): Sequential(
              (0): Conv2d(160, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
          )
          (2): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (1): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=80, bias=False)
                (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(80, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): None
          )
        )
        (relu): ReLU()
      )
    )
    (transition2): ModuleList(
      (0): None
      (1): None
      (2): None
      (3): Sequential(
        (0): Sequential(
          (0): Conv2d(160, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=160, bias=False)
          (1): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Conv2d(160, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (3): SyncBatchNorm(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (4): ReLU()
        )
      )
    )
    (stage2): Sequential(
      (0): LiteHRModule(
        (layers): Sequential(
          (0): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(300, 37, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(37, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(37, 300, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): ConvModule(
                (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (3): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
          (1): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(300, 37, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(37, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(37, 300, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): ConvModule(
                (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (3): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
        )
        (fuse_layers): ModuleList(
          (0): ModuleList(
            (0): None
            (1): Sequential(
              (0): Conv2d(80, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
            (2): Sequential(
              (0): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=4.0, mode=nearest)
            )
            (3): Sequential(
              (0): Conv2d(320, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=8.0, mode=nearest)
            )
          )
          (1): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): None
            (2): Sequential(
              (0): Conv2d(160, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
            (3): Sequential(
              (0): Conv2d(320, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=4.0, mode=nearest)
            )
          )
          (2): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (1): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=80, bias=False)
                (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(80, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): None
            (3): Sequential(
              (0): Conv2d(320, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
          )
          (3): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (1): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (2): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=80, bias=False)
                (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (1): Sequential(
                (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=80, bias=False)
                (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(80, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): Sequential(
              (0): Sequential(
                (0): Conv2d(160, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=160, bias=False)
                (1): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(160, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): None
          )
        )
        (relu): ReLU()
      )
      (1): LiteHRModule(
        (layers): Sequential(
          (0): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(300, 37, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(37, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(37, 300, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): ConvModule(
                (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (3): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
          (1): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(300, 37, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(37, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(37, 300, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): ConvModule(
                (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (3): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
        )
        (fuse_layers): ModuleList(
          (0): ModuleList(
            (0): None
            (1): Sequential(
              (0): Conv2d(80, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
            (2): Sequential(
              (0): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=4.0, mode=nearest)
            )
            (3): Sequential(
              (0): Conv2d(320, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=8.0, mode=nearest)
            )
          )
          (1): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): None
            (2): Sequential(
              (0): Conv2d(160, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
            (3): Sequential(
              (0): Conv2d(320, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=4.0, mode=nearest)
            )
          )
          (2): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (1): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=80, bias=False)
                (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(80, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): None
            (3): Sequential(
              (0): Conv2d(320, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
          )
          (3): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (1): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (2): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=80, bias=False)
                (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (1): Sequential(
                (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=80, bias=False)
                (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(80, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): Sequential(
              (0): Sequential(
                (0): Conv2d(160, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=160, bias=False)
                (1): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(160, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): None
          )
        )
        (relu): ReLU()
      )
      (2): LiteHRModule(
        (layers): Sequential(
          (0): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(300, 37, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(37, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(37, 300, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): ConvModule(
                (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (3): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
          (1): ConditionalChannelWeighting(
            (cross_resolution_weighting): CrossResolutionWeighting(
              (conv1): ConvModule(
                (conv): Conv2d(300, 37, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(37, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): ReLU(inplace=True)
              )
              (conv2): ConvModule(
                (conv): Conv2d(37, 300, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): SyncBatchNorm(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (activate): Sigmoid()
              )
            )
            (depthwise_convs): ModuleList(
              (0): ConvModule(
                (conv): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)
                (bn): SyncBatchNorm(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (1): ConvModule(
                (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)
                (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (2): ConvModule(
                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)
                (bn): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
              (3): ConvModule(
                (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=160, bias=False)
                (bn): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (spatial_weighting): ModuleList(
              (0): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(20, 5, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(5, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (1): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (2): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
              (3): SpatialWeighting(
                (global_avgpool): AdaptiveAvgPool2d(output_size=1)
                (conv1): ConvModule(
                  (conv): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1))
                  (activate): ReLU(inplace=True)
                )
                (conv2): ConvModule(
                  (conv): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1))
                  (activate): Sigmoid()
                )
              )
            )
          )
        )
        (fuse_layers): ModuleList(
          (0): ModuleList(
            (0): None
            (1): Sequential(
              (0): Conv2d(80, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
            (2): Sequential(
              (0): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=4.0, mode=nearest)
            )
            (3): Sequential(
              (0): Conv2d(320, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=8.0, mode=nearest)
            )
          )
          (1): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): None
            (2): Sequential(
              (0): Conv2d(160, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
            (3): Sequential(
              (0): Conv2d(320, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=4.0, mode=nearest)
            )
          )
          (2): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (1): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=80, bias=False)
                (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(80, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): None
            (3): Sequential(
              (0): Conv2d(320, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): Upsample(scale_factor=2.0, mode=nearest)
            )
          )
          (3): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (1): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (2): Sequential(
                (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=40, bias=False)
                (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(40, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=80, bias=False)
                (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): ReLU(inplace=True)
              )
              (1): Sequential(
                (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=80, bias=False)
                (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(80, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): Sequential(
              (0): Sequential(
                (0): Conv2d(160, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=160, bias=False)
                (1): SyncBatchNorm(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): Conv2d(160, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (3): SyncBatchNorm(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): None
          )
        )
        (relu): ReLU()
      )
    )
  )
  init_cfg=[{'type': 'Normal', 'std': 0.001, 'layer': 'Conv2d'}, {'type': 'Constant', 'val': 1, 'layer': ['_BatchNorm', 'GroupNorm']}]
  (decode_head): FCNHead(
    input_transform=None, ignore_index=255, align_corners=False
    (loss_decode): CrossEntropyLoss()
    (conv_seg): Conv2d(40, 150, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (convs): Sequential(
      (0): ConvModule(
        (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (conv_cat): ConvModule(
      (conv): Conv2d(80, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
)
2021-08-14 02:14:01,648 - mmseg - INFO - Loaded 20210 images
2021-08-14 02:14:08,282 - mmseg - INFO - Loaded 2000 images
2021-08-14 02:14:08,284 - mmseg - INFO - Start running, host: hejunjun@SH-IDC2-172-20-20-72, work_dir: /mnt/lustrenew/hejunjun/mmseg_dev/lite_hrnet/mmsegmentation/work_dirs/fcn_litehr30-without-head_512x512_160k_ade20k
2021-08-14 02:14:08,284 - mmseg - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(NORMAL      ) CheckpointHook                     
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) PolyLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
2021-08-14 02:14:08,285 - mmseg - INFO - workflow: [('train', 1)], max: 160000 iters
2021-08-14 02:15:49,156 - mmseg - INFO - Iter [50/160000]	lr: 9.997e-03, eta: 2 days, 12:01:41, time: 1.351, data_time: 0.022, memory: 5545, decode.loss_seg: 3.4992, decode.acc_seg: 13.7165, loss: 3.4992
2021-08-14 02:16:52,399 - mmseg - INFO - Iter [100/160000]	lr: 9.994e-03, eta: 2 days, 10:05:59, time: 1.265, data_time: 0.013, memory: 5545, decode.loss_seg: 2.9912, decode.acc_seg: 15.7177, loss: 2.9912
2021-08-14 02:17:54,421 - mmseg - INFO - Iter [150/160000]	lr: 9.992e-03, eta: 2 days, 9:04:28, time: 1.240, data_time: 0.013, memory: 5545, decode.loss_seg: 2.9076, decode.acc_seg: 15.5674, loss: 2.9076
2021-08-14 02:18:58,968 - mmseg - INFO - Iter [200/160000]	lr: 9.989e-03, eta: 2 days, 9:07:04, time: 1.291, data_time: 0.013, memory: 5545, decode.loss_seg: 2.8278, decode.acc_seg: 15.7166, loss: 2.8278
2021-08-14 02:20:03,644 - mmseg - INFO - Iter [250/160000]	lr: 9.986e-03, eta: 2 days, 9:09:32, time: 1.293, data_time: 0.013, memory: 5545, decode.loss_seg: 2.7781, decode.acc_seg: 16.2116, loss: 2.7781
2021-08-14 02:21:07,503 - mmseg - INFO - Iter [300/160000]	lr: 9.983e-03, eta: 2 days, 9:03:44, time: 1.277, data_time: 0.013, memory: 5545, decode.loss_seg: 2.7389, decode.acc_seg: 16.2438, loss: 2.7389
2021-08-14 02:22:12,238 - mmseg - INFO - Iter [350/160000]	lr: 9.981e-03, eta: 2 days, 9:05:59, time: 1.295, data_time: 0.013, memory: 5545, decode.loss_seg: 2.7336, decode.acc_seg: 17.4398, loss: 2.7336
2021-08-14 02:23:15,765 - mmseg - INFO - Iter [400/160000]	lr: 9.978e-03, eta: 2 days, 8:59:05, time: 1.270, data_time: 0.012, memory: 5545, decode.loss_seg: 2.7416, decode.acc_seg: 17.4879, loss: 2.7416
2021-08-14 02:24:20,035 - mmseg - INFO - Iter [450/160000]	lr: 9.975e-03, eta: 2 days, 8:57:58, time: 1.285, data_time: 0.013, memory: 5545, decode.loss_seg: 2.6805, decode.acc_seg: 17.9098, loss: 2.6805
2021-08-14 02:25:21,097 - mmseg - INFO - Iter [500/160000]	lr: 9.972e-03, eta: 2 days, 8:40:03, time: 1.222, data_time: 0.013, memory: 5545, decode.loss_seg: 2.6958, decode.acc_seg: 18.8559, loss: 2.6958
2021-08-14 02:26:25,980 - mmseg - INFO - Iter [550/160000]	lr: 9.969e-03, eta: 2 days, 8:43:17, time: 1.297, data_time: 0.012, memory: 5545, decode.loss_seg: 2.6725, decode.acc_seg: 18.7767, loss: 2.6725
2021-08-14 02:27:26,665 - mmseg - INFO - Iter [600/160000]	lr: 9.967e-03, eta: 2 days, 8:27:35, time: 1.215, data_time: 0.013, memory: 5545, decode.loss_seg: 2.7125, decode.acc_seg: 19.4822, loss: 2.7125
2021-08-14 02:29:04,543 - mmseg - INFO - Iter [650/160000]	lr: 9.964e-03, eta: 2 days, 10:45:48, time: 1.957, data_time: 0.739, memory: 5545, decode.loss_seg: 2.6685, decode.acc_seg: 20.2892, loss: 2.6685
2021-08-14 02:30:07,873 - mmseg - INFO - Iter [700/160000]	lr: 9.961e-03, eta: 2 days, 10:33:11, time: 1.267, data_time: 0.014, memory: 5545, decode.loss_seg: 2.6797, decode.acc_seg: 19.5848, loss: 2.6797
2021-08-14 02:31:09,513 - mmseg - INFO - Iter [750/160000]	lr: 9.958e-03, eta: 2 days, 10:16:10, time: 1.233, data_time: 0.013, memory: 5545, decode.loss_seg: 2.6969, decode.acc_seg: 19.5869, loss: 2.6969
2021-08-14 02:32:11,867 - mmseg - INFO - Iter [800/160000]	lr: 9.955e-03, eta: 2 days, 10:03:26, time: 1.247, data_time: 0.013, memory: 5545, decode.loss_seg: 2.6010, decode.acc_seg: 21.9966, loss: 2.6010
2021-08-14 02:33:13,005 - mmseg - INFO - Iter [850/160000]	lr: 9.953e-03, eta: 2 days, 9:48:15, time: 1.223, data_time: 0.013, memory: 5545, decode.loss_seg: 2.5854, decode.acc_seg: 20.8473, loss: 2.5854
2021-08-14 02:34:14,738 - mmseg - INFO - Iter [900/160000]	lr: 9.950e-03, eta: 2 days, 9:36:24, time: 1.235, data_time: 0.013, memory: 5545, decode.loss_seg: 2.6081, decode.acc_seg: 21.1067, loss: 2.6081
2021-08-14 02:35:14,378 - mmseg - INFO - Iter [950/160000]	lr: 9.947e-03, eta: 2 days, 9:19:51, time: 1.193, data_time: 0.013, memory: 5545, decode.loss_seg: 2.5406, decode.acc_seg: 22.9033, loss: 2.5406
2021-08-14 02:36:16,112 - mmseg - INFO - Exp name: fcn_litehr30-without-head_512x512_160k_ade20k.py
2021-08-14 02:36:16,112 - mmseg - INFO - Iter [1000/160000]	lr: 9.944e-03, eta: 2 days, 9:10:24, time: 1.234, data_time: 0.013, memory: 5545, decode.loss_seg: 2.5636, decode.acc_seg: 24.5608, loss: 2.5636
2021-08-14 02:37:19,284 - mmseg - INFO - Iter [1050/160000]	lr: 9.942e-03, eta: 2 days, 9:05:25, time: 1.263, data_time: 0.013, memory: 5545, decode.loss_seg: 2.4831, decode.acc_seg: 25.3056, loss: 2.4831
2021-08-14 02:38:22,692 - mmseg - INFO - Iter [1100/160000]	lr: 9.939e-03, eta: 2 days, 9:01:21, time: 1.268, data_time: 0.013, memory: 5545, decode.loss_seg: 2.4267, decode.acc_seg: 26.9191, loss: 2.4267
2021-08-14 02:39:23,344 - mmseg - INFO - Iter [1150/160000]	lr: 9.936e-03, eta: 2 days, 8:51:13, time: 1.213, data_time: 0.013, memory: 5545, decode.loss_seg: 2.3957, decode.acc_seg: 28.0204, loss: 2.3957
2021-08-14 02:40:26,533 - mmseg - INFO - Iter [1200/160000]	lr: 9.933e-03, eta: 2 days, 8:47:21, time: 1.263, data_time: 0.013, memory: 5545, decode.loss_seg: 2.3303, decode.acc_seg: 29.1326, loss: 2.3303
2021-08-14 02:41:28,788 - mmseg - INFO - Iter [1250/160000]	lr: 9.930e-03, eta: 2 days, 8:41:54, time: 1.246, data_time: 0.014, memory: 5545, decode.loss_seg: 2.2550, decode.acc_seg: 30.4905, loss: 2.2550
2021-08-14 02:43:05,145 - mmseg - INFO - Iter [1300/160000]	lr: 9.928e-03, eta: 2 days, 9:46:04, time: 1.927, data_time: 0.654, memory: 5545, decode.loss_seg: 2.3087, decode.acc_seg: 29.0298, loss: 2.3087
2021-08-14 02:44:09,006 - mmseg - INFO - Iter [1350/160000]	lr: 9.925e-03, eta: 2 days, 9:41:39, time: 1.276, data_time: 0.013, memory: 5545, decode.loss_seg: 2.2219, decode.acc_seg: 31.0777, loss: 2.2219
2021-08-14 02:45:12,384 - mmseg - INFO - Iter [1400/160000]	lr: 9.922e-03, eta: 2 days, 9:36:40, time: 1.268, data_time: 0.013, memory: 5545, decode.loss_seg: 2.2398, decode.acc_seg: 30.1345, loss: 2.2398
2021-08-14 02:46:17,156 - mmseg - INFO - Iter [1450/160000]	lr: 9.919e-03, eta: 2 days, 9:34:24, time: 1.295, data_time: 0.013, memory: 5545, decode.loss_seg: 2.1638, decode.acc_seg: 30.9380, loss: 2.1638
2021-08-14 02:47:21,036 - mmseg - INFO - Iter [1500/160000]	lr: 9.916e-03, eta: 2 days, 9:30:45, time: 1.278, data_time: 0.014, memory: 5545, decode.loss_seg: 2.1728, decode.acc_seg: 31.0741, loss: 2.1728
2021-08-14 02:48:22,915 - mmseg - INFO - Iter [1550/160000]	lr: 9.914e-03, eta: 2 days, 9:23:49, time: 1.238, data_time: 0.014, memory: 5545, decode.loss_seg: 2.0819, decode.acc_seg: 32.8050, loss: 2.0819
2021-08-14 02:49:25,126 - mmseg - INFO - Iter [1600/160000]	lr: 9.911e-03, eta: 2 days, 9:17:48, time: 1.244, data_time: 0.013, memory: 5545, decode.loss_seg: 2.1528, decode.acc_seg: 31.1618, loss: 2.1528
2021-08-14 02:50:29,246 - mmseg - INFO - Iter [1650/160000]	lr: 9.908e-03, eta: 2 days, 9:15:04, time: 1.282, data_time: 0.013, memory: 5545, decode.loss_seg: 2.0532, decode.acc_seg: 33.2002, loss: 2.0532
2021-08-14 02:51:30,966 - mmseg - INFO - Iter [1700/160000]	lr: 9.905e-03, eta: 2 days, 9:08:48, time: 1.235, data_time: 0.014, memory: 5545, decode.loss_seg: 2.0996, decode.acc_seg: 32.6002, loss: 2.0996
2021-08-14 02:52:31,647 - mmseg - INFO - Iter [1750/160000]	lr: 9.903e-03, eta: 2 days, 9:01:14, time: 1.214, data_time: 0.014, memory: 5545, decode.loss_seg: 2.0988, decode.acc_seg: 33.0984, loss: 2.0988
2021-08-14 02:53:33,354 - mmseg - INFO - Iter [1800/160000]	lr: 9.900e-03, eta: 2 days, 8:55:36, time: 1.235, data_time: 0.014, memory: 5545, decode.loss_seg: 2.0523, decode.acc_seg: 33.7608, loss: 2.0523
2021-08-14 02:54:34,889 - mmseg - INFO - Iter [1850/160000]	lr: 9.897e-03, eta: 2 days, 8:49:54, time: 1.231, data_time: 0.013, memory: 5545, decode.loss_seg: 2.0601, decode.acc_seg: 33.0915, loss: 2.0601
2021-08-14 02:56:09,855 - mmseg - INFO - Iter [1900/160000]	lr: 9.894e-03, eta: 2 days, 9:30:47, time: 1.899, data_time: 0.687, memory: 5545, decode.loss_seg: 2.0663, decode.acc_seg: 34.0574, loss: 2.0663
2021-08-14 02:57:11,321 - mmseg - INFO - Iter [1950/160000]	lr: 9.891e-03, eta: 2 days, 9:24:18, time: 1.230, data_time: 0.013, memory: 5545, decode.loss_seg: 2.0029, decode.acc_seg: 32.8795, loss: 2.0029
2021-08-14 02:58:14,055 - mmseg - INFO - Exp name: fcn_litehr30-without-head_512x512_160k_ade20k.py
2021-08-14 02:58:14,055 - mmseg - INFO - Iter [2000/160000]	lr: 9.889e-03, eta: 2 days, 9:19:42, time: 1.254, data_time: 0.013, memory: 5545, decode.loss_seg: 2.0540, decode.acc_seg: 33.4247, loss: 2.0540
2021-08-14 02:59:17,531 - mmseg - INFO - Iter [2050/160000]	lr: 9.886e-03, eta: 2 days, 9:16:17, time: 1.270, data_time: 0.014, memory: 5545, decode.loss_seg: 1.9533, decode.acc_seg: 35.4479, loss: 1.9533
2021-08-14 03:00:17,729 - mmseg - INFO - Iter [2100/160000]	lr: 9.883e-03, eta: 2 days, 9:08:50, time: 1.204, data_time: 0.014, memory: 5545, decode.loss_seg: 2.0480, decode.acc_seg: 34.0521, loss: 2.0480
2021-08-14 03:01:18,921 - mmseg - INFO - Iter [2150/160000]	lr: 9.880e-03, eta: 2 days, 9:02:55, time: 1.224, data_time: 0.014, memory: 5545, decode.loss_seg: 2.0026, decode.acc_seg: 33.5238, loss: 2.0026
2021-08-14 03:02:20,660 - mmseg - INFO - Iter [2200/160000]	lr: 9.877e-03, eta: 2 days, 8:57:52, time: 1.235, data_time: 0.013, memory: 5545, decode.loss_seg: 1.9598, decode.acc_seg: 34.2522, loss: 1.9598
2021-08-14 03:03:21,710 - mmseg - INFO - Iter [2250/160000]	lr: 9.875e-03, eta: 2 days, 8:52:12, time: 1.221, data_time: 0.013, memory: 5545, decode.loss_seg: 1.9712, decode.acc_seg: 35.2301, loss: 1.9712
2021-08-14 03:04:24,319 - mmseg - INFO - Iter [2300/160000]	lr: 9.872e-03, eta: 2 days, 8:48:29, time: 1.252, data_time: 0.013, memory: 5545, decode.loss_seg: 1.9720, decode.acc_seg: 35.0605, loss: 1.9720
2021-08-14 03:05:25,723 - mmseg - INFO - Iter [2350/160000]	lr: 9.869e-03, eta: 2 days, 8:43:35, time: 1.229, data_time: 0.015, memory: 5545, decode.loss_seg: 1.9754, decode.acc_seg: 35.0419, loss: 1.9754
2021-08-14 03:06:25,932 - mmseg - INFO - Iter [2400/160000]	lr: 9.866e-03, eta: 2 days, 8:37:31, time: 1.204, data_time: 0.013, memory: 5545, decode.loss_seg: 1.9173, decode.acc_seg: 36.8225, loss: 1.9173
2021-08-14 03:07:24,758 - mmseg - INFO - Iter [2450/160000]	lr: 9.864e-03, eta: 2 days, 8:30:08, time: 1.176, data_time: 0.013, memory: 5545, decode.loss_seg: 1.9088, decode.acc_seg: 36.0751, loss: 1.9088
2021-08-14 03:08:27,465 - mmseg - INFO - Iter [2500/160000]	lr: 9.861e-03, eta: 2 days, 8:27:07, time: 1.254, data_time: 0.013, memory: 5545, decode.loss_seg: 1.9684, decode.acc_seg: 35.8627, loss: 1.9684
2021-08-14 03:10:04,424 - mmseg - INFO - Iter [2550/160000]	lr: 9.858e-03, eta: 2 days, 8:59:27, time: 1.940, data_time: 0.711, memory: 5545, decode.loss_seg: 1.8930, decode.acc_seg: 36.2027, loss: 1.8930
2021-08-14 03:11:06,406 - mmseg - INFO - Iter [2600/160000]	lr: 9.855e-03, eta: 2 days, 8:55:11, time: 1.240, data_time: 0.013, memory: 5545, decode.loss_seg: 1.8570, decode.acc_seg: 36.4748, loss: 1.8570
2021-08-14 03:12:06,579 - mmseg - INFO - Iter [2650/160000]	lr: 9.852e-03, eta: 2 days, 8:49:12, time: 1.203, data_time: 0.013, memory: 5545, decode.loss_seg: 1.9308, decode.acc_seg: 36.4745, loss: 1.9308
2021-08-14 03:13:08,952 - mmseg - INFO - Iter [2700/160000]	lr: 9.850e-03, eta: 2 days, 8:45:33, time: 1.247, data_time: 0.013, memory: 5545, decode.loss_seg: 1.9142, decode.acc_seg: 36.6227, loss: 1.9142
2021-08-14 03:14:12,915 - mmseg - INFO - Iter [2750/160000]	lr: 9.847e-03, eta: 2 days, 8:43:32, time: 1.279, data_time: 0.013, memory: 5545, decode.loss_seg: 1.9170, decode.acc_seg: 35.7220, loss: 1.9170
2021-08-14 03:15:16,089 - mmseg - INFO - Iter [2800/160000]	lr: 9.844e-03, eta: 2 days, 8:40:50, time: 1.264, data_time: 0.013, memory: 5545, decode.loss_seg: 1.8029, decode.acc_seg: 37.4766, loss: 1.8029
2021-08-14 03:16:15,598 - mmseg - INFO - Iter [2850/160000]	lr: 9.841e-03, eta: 2 days, 8:34:46, time: 1.190, data_time: 0.013, memory: 5545, decode.loss_seg: 1.9019, decode.acc_seg: 36.2320, loss: 1.9019
2021-08-14 03:17:17,238 - mmseg - INFO - Iter [2900/160000]	lr: 9.838e-03, eta: 2 days, 8:30:49, time: 1.233, data_time: 0.014, memory: 5545, decode.loss_seg: 1.8276, decode.acc_seg: 37.7744, loss: 1.8276
2021-08-14 03:18:19,901 - mmseg - INFO - Iter [2950/160000]	lr: 9.836e-03, eta: 2 days, 8:27:55, time: 1.254, data_time: 0.014, memory: 5545, decode.loss_seg: 1.8282, decode.acc_seg: 37.6344, loss: 1.8282
2021-08-14 03:19:21,542 - mmseg - INFO - Exp name: fcn_litehr30-without-head_512x512_160k_ade20k.py
2021-08-14 03:19:21,543 - mmseg - INFO - Iter [3000/160000]	lr: 9.833e-03, eta: 2 days, 8:24:09, time: 1.233, data_time: 0.013, memory: 5545, decode.loss_seg: 1.8815, decode.acc_seg: 36.6927, loss: 1.8815
2021-08-14 03:20:22,066 - mmseg - INFO - Iter [3050/160000]	lr: 9.830e-03, eta: 2 days, 8:19:31, time: 1.211, data_time: 0.013, memory: 5545, decode.loss_seg: 1.8950, decode.acc_seg: 37.0482, loss: 1.8950
2021-08-14 03:21:25,276 - mmseg - INFO - Iter [3100/160000]	lr: 9.827e-03, eta: 2 days, 8:17:15, time: 1.264, data_time: 0.013, memory: 5545, decode.loss_seg: 1.8426, decode.acc_seg: 37.9495, loss: 1.8426
2021-08-14 03:22:26,788 - mmseg - INFO - Iter [3150/160000]	lr: 9.824e-03, eta: 2 days, 8:13:39, time: 1.231, data_time: 0.013, memory: 5545, decode.loss_seg: 1.8368, decode.acc_seg: 38.4623, loss: 1.8368
2021-08-14 03:24:01,872 - mmseg - INFO - Iter [3200/160000]	lr: 9.822e-03, eta: 2 days, 8:37:33, time: 1.902, data_time: 0.681, memory: 5545, decode.loss_seg: 1.8577, decode.acc_seg: 36.8143, loss: 1.8577
2021-08-14 03:25:01,957 - mmseg - INFO - Iter [3250/160000]	lr: 9.819e-03, eta: 2 days, 8:32:29, time: 1.201, data_time: 0.013, memory: 5545, decode.loss_seg: 1.8675, decode.acc_seg: 38.4479, loss: 1.8675
2021-08-14 03:26:05,436 - mmseg - INFO - Iter [3300/160000]	lr: 9.816e-03, eta: 2 days, 8:30:15, time: 1.269, data_time: 0.014, memory: 5545, decode.loss_seg: 1.8404, decode.acc_seg: 38.0933, loss: 1.8404
2021-08-14 03:27:07,738 - mmseg - INFO - Iter [3350/160000]	lr: 9.813e-03, eta: 2 days, 8:27:08, time: 1.246, data_time: 0.014, memory: 5545, decode.loss_seg: 1.8194, decode.acc_seg: 38.3923, loss: 1.8194
2021-08-14 03:28:11,996 - mmseg - INFO - Iter [3400/160000]	lr: 9.811e-03, eta: 2 days, 8:25:35, time: 1.285, data_time: 0.014, memory: 5545, decode.loss_seg: 1.8024, decode.acc_seg: 38.8887, loss: 1.8024
2021-08-14 03:29:15,280 - mmseg - INFO - Iter [3450/160000]	lr: 9.808e-03, eta: 2 days, 8:23:19, time: 1.266, data_time: 0.014, memory: 5545, decode.loss_seg: 1.8196, decode.acc_seg: 37.8303, loss: 1.8196
2021-08-14 03:30:20,436 - mmseg - INFO - Iter [3500/160000]	lr: 9.805e-03, eta: 2 days, 8:22:28, time: 1.303, data_time: 0.014, memory: 5545, decode.loss_seg: 1.7995, decode.acc_seg: 38.4217, loss: 1.7995
2021-08-14 03:31:22,100 - mmseg - INFO - Iter [3550/160000]	lr: 9.802e-03, eta: 2 days, 8:19:05, time: 1.234, data_time: 0.014, memory: 5545, decode.loss_seg: 1.7845, decode.acc_seg: 37.7764, loss: 1.7845
2021-08-14 03:32:22,422 - mmseg - INFO - Iter [3600/160000]	lr: 9.799e-03, eta: 2 days, 8:14:46, time: 1.206, data_time: 0.013, memory: 5545, decode.loss_seg: 1.7901, decode.acc_seg: 38.8695, loss: 1.7901
2021-08-14 03:33:22,401 - mmseg - INFO - Iter [3650/160000]	lr: 9.797e-03, eta: 2 days, 8:10:16, time: 1.199, data_time: 0.013, memory: 5545, decode.loss_seg: 1.7959, decode.acc_seg: 38.7036, loss: 1.7959
2021-08-14 03:34:23,625 - mmseg - INFO - Iter [3700/160000]	lr: 9.794e-03, eta: 2 days, 8:06:46, time: 1.225, data_time: 0.013, memory: 5545, decode.loss_seg: 1.7643, decode.acc_seg: 39.2664, loss: 1.7643
2021-08-14 03:35:24,325 - mmseg - INFO - Iter [3750/160000]	lr: 9.791e-03, eta: 2 days, 8:02:58, time: 1.214, data_time: 0.013, memory: 5545, decode.loss_seg: 1.7548, decode.acc_seg: 39.1769, loss: 1.7548
2021-08-14 03:37:00,191 - mmseg - INFO - Iter [3800/160000]	lr: 9.788e-03, eta: 2 days, 8:23:20, time: 1.917, data_time: 0.718, memory: 5545, decode.loss_seg: 1.8014, decode.acc_seg: 38.5556, loss: 1.8014
2021-08-14 03:38:03,964 - mmseg - INFO - Iter [3850/160000]	lr: 9.785e-03, eta: 2 days, 8:21:26, time: 1.275, data_time: 0.014, memory: 5545, decode.loss_seg: 1.7697, decode.acc_seg: 38.7104, loss: 1.7697
2021-08-14 03:39:05,143 - mmseg - INFO - Iter [3900/160000]	lr: 9.783e-03, eta: 2 days, 8:17:50, time: 1.224, data_time: 0.015, memory: 5545, decode.loss_seg: 1.7132, decode.acc_seg: 39.8128, loss: 1.7132
2021-08-14 03:40:05,869 - mmseg - INFO - Iter [3950/160000]	lr: 9.780e-03, eta: 2 days, 8:14:00, time: 1.215, data_time: 0.014, memory: 5545, decode.loss_seg: 1.7812, decode.acc_seg: 39.5812, loss: 1.7812
2021-08-14 03:41:07,081 - mmseg - INFO - Exp name: fcn_litehr30-without-head_512x512_160k_ade20k.py
2021-08-14 03:41:07,082 - mmseg - INFO - Iter [4000/160000]	lr: 9.777e-03, eta: 2 days, 8:10:32, time: 1.224, data_time: 0.015, memory: 5545, decode.loss_seg: 1.7325, decode.acc_seg: 39.4142, loss: 1.7325
2021-08-14 03:42:12,731 - mmseg - INFO - Iter [4050/160000]	lr: 9.774e-03, eta: 2 days, 8:09:58, time: 1.313, data_time: 0.014, memory: 5545, decode.loss_seg: 1.7620, decode.acc_seg: 39.2102, loss: 1.7620
2021-08-14 03:43:19,672 - mmseg - INFO - Iter [4100/160000]	lr: 9.771e-03, eta: 2 days, 8:10:14, time: 1.339, data_time: 0.014, memory: 5545, decode.loss_seg: 1.7667, decode.acc_seg: 38.7718, loss: 1.7667
2021-08-14 03:44:24,752 - mmseg - INFO - Iter [4150/160000]	lr: 9.769e-03, eta: 2 days, 8:09:18, time: 1.302, data_time: 0.014, memory: 5545, decode.loss_seg: 1.7536, decode.acc_seg: 38.8013, loss: 1.7536
2021-08-14 03:45:25,600 - mmseg - INFO - Iter [4200/160000]	lr: 9.766e-03, eta: 2 days, 8:05:44, time: 1.217, data_time: 0.015, memory: 5545, decode.loss_seg: 1.7436, decode.acc_seg: 38.8988, loss: 1.7436
2021-08-14 03:46:25,272 - mmseg - INFO - Iter [4250/160000]	lr: 9.763e-03, eta: 2 days, 8:01:32, time: 1.194, data_time: 0.015, memory: 5545, decode.loss_seg: 1.7215, decode.acc_seg: 39.7236, loss: 1.7215
2021-08-14 03:47:26,038 - mmseg - INFO - Iter [4300/160000]	lr: 9.760e-03, eta: 2 days, 7:58:03, time: 1.215, data_time: 0.014, memory: 5545, decode.loss_seg: 1.7220, decode.acc_seg: 39.7653, loss: 1.7220
2021-08-14 03:48:30,282 - mmseg - INFO - Iter [4350/160000]	lr: 9.757e-03, eta: 2 days, 7:56:41, time: 1.285, data_time: 0.015, memory: 5545, decode.loss_seg: 1.7361, decode.acc_seg: 39.5532, loss: 1.7361
2021-08-14 03:49:33,562 - mmseg - INFO - Iter [4400/160000]	lr: 9.755e-03, eta: 2 days, 7:54:47, time: 1.266, data_time: 0.014, memory: 5545, decode.loss_seg: 1.7180, decode.acc_seg: 39.9922, loss: 1.7180
2021-08-14 03:51:09,943 - mmseg - INFO - Iter [4450/160000]	lr: 9.752e-03, eta: 2 days, 8:12:10, time: 1.927, data_time: 0.687, memory: 5545, decode.loss_seg: 1.7016, decode.acc_seg: 40.3647, loss: 1.7016
2021-08-14 03:52:11,422 - mmseg - INFO - Iter [4500/160000]	lr: 9.749e-03, eta: 2 days, 8:09:01, time: 1.229, data_time: 0.014, memory: 5545, decode.loss_seg: 1.7195, decode.acc_seg: 38.9724, loss: 1.7195
2021-08-14 03:53:11,297 - mmseg - INFO - Iter [4550/160000]	lr: 9.746e-03, eta: 2 days, 8:05:03, time: 1.199, data_time: 0.015, memory: 5545, decode.loss_seg: 1.7549, decode.acc_seg: 39.2703, loss: 1.7549
2021-08-14 03:54:14,025 - mmseg - INFO - Iter [4600/160000]	lr: 9.744e-03, eta: 2 days, 8:02:41, time: 1.253, data_time: 0.013, memory: 5545, decode.loss_seg: 1.7291, decode.acc_seg: 40.3665, loss: 1.7291
2021-08-14 03:55:17,665 - mmseg - INFO - Iter [4650/160000]	lr: 9.741e-03, eta: 2 days, 8:00:55, time: 1.274, data_time: 0.014, memory: 5545, decode.loss_seg: 1.6480, decode.acc_seg: 40.8801, loss: 1.6480
2021-08-14 03:56:18,776 - mmseg - INFO - Iter [4700/160000]	lr: 9.738e-03, eta: 2 days, 7:57:45, time: 1.222, data_time: 0.013, memory: 5545, decode.loss_seg: 1.6534, decode.acc_seg: 40.8910, loss: 1.6534
2021-08-14 03:57:20,595 - mmseg - INFO - Iter [4750/160000]	lr: 9.735e-03, eta: 2 days, 7:55:00, time: 1.236, data_time: 0.013, memory: 5545, decode.loss_seg: 1.6874, decode.acc_seg: 39.6932, loss: 1.6874
2021-08-14 03:58:20,977 - mmseg - INFO - Iter [4800/160000]	lr: 9.732e-03, eta: 2 days, 7:51:31, time: 1.207, data_time: 0.013, memory: 5545, decode.loss_seg: 1.6712, decode.acc_seg: 41.0316, loss: 1.6712
2021-08-14 03:59:25,789 - mmseg - INFO - Iter [4850/160000]	lr: 9.730e-03, eta: 2 days, 7:50:27, time: 1.296, data_time: 0.014, memory: 5545, decode.loss_seg: 1.7032, decode.acc_seg: 40.6884, loss: 1.7032
2021-08-14 04:00:29,629 - mmseg - INFO - Iter [4900/160000]	lr: 9.727e-03, eta: 2 days, 7:48:52, time: 1.277, data_time: 0.013, memory: 5545, decode.loss_seg: 1.6663, decode.acc_seg: 41.9066, loss: 1.6663
2021-08-14 04:01:30,540 - mmseg - INFO - Iter [4950/160000]	lr: 9.724e-03, eta: 2 days, 7:45:47, time: 1.219, data_time: 0.013, memory: 5545, decode.loss_seg: 1.7266, decode.acc_seg: 39.6854, loss: 1.7266
2021-08-14 04:02:31,523 - mmseg - INFO - Exp name: fcn_litehr30-without-head_512x512_160k_ade20k.py
2021-08-14 04:02:31,524 - mmseg - INFO - Iter [5000/160000]	lr: 9.721e-03, eta: 2 days, 7:42:46, time: 1.219, data_time: 0.013, memory: 5545, decode.loss_seg: 1.6679, decode.acc_seg: 41.1375, loss: 1.6679
2021-08-14 04:04:12,219 - mmseg - INFO - Iter [5050/160000]	lr: 9.718e-03, eta: 2 days, 8:00:06, time: 2.014, data_time: 0.680, memory: 5545, decode.loss_seg: 1.6877, decode.acc_seg: 40.7935, loss: 1.6877
2021-08-14 04:05:14,660 - mmseg - INFO - Iter [5100/160000]	lr: 9.716e-03, eta: 2 days, 7:57:41, time: 1.249, data_time: 0.014, memory: 5545, decode.loss_seg: 1.5672, decode.acc_seg: 41.7356, loss: 1.5672
2021-08-14 04:06:15,631 - mmseg - INFO - Iter [5150/160000]	lr: 9.713e-03, eta: 2 days, 7:54:34, time: 1.219, data_time: 0.014, memory: 5545, decode.loss_seg: 1.6818, decode.acc_seg: 40.0728, loss: 1.6818
2021-08-14 04:07:18,639 - mmseg - INFO - Iter [5200/160000]	lr: 9.710e-03, eta: 2 days, 7:52:30, time: 1.261, data_time: 0.013, memory: 5545, decode.loss_seg: 1.6917, decode.acc_seg: 41.0269, loss: 1.6917
2021-08-14 04:08:19,484 - mmseg - INFO - Iter [5250/160000]	lr: 9.707e-03, eta: 2 days, 7:49:24, time: 1.217, data_time: 0.013, memory: 5545, decode.loss_seg: 1.6330, decode.acc_seg: 42.0646, loss: 1.6330
2021-08-14 04:09:22,496 - mmseg - INFO - Iter [5300/160000]	lr: 9.704e-03, eta: 2 days, 7:47:22, time: 1.259, data_time: 0.013, memory: 5545, decode.loss_seg: 1.6821, decode.acc_seg: 40.9371, loss: 1.6821
2021-08-14 04:10:26,194 - mmseg - INFO - Iter [5350/160000]	lr: 9.702e-03, eta: 2 days, 7:45:42, time: 1.275, data_time: 0.014, memory: 5545, decode.loss_seg: 1.7076, decode.acc_seg: 40.7742, loss: 1.7076
2021-08-14 04:11:28,668 - mmseg - INFO - Iter [5400/160000]	lr: 9.699e-03, eta: 2 days, 7:43:28, time: 1.249, data_time: 0.013, memory: 5545, decode.loss_seg: 1.6687, decode.acc_seg: 42.0254, loss: 1.6687
2021-08-14 04:12:30,365 - mmseg - INFO - Iter [5450/160000]	lr: 9.696e-03, eta: 2 days, 7:40:53, time: 1.235, data_time: 0.014, memory: 5545, decode.loss_seg: 1.6170, decode.acc_seg: 41.8542, loss: 1.6170
2021-08-14 04:13:30,968 - mmseg - INFO - Iter [5500/160000]	lr: 9.693e-03, eta: 2 days, 7:37:48, time: 1.211, data_time: 0.013, memory: 5545, decode.loss_seg: 1.5835, decode.acc_seg: 41.8569, loss: 1.5835
2021-08-14 04:14:30,481 - mmseg - INFO - Iter [5550/160000]	lr: 9.690e-03, eta: 2 days, 7:34:17, time: 1.191, data_time: 0.014, memory: 5545, decode.loss_seg: 1.6476, decode.acc_seg: 42.1411, loss: 1.6476
2021-08-14 04:15:32,413 - mmseg - INFO - Iter [5600/160000]	lr: 9.688e-03, eta: 2 days, 7:31:53, time: 1.238, data_time: 0.013, memory: 5545, decode.loss_seg: 1.5763, decode.acc_seg: 41.3883, loss: 1.5763
2021-08-14 04:16:34,573 - mmseg - INFO - Iter [5650/160000]	lr: 9.685e-03, eta: 2 days, 7:29:38, time: 1.243, data_time: 0.013, memory: 5545, decode.loss_seg: 1.6078, decode.acc_seg: 41.3528, loss: 1.6078
2021-08-14 04:18:13,089 - mmseg - INFO - Iter [5700/160000]	lr: 9.682e-03, eta: 2 days, 7:43:48, time: 1.970, data_time: 0.713, memory: 5545, decode.loss_seg: 1.6572, decode.acc_seg: 40.7754, loss: 1.6572
2021-08-14 04:19:14,153 - mmseg - INFO - Iter [5750/160000]	lr: 9.679e-03, eta: 2 days, 7:40:57, time: 1.221, data_time: 0.014, memory: 5545, decode.loss_seg: 1.6209, decode.acc_seg: 40.5199, loss: 1.6209
2021-08-14 04:20:17,809 - mmseg - INFO - Iter [5800/160000]	lr: 9.676e-03, eta: 2 days, 7:39:17, time: 1.273, data_time: 0.013, memory: 5545, decode.loss_seg: 1.6434, decode.acc_seg: 42.1212, loss: 1.6434
2021-08-14 04:21:19,284 - mmseg - INFO - Iter [5850/160000]	lr: 9.674e-03, eta: 2 days, 7:36:40, time: 1.230, data_time: 0.014, memory: 5545, decode.loss_seg: 1.6272, decode.acc_seg: 41.0784, loss: 1.6272
2021-08-14 04:22:19,474 - mmseg - INFO - Iter [5900/160000]	lr: 9.671e-03, eta: 2 days, 7:33:32, time: 1.204, data_time: 0.013, memory: 5545, decode.loss_seg: 1.6362, decode.acc_seg: 41.7444, loss: 1.6362
2021-08-14 04:23:20,721 - mmseg - INFO - Iter [5950/160000]	lr: 9.668e-03, eta: 2 days, 7:30:52, time: 1.225, data_time: 0.013, memory: 5545, decode.loss_seg: 1.6305, decode.acc_seg: 40.4928, loss: 1.6305
2021-08-14 04:24:20,101 - mmseg - INFO - Exp name: fcn_litehr30-without-head_512x512_160k_ade20k.py
2021-08-14 04:24:20,102 - mmseg - INFO - Iter [6000/160000]	lr: 9.665e-03, eta: 2 days, 7:27:27, time: 1.188, data_time: 0.013, memory: 5545, decode.loss_seg: 1.5759, decode.acc_seg: 41.5789, loss: 1.5759
2021-08-14 04:25:22,151 - mmseg - INFO - Iter [6050/160000]	lr: 9.663e-03, eta: 2 days, 7:25:11, time: 1.241, data_time: 0.013, memory: 5545, decode.loss_seg: 1.5917, decode.acc_seg: 42.7554, loss: 1.5917
2021-08-14 04:26:28,033 - mmseg - INFO - Iter [6100/160000]	lr: 9.660e-03, eta: 2 days, 7:24:33, time: 1.317, data_time: 0.013, memory: 5545, decode.loss_seg: 1.6145, decode.acc_seg: 41.8322, loss: 1.6145
2021-08-14 04:27:29,807 - mmseg - INFO - Iter [6150/160000]	lr: 9.657e-03, eta: 2 days, 7:22:13, time: 1.236, data_time: 0.014, memory: 5545, decode.loss_seg: 1.6160, decode.acc_seg: 43.6198, loss: 1.6160
2021-08-14 04:28:33,153 - mmseg - INFO - Iter [6200/160000]	lr: 9.654e-03, eta: 2 days, 7:20:33, time: 1.267, data_time: 0.013, memory: 5545, decode.loss_seg: 1.6008, decode.acc_seg: 42.8564, loss: 1.6008
2021-08-14 04:29:33,551 - mmseg - INFO - Iter [6250/160000]	lr: 9.651e-03, eta: 2 days, 7:17:40, time: 1.207, data_time: 0.013, memory: 5545, decode.loss_seg: 1.6129, decode.acc_seg: 41.9248, loss: 1.6129
2021-08-14 04:30:35,934 - mmseg - INFO - Iter [6300/160000]	lr: 9.649e-03, eta: 2 days, 7:15:38, time: 1.248, data_time: 0.013, memory: 5545, decode.loss_seg: 1.6611, decode.acc_seg: 41.9296, loss: 1.6611
2021-08-14 04:32:13,815 - mmseg - INFO - Iter [6350/160000]	lr: 9.646e-03, eta: 2 days, 7:27:56, time: 1.958, data_time: 0.722, memory: 5545, decode.loss_seg: 1.6327, decode.acc_seg: 42.6444, loss: 1.6327
2021-08-14 04:33:15,053 - mmseg - INFO - Iter [6400/160000]	lr: 9.643e-03, eta: 2 days, 7:25:21, time: 1.224, data_time: 0.013, memory: 5545, decode.loss_seg: 1.5792, decode.acc_seg: 42.6269, loss: 1.5792
2021-08-14 04:34:15,028 - mmseg - INFO - Iter [6450/160000]	lr: 9.640e-03, eta: 2 days, 7:22:18, time: 1.200, data_time: 0.014, memory: 5545, decode.loss_seg: 1.5827, decode.acc_seg: 42.0035, loss: 1.5827
2021-08-14 04:35:17,240 - mmseg - INFO - Iter [6500/160000]	lr: 9.637e-03, eta: 2 days, 7:20:09, time: 1.244, data_time: 0.014, memory: 5545, decode.loss_seg: 1.6156, decode.acc_seg: 41.7918, loss: 1.6156
2021-08-14 04:36:18,408 - mmseg - INFO - Iter [6550/160000]	lr: 9.635e-03, eta: 2 days, 7:17:36, time: 1.223, data_time: 0.014, memory: 5545, decode.loss_seg: 1.5931, decode.acc_seg: 41.6110, loss: 1.5931
2021-08-14 04:37:19,854 - mmseg - INFO - Iter [6600/160000]	lr: 9.632e-03, eta: 2 days, 7:15:13, time: 1.230, data_time: 0.015, memory: 5545, decode.loss_seg: 1.5722, decode.acc_seg: 42.4338, loss: 1.5722
2021-08-14 04:38:19,951 - mmseg - INFO - Iter [6650/160000]	lr: 9.629e-03, eta: 2 days, 7:12:19, time: 1.202, data_time: 0.015, memory: 5545, decode.loss_seg: 1.5964, decode.acc_seg: 42.0259, loss: 1.5964
2021-08-14 04:39:20,791 - mmseg - INFO - Iter [6700/160000]	lr: 9.626e-03, eta: 2 days, 7:09:43, time: 1.217, data_time: 0.014, memory: 5545, decode.loss_seg: 1.5660, decode.acc_seg: 43.6752, loss: 1.5660
2021-08-14 04:40:24,251 - mmseg - INFO - Iter [6750/160000]	lr: 9.623e-03, eta: 2 days, 7:08:08, time: 1.269, data_time: 0.015, memory: 5545, decode.loss_seg: 1.5789, decode.acc_seg: 42.1594, loss: 1.5789
2021-08-14 04:41:25,832 - mmseg - INFO - Iter [6800/160000]	lr: 9.621e-03, eta: 2 days, 7:05:52, time: 1.232, data_time: 0.014, memory: 5545, decode.loss_seg: 1.6156, decode.acc_seg: 42.7150, loss: 1.6156
2021-08-14 04:42:27,620 - mmseg - INFO - Iter [6850/160000]	lr: 9.618e-03, eta: 2 days, 7:03:42, time: 1.236, data_time: 0.014, memory: 5545, decode.loss_seg: 1.6053, decode.acc_seg: 42.4781, loss: 1.6053
2021-08-14 04:43:30,075 - mmseg - INFO - Iter [6900/160000]	lr: 9.615e-03, eta: 2 days, 7:01:47, time: 1.249, data_time: 0.013, memory: 5545, decode.loss_seg: 1.5997, decode.acc_seg: 43.4640, loss: 1.5997
2021-08-14 04:45:11,850 - mmseg - INFO - Iter [6950/160000]	lr: 9.612e-03, eta: 2 days, 7:14:18, time: 2.035, data_time: 0.732, memory: 5545, decode.loss_seg: 1.5368, decode.acc_seg: 43.0076, loss: 1.5368
2021-08-14 04:46:16,849 - mmseg - INFO - Exp name: fcn_litehr30-without-head_512x512_160k_ade20k.py
2021-08-14 04:46:16,849 - mmseg - INFO - Iter [7000/160000]	lr: 9.609e-03, eta: 2 days, 7:13:14, time: 1.300, data_time: 0.014, memory: 5545, decode.loss_seg: 1.5764, decode.acc_seg: 42.4887, loss: 1.5764
2021-08-14 04:47:19,390 - mmseg - INFO - Iter [7050/160000]	lr: 9.607e-03, eta: 2 days, 7:11:17, time: 1.251, data_time: 0.014, memory: 5545, decode.loss_seg: 1.5679, decode.acc_seg: 43.3553, loss: 1.5679
2021-08-14 04:48:22,548 - mmseg - INFO - Iter [7100/160000]	lr: 9.604e-03, eta: 2 days, 7:09:33, time: 1.263, data_time: 0.014, memory: 5545, decode.loss_seg: 1.5769, decode.acc_seg: 42.3478, loss: 1.5769
2021-08-14 04:49:24,860 - mmseg - INFO - Iter [7150/160000]	lr: 9.601e-03, eta: 2 days, 7:07:32, time: 1.246, data_time: 0.013, memory: 5545, decode.loss_seg: 1.5778, decode.acc_seg: 42.6748, loss: 1.5778
2021-08-14 04:50:27,927 - mmseg - INFO - Iter [7200/160000]	lr: 9.598e-03, eta: 2 days, 7:05:47, time: 1.261, data_time: 0.013, memory: 5545, decode.loss_seg: 1.5133, decode.acc_seg: 43.1176, loss: 1.5133
2021-08-14 04:51:33,688 - mmseg - INFO - Iter [7250/160000]	lr: 9.595e-03, eta: 2 days, 7:05:01, time: 1.316, data_time: 0.014, memory: 5545, decode.loss_seg: 1.5606, decode.acc_seg: 43.2374, loss: 1.5606
2021-08-14 04:52:34,373 - mmseg - INFO - Iter [7300/160000]	lr: 9.593e-03, eta: 2 days, 7:02:28, time: 1.214, data_time: 0.014, memory: 5545, decode.loss_seg: 1.5833, decode.acc_seg: 42.9812, loss: 1.5833
2021-08-14 04:53:35,716 - mmseg - INFO - Iter [7350/160000]	lr: 9.590e-03, eta: 2 days, 7:00:10, time: 1.227, data_time: 0.013, memory: 5545, decode.loss_seg: 1.5571, decode.acc_seg: 43.2405, loss: 1.5571
2021-08-14 04:54:35,755 - mmseg - INFO - Iter [7400/160000]	lr: 9.587e-03, eta: 2 days, 6:57:25, time: 1.200, data_time: 0.013, memory: 5545, decode.loss_seg: 1.5044, decode.acc_seg: 43.3487, loss: 1.5044
2021-08-14 04:55:37,004 - mmseg - INFO - Iter [7450/160000]	lr: 9.584e-03, eta: 2 days, 6:55:08, time: 1.226, data_time: 0.014, memory: 5545, decode.loss_seg: 1.5701, decode.acc_seg: 43.9365, loss: 1.5701
2021-08-14 04:56:37,360 - mmseg - INFO - Iter [7500/160000]	lr: 9.581e-03, eta: 2 days, 6:52:31, time: 1.206, data_time: 0.013, memory: 5545, decode.loss_seg: 1.6132, decode.acc_seg: 42.8480, loss: 1.6132
2021-08-14 04:57:38,734 - mmseg - INFO - Iter [7550/160000]	lr: 9.579e-03, eta: 2 days, 6:50:18, time: 1.228, data_time: 0.014, memory: 5545, decode.loss_seg: 1.5579, decode.acc_seg: 43.4554, loss: 1.5579
2021-08-14 04:59:18,081 - mmseg - INFO - Iter [7600/160000]	lr: 9.576e-03, eta: 2 days, 7:00:47, time: 1.987, data_time: 0.725, memory: 5545, decode.loss_seg: 1.5113, decode.acc_seg: 43.4110, loss: 1.5113
2021-08-14 05:00:19,044 - mmseg - INFO - Iter [7650/160000]	lr: 9.573e-03, eta: 2 days, 6:58:22, time: 1.219, data_time: 0.014, memory: 5545, decode.loss_seg: 1.5514, decode.acc_seg: 43.1336, loss: 1.5514
2021-08-14 05:01:20,951 - mmseg - INFO - Iter [7700/160000]	lr: 9.570e-03, eta: 2 days, 6:56:17, time: 1.238, data_time: 0.013, memory: 5545, decode.loss_seg: 1.5044, decode.acc_seg: 44.7816, loss: 1.5044
2021-08-14 05:02:24,999 - mmseg - INFO - Iter [7750/160000]	lr: 9.567e-03, eta: 2 days, 6:54:55, time: 1.281, data_time: 0.014, memory: 5545, decode.loss_seg: 1.5367, decode.acc_seg: 43.3083, loss: 1.5367
2021-08-14 05:03:31,163 - mmseg - INFO - Iter [7800/160000]	lr: 9.565e-03, eta: 2 days, 6:54:14, time: 1.323, data_time: 0.014, memory: 5545, decode.loss_seg: 1.5618, decode.acc_seg: 42.7184, loss: 1.5618
2021-08-14 05:04:33,105 - mmseg - INFO - Iter [7850/160000]	lr: 9.562e-03, eta: 2 days, 6:52:12, time: 1.240, data_time: 0.014, memory: 5545, decode.loss_seg: 1.5283, decode.acc_seg: 43.6392, loss: 1.5283
2021-08-14 05:05:33,771 - mmseg - INFO - Iter [7900/160000]	lr: 9.559e-03, eta: 2 days, 6:49:45, time: 1.214, data_time: 0.013, memory: 5545, decode.loss_seg: 1.5503, decode.acc_seg: 42.9911, loss: 1.5503
2021-08-14 05:06:36,113 - mmseg - INFO - Iter [7950/160000]	lr: 9.556e-03, eta: 2 days, 6:47:51, time: 1.246, data_time: 0.013, memory: 5545, decode.loss_seg: 1.5411, decode.acc_seg: 43.6075, loss: 1.5411
2021-08-14 05:07:36,011 - mmseg - INFO - Exp name: fcn_litehr30-without-head_512x512_160k_ade20k.py
2021-08-14 05:07:36,011 - mmseg - INFO - Iter [8000/160000]	lr: 9.553e-03, eta: 2 days, 6:45:12, time: 1.199, data_time: 0.014, memory: 5545, decode.loss_seg: 1.5476, decode.acc_seg: 43.3127, loss: 1.5476
2021-08-14 05:08:37,711 - mmseg - INFO - Iter [8050/160000]	lr: 9.551e-03, eta: 2 days, 6:43:08, time: 1.234, data_time: 0.013, memory: 5545, decode.loss_seg: 1.5064, decode.acc_seg: 43.8748, loss: 1.5064
2021-08-14 05:09:40,282 - mmseg - INFO - Iter [8100/160000]	lr: 9.548e-03, eta: 2 days, 6:41:21, time: 1.251, data_time: 0.013, memory: 5545, decode.loss_seg: 1.5538, decode.acc_seg: 44.1848, loss: 1.5538
2021-08-14 05:10:43,668 - mmseg - INFO - Iter [8150/160000]	lr: 9.545e-03, eta: 2 days, 6:39:49, time: 1.267, data_time: 0.014, memory: 5545, decode.loss_seg: 1.5616, decode.acc_seg: 43.3617, loss: 1.5616
2021-08-14 05:11:46,078 - mmseg - INFO - Iter [8200/160000]	lr: 9.542e-03, eta: 2 days, 6:38:00, time: 1.249, data_time: 0.014, memory: 5545, decode.loss_seg: 1.5356, decode.acc_seg: 42.7820, loss: 1.5356
2021-08-14 05:13:24,361 - mmseg - INFO - Iter [8250/160000]	lr: 9.539e-03, eta: 2 days, 6:47:12, time: 1.966, data_time: 0.645, memory: 5545, decode.loss_seg: 1.4935, decode.acc_seg: 44.3977, loss: 1.4935
2021-08-14 05:14:30,666 - mmseg - INFO - Iter [8300/160000]	lr: 9.537e-03, eta: 2 days, 6:46:30, time: 1.326, data_time: 0.013, memory: 5545, decode.loss_seg: 1.5413, decode.acc_seg: 43.9170, loss: 1.5413
2021-08-14 05:15:37,839 - mmseg - INFO - Iter [8350/160000]	lr: 9.534e-03, eta: 2 days, 6:46:05, time: 1.343, data_time: 0.014, memory: 5545, decode.loss_seg: 1.5339, decode.acc_seg: 44.2603, loss: 1.5339
2021-08-14 05:16:40,070 - mmseg - INFO - Iter [8400/160000]	lr: 9.531e-03, eta: 2 days, 6:44:10, time: 1.245, data_time: 0.015, memory: 5545, decode.loss_seg: 1.5024, decode.acc_seg: 44.0629, loss: 1.5024
2021-08-14 05:17:43,376 - mmseg - INFO - Iter [8450/160000]	lr: 9.528e-03, eta: 2 days, 6:42:35, time: 1.266, data_time: 0.014, memory: 5545, decode.loss_seg: 1.5036, decode.acc_seg: 43.7211, loss: 1.5036
2021-08-14 05:18:47,037 - mmseg - INFO - Iter [8500/160000]	lr: 9.525e-03, eta: 2 days, 6:41:06, time: 1.273, data_time: 0.014, memory: 5545, decode.loss_seg: 1.5238, decode.acc_seg: 43.3668, loss: 1.5238
2021-08-14 05:19:47,699 - mmseg - INFO - Iter [8550/160000]	lr: 9.523e-03, eta: 2 days, 6:38:45, time: 1.213, data_time: 0.014, memory: 5545, decode.loss_seg: 1.5388, decode.acc_seg: 43.3802, loss: 1.5388
2021-08-14 05:20:51,162 - mmseg - INFO - Iter [8600/160000]	lr: 9.520e-03, eta: 2 days, 6:37:15, time: 1.270, data_time: 0.014, memory: 5545, decode.loss_seg: 1.4995, decode.acc_seg: 44.3475, loss: 1.4995
2021-08-14 05:21:51,457 - mmseg - INFO - Iter [8650/160000]	lr: 9.517e-03, eta: 2 days, 6:34:48, time: 1.205, data_time: 0.013, memory: 5545, decode.loss_seg: 1.5149, decode.acc_seg: 44.2190, loss: 1.5149
2021-08-14 05:22:54,591 - mmseg - INFO - Iter [8700/160000]	lr: 9.514e-03, eta: 2 days, 6:33:12, time: 1.263, data_time: 0.014, memory: 5545, decode.loss_seg: 1.5026, decode.acc_seg: 44.6153, loss: 1.5026
2021-08-14 05:23:58,069 - mmseg - INFO - Iter [8750/160000]	lr: 9.511e-03, eta: 2 days, 6:31:43, time: 1.270, data_time: 0.014, memory: 5545, decode.loss_seg: 1.4960, decode.acc_seg: 43.9566, loss: 1.4960
2021-08-14 05:25:02,157 - mmseg - INFO - Iter [8800/160000]	lr: 9.509e-03, eta: 2 days, 6:30:24, time: 1.281, data_time: 0.013, memory: 5545, decode.loss_seg: 1.4956, decode.acc_seg: 43.8839, loss: 1.4956
2021-08-14 05:26:40,131 - mmseg - INFO - Iter [8850/160000]	lr: 9.506e-03, eta: 2 days, 6:38:45, time: 1.961, data_time: 0.731, memory: 5545, decode.loss_seg: 1.5353, decode.acc_seg: 43.6292, loss: 1.5353
2021-08-14 05:27:40,338 - mmseg - INFO - Iter [8900/160000]	lr: 9.503e-03, eta: 2 days, 6:36:17, time: 1.204, data_time: 0.013, memory: 5545, decode.loss_seg: 1.4867, decode.acc_seg: 44.2654, loss: 1.4867
2021-08-14 05:28:41,000 - mmseg - INFO - Iter [8950/160000]	lr: 9.500e-03, eta: 2 days, 6:33:57, time: 1.213, data_time: 0.013, memory: 5545, decode.loss_seg: 1.4945, decode.acc_seg: 44.1299, loss: 1.4945
2021-08-14 05:29:42,936 - mmseg - INFO - Exp name: fcn_litehr30-without-head_512x512_160k_ade20k.py
2021-08-14 05:29:42,937 - mmseg - INFO - Iter [9000/160000]	lr: 9.497e-03, eta: 2 days, 6:32:00, time: 1.238, data_time: 0.014, memory: 5545, decode.loss_seg: 1.5226, decode.acc_seg: 43.8568, loss: 1.5226
2021-08-14 05:30:44,006 - mmseg - INFO - Iter [9050/160000]	lr: 9.495e-03, eta: 2 days, 6:29:50, time: 1.222, data_time: 0.014, memory: 5545, decode.loss_seg: 1.4872, decode.acc_seg: 44.2741, loss: 1.4872
2021-08-14 05:31:46,344 - mmseg - INFO - Iter [9100/160000]	lr: 9.492e-03, eta: 2 days, 6:28:01, time: 1.246, data_time: 0.013, memory: 5545, decode.loss_seg: 1.4776, decode.acc_seg: 44.4366, loss: 1.4776
2021-08-14 05:32:49,372 - mmseg - INFO - Iter [9150/160000]	lr: 9.489e-03, eta: 2 days, 6:26:24, time: 1.261, data_time: 0.014, memory: 5545, decode.loss_seg: 1.5077, decode.acc_seg: 44.6725, loss: 1.5077
2021-08-14 05:33:51,249 - mmseg - INFO - Iter [9200/160000]	lr: 9.486e-03, eta: 2 days, 6:24:29, time: 1.238, data_time: 0.014, memory: 5545, decode.loss_seg: 1.5134, decode.acc_seg: 43.8678, loss: 1.5134
2021-08-14 05:34:54,338 - mmseg - INFO - Iter [9250/160000]	lr: 9.483e-03, eta: 2 days, 6:22:53, time: 1.261, data_time: 0.013, memory: 5545, decode.loss_seg: 1.4255, decode.acc_seg: 44.4871, loss: 1.4255
2021-08-14 05:35:57,699 - mmseg - INFO - Iter [9300/160000]	lr: 9.481e-03, eta: 2 days, 6:21:23, time: 1.267, data_time: 0.014, memory: 5545, decode.loss_seg: 1.4913, decode.acc_seg: 44.1940, loss: 1.4913
2021-08-14 05:37:04,680 - mmseg - INFO - Iter [9350/160000]	lr: 9.478e-03, eta: 2 days, 6:20:50, time: 1.339, data_time: 0.013, memory: 5545, decode.loss_seg: 1.5443, decode.acc_seg: 44.0499, loss: 1.5443
2021-08-14 05:38:06,200 - mmseg - INFO - Iter [9400/160000]	lr: 9.475e-03, eta: 2 days, 6:18:52, time: 1.232, data_time: 0.014, memory: 5545, decode.loss_seg: 1.4870, decode.acc_seg: 44.0645, loss: 1.4870
2021-08-14 05:39:08,408 - mmseg - INFO - Iter [9450/160000]	lr: 9.472e-03, eta: 2 days, 6:17:03, time: 1.243, data_time: 0.013, memory: 5545, decode.loss_seg: 1.5259, decode.acc_seg: 42.8248, loss: 1.5259
2021-08-14 05:40:44,726 - mmseg - INFO - Iter [9500/160000]	lr: 9.469e-03, eta: 2 days, 6:24:17, time: 1.927, data_time: 0.694, memory: 5545, decode.loss_seg: 1.4292, decode.acc_seg: 46.1320, loss: 1.4292
2021-08-14 05:41:47,138 - mmseg - INFO - Iter [9550/160000]	lr: 9.467e-03, eta: 2 days, 6:22:29, time: 1.247, data_time: 0.013, memory: 5545, decode.loss_seg: 1.4916, decode.acc_seg: 43.7705, loss: 1.4916
2021-08-14 05:42:52,877 - mmseg - INFO - Iter [9600/160000]	lr: 9.464e-03, eta: 2 days, 6:21:35, time: 1.315, data_time: 0.013, memory: 5545, decode.loss_seg: 1.5001, decode.acc_seg: 44.5533, loss: 1.5001
2021-08-14 05:43:58,485 - mmseg - INFO - Iter [9650/160000]	lr: 9.461e-03, eta: 2 days, 6:20:38, time: 1.312, data_time: 0.013, memory: 5545, decode.loss_seg: 1.5173, decode.acc_seg: 44.2814, loss: 1.5173
2021-08-14 05:45:03,553 - mmseg - INFO - Iter [9700/160000]	lr: 9.458e-03, eta: 2 days, 6:19:33, time: 1.301, data_time: 0.014, memory: 5545, decode.loss_seg: 1.4782, decode.acc_seg: 44.2424, loss: 1.4782
2021-08-14 05:46:10,027 - mmseg - INFO - Iter [9750/160000]	lr: 9.455e-03, eta: 2 days, 6:18:50, time: 1.329, data_time: 0.014, memory: 5545, decode.loss_seg: 1.4271, decode.acc_seg: 46.6718, loss: 1.4271
2021-08-14 05:47:14,382 - mmseg - INFO - Iter [9800/160000]	lr: 9.453e-03, eta: 2 days, 6:17:34, time: 1.288, data_time: 0.014, memory: 5545, decode.loss_seg: 1.4815, decode.acc_seg: 44.1632, loss: 1.4815
2021-08-14 05:48:16,840 - mmseg - INFO - Iter [9850/160000]	lr: 9.450e-03, eta: 2 days, 6:15:49, time: 1.249, data_time: 0.013, memory: 5545, decode.loss_seg: 1.4563, decode.acc_seg: 45.1738, loss: 1.4563
2021-08-14 05:49:16,338 - mmseg - INFO - Iter [9900/160000]	lr: 9.447e-03, eta: 2 days, 6:13:20, time: 1.190, data_time: 0.013, memory: 5545, decode.loss_seg: 1.4871, decode.acc_seg: 45.9921, loss: 1.4871
2021-08-14 05:50:19,446 - mmseg - INFO - Iter [9950/160000]	lr: 9.444e-03, eta: 2 days, 6:11:46, time: 1.261, data_time: 0.013, memory: 5545, decode.loss_seg: 1.4598, decode.acc_seg: 43.8767, loss: 1.4598
2021-08-14 05:51:25,035 - mmseg - INFO - Exp name: fcn_litehr30-without-head_512x512_160k_ade20k.py
2021-08-14 05:51:25,035 - mmseg - INFO - Iter [10000/160000]	lr: 9.441e-03, eta: 2 days, 6:10:50, time: 1.313, data_time: 0.014, memory: 5545, decode.loss_seg: 1.4820, decode.acc_seg: 44.8320, loss: 1.4820
2021-08-14 05:52:26,973 - mmseg - INFO - Iter [10050/160000]	lr: 9.439e-03, eta: 2 days, 6:08:59, time: 1.239, data_time: 0.013, memory: 5545, decode.loss_seg: 1.4544, decode.acc_seg: 45.3971, loss: 1.4544
2021-08-14 05:54:04,535 - mmseg - INFO - Iter [10100/160000]	lr: 9.436e-03, eta: 2 days, 6:15:57, time: 1.951, data_time: 0.667, memory: 5545, decode.loss_seg: 1.4764, decode.acc_seg: 44.5975, loss: 1.4764
2021-08-14 05:55:07,128 - mmseg - INFO - Iter [10150/160000]	lr: 9.433e-03, eta: 2 days, 6:14:14, time: 1.252, data_time: 0.013, memory: 5545, decode.loss_seg: 1.4182, decode.acc_seg: 45.7135, loss: 1.4182
2021-08-14 05:56:11,555 - mmseg - INFO - Iter [10200/160000]	lr: 9.430e-03, eta: 2 days, 6:12:58, time: 1.288, data_time: 0.013, memory: 5545, decode.loss_seg: 1.4188, decode.acc_seg: 46.7623, loss: 1.4188
2021-08-14 05:57:16,719 - mmseg - INFO - Iter [10250/160000]	lr: 9.427e-03, eta: 2 days, 6:11:54, time: 1.304, data_time: 0.013, memory: 5545, decode.loss_seg: 1.4728, decode.acc_seg: 45.0351, loss: 1.4728
2021-08-14 05:58:19,347 - mmseg - INFO - Iter [10300/160000]	lr: 9.425e-03, eta: 2 days, 6:10:12, time: 1.253, data_time: 0.012, memory: 5545, decode.loss_seg: 1.4427, decode.acc_seg: 45.3331, loss: 1.4427
2021-08-14 05:59:17,992 - mmseg - INFO - Iter [10350/160000]	lr: 9.422e-03, eta: 2 days, 6:07:33, time: 1.173, data_time: 0.012, memory: 5545, decode.loss_seg: 1.4693, decode.acc_seg: 45.0627, loss: 1.4693
2021-08-14 06:00:19,128 - mmseg - INFO - Iter [10400/160000]	lr: 9.419e-03, eta: 2 days, 6:05:30, time: 1.222, data_time: 0.012, memory: 5545, decode.loss_seg: 1.4470, decode.acc_seg: 45.3948, loss: 1.4470
2021-08-14 06:01:21,506 - mmseg - INFO - Iter [10450/160000]	lr: 9.416e-03, eta: 2 days, 6:03:46, time: 1.248, data_time: 0.013, memory: 5545, decode.loss_seg: 1.4897, decode.acc_seg: 44.3954, loss: 1.4897
2021-08-14 06:02:27,216 - mmseg - INFO - Iter [10500/160000]	lr: 9.413e-03, eta: 2 days, 6:02:51, time: 1.315, data_time: 0.013, memory: 5545, decode.loss_seg: 1.4586, decode.acc_seg: 44.6603, loss: 1.4586
2021-08-14 06:03:30,502 - mmseg - INFO - Iter [10550/160000]	lr: 9.411e-03, eta: 2 days, 6:01:20, time: 1.265, data_time: 0.013, memory: 5545, decode.loss_seg: 1.4551, decode.acc_seg: 44.8580, loss: 1.4551
2021-08-14 06:04:31,516 - mmseg - INFO - Iter [10600/160000]	lr: 9.408e-03, eta: 2 days, 5:59:18, time: 1.221, data_time: 0.013, memory: 5545, decode.loss_seg: 1.4391, decode.acc_seg: 46.3918, loss: 1.4391
2021-08-14 06:05:32,501 - mmseg - INFO - Iter [10650/160000]	lr: 9.405e-03, eta: 2 days, 5:57:16, time: 1.219, data_time: 0.013, memory: 5545, decode.loss_seg: 1.4101, decode.acc_seg: 45.5636, loss: 1.4101
2021-08-14 06:06:34,005 - mmseg - INFO - Iter [10700/160000]	lr: 9.402e-03, eta: 2 days, 5:55:22, time: 1.231, data_time: 0.014, memory: 5545, decode.loss_seg: 1.5033, decode.acc_seg: 44.4115, loss: 1.5033
2021-08-14 06:08:20,743 - mmseg - INFO - Iter [10750/160000]	lr: 9.399e-03, eta: 2 days, 6:03:56, time: 2.135, data_time: 0.928, memory: 5545, decode.loss_seg: 1.4266, decode.acc_seg: 45.1733, loss: 1.4266
2021-08-14 06:09:23,102 - mmseg - INFO - Iter [10800/160000]	lr: 9.397e-03, eta: 2 days, 6:02:11, time: 1.246, data_time: 0.014, memory: 5545, decode.loss_seg: 1.4179, decode.acc_seg: 45.4066, loss: 1.4179
2021-08-14 06:10:28,115 - mmseg - INFO - Iter [10850/160000]	lr: 9.394e-03, eta: 2 days, 6:01:04, time: 1.300, data_time: 0.014, memory: 5545, decode.loss_seg: 1.4685, decode.acc_seg: 45.0261, loss: 1.4685
2021-08-14 06:11:30,899 - mmseg - INFO - Iter [10900/160000]	lr: 9.391e-03, eta: 2 days, 5:59:25, time: 1.256, data_time: 0.014, memory: 5545, decode.loss_seg: 1.4576, decode.acc_seg: 45.5428, loss: 1.4576
2021-08-14 06:12:37,295 - mmseg - INFO - Iter [10950/160000]	lr: 9.388e-03, eta: 2 days, 5:58:37, time: 1.328, data_time: 0.014, memory: 5545, decode.loss_seg: 1.4233, decode.acc_seg: 44.5133, loss: 1.4233
2021-08-14 06:13:44,544 - mmseg - INFO - Exp name: fcn_litehr30-without-head_512x512_160k_ade20k.py
2021-08-14 06:13:44,545 - mmseg - INFO - Iter [11000/160000]	lr: 9.385e-03, eta: 2 days, 5:58:00, time: 1.345, data_time: 0.014, memory: 5545, decode.loss_seg: 1.4567, decode.acc_seg: 45.7517, loss: 1.4567
2021-08-14 06:14:48,497 - mmseg - INFO - Iter [11050/160000]	lr: 9.383e-03, eta: 2 days, 5:56:38, time: 1.279, data_time: 0.014, memory: 5545, decode.loss_seg: 1.4524, decode.acc_seg: 45.1656, loss: 1.4524
2021-08-14 06:15:48,418 - mmseg - INFO - Iter [11100/160000]	lr: 9.380e-03, eta: 2 days, 5:54:22, time: 1.199, data_time: 0.014, memory: 5545, decode.loss_seg: 1.4480, decode.acc_seg: 44.8255, loss: 1.4480
2021-08-14 06:16:51,864 - mmseg - INFO - Iter [11150/160000]	lr: 9.377e-03, eta: 2 days, 5:52:54, time: 1.269, data_time: 0.013, memory: 5545, decode.loss_seg: 1.4648, decode.acc_seg: 44.6219, loss: 1.4648
2021-08-14 06:17:55,329 - mmseg - INFO - Iter [11200/160000]	lr: 9.374e-03, eta: 2 days, 5:51:27, time: 1.269, data_time: 0.013, memory: 5545, decode.loss_seg: 1.4071, decode.acc_seg: 46.1205, loss: 1.4071
2021-08-14 06:18:56,043 - mmseg - INFO - Iter [11250/160000]	lr: 9.371e-03, eta: 2 days, 5:49:23, time: 1.214, data_time: 0.013, memory: 5545, decode.loss_seg: 1.4571, decode.acc_seg: 44.6933, loss: 1.4571
2021-08-14 06:19:58,665 - mmseg - INFO - Iter [11300/160000]	lr: 9.369e-03, eta: 2 days, 5:47:44, time: 1.252, data_time: 0.013, memory: 5545, decode.loss_seg: 1.4688, decode.acc_seg: 45.3748, loss: 1.4688
2021-08-14 06:21:04,108 - mmseg - INFO - Iter [11350/160000]	lr: 9.366e-03, eta: 2 days, 5:46:43, time: 1.309, data_time: 0.014, memory: 5545, decode.loss_seg: 1.4104, decode.acc_seg: 46.5307, loss: 1.4104
2021-08-14 06:22:40,460 - mmseg - INFO - Iter [11400/160000]	lr: 9.363e-03, eta: 2 days, 5:52:26, time: 1.928, data_time: 0.702, memory: 5545, decode.loss_seg: 1.4199, decode.acc_seg: 45.3650, loss: 1.4199
2021-08-14 06:23:42,079 - mmseg - INFO - Iter [11450/160000]	lr: 9.360e-03, eta: 2 days, 5:50:33, time: 1.232, data_time: 0.013, memory: 5545, decode.loss_seg: 1.4556, decode.acc_seg: 46.0657, loss: 1.4556
2021-08-14 06:24:41,413 - mmseg - INFO - Iter [11500/160000]	lr: 9.357e-03, eta: 2 days, 5:48:12, time: 1.187, data_time: 0.013, memory: 5545, decode.loss_seg: 1.4514, decode.acc_seg: 45.0975, loss: 1.4514
2021-08-14 06:25:42,648 - mmseg - INFO - Iter [11550/160000]	lr: 9.354e-03, eta: 2 days, 5:46:15, time: 1.225, data_time: 0.013, memory: 5545, decode.loss_seg: 1.4360, decode.acc_seg: 46.3451, loss: 1.4360
2021-08-14 06:26:44,100 - mmseg - INFO - Iter [11600/160000]	lr: 9.352e-03, eta: 2 days, 5:44:22, time: 1.229, data_time: 0.013, memory: 5545, decode.loss_seg: 1.4301, decode.acc_seg: 45.6512, loss: 1.4301
2021-08-14 06:27:46,993 - mmseg - INFO - Iter [11650/160000]	lr: 9.349e-03, eta: 2 days, 5:42:48, time: 1.258, data_time: 0.013, memory: 5545, decode.loss_seg: 1.4237, decode.acc_seg: 46.2668, loss: 1.4237
2021-08-14 06:28:47,335 - mmseg - INFO - Iter [11700/160000]	lr: 9.346e-03, eta: 2 days, 5:40:41, time: 1.206, data_time: 0.013, memory: 5545, decode.loss_seg: 1.4202, decode.acc_seg: 46.3457, loss: 1.4202
2021-08-14 06:29:48,531 - mmseg - INFO - Iter [11750/160000]	lr: 9.343e-03, eta: 2 days, 5:38:46, time: 1.225, data_time: 0.014, memory: 5545, decode.loss_seg: 1.4075, decode.acc_seg: 46.1490, loss: 1.4075
2021-08-14 06:30:49,487 - mmseg - INFO - Iter [11800/160000]	lr: 9.340e-03, eta: 2 days, 5:36:48, time: 1.218, data_time: 0.013, memory: 5545, decode.loss_seg: 1.4419, decode.acc_seg: 45.6948, loss: 1.4419
2021-08-14 06:31:49,774 - mmseg - INFO - Iter [11850/160000]	lr: 9.338e-03, eta: 2 days, 5:34:43, time: 1.207, data_time: 0.014, memory: 5545, decode.loss_seg: 1.4650, decode.acc_seg: 44.5966, loss: 1.4650
2021-08-14 06:32:49,495 - mmseg - INFO - Iter [11900/160000]	lr: 9.335e-03, eta: 2 days, 5:32:31, time: 1.194, data_time: 0.013, memory: 5545, decode.loss_seg: 1.4081, decode.acc_seg: 45.3089, loss: 1.4081
2021-08-14 06:33:51,276 - mmseg - INFO - Iter [11950/160000]	lr: 9.332e-03, eta: 2 days, 5:30:45, time: 1.235, data_time: 0.013, memory: 5545, decode.loss_seg: 1.4273, decode.acc_seg: 46.4639, loss: 1.4273
2021-08-14 06:35:29,514 - mmseg - INFO - Exp name: fcn_litehr30-without-head_512x512_160k_ade20k.py
2021-08-14 06:35:29,518 - mmseg - INFO - Iter [12000/160000]	lr: 9.329e-03, eta: 2 days, 5:36:29, time: 1.965, data_time: 0.663, memory: 5545, decode.loss_seg: 1.4536, decode.acc_seg: 44.9185, loss: 1.4536
2021-08-14 06:36:32,668 - mmseg - INFO - Iter [12050/160000]	lr: 9.326e-03, eta: 2 days, 5:34:59, time: 1.262, data_time: 0.014, memory: 5545, decode.loss_seg: 1.4335, decode.acc_seg: 45.3232, loss: 1.4335
2021-08-14 06:37:36,406 - mmseg - INFO - Iter [12100/160000]	lr: 9.324e-03, eta: 2 days, 5:33:36, time: 1.275, data_time: 0.014, memory: 5545, decode.loss_seg: 1.4215, decode.acc_seg: 45.9991, loss: 1.4215
2021-08-14 06:38:38,029 - mmseg - INFO - Iter [12150/160000]	lr: 9.321e-03, eta: 2 days, 5:31:47, time: 1.232, data_time: 0.013, memory: 5545, decode.loss_seg: 1.4331, decode.acc_seg: 45.8915, loss: 1.4331
2021-08-14 06:39:40,882 - mmseg - INFO - Iter [12200/160000]	lr: 9.318e-03, eta: 2 days, 5:30:14, time: 1.257, data_time: 0.013, memory: 5545, decode.loss_seg: 1.4288, decode.acc_seg: 45.3273, loss: 1.4288
2021-08-14 06:40:46,203 - mmseg - INFO - Iter [12250/160000]	lr: 9.315e-03, eta: 2 days, 5:29:11, time: 1.307, data_time: 0.014, memory: 5545, decode.loss_seg: 1.4183, decode.acc_seg: 46.4746, loss: 1.4183
2021-08-14 06:41:45,678 - mmseg - INFO - Iter [12300/160000]	lr: 9.312e-03, eta: 2 days, 5:26:58, time: 1.189, data_time: 0.013, memory: 5545, decode.loss_seg: 1.4213, decode.acc_seg: 45.6554, loss: 1.4213
2021-08-14 06:42:48,207 - mmseg - INFO - Iter [12350/160000]	lr: 9.310e-03, eta: 2 days, 5:25:21, time: 1.250, data_time: 0.013, memory: 5545, decode.loss_seg: 1.4125, decode.acc_seg: 46.1016, loss: 1.4125
2021-08-14 06:43:51,354 - mmseg - INFO - Iter [12400/160000]	lr: 9.307e-03, eta: 2 days, 5:23:52, time: 1.263, data_time: 0.014, memory: 5545, decode.loss_seg: 1.3863, decode.acc_seg: 45.8089, loss: 1.3863
2021-08-14 06:44:50,443 - mmseg - INFO - Iter [12450/160000]	lr: 9.304e-03, eta: 2 days, 5:21:36, time: 1.182, data_time: 0.014, memory: 5545, decode.loss_seg: 1.4120, decode.acc_seg: 45.8674, loss: 1.4120
2021-08-14 06:45:49,709 - mmseg - INFO - Iter [12500/160000]	lr: 9.301e-03, eta: 2 days, 5:19:22, time: 1.185, data_time: 0.013, memory: 5545, decode.loss_seg: 1.4076, decode.acc_seg: 47.0814, loss: 1.4076
2021-08-14 06:46:49,116 - mmseg - INFO - Iter [12550/160000]	lr: 9.298e-03, eta: 2 days, 5:17:10, time: 1.188, data_time: 0.013, memory: 5545, decode.loss_seg: 1.4111, decode.acc_seg: 45.4813, loss: 1.4111
2021-08-14 06:47:50,654 - mmseg - INFO - Iter [12600/160000]	lr: 9.296e-03, eta: 2 days, 5:15:24, time: 1.231, data_time: 0.013, memory: 5545, decode.loss_seg: 1.3898, decode.acc_seg: 46.6019, loss: 1.3898
2021-08-14 06:49:26,938 - mmseg - INFO - Iter [12650/160000]	lr: 9.293e-03, eta: 2 days, 5:20:23, time: 1.926, data_time: 0.666, memory: 5545, decode.loss_seg: 1.3867, decode.acc_seg: 46.1662, loss: 1.3867
2021-08-14 06:50:28,781 - mmseg - INFO - Iter [12700/160000]	lr: 9.290e-03, eta: 2 days, 5:18:40, time: 1.237, data_time: 0.013, memory: 5545, decode.loss_seg: 1.3832, decode.acc_seg: 46.4301, loss: 1.3832
2021-08-14 06:51:31,581 - mmseg - INFO - Iter [12750/160000]	lr: 9.287e-03, eta: 2 days, 5:17:07, time: 1.255, data_time: 0.013, memory: 5545, decode.loss_seg: 1.3700, decode.acc_seg: 46.9721, loss: 1.3700
2021-08-14 06:52:37,531 - mmseg - INFO - Iter [12800/160000]	lr: 9.284e-03, eta: 2 days, 5:16:11, time: 1.319, data_time: 0.014, memory: 5545, decode.loss_seg: 1.4018, decode.acc_seg: 46.3842, loss: 1.4018
2021-08-14 06:53:39,276 - mmseg - INFO - Iter [12850/160000]	lr: 9.282e-03, eta: 2 days, 5:14:28, time: 1.236, data_time: 0.014, memory: 5545, decode.loss_seg: 1.3993, decode.acc_seg: 46.0251, loss: 1.3993
2021-08-14 06:54:41,021 - mmseg - INFO - Iter [12900/160000]	lr: 9.279e-03, eta: 2 days, 5:12:44, time: 1.234, data_time: 0.014, memory: 5545, decode.loss_seg: 1.3775, decode.acc_seg: 46.1655, loss: 1.3775
2021-08-14 06:55:44,388 - mmseg - INFO - Iter [12950/160000]	lr: 9.276e-03, eta: 2 days, 5:11:19, time: 1.267, data_time: 0.014, memory: 5545, decode.loss_seg: 1.4009, decode.acc_seg: 46.9061, loss: 1.4009
2021-08-14 06:56:45,510 - mmseg - INFO - Exp name: fcn_litehr30-without-head_512x512_160k_ade20k.py
2021-08-14 06:56:45,511 - mmseg - INFO - Iter [13000/160000]	lr: 9.273e-03, eta: 2 days, 5:09:29, time: 1.223, data_time: 0.014, memory: 5545, decode.loss_seg: 1.4101, decode.acc_seg: 47.0956, loss: 1.4101
2021-08-14 06:57:46,473 - mmseg - INFO - Iter [13050/160000]	lr: 9.270e-03, eta: 2 days, 5:07:37, time: 1.220, data_time: 0.014, memory: 5545, decode.loss_seg: 1.3737, decode.acc_seg: 46.9642, loss: 1.3737
2021-08-14 06:58:45,820 - mmseg - INFO - Iter [13100/160000]	lr: 9.267e-03, eta: 2 days, 5:05:28, time: 1.187, data_time: 0.013, memory: 5545, decode.loss_seg: 1.3447, decode.acc_seg: 45.6892, loss: 1.3447
2021-08-14 06:59:45,661 - mmseg - INFO - Iter [13150/160000]	lr: 9.265e-03, eta: 2 days, 5:03:25, time: 1.197, data_time: 0.014, memory: 5545, decode.loss_seg: 1.4210, decode.acc_seg: 44.9751, loss: 1.4210
2021-08-14 07:00:46,126 - mmseg - INFO - Iter [13200/160000]	lr: 9.262e-03, eta: 2 days, 5:01:29, time: 1.209, data_time: 0.014, memory: 5545, decode.loss_seg: 1.3954, decode.acc_seg: 46.0945, loss: 1.3954
2021-08-14 07:01:46,026 - mmseg - INFO - Iter [13250/160000]	lr: 9.259e-03, eta: 2 days, 4:59:27, time: 1.198, data_time: 0.014, memory: 5545, decode.loss_seg: 1.4021, decode.acc_seg: 45.5274, loss: 1.4021
2021-08-14 07:03:23,628 - mmseg - INFO - Iter [13300/160000]	lr: 9.256e-03, eta: 2 days, 5:04:22, time: 1.952, data_time: 0.709, memory: 5545, decode.loss_seg: 1.3866, decode.acc_seg: 45.9869, loss: 1.3866
2021-08-14 07:04:24,159 - mmseg - INFO - Iter [13350/160000]	lr: 9.253e-03, eta: 2 days, 5:02:26, time: 1.210, data_time: 0.014, memory: 5545, decode.loss_seg: 1.3684, decode.acc_seg: 46.5873, loss: 1.3684
2021-08-14 07:05:29,948 - mmseg - INFO - Iter [13400/160000]	lr: 9.251e-03, eta: 2 days, 5:01:28, time: 1.316, data_time: 0.015, memory: 5545, decode.loss_seg: 1.3537, decode.acc_seg: 47.3091, loss: 1.3537
2021-08-14 07:06:31,554 - mmseg - INFO - Iter [13450/160000]	lr: 9.248e-03, eta: 2 days, 4:59:45, time: 1.233, data_time: 0.015, memory: 5545, decode.loss_seg: 1.4248, decode.acc_seg: 45.9171, loss: 1.4248
2021-08-14 07:07:33,126 - mmseg - INFO - Iter [13500/160000]	lr: 9.245e-03, eta: 2 days, 4:58:02, time: 1.231, data_time: 0.015, memory: 5545, decode.loss_seg: 1.3961, decode.acc_seg: 46.1889, loss: 1.3961
2021-08-14 07:08:33,133 - mmseg - INFO - Iter [13550/160000]	lr: 9.242e-03, eta: 2 days, 4:56:02, time: 1.200, data_time: 0.014, memory: 5545, decode.loss_seg: 1.3499, decode.acc_seg: 46.5448, loss: 1.3499
2021-08-14 07:09:33,552 - mmseg - INFO - Iter [13600/160000]	lr: 9.239e-03, eta: 2 days, 4:54:07, time: 1.208, data_time: 0.014, memory: 5545, decode.loss_seg: 1.4105, decode.acc_seg: 46.9829, loss: 1.4105
2021-08-14 07:10:35,794 - mmseg - INFO - Iter [13650/160000]	lr: 9.237e-03, eta: 2 days, 4:52:32, time: 1.245, data_time: 0.014, memory: 5545, decode.loss_seg: 1.3592, decode.acc_seg: 47.3121, loss: 1.3592
2021-08-14 07:11:36,836 - mmseg - INFO - Iter [13700/160000]	lr: 9.234e-03, eta: 2 days, 4:50:44, time: 1.220, data_time: 0.014, memory: 5545, decode.loss_seg: 1.4187, decode.acc_seg: 45.9974, loss: 1.4187
2021-08-14 07:12:37,817 - mmseg - INFO - Iter [13750/160000]	lr: 9.231e-03, eta: 2 days, 4:48:56, time: 1.220, data_time: 0.014, memory: 5545, decode.loss_seg: 1.3977, decode.acc_seg: 46.3812, loss: 1.3977
2021-08-14 07:13:39,349 - mmseg - INFO - Iter [13800/160000]	lr: 9.228e-03, eta: 2 days, 4:47:15, time: 1.231, data_time: 0.014, memory: 5545, decode.loss_seg: 1.3635, decode.acc_seg: 46.8832, loss: 1.3635
2021-08-14 07:14:39,757 - mmseg - INFO - Iter [13850/160000]	lr: 9.225e-03, eta: 2 days, 4:45:21, time: 1.207, data_time: 0.014, memory: 5545, decode.loss_seg: 1.4114, decode.acc_seg: 46.1196, loss: 1.4114
2021-08-14 07:16:17,406 - mmseg - INFO - Iter [13900/160000]	lr: 9.223e-03, eta: 2 days, 4:49:59, time: 1.953, data_time: 0.662, memory: 5545, decode.loss_seg: 1.4022, decode.acc_seg: 46.1370, loss: 1.4022
2021-08-14 07:17:18,566 - mmseg - INFO - Iter [13950/160000]	lr: 9.220e-03, eta: 2 days, 4:48:13, time: 1.224, data_time: 0.015, memory: 5545, decode.loss_seg: 1.3705, decode.acc_seg: 46.0863, loss: 1.3705
2021-08-14 07:18:19,613 - mmseg - INFO - Exp name: fcn_litehr30-without-head_512x512_160k_ade20k.py
2021-08-14 07:18:19,613 - mmseg - INFO - Iter [14000/160000]	lr: 9.217e-03, eta: 2 days, 4:46:26, time: 1.220, data_time: 0.012, memory: 5545, decode.loss_seg: 1.4179, decode.acc_seg: 46.4097, loss: 1.4179
2021-08-14 07:19:18,903 - mmseg - INFO - Iter [14050/160000]	lr: 9.214e-03, eta: 2 days, 4:44:21, time: 1.186, data_time: 0.013, memory: 5545, decode.loss_seg: 1.3401, decode.acc_seg: 46.8225, loss: 1.3401
2021-08-14 07:20:22,846 - mmseg - INFO - Iter [14100/160000]	lr: 9.211e-03, eta: 2 days, 4:43:04, time: 1.278, data_time: 0.013, memory: 5545, decode.loss_seg: 1.4039, decode.acc_seg: 45.4824, loss: 1.4039
2021-08-14 07:21:29,386 - mmseg - INFO - Iter [14150/160000]	lr: 9.208e-03, eta: 2 days, 4:42:15, time: 1.331, data_time: 0.013, memory: 5545, decode.loss_seg: 1.3691, decode.acc_seg: 46.3806, loss: 1.3691
2021-08-14 07:22:35,121 - mmseg - INFO - Iter [14200/160000]	lr: 9.206e-03, eta: 2 days, 4:41:17, time: 1.314, data_time: 0.013, memory: 5545, decode.loss_seg: 1.3771, decode.acc_seg: 47.1693, loss: 1.3771
2021-08-14 07:23:40,186 - mmseg - INFO - Iter [14250/160000]	lr: 9.203e-03, eta: 2 days, 4:40:12, time: 1.302, data_time: 0.014, memory: 5545, decode.loss_seg: 1.3759, decode.acc_seg: 47.0394, loss: 1.3759
2021-08-14 07:24:43,617 - mmseg - INFO - Iter [14300/160000]	lr: 9.200e-03, eta: 2 days, 4:38:51, time: 1.269, data_time: 0.014, memory: 5545, decode.loss_seg: 1.3652, decode.acc_seg: 46.1911, loss: 1.3652
2021-08-14 07:25:47,840 - mmseg - INFO - Iter [14350/160000]	lr: 9.197e-03, eta: 2 days, 4:37:37, time: 1.284, data_time: 0.014, memory: 5545, decode.loss_seg: 1.3452, decode.acc_seg: 47.6103, loss: 1.3452
2021-08-14 07:26:50,988 - mmseg - INFO - Iter [14400/160000]	lr: 9.194e-03, eta: 2 days, 4:36:13, time: 1.264, data_time: 0.014, memory: 5545, decode.loss_seg: 1.3801, decode.acc_seg: 47.3396, loss: 1.3801
2021-08-14 07:27:52,429 - mmseg - INFO - Iter [14450/160000]	lr: 9.192e-03, eta: 2 days, 4:34:32, time: 1.228, data_time: 0.013, memory: 5545, decode.loss_seg: 1.3511, decode.acc_seg: 47.0522, loss: 1.3511
2021-08-14 07:28:55,766 - mmseg - INFO - Iter [14500/160000]	lr: 9.189e-03, eta: 2 days, 4:33:10, time: 1.267, data_time: 0.014, memory: 5545, decode.loss_seg: 1.3242, decode.acc_seg: 48.3791, loss: 1.3242
2021-08-14 07:30:31,795 - mmseg - INFO - Iter [14550/160000]	lr: 9.186e-03, eta: 2 days, 4:37:15, time: 1.921, data_time: 0.662, memory: 5545, decode.loss_seg: 1.3835, decode.acc_seg: 45.9669, loss: 1.3835
2021-08-14 07:31:33,634 - mmseg - INFO - Iter [14600/160000]	lr: 9.183e-03, eta: 2 days, 4:35:37, time: 1.237, data_time: 0.015, memory: 5545, decode.loss_seg: 1.3784, decode.acc_seg: 46.3394, loss: 1.3784
2021-08-14 07:32:33,023 - mmseg - INFO - Iter [14650/160000]	lr: 9.180e-03, eta: 2 days, 4:33:36, time: 1.188, data_time: 0.013, memory: 5545, decode.loss_seg: 1.3634, decode.acc_seg: 46.8777, loss: 1.3634
2021-08-14 07:33:35,397 - mmseg - INFO - Iter [14700/160000]	lr: 9.178e-03, eta: 2 days, 4:32:03, time: 1.247, data_time: 0.013, memory: 5545, decode.loss_seg: 1.3428, decode.acc_seg: 46.9197, loss: 1.3428
2021-08-14 07:34:37,662 - mmseg - INFO - Iter [14750/160000]	lr: 9.175e-03, eta: 2 days, 4:30:31, time: 1.246, data_time: 0.014, memory: 5545, decode.loss_seg: 1.3499, decode.acc_seg: 46.9062, loss: 1.3499
2021-08-14 07:35:40,351 - mmseg - INFO - Iter [14800/160000]	lr: 9.172e-03, eta: 2 days, 4:29:02, time: 1.254, data_time: 0.014, memory: 5545, decode.loss_seg: 1.3931, decode.acc_seg: 46.9742, loss: 1.3931
2021-08-14 07:36:40,105 - mmseg - INFO - Iter [14850/160000]	lr: 9.169e-03, eta: 2 days, 4:27:05, time: 1.194, data_time: 0.013, memory: 5545, decode.loss_seg: 1.3492, decode.acc_seg: 47.2339, loss: 1.3492
2021-08-14 07:37:41,965 - mmseg - INFO - Iter [14900/160000]	lr: 9.166e-03, eta: 2 days, 4:25:29, time: 1.238, data_time: 0.014, memory: 5545, decode.loss_seg: 1.3597, decode.acc_seg: 46.8683, loss: 1.3597
2021-08-14 07:38:43,944 - mmseg - INFO - Iter [14950/160000]	lr: 9.163e-03, eta: 2 days, 4:23:55, time: 1.239, data_time: 0.013, memory: 5545, decode.loss_seg: 1.3486, decode.acc_seg: 47.1016, loss: 1.3486
2021-08-14 07:39:44,172 - mmseg - INFO - Exp name: fcn_litehr30-without-head_512x512_160k_ade20k.py
2021-08-14 07:39:44,172 - mmseg - INFO - Iter [15000/160000]	lr: 9.161e-03, eta: 2 days, 4:22:03, time: 1.205, data_time: 0.013, memory: 5545, decode.loss_seg: 1.3728, decode.acc_seg: 46.5921, loss: 1.3728
2021-08-14 07:40:46,991 - mmseg - INFO - Iter [15050/160000]	lr: 9.158e-03, eta: 2 days, 4:20:37, time: 1.256, data_time: 0.013, memory: 5545, decode.loss_seg: 1.3150, decode.acc_seg: 47.7270, loss: 1.3150
2021-08-14 07:41:49,512 - mmseg - INFO - Iter [15100/160000]	lr: 9.155e-03, eta: 2 days, 4:19:08, time: 1.250, data_time: 0.014, memory: 5545, decode.loss_seg: 1.3375, decode.acc_seg: 46.9429, loss: 1.3375
2021-08-14 07:43:25,443 - mmseg - INFO - Iter [15150/160000]	lr: 9.152e-03, eta: 2 days, 4:22:59, time: 1.919, data_time: 0.722, memory: 5545, decode.loss_seg: 1.3283, decode.acc_seg: 47.7567, loss: 1.3283
2021-08-14 07:44:26,852 - mmseg - INFO - Iter [15200/160000]	lr: 9.149e-03, eta: 2 days, 4:21:19, time: 1.228, data_time: 0.014, memory: 5545, decode.loss_seg: 1.3331, decode.acc_seg: 46.4264, loss: 1.3331
2021-08-14 07:45:29,262 - mmseg - INFO - Iter [15250/160000]	lr: 9.147e-03, eta: 2 days, 4:19:48, time: 1.248, data_time: 0.014, memory: 5545, decode.loss_seg: 1.3579, decode.acc_seg: 46.8905, loss: 1.3579
2021-08-14 07:46:30,339 - mmseg - INFO - Iter [15300/160000]	lr: 9.144e-03, eta: 2 days, 4:18:05, time: 1.221, data_time: 0.013, memory: 5545, decode.loss_seg: 1.3820, decode.acc_seg: 48.0587, loss: 1.3820
2021-08-14 07:47:32,898 - mmseg - INFO - Iter [15350/160000]	lr: 9.141e-03, eta: 2 days, 4:16:37, time: 1.251, data_time: 0.014, memory: 5545, decode.loss_seg: 1.3481, decode.acc_seg: 46.7319, loss: 1.3481
2021-08-14 07:48:36,516 - mmseg - INFO - Iter [15400/160000]	lr: 9.138e-03, eta: 2 days, 4:15:18, time: 1.273, data_time: 0.014, memory: 5545, decode.loss_seg: 1.3830, decode.acc_seg: 47.1291, loss: 1.3830
2021-08-14 07:49:38,001 - mmseg - INFO - Iter [15450/160000]	lr: 9.135e-03, eta: 2 days, 4:13:40, time: 1.229, data_time: 0.014, memory: 5545, decode.loss_seg: 1.3657, decode.acc_seg: 48.1170, loss: 1.3657
2021-08-14 07:50:42,698 - mmseg - INFO - Iter [15500/160000]	lr: 9.133e-03, eta: 2 days, 4:12:32, time: 1.294, data_time: 0.014, memory: 5545, decode.loss_seg: 1.3515, decode.acc_seg: 46.4842, loss: 1.3515
2021-08-14 07:51:42,743 - mmseg - INFO - Iter [15550/160000]	lr: 9.130e-03, eta: 2 days, 4:10:41, time: 1.201, data_time: 0.015, memory: 5545, decode.loss_seg: 1.3584, decode.acc_seg: 46.3205, loss: 1.3584
2021-08-14 07:52:45,682 - mmseg - INFO - Iter [15600/160000]	lr: 9.127e-03, eta: 2 days, 4:09:16, time: 1.258, data_time: 0.014, memory: 5545, decode.loss_seg: 1.3575, decode.acc_seg: 46.3133, loss: 1.3575
2021-08-14 07:53:45,463 - mmseg - INFO - Iter [15650/160000]	lr: 9.124e-03, eta: 2 days, 4:07:23, time: 1.196, data_time: 0.014, memory: 5545, decode.loss_seg: 1.3553, decode.acc_seg: 47.0503, loss: 1.3553
2021-08-14 07:54:46,001 - mmseg - INFO - Iter [15700/160000]	lr: 9.121e-03, eta: 2 days, 4:05:37, time: 1.211, data_time: 0.014, memory: 5545, decode.loss_seg: 1.3621, decode.acc_seg: 47.4357, loss: 1.3621
2021-08-14 07:55:47,997 - mmseg - INFO - Iter [15750/160000]	lr: 9.118e-03, eta: 2 days, 4:04:04, time: 1.239, data_time: 0.014, memory: 5545, decode.loss_seg: 1.3156, decode.acc_seg: 46.7562, loss: 1.3156
2021-08-14 07:57:26,294 - mmseg - INFO - Iter [15800/160000]	lr: 9.116e-03, eta: 2 days, 4:08:04, time: 1.967, data_time: 0.694, memory: 5545, decode.loss_seg: 1.3468, decode.acc_seg: 47.3999, loss: 1.3468
2021-08-14 07:58:31,274 - mmseg - INFO - Iter [15850/160000]	lr: 9.113e-03, eta: 2 days, 4:06:57, time: 1.299, data_time: 0.014, memory: 5545, decode.loss_seg: 1.3225, decode.acc_seg: 46.4593, loss: 1.3225
2021-08-14 07:59:36,855 - mmseg - INFO - Iter [15900/160000]	lr: 9.110e-03, eta: 2 days, 4:05:57, time: 1.312, data_time: 0.014, memory: 5545, decode.loss_seg: 1.3250, decode.acc_seg: 48.5339, loss: 1.3250
2021-08-14 08:00:38,026 - mmseg - INFO - Iter [15950/160000]	lr: 9.107e-03, eta: 2 days, 4:04:17, time: 1.224, data_time: 0.013, memory: 5545, decode.loss_seg: 1.3115, decode.acc_seg: 47.2298, loss: 1.3115
2021-08-14 08:01:37,529 - mmseg - INFO - Saving checkpoint at 16000 iterations
2021-08-14 08:01:37,840 - mmseg - INFO - Exp name: fcn_litehr30-without-head_512x512_160k_ade20k.py
2021-08-14 08:01:37,843 - mmseg - INFO - Iter [16000/160000]	lr: 9.104e-03, eta: 2 days, 4:02:25, time: 1.197, data_time: 0.013, memory: 5545, decode.loss_seg: 1.3762, decode.acc_seg: 47.0583, loss: 1.3762
2021-08-14 08:04:21,557 - mmseg - INFO - per class results:
2021-08-14 08:04:21,569 - mmseg - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        | 48.64 | 84.28 |
|       building      | 60.39 | 85.89 |
|         sky         | 86.86 | 95.74 |
|        floor        | 52.31 | 76.26 |
|         tree        | 49.16 | 61.93 |
|       ceiling       | 63.95 | 81.99 |
|         road        | 56.52 | 84.76 |
|         bed         | 49.21 | 67.95 |
|      windowpane     | 37.34 | 52.88 |
|        grass        | 45.27 | 86.06 |
|       cabinet       | 29.45 | 42.95 |
|       sidewalk      | 21.24 | 26.54 |
|        person       | 28.42 |  38.6 |
|        earth        | 11.68 | 13.87 |
|         door        |  8.49 | 10.39 |
|        table        | 14.39 | 19.87 |
|       mountain      | 24.71 | 31.02 |
|        plant        | 12.26 | 13.41 |
|       curtain       | 26.78 | 31.72 |
|        chair        | 16.58 | 25.33 |
|         car         |  48.8 | 70.27 |
|        water        | 10.15 | 12.37 |
|       painting      | 38.76 | 47.75 |
|         sofa        | 21.79 | 44.33 |
|        shelf        |  9.62 | 12.88 |
|        house        | 16.51 | 22.87 |
|         sea         | 18.53 | 77.77 |
|        mirror       |  4.6  |  5.43 |
|         rug         | 10.07 | 10.42 |
|        field        |  9.97 | 18.78 |
|       armchair      |  0.37 |  0.38 |
|         seat        |  5.33 |  6.25 |
|        fence        |  3.14 |  3.91 |
|         desk        |  0.08 |  0.08 |
|         rock        |  2.12 |  2.22 |
|       wardrobe      |  0.05 |  0.05 |
|         lamp        | 11.86 |  13.2 |
|       bathtub       |  3.58 |  3.95 |
|       railing       |  0.46 |  0.46 |
|       cushion       | 11.29 |  14.9 |
|         base        |  0.0  |  0.0  |
|         box         |  0.0  |  0.0  |
|        column       |  0.0  |  0.0  |
|      signboard      |  0.0  |  0.0  |
|   chest of drawers  |  2.28 |  2.5  |
|       counter       |  0.0  |  0.0  |
|         sand        |  3.66 |  4.17 |
|         sink        | 10.54 | 12.84 |
|      skyscraper     | 25.45 | 53.64 |
|      fireplace      | 25.87 | 32.68 |
|     refrigerator    |  0.0  |  0.0  |
|      grandstand     |  0.43 |  0.45 |
|         path        |  0.0  |  0.0  |
|        stairs       |  0.12 |  0.12 |
|        runway       |  13.5 | 14.23 |
|         case        |  0.0  |  0.0  |
|      pool table     | 16.81 | 55.03 |
|        pillow       | 13.26 | 15.08 |
|     screen door     |  0.0  |  0.0  |
|       stairway      |  0.72 |  0.86 |
|        river        |  3.15 |  4.09 |
|        bridge       |  0.0  |  0.0  |
|       bookcase      |  0.15 |  0.15 |
|        blind        |  0.0  |  0.0  |
|     coffee table    |  5.92 |  6.56 |
|        toilet       | 18.16 | 24.74 |
|        flower       |  4.5  |  5.19 |
|         book        |  0.01 |  0.01 |
|         hill        |  0.84 |  0.91 |
|        bench        |  0.26 |  0.26 |
|      countertop     |  0.1  |  0.1  |
|        stove        |  3.86 |  4.19 |
|         palm        |  0.0  |  0.0  |
|    kitchen island   |  0.0  |  0.0  |
|       computer      |  1.74 |  1.84 |
|     swivel chair    |  0.0  |  0.0  |
|         boat        |  0.0  |  0.0  |
|         bar         |  0.0  |  0.0  |
|    arcade machine   |  0.0  |  0.0  |
|        hovel        |  0.0  |  0.0  |
|         bus         |  0.0  |  0.0  |
|        towel        |  0.0  |  0.0  |
|        light        |  0.0  |  0.0  |
|        truck        |  0.0  |  0.0  |
|        tower        |  0.0  |  0.0  |
|      chandelier     | 18.94 | 23.94 |
|        awning       |  0.0  |  0.0  |
|     streetlight     |  0.0  |  0.0  |
|        booth        |  0.0  |  0.0  |
| television receiver |  0.23 |  0.23 |
|       airplane      |  0.03 |  0.03 |
|      dirt track     |  0.0  |  0.0  |
|       apparel       |  0.0  |  0.0  |
|         pole        |  0.0  |  0.0  |
|         land        |  0.0  |  0.0  |
|      bannister      |  0.0  |  0.0  |
|      escalator      |  0.0  |  0.0  |
|       ottoman       |  0.0  |  0.0  |
|        bottle       |  0.0  |  0.0  |
|        buffet       |  0.0  |  0.0  |
|        poster       |  0.0  |  0.0  |
|        stage        |  0.0  |  0.0  |
|         van         |  0.0  |  0.0  |
|         ship        |  0.0  |  0.0  |
|       fountain      |  0.0  |  0.0  |
|    conveyer belt    |  0.0  |  0.0  |
|        canopy       |  0.0  |  0.0  |
|        washer       |  0.0  |  0.0  |
|      plaything      |  0.0  |  0.0  |
|    swimming pool    |  0.45 |  0.53 |
|        stool        |  0.0  |  0.0  |
|        barrel       |  0.0  |  0.0  |
|        basket       |  0.0  |  0.0  |
|      waterfall      | 18.05 | 24.45 |
|         tent        |  0.15 |  0.15 |
|         bag         |  0.0  |  0.0  |
|       minibike      |  0.0  |  0.0  |
|        cradle       |  2.9  |  2.92 |
|         oven        |  0.0  |  0.0  |
|         ball        |  0.0  |  0.0  |
|         food        |  0.0  |  0.0  |
|         step        |  0.0  |  0.0  |
|         tank        |  0.0  |  0.0  |
|      trade name     |  0.0  |  0.0  |
|      microwave      |  0.01 |  0.01 |
|         pot         |  0.0  |  0.0  |
|        animal       |  0.0  |  0.0  |
|       bicycle       |  0.0  |  0.0  |
|         lake        |  0.0  |  0.0  |
|      dishwasher     |  0.0  |  0.0  |
|        screen       |  0.0  |  0.0  |
|       blanket       |  0.0  |  0.0  |
|      sculpture      |  0.0  |  0.0  |
|         hood        |  0.0  |  0.0  |
|        sconce       |  0.0  |  0.0  |
|         vase        |  0.0  |  0.0  |
|    traffic light    |  0.0  |  0.0  |
|         tray        |  0.0  |  0.0  |
|        ashcan       |  0.0  |  0.0  |
|         fan         |  0.0  |  0.0  |
|         pier        |  0.0  |  0.0  |
|      crt screen     |  0.0  |  0.0  |
|        plate        |  0.0  |  0.0  |
|       monitor       |  0.0  |  0.0  |
|    bulletin board   |  0.0  |  0.0  |
|        shower       |  0.0  |  0.0  |
|       radiator      |  0.0  |  0.0  |
|        glass        |  0.0  |  0.0  |
|        clock        |  0.0  |  0.0  |
|         flag        |  0.0  |  0.0  |
+---------------------+-------+-------+
2021-08-14 08:04:21,569 - mmseg - INFO - Summary:
2021-08-14 08:04:21,570 - mmseg - INFO - 
+-------+------+-------+
|  aAcc | mIoU |  mAcc |
+-------+------+-------+
| 60.28 | 7.75 | 11.28 |
+-------+------+-------+
2021-08-14 08:04:21,682 - mmseg - INFO - Exp name: fcn_litehr30-without-head_512x512_160k_ade20k.py
2021-08-14 08:04:21,682 - mmseg - INFO - Iter(val) [250]	aAcc: 0.6028, mIoU: 0.0775, mAcc: 0.1128, IoU.wall: 0.4864, IoU.building: 0.6039, IoU.sky: 0.8686, IoU.floor: 0.5231, IoU.tree: 0.4916, IoU.ceiling: 0.6395, IoU.road: 0.5652, IoU.bed : 0.4921, IoU.windowpane: 0.3734, IoU.grass: 0.4527, IoU.cabinet: 0.2945, IoU.sidewalk: 0.2124, IoU.person: 0.2842, IoU.earth: 0.1168, IoU.door: 0.0849, IoU.table: 0.1439, IoU.mountain: 0.2471, IoU.plant: 0.1226, IoU.curtain: 0.2678, IoU.chair: 0.1658, IoU.car: 0.4880, IoU.water: 0.1015, IoU.painting: 0.3876, IoU.sofa: 0.2179, IoU.shelf: 0.0962, IoU.house: 0.1651, IoU.sea: 0.1853, IoU.mirror: 0.0460, IoU.rug: 0.1007, IoU.field: 0.0997, IoU.armchair: 0.0037, IoU.seat: 0.0533, IoU.fence: 0.0314, IoU.desk: 0.0008, IoU.rock: 0.0212, IoU.wardrobe: 0.0005, IoU.lamp: 0.1186, IoU.bathtub: 0.0358, IoU.railing: 0.0046, IoU.cushion: 0.1129, IoU.base: 0.0000, IoU.box: 0.0000, IoU.column: 0.0000, IoU.signboard: 0.0000, IoU.chest of drawers: 0.0228, IoU.counter: 0.0000, IoU.sand: 0.0366, IoU.sink: 0.1054, IoU.skyscraper: 0.2545, IoU.fireplace: 0.2587, IoU.refrigerator: 0.0000, IoU.grandstand: 0.0043, IoU.path: 0.0000, IoU.stairs: 0.0012, IoU.runway: 0.1350, IoU.case: 0.0000, IoU.pool table: 0.1681, IoU.pillow: 0.1326, IoU.screen door: 0.0000, IoU.stairway: 0.0072, IoU.river: 0.0315, IoU.bridge: 0.0000, IoU.bookcase: 0.0015, IoU.blind: 0.0000, IoU.coffee table: 0.0592, IoU.toilet: 0.1816, IoU.flower: 0.0450, IoU.book: 0.0001, IoU.hill: 0.0084, IoU.bench: 0.0026, IoU.countertop: 0.0010, IoU.stove: 0.0386, IoU.palm: 0.0000, IoU.kitchen island: 0.0000, IoU.computer: 0.0174, IoU.swivel chair: 0.0000, IoU.boat: 0.0000, IoU.bar: 0.0000, IoU.arcade machine: 0.0000, IoU.hovel: 0.0000, IoU.bus: 0.0000, IoU.towel: 0.0000, IoU.light: 0.0000, IoU.truck: 0.0000, IoU.tower: 0.0000, IoU.chandelier: 0.1894, IoU.awning: 0.0000, IoU.streetlight: 0.0000, IoU.booth: 0.0000, IoU.television receiver: 0.0023, IoU.airplane: 0.0003, IoU.dirt track: 0.0000, IoU.apparel: 0.0000, IoU.pole: 0.0000, IoU.land: 0.0000, IoU.bannister: 0.0000, IoU.escalator: 0.0000, IoU.ottoman: 0.0000, IoU.bottle: 0.0000, IoU.buffet: 0.0000, IoU.poster: 0.0000, IoU.stage: 0.0000, IoU.van: 0.0000, IoU.ship: 0.0000, IoU.fountain: 0.0000, IoU.conveyer belt: 0.0000, IoU.canopy: 0.0000, IoU.washer: 0.0000, IoU.plaything: 0.0000, IoU.swimming pool: 0.0045, IoU.stool: 0.0000, IoU.barrel: 0.0000, IoU.basket: 0.0000, IoU.waterfall: 0.1805, IoU.tent: 0.0015, IoU.bag: 0.0000, IoU.minibike: 0.0000, IoU.cradle: 0.0290, IoU.oven: 0.0000, IoU.ball: 0.0000, IoU.food: 0.0000, IoU.step: 0.0000, IoU.tank: 0.0000, IoU.trade name: 0.0000, IoU.microwave: 0.0001, IoU.pot: 0.0000, IoU.animal: 0.0000, IoU.bicycle: 0.0000, IoU.lake: 0.0000, IoU.dishwasher: 0.0000, IoU.screen: 0.0000, IoU.blanket: 0.0000, IoU.sculpture: 0.0000, IoU.hood: 0.0000, IoU.sconce: 0.0000, IoU.vase: 0.0000, IoU.traffic light: 0.0000, IoU.tray: 0.0000, IoU.ashcan: 0.0000, IoU.fan: 0.0000, IoU.pier: 0.0000, IoU.crt screen: 0.0000, IoU.plate: 0.0000, IoU.monitor: 0.0000, IoU.bulletin board: 0.0000, IoU.shower: 0.0000, IoU.radiator: 0.0000, IoU.glass: 0.0000, IoU.clock: 0.0000, IoU.flag: 0.0000, Acc.wall: 0.8428, Acc.building: 0.8589, Acc.sky: 0.9574, Acc.floor: 0.7626, Acc.tree: 0.6193, Acc.ceiling: 0.8199, Acc.road: 0.8476, Acc.bed : 0.6795, Acc.windowpane: 0.5288, Acc.grass: 0.8606, Acc.cabinet: 0.4295, Acc.sidewalk: 0.2654, Acc.person: 0.3860, Acc.earth: 0.1387, Acc.door: 0.1039, Acc.table: 0.1987, Acc.mountain: 0.3102, Acc.plant: 0.1341, Acc.curtain: 0.3172, Acc.chair: 0.2533, Acc.car: 0.7027, Acc.water: 0.1237, Acc.painting: 0.4775, Acc.sofa: 0.4433, Acc.shelf: 0.1288, Acc.house: 0.2287, Acc.sea: 0.7777, Acc.mirror: 0.0543, Acc.rug: 0.1042, Acc.field: 0.1878, Acc.armchair: 0.0038, Acc.seat: 0.0625, Acc.fence: 0.0391, Acc.desk: 0.0008, Acc.rock: 0.0222, Acc.wardrobe: 0.0005, Acc.lamp: 0.1320, Acc.bathtub: 0.0395, Acc.railing: 0.0046, Acc.cushion: 0.1490, Acc.base: 0.0000, Acc.box: 0.0000, Acc.column: 0.0000, Acc.signboard: 0.0000, Acc.chest of drawers: 0.0250, Acc.counter: 0.0000, Acc.sand: 0.0417, Acc.sink: 0.1284, Acc.skyscraper: 0.5364, Acc.fireplace: 0.3268, Acc.refrigerator: 0.0000, Acc.grandstand: 0.0045, Acc.path: 0.0000, Acc.stairs: 0.0012, Acc.runway: 0.1423, Acc.case: 0.0000, Acc.pool table: 0.5503, Acc.pillow: 0.1508, Acc.screen door: 0.0000, Acc.stairway: 0.0086, Acc.river: 0.0409, Acc.bridge: 0.0000, Acc.bookcase: 0.0015, Acc.blind: 0.0000, Acc.coffee table: 0.0656, Acc.toilet: 0.2474, Acc.flower: 0.0519, Acc.book: 0.0001, Acc.hill: 0.0091, Acc.bench: 0.0026, Acc.countertop: 0.0010, Acc.stove: 0.0419, Acc.palm: 0.0000, Acc.kitchen island: 0.0000, Acc.computer: 0.0184, Acc.swivel chair: 0.0000, Acc.boat: 0.0000, Acc.bar: 0.0000, Acc.arcade machine: 0.0000, Acc.hovel: 0.0000, Acc.bus: 0.0000, Acc.towel: 0.0000, Acc.light: 0.0000, Acc.truck: 0.0000, Acc.tower: 0.0000, Acc.chandelier: 0.2394, Acc.awning: 0.0000, Acc.streetlight: 0.0000, Acc.booth: 0.0000, Acc.television receiver: 0.0023, Acc.airplane: 0.0003, Acc.dirt track: 0.0000, Acc.apparel: 0.0000, Acc.pole: 0.0000, Acc.land: 0.0000, Acc.bannister: 0.0000, Acc.escalator: 0.0000, Acc.ottoman: 0.0000, Acc.bottle: 0.0000, Acc.buffet: 0.0000, Acc.poster: 0.0000, Acc.stage: 0.0000, Acc.van: 0.0000, Acc.ship: 0.0000, Acc.fountain: 0.0000, Acc.conveyer belt: 0.0000, Acc.canopy: 0.0000, Acc.washer: 0.0000, Acc.plaything: 0.0000, Acc.swimming pool: 0.0053, Acc.stool: 0.0000, Acc.barrel: 0.0000, Acc.basket: 0.0000, Acc.waterfall: 0.2445, Acc.tent: 0.0015, Acc.bag: 0.0000, Acc.minibike: 0.0000, Acc.cradle: 0.0292, Acc.oven: 0.0000, Acc.ball: 0.0000, Acc.food: 0.0000, Acc.step: 0.0000, Acc.tank: 0.0000, Acc.trade name: 0.0000, Acc.microwave: 0.0001, Acc.pot: 0.0000, Acc.animal: 0.0000, Acc.bicycle: 0.0000, Acc.lake: 0.0000, Acc.dishwasher: 0.0000, Acc.screen: 0.0000, Acc.blanket: 0.0000, Acc.sculpture: 0.0000, Acc.hood: 0.0000, Acc.sconce: 0.0000, Acc.vase: 0.0000, Acc.traffic light: 0.0000, Acc.tray: 0.0000, Acc.ashcan: 0.0000, Acc.fan: 0.0000, Acc.pier: 0.0000, Acc.crt screen: 0.0000, Acc.plate: 0.0000, Acc.monitor: 0.0000, Acc.bulletin board: 0.0000, Acc.shower: 0.0000, Acc.radiator: 0.0000, Acc.glass: 0.0000, Acc.clock: 0.0000, Acc.flag: 0.0000
2021-08-14 08:05:25,103 - mmseg - INFO - Iter [16050/160000]	lr: 9.102e-03, eta: 2 days, 4:25:34, time: 4.545, data_time: 3.292, memory: 5545, decode.loss_seg: 1.3331, decode.acc_seg: 47.8718, loss: 1.3331
2021-08-14 08:06:28,086 - mmseg - INFO - Iter [16100/160000]	lr: 9.099e-03, eta: 2 days, 4:24:06, time: 1.259, data_time: 0.013, memory: 5545, decode.loss_seg: 1.3625, decode.acc_seg: 46.2252, loss: 1.3625
2021-08-14 08:07:28,184 - mmseg - INFO - Iter [16150/160000]	lr: 9.096e-03, eta: 2 days, 4:22:11, time: 1.202, data_time: 0.014, memory: 5545, decode.loss_seg: 1.3333, decode.acc_seg: 47.1006, loss: 1.3333
2021-08-14 08:08:29,255 - mmseg - INFO - Iter [16200/160000]	lr: 9.093e-03, eta: 2 days, 4:20:26, time: 1.221, data_time: 0.014, memory: 5545, decode.loss_seg: 1.3535, decode.acc_seg: 47.3499, loss: 1.3535
2021-08-14 08:09:32,304 - mmseg - INFO - Iter [16250/160000]	lr: 9.090e-03, eta: 2 days, 4:18:59, time: 1.261, data_time: 0.014, memory: 5545, decode.loss_seg: 1.3536, decode.acc_seg: 46.5589, loss: 1.3536
2021-08-14 08:10:37,191 - mmseg - INFO - Iter [16300/160000]	lr: 9.088e-03, eta: 2 days, 4:17:48, time: 1.298, data_time: 0.014, memory: 5545, decode.loss_seg: 1.3479, decode.acc_seg: 47.8928, loss: 1.3479
2021-08-14 08:11:38,624 - mmseg - INFO - Iter [16350/160000]	lr: 9.085e-03, eta: 2 days, 4:16:07, time: 1.229, data_time: 0.014, memory: 5545, decode.loss_seg: 1.3109, decode.acc_seg: 48.3320, loss: 1.3109
2021-08-14 08:12:38,412 - mmseg - INFO - Iter [16400/160000]	lr: 9.082e-03, eta: 2 days, 4:14:11, time: 1.196, data_time: 0.013, memory: 5545, decode.loss_seg: 1.3402, decode.acc_seg: 47.3946, loss: 1.3402
2021-08-14 08:14:13,738 - mmseg - INFO - Iter [16450/160000]	lr: 9.079e-03, eta: 2 days, 4:17:27, time: 1.907, data_time: 0.669, memory: 5545, decode.loss_seg: 1.3238, decode.acc_seg: 47.3611, loss: 1.3238
2021-08-14 08:15:16,174 - mmseg - INFO - Iter [16500/160000]	lr: 9.076e-03, eta: 2 days, 4:15:53, time: 1.248, data_time: 0.014, memory: 5545, decode.loss_seg: 1.3349, decode.acc_seg: 48.9534, loss: 1.3349
2021-08-14 08:16:16,437 - mmseg - INFO - Iter [16550/160000]	lr: 9.073e-03, eta: 2 days, 4:14:02, time: 1.205, data_time: 0.013, memory: 5545, decode.loss_seg: 1.3488, decode.acc_seg: 46.7636, loss: 1.3488
2021-08-14 08:17:17,818 - mmseg - INFO - Iter [16600/160000]	lr: 9.071e-03, eta: 2 days, 4:12:20, time: 1.228, data_time: 0.015, memory: 5545, decode.loss_seg: 1.3285, decode.acc_seg: 48.3554, loss: 1.3285
2021-08-14 08:18:21,844 - mmseg - INFO - Iter [16650/160000]	lr: 9.068e-03, eta: 2 days, 4:11:02, time: 1.281, data_time: 0.014, memory: 5545, decode.loss_seg: 1.3328, decode.acc_seg: 46.9532, loss: 1.3328
2021-08-14 08:19:25,066 - mmseg - INFO - Iter [16700/160000]	lr: 9.065e-03, eta: 2 days, 4:09:36, time: 1.264, data_time: 0.013, memory: 5545, decode.loss_seg: 1.3524, decode.acc_seg: 47.9397, loss: 1.3524
2021-08-14 08:20:30,586 - mmseg - INFO - Iter [16750/160000]	lr: 9.062e-03, eta: 2 days, 4:08:31, time: 1.311, data_time: 0.014, memory: 5545, decode.loss_seg: 1.3381, decode.acc_seg: 46.5290, loss: 1.3381
2021-08-14 08:21:34,319 - mmseg - INFO - Iter [16800/160000]	lr: 9.059e-03, eta: 2 days, 4:07:10, time: 1.274, data_time: 0.013, memory: 5545, decode.loss_seg: 1.3588, decode.acc_seg: 46.6449, loss: 1.3588
2021-08-14 08:22:38,170 - mmseg - INFO - Iter [16850/160000]	lr: 9.057e-03, eta: 2 days, 4:05:51, time: 1.277, data_time: 0.013, memory: 5545, decode.loss_seg: 1.3204, decode.acc_seg: 47.7445, loss: 1.3204
2021-08-14 08:23:40,825 - mmseg - INFO - Iter [16900/160000]	lr: 9.054e-03, eta: 2 days, 4:04:21, time: 1.253, data_time: 0.014, memory: 5545, decode.loss_seg: 1.3198, decode.acc_seg: 47.6503, loss: 1.3198
2021-08-14 08:24:42,771 - mmseg - INFO - Iter [16950/160000]	lr: 9.051e-03, eta: 2 days, 4:02:45, time: 1.239, data_time: 0.014, memory: 5545, decode.loss_seg: 1.3135, decode.acc_seg: 48.8673, loss: 1.3135
2021-08-14 08:25:44,717 - mmseg - INFO - Exp name: fcn_litehr30-without-head_512x512_160k_ade20k.py
2021-08-14 08:25:44,719 - mmseg - INFO - Iter [17000/160000]	lr: 9.048e-03, eta: 2 days, 4:01:10, time: 1.239, data_time: 0.014, memory: 5545, decode.loss_seg: 1.3066, decode.acc_seg: 48.9000, loss: 1.3066
2021-08-14 08:27:20,564 - mmseg - INFO - Iter [17050/160000]	lr: 9.045e-03, eta: 2 days, 4:04:19, time: 1.916, data_time: 0.730, memory: 5545, decode.loss_seg: 1.3236, decode.acc_seg: 47.8955, loss: 1.3236
2021-08-14 08:28:23,804 - mmseg - INFO - Iter [17100/160000]	lr: 9.043e-03, eta: 2 days, 4:02:54, time: 1.265, data_time: 0.015, memory: 5545, decode.loss_seg: 1.3114, decode.acc_seg: 47.3542, loss: 1.3114
2021-08-14 08:29:23,673 - mmseg - INFO - Iter [17150/160000]	lr: 9.040e-03, eta: 2 days, 4:01:01, time: 1.198, data_time: 0.014, memory: 5545, decode.loss_seg: 1.3178, decode.acc_seg: 47.5429, loss: 1.3178
2021-08-14 08:30:23,925 - mmseg - INFO - Iter [17200/160000]	lr: 9.037e-03, eta: 2 days, 3:59:12, time: 1.205, data_time: 0.013, memory: 5545, decode.loss_seg: 1.3433, decode.acc_seg: 47.4384, loss: 1.3433
2021-08-14 08:31:25,151 - mmseg - INFO - Iter [17250/160000]	lr: 9.034e-03, eta: 2 days, 3:57:31, time: 1.224, data_time: 0.014, memory: 5545, decode.loss_seg: 1.3021, decode.acc_seg: 48.4395, loss: 1.3021
2021-08-14 08:32:26,458 - mmseg - INFO - Iter [17300/160000]	lr: 9.031e-03, eta: 2 days, 3:55:51, time: 1.227, data_time: 0.014, memory: 5545, decode.loss_seg: 1.2934, decode.acc_seg: 47.9098, loss: 1.2934
2021-08-14 08:33:27,642 - mmseg - INFO - Iter [17350/160000]	lr: 9.028e-03, eta: 2 days, 3:54:09, time: 1.223, data_time: 0.013, memory: 5545, decode.loss_seg: 1.3078, decode.acc_seg: 47.9212, loss: 1.3078
2021-08-14 08:34:29,357 - mmseg - INFO - Iter [17400/160000]	lr: 9.026e-03, eta: 2 days, 3:52:33, time: 1.235, data_time: 0.014, memory: 5545, decode.loss_seg: 1.3212, decode.acc_seg: 47.7583, loss: 1.3212
2021-08-14 08:35:32,942 - mmseg - INFO - Iter [17450/160000]	lr: 9.023e-03, eta: 2 days, 3:51:12, time: 1.271, data_time: 0.014, memory: 5545, decode.loss_seg: 1.2800, decode.acc_seg: 48.0197, loss: 1.2800
2021-08-14 08:36:32,843 - mmseg - INFO - Iter [17500/160000]	lr: 9.020e-03, eta: 2 days, 3:49:21, time: 1.199, data_time: 0.014, memory: 5545, decode.loss_seg: 1.3188, decode.acc_seg: 48.0869, loss: 1.3188
2021-08-14 08:37:32,896 - mmseg - INFO - Iter [17550/160000]	lr: 9.017e-03, eta: 2 days, 3:47:32, time: 1.201, data_time: 0.013, memory: 5545, decode.loss_seg: 1.3287, decode.acc_seg: 48.3602, loss: 1.3287
2021-08-14 08:38:34,047 - mmseg - INFO - Iter [17600/160000]	lr: 9.014e-03, eta: 2 days, 3:45:52, time: 1.223, data_time: 0.015, memory: 5545, decode.loss_seg: 1.2863, decode.acc_seg: 48.5976, loss: 1.2863
2021-08-14 08:39:37,140 - mmseg - INFO - Iter [17650/160000]	lr: 9.012e-03, eta: 2 days, 3:44:27, time: 1.262, data_time: 0.014, memory: 5545, decode.loss_seg: 1.3275, decode.acc_seg: 47.9395, loss: 1.3275
2021-08-14 08:41:12,933 - mmseg - INFO - Iter [17700/160000]	lr: 9.009e-03, eta: 2 days, 3:47:26, time: 1.916, data_time: 0.729, memory: 5545, decode.loss_seg: 1.3602, decode.acc_seg: 47.7438, loss: 1.3602
2021-08-14 08:42:14,710 - mmseg - INFO - Iter [17750/160000]	lr: 9.006e-03, eta: 2 days, 3:45:50, time: 1.235, data_time: 0.014, memory: 5545, decode.loss_seg: 1.2903, decode.acc_seg: 47.8402, loss: 1.2903
2021-08-14 08:43:16,856 - mmseg - INFO - Iter [17800/160000]	lr: 9.003e-03, eta: 2 days, 3:44:18, time: 1.244, data_time: 0.013, memory: 5545, decode.loss_seg: 1.2995, decode.acc_seg: 48.7189, loss: 1.2995
2021-08-14 08:44:18,071 - mmseg - INFO - Iter [17850/160000]	lr: 9.000e-03, eta: 2 days, 3:42:39, time: 1.224, data_time: 0.013, memory: 5545, decode.loss_seg: 1.2931, decode.acc_seg: 46.9534, loss: 1.2931
2021-08-14 08:45:21,393 - mmseg - INFO - Iter [17900/160000]	lr: 8.997e-03, eta: 2 days, 3:41:16, time: 1.266, data_time: 0.013, memory: 5545, decode.loss_seg: 1.2905, decode.acc_seg: 47.8411, loss: 1.2905
2021-08-14 08:46:26,078 - mmseg - INFO - Iter [17950/160000]	lr: 8.995e-03, eta: 2 days, 3:40:04, time: 1.294, data_time: 0.014, memory: 5545, decode.loss_seg: 1.3070, decode.acc_seg: 48.0196, loss: 1.3070
2021-08-14 08:47:26,287 - mmseg - INFO - Exp name: fcn_litehr30-without-head_512x512_160k_ade20k.py
2021-08-14 08:47:26,288 - mmseg - INFO - Iter [18000/160000]	lr: 8.992e-03, eta: 2 days, 3:38:17, time: 1.204, data_time: 0.014, memory: 5545, decode.loss_seg: 1.3077, decode.acc_seg: 47.7799, loss: 1.3077
2021-08-14 08:48:28,513 - mmseg - INFO - Iter [18050/160000]	lr: 8.989e-03, eta: 2 days, 3:36:47, time: 1.245, data_time: 0.013, memory: 5545, decode.loss_seg: 1.3152, decode.acc_seg: 47.5960, loss: 1.3152
2021-08-14 08:49:32,429 - mmseg - INFO - Iter [18100/160000]	lr: 8.986e-03, eta: 2 days, 3:35:29, time: 1.278, data_time: 0.013, memory: 5545, decode.loss_seg: 1.3142, decode.acc_seg: 48.4204, loss: 1.3142
2021-08-14 08:50:34,198 - mmseg - INFO - Iter [18150/160000]	lr: 8.983e-03, eta: 2 days, 3:33:55, time: 1.235, data_time: 0.013, memory: 5545, decode.loss_seg: 1.2934, decode.acc_seg: 46.9619, loss: 1.2934
2021-08-14 08:51:38,382 - mmseg - INFO - Iter [18200/160000]	lr: 8.981e-03, eta: 2 days, 3:32:40, time: 1.284, data_time: 0.014, memory: 5545, decode.loss_seg: 1.3170, decode.acc_seg: 48.2187, loss: 1.3170
2021-08-14 08:52:37,740 - mmseg - INFO - Iter [18250/160000]	lr: 8.978e-03, eta: 2 days, 3:30:47, time: 1.187, data_time: 0.013, memory: 5545, decode.loss_seg: 1.3051, decode.acc_seg: 48.8317, loss: 1.3051
2021-08-14 08:54:12,661 - mmseg - INFO - Iter [18300/160000]	lr: 8.975e-03, eta: 2 days, 3:33:30, time: 1.897, data_time: 0.709, memory: 5545, decode.loss_seg: 1.3141, decode.acc_seg: 47.5596, loss: 1.3141
2021-08-14 08:55:13,324 - mmseg - INFO - Iter [18350/160000]	lr: 8.972e-03, eta: 2 days, 3:31:47, time: 1.214, data_time: 0.015, memory: 5545, decode.loss_seg: 1.2983, decode.acc_seg: 47.1763, loss: 1.2983
2021-08-14 08:56:16,049 - mmseg - INFO - Iter [18400/160000]	lr: 8.969e-03, eta: 2 days, 3:30:21, time: 1.255, data_time: 0.014, memory: 5545, decode.loss_seg: 1.2966, decode.acc_seg: 48.0883, loss: 1.2966
2021-08-14 08:57:20,594 - mmseg - INFO - Iter [18450/160000]	lr: 8.966e-03, eta: 2 days, 3:29:08, time: 1.291, data_time: 0.014, memory: 5545, decode.loss_seg: 1.2969, decode.acc_seg: 47.8172, loss: 1.2969
2021-08-14 08:58:22,696 - mmseg - INFO - Iter [18500/160000]	lr: 8.964e-03, eta: 2 days, 3:27:37, time: 1.241, data_time: 0.013, memory: 5545, decode.loss_seg: 1.3006, decode.acc_seg: 47.2225, loss: 1.3006
2021-08-14 08:59:28,315 - mmseg - INFO - Iter [18550/160000]	lr: 8.961e-03, eta: 2 days, 3:26:33, time: 1.313, data_time: 0.014, memory: 5545, decode.loss_seg: 1.3260, decode.acc_seg: 48.0209, loss: 1.3260
2021-08-14 09:00:34,101 - mmseg - INFO - Iter [18600/160000]	lr: 8.958e-03, eta: 2 days, 3:25:29, time: 1.315, data_time: 0.014, memory: 5545, decode.loss_seg: 1.2854, decode.acc_seg: 48.1008, loss: 1.2854
2021-08-14 09:01:40,388 - mmseg - INFO - Iter [18650/160000]	lr: 8.955e-03, eta: 2 days, 3:24:30, time: 1.326, data_time: 0.014, memory: 5545, decode.loss_seg: 1.3101, decode.acc_seg: 48.3751, loss: 1.3101
2021-08-14 09:02:41,080 - mmseg - INFO - Iter [18700/160000]	lr: 8.952e-03, eta: 2 days, 3:22:49, time: 1.215, data_time: 0.014, memory: 5545, decode.loss_seg: 1.2898, decode.acc_seg: 48.8827, loss: 1.2898
2021-08-14 09:03:40,834 - mmseg - INFO - Iter [18750/160000]	lr: 8.950e-03, eta: 2 days, 3:21:00, time: 1.194, data_time: 0.013, memory: 5545, decode.loss_seg: 1.3107, decode.acc_seg: 48.6545, loss: 1.3107
2021-08-14 09:04:42,722 - mmseg - INFO - Iter [18800/160000]	lr: 8.947e-03, eta: 2 days, 3:19:28, time: 1.238, data_time: 0.014, memory: 5545, decode.loss_seg: 1.3162, decode.acc_seg: 47.7302, loss: 1.3162
2021-08-14 09:05:46,575 - mmseg - INFO - Iter [18850/160000]	lr: 8.944e-03, eta: 2 days, 3:18:11, time: 1.277, data_time: 0.014, memory: 5545, decode.loss_seg: 1.3154, decode.acc_seg: 47.9287, loss: 1.3154
2021-08-14 09:06:51,358 - mmseg - INFO - Iter [18900/160000]	lr: 8.941e-03, eta: 2 days, 3:17:01, time: 1.295, data_time: 0.013, memory: 5545, decode.loss_seg: 1.3331, decode.acc_seg: 48.0631, loss: 1.3331
2021-08-14 09:08:27,333 - mmseg - INFO - Iter [18950/160000]	lr: 8.938e-03, eta: 2 days, 3:19:43, time: 1.920, data_time: 0.702, memory: 5545, decode.loss_seg: 1.3037, decode.acc_seg: 47.3458, loss: 1.3037
2021-08-14 09:09:29,761 - mmseg - INFO - Exp name: fcn_litehr30-without-head_512x512_160k_ade20k.py
2021-08-14 09:09:29,762 - mmseg - INFO - Iter [19000/160000]	lr: 8.935e-03, eta: 2 days, 3:18:14, time: 1.248, data_time: 0.014, memory: 5545, decode.loss_seg: 1.2867, decode.acc_seg: 48.1755, loss: 1.2867
2021-08-14 09:10:34,536 - mmseg - INFO - Iter [19050/160000]	lr: 8.933e-03, eta: 2 days, 3:17:04, time: 1.295, data_time: 0.013, memory: 5545, decode.loss_seg: 1.3086, decode.acc_seg: 47.5554, loss: 1.3086
2021-08-14 09:11:36,842 - mmseg - INFO - Iter [19100/160000]	lr: 8.930e-03, eta: 2 days, 3:15:35, time: 1.246, data_time: 0.014, memory: 5545, decode.loss_seg: 1.2899, decode.acc_seg: 48.4813, loss: 1.2899
2021-08-14 09:12:37,479 - mmseg - INFO - Iter [19150/160000]	lr: 8.927e-03, eta: 2 days, 3:13:54, time: 1.213, data_time: 0.014, memory: 5545, decode.loss_seg: 1.2667, decode.acc_seg: 49.2522, loss: 1.2667
2021-08-14 09:13:38,922 - mmseg - INFO - Iter [19200/160000]	lr: 8.924e-03, eta: 2 days, 3:12:19, time: 1.228, data_time: 0.014, memory: 5545, decode.loss_seg: 1.2733, decode.acc_seg: 48.2604, loss: 1.2733
2021-08-14 09:14:41,796 - mmseg - INFO - Iter [19250/160000]	lr: 8.921e-03, eta: 2 days, 3:10:54, time: 1.257, data_time: 0.013, memory: 5545, decode.loss_seg: 1.3288, decode.acc_seg: 48.0251, loss: 1.3288
2021-08-14 09:15:43,632 - mmseg - INFO - Iter [19300/160000]	lr: 8.918e-03, eta: 2 days, 3:09:23, time: 1.237, data_time: 0.014, memory: 5545, decode.loss_seg: 1.2917, decode.acc_seg: 49.4326, loss: 1.2917
2021-08-14 09:16:43,283 - mmseg - INFO - Iter [19350/160000]	lr: 8.916e-03, eta: 2 days, 3:07:35, time: 1.192, data_time: 0.013, memory: 5545, decode.loss_seg: 1.2815, decode.acc_seg: 48.6157, loss: 1.2815
2021-08-14 09:17:48,710 - mmseg - INFO - Iter [19400/160000]	lr: 8.913e-03, eta: 2 days, 3:06:29, time: 1.308, data_time: 0.014, memory: 5545, decode.loss_seg: 1.2615, decode.acc_seg: 48.4931, loss: 1.2615
2021-08-14 09:18:54,343 - mmseg - INFO - Iter [19450/160000]	lr: 8.910e-03, eta: 2 days, 3:05:25, time: 1.313, data_time: 0.015, memory: 5545, decode.loss_seg: 1.2433, decode.acc_seg: 48.2259, loss: 1.2433
2021-08-14 09:19:58,964 - mmseg - INFO - Iter [19500/160000]	lr: 8.907e-03, eta: 2 days, 3:04:14, time: 1.292, data_time: 0.014, memory: 5545, decode.loss_seg: 1.2712, decode.acc_seg: 48.9890, loss: 1.2712
2021-08-14 09:21:04,205 - mmseg - INFO - Iter [19550/160000]	lr: 8.904e-03, eta: 2 days, 3:03:07, time: 1.306, data_time: 0.014, memory: 5545, decode.loss_seg: 1.3166, decode.acc_seg: 49.1204, loss: 1.3166
2021-08-14 09:22:42,301 - mmseg - INFO - Iter [19600/160000]	lr: 8.902e-03, eta: 2 days, 3:05:56, time: 1.962, data_time: 0.724, memory: 5545, decode.loss_seg: 1.2768, decode.acc_seg: 48.5423, loss: 1.2768
2021-08-14 09:23:45,282 - mmseg - INFO - Iter [19650/160000]	lr: 8.899e-03, eta: 2 days, 3:04:32, time: 1.260, data_time: 0.013, memory: 5545, decode.loss_seg: 1.2981, decode.acc_seg: 47.9428, loss: 1.2981
2021-08-14 09:24:51,026 - mmseg - INFO - Iter [19700/160000]	lr: 8.896e-03, eta: 2 days, 3:03:28, time: 1.314, data_time: 0.012, memory: 5545, decode.loss_seg: 1.2718, decode.acc_seg: 48.9906, loss: 1.2718
2021-08-14 09:25:53,195 - mmseg - INFO - Iter [19750/160000]	lr: 8.893e-03, eta: 2 days, 3:01:59, time: 1.244, data_time: 0.013, memory: 5545, decode.loss_seg: 1.2847, decode.acc_seg: 48.4848, loss: 1.2847
2021-08-14 09:26:54,335 - mmseg - INFO - Iter [19800/160000]	lr: 8.890e-03, eta: 2 days, 3:00:23, time: 1.222, data_time: 0.013, memory: 5545, decode.loss_seg: 1.2670, decode.acc_seg: 48.2802, loss: 1.2670
2021-08-14 09:27:57,071 - mmseg - INFO - Iter [19850/160000]	lr: 8.887e-03, eta: 2 days, 2:58:58, time: 1.255, data_time: 0.014, memory: 5545, decode.loss_seg: 1.3052, decode.acc_seg: 47.6251, loss: 1.3052
2021-08-14 09:28:56,578 - mmseg - INFO - Iter [19900/160000]	lr: 8.885e-03, eta: 2 days, 2:57:11, time: 1.191, data_time: 0.013, memory: 5545, decode.loss_seg: 1.2999, decode.acc_seg: 48.3774, loss: 1.2999
2021-08-14 09:29:58,156 - mmseg - INFO - Iter [19950/160000]	lr: 8.882e-03, eta: 2 days, 2:55:38, time: 1.231, data_time: 0.013, memory: 5545, decode.loss_seg: 1.2615, decode.acc_seg: 49.0242, loss: 1.2615
2021-08-14 09:31:00,052 - mmseg - INFO - Exp name: fcn_litehr30-without-head_512x512_160k_ade20k.py
2021-08-14 09:31:00,053 - mmseg - INFO - Iter [20000/160000]	lr: 8.879e-03, eta: 2 days, 2:54:08, time: 1.239, data_time: 0.014, memory: 5545, decode.loss_seg: 1.2810, decode.acc_seg: 48.0818, loss: 1.2810
2021-08-14 09:32:00,163 - mmseg - INFO - Iter [20050/160000]	lr: 8.876e-03, eta: 2 days, 2:52:25, time: 1.201, data_time: 0.013, memory: 5545, decode.loss_seg: 1.2622, decode.acc_seg: 49.1799, loss: 1.2622
2021-08-14 09:33:01,710 - mmseg - INFO - Iter [20100/160000]	lr: 8.873e-03, eta: 2 days, 2:50:52, time: 1.231, data_time: 0.013, memory: 5545, decode.loss_seg: 1.2890, decode.acc_seg: 49.2643, loss: 1.2890
2021-08-14 09:34:06,474 - mmseg - INFO - Iter [20150/160000]	lr: 8.871e-03, eta: 2 days, 2:49:42, time: 1.295, data_time: 0.013, memory: 5545, decode.loss_seg: 1.2819, decode.acc_seg: 49.0117, loss: 1.2819
2021-08-14 09:35:44,670 - mmseg - INFO - Iter [20200/160000]	lr: 8.868e-03, eta: 2 days, 2:52:24, time: 1.964, data_time: 0.715, memory: 5545, decode.loss_seg: 1.2864, decode.acc_seg: 48.9409, loss: 1.2864
2021-08-14 09:36:47,179 - mmseg - INFO - Iter [20250/160000]	lr: 8.865e-03, eta: 2 days, 2:50:57, time: 1.250, data_time: 0.014, memory: 5545, decode.loss_seg: 1.2278, decode.acc_seg: 49.5518, loss: 1.2278
2021-08-14 09:37:48,319 - mmseg - INFO - Iter [20300/160000]	lr: 8.862e-03, eta: 2 days, 2:49:22, time: 1.223, data_time: 0.014, memory: 5545, decode.loss_seg: 1.2861, decode.acc_seg: 49.1363, loss: 1.2861
2021-08-14 09:38:48,770 - mmseg - INFO - Iter [20350/160000]	lr: 8.859e-03, eta: 2 days, 2:47:42, time: 1.209, data_time: 0.013, memory: 5545, decode.loss_seg: 1.2341, decode.acc_seg: 49.4008, loss: 1.2341
2021-08-14 09:39:52,566 - mmseg - INFO - Iter [20400/160000]	lr: 8.856e-03, eta: 2 days, 2:46:25, time: 1.276, data_time: 0.013, memory: 5545, decode.loss_seg: 1.2964, decode.acc_seg: 48.2042, loss: 1.2964
2021-08-14 09:40:53,794 - mmseg - INFO - Iter [20450/160000]	lr: 8.854e-03, eta: 2 days, 2:44:51, time: 1.225, data_time: 0.013, memory: 5545, decode.loss_seg: 1.2681, decode.acc_seg: 49.4328, loss: 1.2681
2021-08-14 09:41:56,597 - mmseg - INFO - Iter [20500/160000]	lr: 8.851e-03, eta: 2 days, 2:43:27, time: 1.255, data_time: 0.013, memory: 5545, decode.loss_seg: 1.3037, decode.acc_seg: 48.7578, loss: 1.3037
2021-08-14 09:43:02,708 - mmseg - INFO - Iter [20550/160000]	lr: 8.848e-03, eta: 2 days, 2:42:26, time: 1.322, data_time: 0.015, memory: 5545, decode.loss_seg: 1.2560, decode.acc_seg: 48.3943, loss: 1.2560
2021-08-14 09:44:08,619 - mmseg - INFO - Iter [20600/160000]	lr: 8.845e-03, eta: 2 days, 2:41:24, time: 1.319, data_time: 0.014, memory: 5545, decode.loss_seg: 1.2812, decode.acc_seg: 48.5234, loss: 1.2812
2021-08-14 09:45:08,518 - mmseg - INFO - Iter [20650/160000]	lr: 8.842e-03, eta: 2 days, 2:39:41, time: 1.198, data_time: 0.014, memory: 5545, decode.loss_seg: 1.2493, decode.acc_seg: 48.4329, loss: 1.2493
2021-08-14 09:46:10,294 - mmseg - INFO - Iter [20700/160000]	lr: 8.839e-03, eta: 2 days, 2:38:11, time: 1.236, data_time: 0.014, memory: 5545, decode.loss_seg: 1.2773, decode.acc_seg: 48.8609, loss: 1.2773
2021-08-14 09:47:11,518 - mmseg - INFO - Iter [20750/160000]	lr: 8.837e-03, eta: 2 days, 2:36:37, time: 1.224, data_time: 0.013, memory: 5545, decode.loss_seg: 1.2820, decode.acc_seg: 48.2799, loss: 1.2820
2021-08-14 09:48:14,336 - mmseg - INFO - Iter [20800/160000]	lr: 8.834e-03, eta: 2 days, 2:35:14, time: 1.257, data_time: 0.013, memory: 5545, decode.loss_seg: 1.2590, decode.acc_seg: 48.8238, loss: 1.2590
2021-08-14 09:49:51,671 - mmseg - INFO - Iter [20850/160000]	lr: 8.831e-03, eta: 2 days, 2:37:42, time: 1.947, data_time: 0.710, memory: 5545, decode.loss_seg: 1.2583, decode.acc_seg: 49.2672, loss: 1.2583
2021-08-14 09:50:54,420 - mmseg - INFO - Iter [20900/160000]	lr: 8.828e-03, eta: 2 days, 2:36:18, time: 1.254, data_time: 0.013, memory: 5545, decode.loss_seg: 1.2353, decode.acc_seg: 48.3245, loss: 1.2353
2021-08-14 09:51:59,722 - mmseg - INFO - Iter [20950/160000]	lr: 8.825e-03, eta: 2 days, 2:35:11, time: 1.306, data_time: 0.014, memory: 5545, decode.loss_seg: 1.2187, decode.acc_seg: 50.0340, loss: 1.2187
2021-08-14 09:53:05,482 - mmseg - INFO - Exp name: fcn_litehr30-without-head_512x512_160k_ade20k.py
2021-08-14 09:53:05,482 - mmseg - INFO - Iter [21000/160000]	lr: 8.823e-03, eta: 2 days, 2:34:08, time: 1.315, data_time: 0.014, memory: 5545, decode.loss_seg: 1.2775, decode.acc_seg: 49.8575, loss: 1.2775
2021-08-14 09:54:07,369 - mmseg - INFO - Iter [21050/160000]	lr: 8.820e-03, eta: 2 days, 2:32:38, time: 1.238, data_time: 0.013, memory: 5545, decode.loss_seg: 1.2667, decode.acc_seg: 48.4605, loss: 1.2667
2021-08-14 09:55:11,676 - mmseg - INFO - Iter [21100/160000]	lr: 8.817e-03, eta: 2 days, 2:31:25, time: 1.286, data_time: 0.014, memory: 5545, decode.loss_seg: 1.2415, decode.acc_seg: 48.8948, loss: 1.2415
2021-08-14 09:56:14,829 - mmseg - INFO - Iter [21150/160000]	lr: 8.814e-03, eta: 2 days, 2:30:05, time: 1.264, data_time: 0.014, memory: 5545, decode.loss_seg: 1.3068, decode.acc_seg: 48.1974, loss: 1.3068
2021-08-14 09:57:17,212 - mmseg - INFO - Iter [21200/160000]	lr: 8.811e-03, eta: 2 days, 2:28:39, time: 1.248, data_time: 0.013, memory: 5545, decode.loss_seg: 1.2651, decode.acc_seg: 49.8474, loss: 1.2651
2021-08-14 09:58:18,865 - mmseg - INFO - Iter [21250/160000]	lr: 8.808e-03, eta: 2 days, 2:27:09, time: 1.233, data_time: 0.013, memory: 5545, decode.loss_seg: 1.2606, decode.acc_seg: 49.0194, loss: 1.2606
2021-08-14 09:59:18,014 - mmseg - INFO - Iter [21300/160000]	lr: 8.806e-03, eta: 2 days, 2:25:22, time: 1.182, data_time: 0.013, memory: 5545, decode.loss_seg: 1.2902, decode.acc_seg: 47.3852, loss: 1.2902
2021-08-14 10:00:20,164 - mmseg - INFO - Iter [21350/160000]	lr: 8.803e-03, eta: 2 days, 2:23:55, time: 1.243, data_time: 0.013, memory: 5545, decode.loss_seg: 1.2933, decode.acc_seg: 48.5814, loss: 1.2933
2021-08-14 10:01:23,792 - mmseg - INFO - Iter [21400/160000]	lr: 8.800e-03, eta: 2 days, 2:22:38, time: 1.273, data_time: 0.014, memory: 5545, decode.loss_seg: 1.2808, decode.acc_seg: 48.1966, loss: 1.2808
2021-08-14 10:02:25,969 - mmseg - INFO - Iter [21450/160000]	lr: 8.797e-03, eta: 2 days, 2:21:12, time: 1.244, data_time: 0.014, memory: 5545, decode.loss_seg: 1.2731, decode.acc_seg: 47.8544, loss: 1.2731
2021-08-14 10:04:03,471 - mmseg - INFO - Iter [21500/160000]	lr: 8.794e-03, eta: 2 days, 2:23:33, time: 1.950, data_time: 0.730, memory: 5545, decode.loss_seg: 1.2301, decode.acc_seg: 49.1721, loss: 1.2301
2021-08-14 10:05:04,084 - mmseg - INFO - Iter [21550/160000]	lr: 8.791e-03, eta: 2 days, 2:21:56, time: 1.212, data_time: 0.014, memory: 5545, decode.loss_seg: 1.2691, decode.acc_seg: 48.7850, loss: 1.2691
2021-08-14 10:06:04,376 - mmseg - INFO - Iter [21600/160000]	lr: 8.789e-03, eta: 2 days, 2:20:17, time: 1.205, data_time: 0.013, memory: 5545, decode.loss_seg: 1.2426, decode.acc_seg: 49.0449, loss: 1.2426
2021-08-14 10:07:05,596 - mmseg - INFO - Iter [21650/160000]	lr: 8.786e-03, eta: 2 days, 2:18:45, time: 1.224, data_time: 0.014, memory: 5545, decode.loss_seg: 1.2597, decode.acc_seg: 50.2101, loss: 1.2597
2021-08-14 10:08:10,364 - mmseg - INFO - Iter [21700/160000]	lr: 8.783e-03, eta: 2 days, 2:17:35, time: 1.295, data_time: 0.013, memory: 5545, decode.loss_seg: 1.2873, decode.acc_seg: 48.1689, loss: 1.2873
2021-08-14 10:09:14,566 - mmseg - INFO - Iter [21750/160000]	lr: 8.780e-03, eta: 2 days, 2:16:22, time: 1.285, data_time: 0.014, memory: 5545, decode.loss_seg: 1.2327, decode.acc_seg: 49.7648, loss: 1.2327
2021-08-14 10:10:16,401 - mmseg - INFO - Iter [21800/160000]	lr: 8.777e-03, eta: 2 days, 2:14:53, time: 1.237, data_time: 0.013, memory: 5545, decode.loss_seg: 1.2845, decode.acc_seg: 47.7743, loss: 1.2845
2021-08-14 10:11:16,599 - mmseg - INFO - Iter [21850/160000]	lr: 8.775e-03, eta: 2 days, 2:13:14, time: 1.203, data_time: 0.013, memory: 5545, decode.loss_seg: 1.2575, decode.acc_seg: 49.1600, loss: 1.2575
2021-08-14 10:12:18,623 - mmseg - INFO - Iter [21900/160000]	lr: 8.772e-03, eta: 2 days, 2:11:48, time: 1.241, data_time: 0.014, memory: 5545, decode.loss_seg: 1.2225, decode.acc_seg: 50.1863, loss: 1.2225
2021-08-14 10:13:18,768 - mmseg - INFO - Iter [21950/160000]	lr: 8.769e-03, eta: 2 days, 2:10:09, time: 1.203, data_time: 0.013, memory: 5545, decode.loss_seg: 1.2807, decode.acc_seg: 48.3550, loss: 1.2807
2021-08-14 10:14:19,837 - mmseg - INFO - Exp name: fcn_litehr30-without-head_512x512_160k_ade20k.py
2021-08-14 10:14:19,837 - mmseg - INFO - Iter [22000/160000]	lr: 8.766e-03, eta: 2 days, 2:08:36, time: 1.221, data_time: 0.013, memory: 5545, decode.loss_seg: 1.2513, decode.acc_seg: 49.4390, loss: 1.2513
2021-08-14 10:15:20,802 - mmseg - INFO - Iter [22050/160000]	lr: 8.763e-03, eta: 2 days, 2:07:03, time: 1.219, data_time: 0.014, memory: 5545, decode.loss_seg: 1.3101, decode.acc_seg: 49.1145, loss: 1.3101
2021-08-14 10:16:56,441 - mmseg - INFO - Iter [22100/160000]	lr: 8.760e-03, eta: 2 days, 2:09:06, time: 1.913, data_time: 0.728, memory: 5545, decode.loss_seg: 1.2752, decode.acc_seg: 48.0108, loss: 1.2752
2021-08-14 10:18:00,052 - mmseg - INFO - Iter [22150/160000]	lr: 8.758e-03, eta: 2 days, 2:07:49, time: 1.272, data_time: 0.014, memory: 5545, decode.loss_seg: 1.2442, decode.acc_seg: 48.7434, loss: 1.2442
2021-08-14 10:19:00,468 - mmseg - INFO - Iter [22200/160000]	lr: 8.755e-03, eta: 2 days, 2:06:13, time: 1.209, data_time: 0.013, memory: 5545, decode.loss_seg: 1.2506, decode.acc_seg: 50.1218, loss: 1.2506
2021-08-14 10:19:59,485 - mmseg - INFO - Iter [22250/160000]	lr: 8.752e-03, eta: 2 days, 2:04:28, time: 1.180, data_time: 0.013, memory: 5545, decode.loss_seg: 1.2140, decode.acc_seg: 49.3112, loss: 1.2140
2021-08-14 10:21:03,817 - mmseg - INFO - Iter [22300/160000]	lr: 8.749e-03, eta: 2 days, 2:03:15, time: 1.286, data_time: 0.013, memory: 5545, decode.loss_seg: 1.2502, decode.acc_seg: 49.0548, loss: 1.2502
2021-08-14 10:22:05,344 - mmseg - INFO - Iter [22350/160000]	lr: 8.746e-03, eta: 2 days, 2:01:46, time: 1.230, data_time: 0.014, memory: 5545, decode.loss_seg: 1.1961, decode.acc_seg: 49.1007, loss: 1.1961
2021-08-14 10:23:10,641 - mmseg - INFO - Iter [22400/160000]	lr: 8.743e-03, eta: 2 days, 2:00:39, time: 1.306, data_time: 0.014, memory: 5545, decode.loss_seg: 1.2375, decode.acc_seg: 49.4662, loss: 1.2375
2021-08-14 10:24:16,368 - mmseg - INFO - Iter [22450/160000]	lr: 8.741e-03, eta: 2 days, 1:59:36, time: 1.315, data_time: 0.014, memory: 5545, decode.loss_seg: 1.2258, decode.acc_seg: 49.8277, loss: 1.2258
2021-08-14 10:25:21,109 - mmseg - INFO - Iter [22500/160000]	lr: 8.738e-03, eta: 2 days, 1:58:26, time: 1.295, data_time: 0.014, memory: 5545, decode.loss_seg: 1.2547, decode.acc_seg: 49.1375, loss: 1.2547
2021-08-14 10:26:22,958 - mmseg - INFO - Iter [22550/160000]	lr: 8.735e-03, eta: 2 days, 1:56:59, time: 1.238, data_time: 0.014, memory: 5545, decode.loss_seg: 1.2870, decode.acc_seg: 48.7128, loss: 1.2870
2021-08-14 10:27:25,885 - mmseg - INFO - Iter [22600/160000]	lr: 8.732e-03, eta: 2 days, 1:55:39, time: 1.258, data_time: 0.013, memory: 5545, decode.loss_seg: 1.2945, decode.acc_seg: 49.5919, loss: 1.2945
2021-08-14 10:28:30,382 - mmseg - INFO - Iter [22650/160000]	lr: 8.729e-03, eta: 2 days, 1:54:28, time: 1.290, data_time: 0.013, memory: 5545, decode.loss_seg: 1.2327, decode.acc_seg: 49.6404, loss: 1.2327
2021-08-14 10:29:33,425 - mmseg - INFO - Iter [22700/160000]	lr: 8.726e-03, eta: 2 days, 1:53:08, time: 1.261, data_time: 0.014, memory: 5545, decode.loss_seg: 1.2500, decode.acc_seg: 47.9940, loss: 1.2500
2021-08-14 10:31:09,064 - mmseg - INFO - Iter [22750/160000]	lr: 8.724e-03, eta: 2 days, 1:55:05, time: 1.913, data_time: 0.707, memory: 5545, decode.loss_seg: 1.2378, decode.acc_seg: 48.9064, loss: 1.2378
2021-08-14 10:32:09,088 - mmseg - INFO - Iter [22800/160000]	lr: 8.721e-03, eta: 2 days, 1:53:27, time: 1.201, data_time: 0.014, memory: 5545, decode.loss_seg: 1.1929, decode.acc_seg: 49.3000, loss: 1.1929
2021-08-14 10:33:09,126 - mmseg - INFO - Iter [22850/160000]	lr: 8.718e-03, eta: 2 days, 1:51:49, time: 1.200, data_time: 0.012, memory: 5545, decode.loss_seg: 1.2617, decode.acc_seg: 48.8407, loss: 1.2617
2021-08-14 10:34:12,049 - mmseg - INFO - Iter [22900/160000]	lr: 8.715e-03, eta: 2 days, 1:50:28, time: 1.258, data_time: 0.014, memory: 5545, decode.loss_seg: 1.2255, decode.acc_seg: 50.3208, loss: 1.2255
2021-08-14 10:35:12,454 - mmseg - INFO - Iter [22950/160000]	lr: 8.712e-03, eta: 2 days, 1:48:53, time: 1.208, data_time: 0.014, memory: 5545, decode.loss_seg: 1.2324, decode.acc_seg: 47.9195, loss: 1.2324
2021-08-14 10:36:14,449 - mmseg - INFO - Exp name: fcn_litehr30-without-head_512x512_160k_ade20k.py
2021-08-14 10:36:14,450 - mmseg - INFO - Iter [23000/160000]	lr: 8.710e-03, eta: 2 days, 1:47:27, time: 1.240, data_time: 0.014, memory: 5545, decode.loss_seg: 1.2494, decode.acc_seg: 49.0375, loss: 1.2494
2021-08-14 10:37:16,004 - mmseg - INFO - Iter [23050/160000]	lr: 8.707e-03, eta: 2 days, 1:45:59, time: 1.231, data_time: 0.013, memory: 5545, decode.loss_seg: 1.2261, decode.acc_seg: 51.0969, loss: 1.2261
2021-08-14 10:38:15,600 - mmseg - INFO - Iter [23100/160000]	lr: 8.704e-03, eta: 2 days, 1:44:19, time: 1.192, data_time: 0.014, memory: 5545, decode.loss_seg: 1.2147, decode.acc_seg: 48.9654, loss: 1.2147
2021-08-14 10:39:16,500 - mmseg - INFO - Iter [23150/160000]	lr: 8.701e-03, eta: 2 days, 1:42:47, time: 1.218, data_time: 0.013, memory: 5545, decode.loss_seg: 1.2321, decode.acc_seg: 49.4961, loss: 1.2321
2021-08-14 10:40:22,128 - mmseg - INFO - Iter [23200/160000]	lr: 8.698e-03, eta: 2 days, 1:41:43, time: 1.312, data_time: 0.013, memory: 5545, decode.loss_seg: 1.2632, decode.acc_seg: 48.5496, loss: 1.2632
2021-08-14 10:41:25,049 - mmseg - INFO - Iter [23250/160000]	lr: 8.695e-03, eta: 2 days, 1:40:23, time: 1.259, data_time: 0.014, memory: 5545, decode.loss_seg: 1.2467, decode.acc_seg: 49.1593, loss: 1.2467
2021-08-14 10:42:26,300 - mmseg - INFO - Iter [23300/160000]	lr: 8.693e-03, eta: 2 days, 1:38:53, time: 1.226, data_time: 0.014, memory: 5545, decode.loss_seg: 1.2731, decode.acc_seg: 49.0892, loss: 1.2731
2021-08-14 10:44:03,563 - mmseg - INFO - Iter [23350/160000]	lr: 8.690e-03, eta: 2 days, 1:40:55, time: 1.945, data_time: 0.723, memory: 5545, decode.loss_seg: 1.2676, decode.acc_seg: 48.7111, loss: 1.2676
2021-08-14 10:45:06,532 - mmseg - INFO - Iter [23400/160000]	lr: 8.687e-03, eta: 2 days, 1:39:34, time: 1.259, data_time: 0.014, memory: 5545, decode.loss_seg: 1.2413, decode.acc_seg: 49.6831, loss: 1.2413
2021-08-14 10:46:12,842 - mmseg - INFO - Iter [23450/160000]	lr: 8.684e-03, eta: 2 days, 1:38:34, time: 1.326, data_time: 0.014, memory: 5545, decode.loss_seg: 1.2749, decode.acc_seg: 49.3061, loss: 1.2749
2021-08-14 10:47:14,983 - mmseg - INFO - Iter [23500/160000]	lr: 8.681e-03, eta: 2 days, 1:37:10, time: 1.244, data_time: 0.014, memory: 5545, decode.loss_seg: 1.2509, decode.acc_seg: 49.7877, loss: 1.2509
2021-08-14 10:48:18,514 - mmseg - INFO - Iter [23550/160000]	lr: 8.678e-03, eta: 2 days, 1:35:53, time: 1.270, data_time: 0.013, memory: 5545, decode.loss_seg: 1.2157, decode.acc_seg: 48.3296, loss: 1.2157
2021-08-14 10:49:21,968 - mmseg - INFO - Iter [23600/160000]	lr: 8.676e-03, eta: 2 days, 1:34:36, time: 1.270, data_time: 0.014, memory: 5545, decode.loss_seg: 1.2558, decode.acc_seg: 49.1718, loss: 1.2558
2021-08-14 10:50:21,378 - mmseg - INFO - Iter [23650/160000]	lr: 8.673e-03, eta: 2 days, 1:32:56, time: 1.188, data_time: 0.013, memory: 5545, decode.loss_seg: 1.2423, decode.acc_seg: 48.4831, loss: 1.2423
2021-08-14 10:51:23,670 - mmseg - INFO - Iter [23700/160000]	lr: 8.670e-03, eta: 2 days, 1:31:33, time: 1.246, data_time: 0.013, memory: 5545, decode.loss_seg: 1.2134, decode.acc_seg: 49.8452, loss: 1.2134
2021-08-14 10:52:26,100 - mmseg - INFO - Iter [23750/160000]	lr: 8.667e-03, eta: 2 days, 1:30:10, time: 1.248, data_time: 0.013, memory: 5545, decode.loss_seg: 1.1946, decode.acc_seg: 49.9846, loss: 1.1946
2021-08-14 10:53:32,397 - mmseg - INFO - Iter [23800/160000]	lr: 8.664e-03, eta: 2 days, 1:29:10, time: 1.326, data_time: 0.014, memory: 5545, decode.loss_seg: 1.2806, decode.acc_seg: 49.1252, loss: 1.2806
2021-08-14 10:54:37,761 - mmseg - INFO - Iter [23850/160000]	lr: 8.661e-03, eta: 2 days, 1:28:05, time: 1.308, data_time: 0.014, memory: 5545, decode.loss_seg: 1.2601, decode.acc_seg: 49.8682, loss: 1.2601
2021-08-14 10:55:40,668 - mmseg - INFO - Iter [23900/160000]	lr: 8.659e-03, eta: 2 days, 1:26:45, time: 1.258, data_time: 0.014, memory: 5545, decode.loss_seg: 1.2437, decode.acc_seg: 49.0103, loss: 1.2437
2021-08-14 10:56:41,296 - mmseg - INFO - Iter [23950/160000]	lr: 8.656e-03, eta: 2 days, 1:25:12, time: 1.212, data_time: 0.013, memory: 5545, decode.loss_seg: 1.2729, decode.acc_seg: 49.0976, loss: 1.2729
2021-08-14 10:58:17,880 - mmseg - INFO - Exp name: fcn_litehr30-without-head_512x512_160k_ade20k.py
2021-08-14 10:58:17,884 - mmseg - INFO - Iter [24000/160000]	lr: 8.653e-03, eta: 2 days, 1:27:04, time: 1.932, data_time: 0.719, memory: 5545, decode.loss_seg: 1.2326, decode.acc_seg: 49.7585, loss: 1.2326
2021-08-14 10:59:18,901 - mmseg - INFO - Iter [24050/160000]	lr: 8.650e-03, eta: 2 days, 1:25:33, time: 1.220, data_time: 0.013, memory: 5545, decode.loss_seg: 1.2190, decode.acc_seg: 49.8656, loss: 1.2190
2021-08-14 11:00:20,883 - mmseg - INFO - Iter [24100/160000]	lr: 8.647e-03, eta: 2 days, 1:24:09, time: 1.240, data_time: 0.013, memory: 5545, decode.loss_seg: 1.2317, decode.acc_seg: 48.9833, loss: 1.2317
2021-08-14 11:01:21,917 - mmseg - INFO - Iter [24150/160000]	lr: 8.644e-03, eta: 2 days, 1:22:38, time: 1.220, data_time: 0.013, memory: 5545, decode.loss_seg: 1.2232, decode.acc_seg: 49.7973, loss: 1.2232
2021-08-14 11:02:22,591 - mmseg - INFO - Iter [24200/160000]	lr: 8.642e-03, eta: 2 days, 1:21:06, time: 1.213, data_time: 0.014, memory: 5545, decode.loss_seg: 1.2482, decode.acc_seg: 49.3977, loss: 1.2482
2021-08-14 11:03:24,073 - mmseg - INFO - Iter [24250/160000]	lr: 8.639e-03, eta: 2 days, 1:19:39, time: 1.229, data_time: 0.013, memory: 5545, decode.loss_seg: 1.2145, decode.acc_seg: 50.0027, loss: 1.2145
2021-08-14 11:04:30,091 - mmseg - INFO - Iter [24300/160000]	lr: 8.636e-03, eta: 2 days, 1:18:37, time: 1.320, data_time: 0.014, memory: 5545, decode.loss_seg: 1.2414, decode.acc_seg: 48.1257, loss: 1.2414
2021-08-14 11:05:34,590 - mmseg - INFO - Iter [24350/160000]	lr: 8.633e-03, eta: 2 days, 1:17:26, time: 1.291, data_time: 0.014, memory: 5545, decode.loss_seg: 1.2353, decode.acc_seg: 49.8612, loss: 1.2353
2021-08-14 11:06:36,324 - mmseg - INFO - Iter [24400/160000]	lr: 8.630e-03, eta: 2 days, 1:16:00, time: 1.234, data_time: 0.013, memory: 5545, decode.loss_seg: 1.2211, decode.acc_seg: 49.7919, loss: 1.2211
2021-08-14 11:07:39,984 - mmseg - INFO - Iter [24450/160000]	lr: 8.627e-03, eta: 2 days, 1:14:45, time: 1.273, data_time: 0.013, memory: 5545, decode.loss_seg: 1.2667, decode.acc_seg: 48.6356, loss: 1.2667
2021-08-14 11:08:45,144 - mmseg - INFO - Iter [24500/160000]	lr: 8.625e-03, eta: 2 days, 1:13:39, time: 1.304, data_time: 0.014, memory: 5545, decode.loss_seg: 1.2516, decode.acc_seg: 49.2883, loss: 1.2516
2021-08-14 11:09:46,693 - mmseg - INFO - Iter [24550/160000]	lr: 8.622e-03, eta: 2 days, 1:12:12, time: 1.231, data_time: 0.013, memory: 5545, decode.loss_seg: 1.2433, decode.acc_seg: 49.7163, loss: 1.2433
2021-08-14 11:10:50,678 - mmseg - INFO - Iter [24600/160000]	lr: 8.619e-03, eta: 2 days, 1:10:59, time: 1.279, data_time: 0.013, memory: 5545, decode.loss_seg: 1.2622, decode.acc_seg: 48.8415, loss: 1.2622
2021-08-14 11:12:28,971 - mmseg - INFO - Iter [24650/160000]	lr: 8.616e-03, eta: 2 days, 1:12:54, time: 1.966, data_time: 0.704, memory: 5545, decode.loss_seg: 1.2401, decode.acc_seg: 49.9976, loss: 1.2401
2021-08-14 11:13:33,684 - mmseg - INFO - Iter [24700/160000]	lr: 8.613e-03, eta: 2 days, 1:11:45, time: 1.293, data_time: 0.013, memory: 5545, decode.loss_seg: 1.2162, decode.acc_seg: 49.1101, loss: 1.2162
2021-08-14 11:14:39,172 - mmseg - INFO - Iter [24750/160000]	lr: 8.610e-03, eta: 2 days, 1:10:39, time: 1.310, data_time: 0.013, memory: 5545, decode.loss_seg: 1.1959, decode.acc_seg: 50.1732, loss: 1.1959
2021-08-14 11:15:45,419 - mmseg - INFO - Iter [24800/160000]	lr: 8.608e-03, eta: 2 days, 1:09:38, time: 1.325, data_time: 0.014, memory: 5545, decode.loss_seg: 1.2047, decode.acc_seg: 50.2193, loss: 1.2047
2021-08-14 11:16:51,589 - mmseg - INFO - Iter [24850/160000]	lr: 8.605e-03, eta: 2 days, 1:08:37, time: 1.324, data_time: 0.014, memory: 5545, decode.loss_seg: 1.2038, decode.acc_seg: 49.6136, loss: 1.2038
2021-08-14 11:17:55,669 - mmseg - INFO - Iter [24900/160000]	lr: 8.602e-03, eta: 2 days, 1:07:24, time: 1.282, data_time: 0.014, memory: 5545, decode.loss_seg: 1.2455, decode.acc_seg: 48.9474, loss: 1.2455
2021-08-14 11:18:56,329 - mmseg - INFO - Iter [24950/160000]	lr: 8.599e-03, eta: 2 days, 1:05:53, time: 1.214, data_time: 0.013, memory: 5545, decode.loss_seg: 1.2206, decode.acc_seg: 50.5222, loss: 1.2206
2021-08-14 11:19:55,719 - mmseg - INFO - Exp name: fcn_litehr30-without-head_512x512_160k_ade20k.py
2021-08-14 11:19:55,719 - mmseg - INFO - Iter [25000/160000]	lr: 8.596e-03, eta: 2 days, 1:04:15, time: 1.187, data_time: 0.013, memory: 5545, decode.loss_seg: 1.2716, decode.acc_seg: 49.0374, loss: 1.2716
2021-08-14 11:20:57,271 - mmseg - INFO - Iter [25050/160000]	lr: 8.593e-03, eta: 2 days, 1:02:48, time: 1.231, data_time: 0.013, memory: 5545, decode.loss_seg: 1.2304, decode.acc_seg: 48.8794, loss: 1.2304
2021-08-14 11:21:59,114 - mmseg - INFO - Iter [25100/160000]	lr: 8.591e-03, eta: 2 days, 1:01:24, time: 1.237, data_time: 0.014, memory: 5545, decode.loss_seg: 1.2266, decode.acc_seg: 50.4645, loss: 1.2266
2021-08-14 11:23:00,236 - mmseg - INFO - Iter [25150/160000]	lr: 8.588e-03, eta: 2 days, 0:59:55, time: 1.223, data_time: 0.013, memory: 5545, decode.loss_seg: 1.2006, decode.acc_seg: 49.4570, loss: 1.2006
2021-08-14 11:24:02,139 - mmseg - INFO - Iter [25200/160000]	lr: 8.585e-03, eta: 2 days, 0:58:31, time: 1.237, data_time: 0.013, memory: 5545, decode.loss_seg: 1.2515, decode.acc_seg: 49.1777, loss: 1.2515
2021-08-14 11:25:38,202 - mmseg - INFO - Iter [25250/160000]	lr: 8.582e-03, eta: 2 days, 1:00:09, time: 1.922, data_time: 0.709, memory: 5545, decode.loss_seg: 1.2304, decode.acc_seg: 49.9336, loss: 1.2304
2021-08-14 11:26:41,382 - mmseg - INFO - Iter [25300/160000]	lr: 8.579e-03, eta: 2 days, 0:58:52, time: 1.265, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1859, decode.acc_seg: 50.5974, loss: 1.1859
2021-08-14 11:27:43,394 - mmseg - INFO - Iter [25350/160000]	lr: 8.576e-03, eta: 2 days, 0:57:28, time: 1.239, data_time: 0.013, memory: 5545, decode.loss_seg: 1.2050, decode.acc_seg: 49.8030, loss: 1.2050
2021-08-14 11:28:44,325 - mmseg - INFO - Iter [25400/160000]	lr: 8.574e-03, eta: 2 days, 0:55:59, time: 1.219, data_time: 0.014, memory: 5545, decode.loss_seg: 1.2201, decode.acc_seg: 50.0389, loss: 1.2201
2021-08-14 11:29:46,792 - mmseg - INFO - Iter [25450/160000]	lr: 8.571e-03, eta: 2 days, 0:54:37, time: 1.249, data_time: 0.014, memory: 5545, decode.loss_seg: 1.2479, decode.acc_seg: 49.8512, loss: 1.2479
2021-08-14 11:30:53,711 - mmseg - INFO - Iter [25500/160000]	lr: 8.568e-03, eta: 2 days, 0:53:40, time: 1.338, data_time: 0.015, memory: 5545, decode.loss_seg: 1.2379, decode.acc_seg: 50.6256, loss: 1.2379
2021-08-14 11:31:59,140 - mmseg - INFO - Iter [25550/160000]	lr: 8.565e-03, eta: 2 days, 0:52:34, time: 1.309, data_time: 0.014, memory: 5545, decode.loss_seg: 1.2280, decode.acc_seg: 48.4944, loss: 1.2280
2021-08-14 11:32:59,132 - mmseg - INFO - Iter [25600/160000]	lr: 8.562e-03, eta: 2 days, 0:51:00, time: 1.200, data_time: 0.013, memory: 5545, decode.loss_seg: 1.2812, decode.acc_seg: 47.9931, loss: 1.2812
2021-08-14 11:33:59,883 - mmseg - INFO - Iter [25650/160000]	lr: 8.559e-03, eta: 2 days, 0:49:30, time: 1.215, data_time: 0.014, memory: 5545, decode.loss_seg: 1.1939, decode.acc_seg: 50.4017, loss: 1.1939
2021-08-14 11:35:06,202 - mmseg - INFO - Iter [25700/160000]	lr: 8.557e-03, eta: 2 days, 0:48:30, time: 1.326, data_time: 0.014, memory: 5545, decode.loss_seg: 1.2287, decode.acc_seg: 48.8367, loss: 1.2287
2021-08-14 11:36:08,829 - mmseg - INFO - Iter [25750/160000]	lr: 8.554e-03, eta: 2 days, 0:47:10, time: 1.253, data_time: 0.014, memory: 5545, decode.loss_seg: 1.2354, decode.acc_seg: 49.0647, loss: 1.2354
2021-08-14 11:37:10,010 - mmseg - INFO - Iter [25800/160000]	lr: 8.551e-03, eta: 2 days, 0:45:42, time: 1.224, data_time: 0.014, memory: 5545, decode.loss_seg: 1.2160, decode.acc_seg: 49.3783, loss: 1.2160
2021-08-14 11:38:13,017 - mmseg - INFO - Iter [25850/160000]	lr: 8.548e-03, eta: 2 days, 0:44:24, time: 1.259, data_time: 0.013, memory: 5545, decode.loss_seg: 1.2130, decode.acc_seg: 50.5494, loss: 1.2130
2021-08-14 11:39:52,588 - mmseg - INFO - Iter [25900/160000]	lr: 8.545e-03, eta: 2 days, 0:46:16, time: 1.992, data_time: 0.726, memory: 5545, decode.loss_seg: 1.2028, decode.acc_seg: 50.0791, loss: 1.2028
2021-08-14 11:40:55,666 - mmseg - INFO - Iter [25950/160000]	lr: 8.542e-03, eta: 2 days, 0:44:58, time: 1.261, data_time: 0.013, memory: 5545, decode.loss_seg: 1.1927, decode.acc_seg: 49.8440, loss: 1.1927
2021-08-14 11:42:01,158 - mmseg - INFO - Exp name: fcn_litehr30-without-head_512x512_160k_ade20k.py
2021-08-14 11:42:01,159 - mmseg - INFO - Iter [26000/160000]	lr: 8.540e-03, eta: 2 days, 0:43:53, time: 1.310, data_time: 0.014, memory: 5545, decode.loss_seg: 1.1864, decode.acc_seg: 49.8336, loss: 1.1864
2021-08-14 11:43:02,332 - mmseg - INFO - Iter [26050/160000]	lr: 8.537e-03, eta: 2 days, 0:42:25, time: 1.224, data_time: 0.014, memory: 5545, decode.loss_seg: 1.2120, decode.acc_seg: 50.0547, loss: 1.2120
2021-08-14 11:44:04,829 - mmseg - INFO - Iter [26100/160000]	lr: 8.534e-03, eta: 2 days, 0:41:05, time: 1.251, data_time: 0.013, memory: 5545, decode.loss_seg: 1.1878, decode.acc_seg: 50.5677, loss: 1.1878
2021-08-14 11:45:04,467 - mmseg - INFO - Iter [26150/160000]	lr: 8.531e-03, eta: 2 days, 0:39:30, time: 1.193, data_time: 0.013, memory: 5545, decode.loss_seg: 1.2198, decode.acc_seg: 49.0068, loss: 1.2198
2021-08-14 11:46:07,943 - mmseg - INFO - Iter [26200/160000]	lr: 8.528e-03, eta: 2 days, 0:38:14, time: 1.269, data_time: 0.013, memory: 5545, decode.loss_seg: 1.2333, decode.acc_seg: 49.6453, loss: 1.2333
2021-08-14 11:47:09,599 - mmseg - INFO - Iter [26250/160000]	lr: 8.525e-03, eta: 2 days, 0:36:50, time: 1.234, data_time: 0.014, memory: 5545, decode.loss_seg: 1.2089, decode.acc_seg: 49.2156, loss: 1.2089
2021-08-14 11:48:08,697 - mmseg - INFO - Iter [26300/160000]	lr: 8.523e-03, eta: 2 days, 0:35:12, time: 1.181, data_time: 0.013, memory: 5545, decode.loss_seg: 1.2443, decode.acc_seg: 48.4122, loss: 1.2443
2021-08-14 11:49:11,502 - mmseg - INFO - Iter [26350/160000]	lr: 8.520e-03, eta: 2 days, 0:33:53, time: 1.256, data_time: 0.015, memory: 5545, decode.loss_seg: 1.2391, decode.acc_seg: 50.0078, loss: 1.2391
2021-08-14 11:50:13,781 - mmseg - INFO - Iter [26400/160000]	lr: 8.517e-03, eta: 2 days, 0:32:32, time: 1.246, data_time: 0.014, memory: 5545, decode.loss_seg: 1.2205, decode.acc_seg: 51.0644, loss: 1.2205
2021-08-14 11:51:17,920 - mmseg - INFO - Iter [26450/160000]	lr: 8.514e-03, eta: 2 days, 0:31:20, time: 1.283, data_time: 0.014, memory: 5545, decode.loss_seg: 1.2271, decode.acc_seg: 49.5383, loss: 1.2271
2021-08-14 11:52:18,003 - mmseg - INFO - Iter [26500/160000]	lr: 8.511e-03, eta: 2 days, 0:29:48, time: 1.202, data_time: 0.014, memory: 5545, decode.loss_seg: 1.2051, decode.acc_seg: 50.1190, loss: 1.2051
2021-08-14 11:53:55,044 - mmseg - INFO - Iter [26550/160000]	lr: 8.508e-03, eta: 2 days, 0:31:22, time: 1.940, data_time: 0.738, memory: 5545, decode.loss_seg: 1.1490, decode.acc_seg: 50.9112, loss: 1.1490
2021-08-14 11:54:57,762 - mmseg - INFO - Iter [26600/160000]	lr: 8.506e-03, eta: 2 days, 0:30:03, time: 1.254, data_time: 0.014, memory: 5545, decode.loss_seg: 1.2283, decode.acc_seg: 48.8860, loss: 1.2283
2021-08-14 11:55:58,440 - mmseg - INFO - Iter [26650/160000]	lr: 8.503e-03, eta: 2 days, 0:28:33, time: 1.214, data_time: 0.013, memory: 5545, decode.loss_seg: 1.2228, decode.acc_seg: 49.2131, loss: 1.2228
2021-08-14 11:56:59,285 - mmseg - INFO - Iter [26700/160000]	lr: 8.500e-03, eta: 2 days, 0:27:05, time: 1.216, data_time: 0.013, memory: 5545, decode.loss_seg: 1.2152, decode.acc_seg: 49.3207, loss: 1.2152
2021-08-14 11:58:03,003 - mmseg - INFO - Iter [26750/160000]	lr: 8.497e-03, eta: 2 days, 0:25:51, time: 1.274, data_time: 0.013, memory: 5545, decode.loss_seg: 1.1628, decode.acc_seg: 50.7947, loss: 1.1628
2021-08-14 11:59:03,916 - mmseg - INFO - Iter [26800/160000]	lr: 8.494e-03, eta: 2 days, 0:24:23, time: 1.219, data_time: 0.014, memory: 5545, decode.loss_seg: 1.2148, decode.acc_seg: 49.2699, loss: 1.2148
2021-08-14 12:00:06,715 - mmseg - INFO - Iter [26850/160000]	lr: 8.491e-03, eta: 2 days, 0:23:05, time: 1.255, data_time: 0.014, memory: 5545, decode.loss_seg: 1.2229, decode.acc_seg: 49.3138, loss: 1.2229
2021-08-14 12:01:09,414 - mmseg - INFO - Iter [26900/160000]	lr: 8.489e-03, eta: 2 days, 0:21:46, time: 1.255, data_time: 0.016, memory: 5545, decode.loss_seg: 1.2163, decode.acc_seg: 49.6950, loss: 1.2163
2021-08-14 12:02:12,820 - mmseg - INFO - Iter [26950/160000]	lr: 8.486e-03, eta: 2 days, 0:20:31, time: 1.269, data_time: 0.013, memory: 5545, decode.loss_seg: 1.1869, decode.acc_seg: 50.4474, loss: 1.1869
2021-08-14 12:03:15,381 - mmseg - INFO - Exp name: fcn_litehr30-without-head_512x512_160k_ade20k.py
2021-08-14 12:03:15,382 - mmseg - INFO - Iter [27000/160000]	lr: 8.483e-03, eta: 2 days, 0:19:11, time: 1.251, data_time: 0.013, memory: 5545, decode.loss_seg: 1.2193, decode.acc_seg: 50.1606, loss: 1.2193
2021-08-14 12:04:16,475 - mmseg - INFO - Iter [27050/160000]	lr: 8.480e-03, eta: 2 days, 0:17:45, time: 1.222, data_time: 0.014, memory: 5545, decode.loss_seg: 1.2021, decode.acc_seg: 49.8301, loss: 1.2021
2021-08-14 12:05:20,892 - mmseg - INFO - Iter [27100/160000]	lr: 8.477e-03, eta: 2 days, 0:16:35, time: 1.287, data_time: 0.013, memory: 5545, decode.loss_seg: 1.2383, decode.acc_seg: 49.5939, loss: 1.2383
2021-08-14 12:07:09,526 - mmseg - INFO - Iter [27150/160000]	lr: 8.474e-03, eta: 2 days, 0:19:01, time: 2.173, data_time: 0.890, memory: 5545, decode.loss_seg: 1.2144, decode.acc_seg: 50.4126, loss: 1.2144
2021-08-14 12:08:11,614 - mmseg - INFO - Iter [27200/160000]	lr: 8.472e-03, eta: 2 days, 0:17:39, time: 1.241, data_time: 0.013, memory: 5545, decode.loss_seg: 1.2353, decode.acc_seg: 48.5313, loss: 1.2353
2021-08-14 12:09:14,570 - mmseg - INFO - Iter [27250/160000]	lr: 8.469e-03, eta: 2 days, 0:16:21, time: 1.260, data_time: 0.013, memory: 5545, decode.loss_seg: 1.1927, decode.acc_seg: 50.3495, loss: 1.1927
2021-08-14 12:10:14,902 - mmseg - INFO - Iter [27300/160000]	lr: 8.466e-03, eta: 2 days, 0:14:51, time: 1.206, data_time: 0.013, memory: 5545, decode.loss_seg: 1.1875, decode.acc_seg: 51.3637, loss: 1.1875
2021-08-14 12:11:16,400 - mmseg - INFO - Iter [27350/160000]	lr: 8.463e-03, eta: 2 days, 0:13:26, time: 1.230, data_time: 0.014, memory: 5545, decode.loss_seg: 1.1801, decode.acc_seg: 49.9762, loss: 1.1801
2021-08-14 12:12:16,937 - mmseg - INFO - Iter [27400/160000]	lr: 8.460e-03, eta: 2 days, 0:11:57, time: 1.211, data_time: 0.013, memory: 5545, decode.loss_seg: 1.2658, decode.acc_seg: 48.5580, loss: 1.2658
2021-08-14 12:13:19,297 - mmseg - INFO - Iter [27450/160000]	lr: 8.457e-03, eta: 2 days, 0:10:37, time: 1.247, data_time: 0.013, memory: 5545, decode.loss_seg: 1.2000, decode.acc_seg: 50.1448, loss: 1.2000
2021-08-14 12:14:22,296 - mmseg - INFO - Iter [27500/160000]	lr: 8.455e-03, eta: 2 days, 0:09:20, time: 1.260, data_time: 0.013, memory: 5545, decode.loss_seg: 1.1825, decode.acc_seg: 51.2553, loss: 1.1825
2021-08-14 12:15:26,011 - mmseg - INFO - Iter [27550/160000]	lr: 8.452e-03, eta: 2 days, 0:08:06, time: 1.274, data_time: 0.013, memory: 5545, decode.loss_seg: 1.2433, decode.acc_seg: 48.9031, loss: 1.2433
2021-08-14 12:16:32,377 - mmseg - INFO - Iter [27600/160000]	lr: 8.449e-03, eta: 2 days, 0:07:05, time: 1.327, data_time: 0.014, memory: 5545, decode.loss_seg: 1.2235, decode.acc_seg: 49.8548, loss: 1.2235
2021-08-14 12:17:32,877 - mmseg - INFO - Iter [27650/160000]	lr: 8.446e-03, eta: 2 days, 0:05:37, time: 1.211, data_time: 0.014, memory: 5545, decode.loss_seg: 1.2094, decode.acc_seg: 50.0280, loss: 1.2094
2021-08-14 12:18:35,718 - mmseg - INFO - Iter [27700/160000]	lr: 8.443e-03, eta: 2 days, 0:04:19, time: 1.256, data_time: 0.013, memory: 5545, decode.loss_seg: 1.1847, decode.acc_seg: 51.2035, loss: 1.1847
2021-08-14 12:19:37,113 - mmseg - INFO - Iter [27750/160000]	lr: 8.440e-03, eta: 2 days, 0:02:54, time: 1.228, data_time: 0.013, memory: 5545, decode.loss_seg: 1.2274, decode.acc_seg: 49.2906, loss: 1.2274
2021-08-14 12:21:13,414 - mmseg - INFO - Iter [27800/160000]	lr: 8.438e-03, eta: 2 days, 0:04:16, time: 1.925, data_time: 0.735, memory: 5545, decode.loss_seg: 1.2395, decode.acc_seg: 49.4800, loss: 1.2395
2021-08-14 12:22:14,663 - mmseg - INFO - Iter [27850/160000]	lr: 8.435e-03, eta: 2 days, 0:02:50, time: 1.226, data_time: 0.014, memory: 5545, decode.loss_seg: 1.1574, decode.acc_seg: 51.0009, loss: 1.1574
2021-08-14 12:23:17,636 - mmseg - INFO - Iter [27900/160000]	lr: 8.432e-03, eta: 2 days, 0:01:33, time: 1.259, data_time: 0.013, memory: 5545, decode.loss_seg: 1.1935, decode.acc_seg: 50.0228, loss: 1.1935
2021-08-14 12:24:23,496 - mmseg - INFO - Iter [27950/160000]	lr: 8.429e-03, eta: 2 days, 0:00:30, time: 1.317, data_time: 0.013, memory: 5545, decode.loss_seg: 1.1900, decode.acc_seg: 50.3508, loss: 1.1900
2021-08-14 12:25:29,532 - mmseg - INFO - Exp name: fcn_litehr30-without-head_512x512_160k_ade20k.py
2021-08-14 12:25:29,533 - mmseg - INFO - Iter [28000/160000]	lr: 8.426e-03, eta: 1 day, 23:59:27, time: 1.321, data_time: 0.014, memory: 5545, decode.loss_seg: 1.1771, decode.acc_seg: 50.6031, loss: 1.1771
2021-08-14 12:26:30,367 - mmseg - INFO - Iter [28050/160000]	lr: 8.423e-03, eta: 1 day, 23:58:00, time: 1.216, data_time: 0.014, memory: 5545, decode.loss_seg: 1.1862, decode.acc_seg: 50.9208, loss: 1.1862
2021-08-14 12:27:32,919 - mmseg - INFO - Iter [28100/160000]	lr: 8.421e-03, eta: 1 day, 23:56:41, time: 1.252, data_time: 0.014, memory: 5545, decode.loss_seg: 1.2056, decode.acc_seg: 49.9889, loss: 1.2056
2021-08-14 12:28:33,292 - mmseg - INFO - Iter [28150/160000]	lr: 8.418e-03, eta: 1 day, 23:55:12, time: 1.207, data_time: 0.013, memory: 5545, decode.loss_seg: 1.1776, decode.acc_seg: 50.6897, loss: 1.1776
2021-08-14 12:29:34,942 - mmseg - INFO - Iter [28200/160000]	lr: 8.415e-03, eta: 1 day, 23:53:49, time: 1.233, data_time: 0.013, memory: 5545, decode.loss_seg: 1.1949, decode.acc_seg: 50.4132, loss: 1.1949
2021-08-14 12:30:35,951 - mmseg - INFO - Iter [28250/160000]	lr: 8.412e-03, eta: 1 day, 23:52:23, time: 1.219, data_time: 0.013, memory: 5545, decode.loss_seg: 1.2521, decode.acc_seg: 50.1575, loss: 1.2521
2021-08-14 12:31:37,799 - mmseg - INFO - Iter [28300/160000]	lr: 8.409e-03, eta: 1 day, 23:51:01, time: 1.238, data_time: 0.014, memory: 5545, decode.loss_seg: 1.1485, decode.acc_seg: 50.9301, loss: 1.1485
2021-08-14 12:32:41,873 - mmseg - INFO - Iter [28350/160000]	lr: 8.406e-03, eta: 1 day, 23:49:49, time: 1.281, data_time: 0.013, memory: 5545, decode.loss_seg: 1.2290, decode.acc_seg: 50.4374, loss: 1.2290
2021-08-14 12:34:19,623 - mmseg - INFO - Iter [28400/160000]	lr: 8.403e-03, eta: 1 day, 23:51:14, time: 1.955, data_time: 0.672, memory: 5545, decode.loss_seg: 1.2067, decode.acc_seg: 50.7428, loss: 1.2067
2021-08-14 12:35:21,938 - mmseg - INFO - Iter [28450/160000]	lr: 8.401e-03, eta: 1 day, 23:49:54, time: 1.247, data_time: 0.014, memory: 5545, decode.loss_seg: 1.2051, decode.acc_seg: 49.8851, loss: 1.2051
2021-08-14 12:36:24,293 - mmseg - INFO - Iter [28500/160000]	lr: 8.398e-03, eta: 1 day, 23:48:34, time: 1.246, data_time: 0.013, memory: 5545, decode.loss_seg: 1.1894, decode.acc_seg: 50.0727, loss: 1.1894
2021-08-14 12:37:26,414 - mmseg - INFO - Iter [28550/160000]	lr: 8.395e-03, eta: 1 day, 23:47:13, time: 1.242, data_time: 0.014, memory: 5545, decode.loss_seg: 1.2078, decode.acc_seg: 49.6088, loss: 1.2078
2021-08-14 12:38:31,121 - mmseg - INFO - Iter [28600/160000]	lr: 8.392e-03, eta: 1 day, 23:46:05, time: 1.294, data_time: 0.013, memory: 5545, decode.loss_seg: 1.1387, decode.acc_seg: 51.2157, loss: 1.1387
2021-08-14 12:39:34,312 - mmseg - INFO - Iter [28650/160000]	lr: 8.389e-03, eta: 1 day, 23:44:49, time: 1.264, data_time: 0.013, memory: 5545, decode.loss_seg: 1.1786, decode.acc_seg: 50.8500, loss: 1.1786
2021-08-14 12:40:40,842 - mmseg - INFO - Iter [28700/160000]	lr: 8.386e-03, eta: 1 day, 23:43:48, time: 1.330, data_time: 0.014, memory: 5545, decode.loss_seg: 1.2029, decode.acc_seg: 50.1369, loss: 1.2029
2021-08-14 12:41:44,798 - mmseg - INFO - Iter [28750/160000]	lr: 8.384e-03, eta: 1 day, 23:42:36, time: 1.280, data_time: 0.014, memory: 5545, decode.loss_seg: 1.1563, decode.acc_seg: 50.7231, loss: 1.1563
2021-08-14 12:42:46,803 - mmseg - INFO - Iter [28800/160000]	lr: 8.381e-03, eta: 1 day, 23:41:15, time: 1.239, data_time: 0.013, memory: 5545, decode.loss_seg: 1.1543, decode.acc_seg: 49.8647, loss: 1.1543
2021-08-14 12:43:48,617 - mmseg - INFO - Iter [28850/160000]	lr: 8.378e-03, eta: 1 day, 23:39:54, time: 1.237, data_time: 0.014, memory: 5545, decode.loss_seg: 1.2085, decode.acc_seg: 50.7309, loss: 1.2085
2021-08-14 12:44:48,884 - mmseg - INFO - Iter [28900/160000]	lr: 8.375e-03, eta: 1 day, 23:38:25, time: 1.205, data_time: 0.013, memory: 5545, decode.loss_seg: 1.2115, decode.acc_seg: 49.5141, loss: 1.2115
2021-08-14 12:45:51,126 - mmseg - INFO - Iter [28950/160000]	lr: 8.372e-03, eta: 1 day, 23:37:05, time: 1.244, data_time: 0.013, memory: 5545, decode.loss_seg: 1.1763, decode.acc_seg: 50.3164, loss: 1.1763
2021-08-14 12:46:54,914 - mmseg - INFO - Exp name: fcn_litehr30-without-head_512x512_160k_ade20k.py
2021-08-14 12:46:54,914 - mmseg - INFO - Iter [29000/160000]	lr: 8.369e-03, eta: 1 day, 23:35:52, time: 1.276, data_time: 0.014, memory: 5545, decode.loss_seg: 1.1954, decode.acc_seg: 49.8385, loss: 1.1954
2021-08-14 12:48:31,809 - mmseg - INFO - Iter [29050/160000]	lr: 8.367e-03, eta: 1 day, 23:37:09, time: 1.938, data_time: 0.729, memory: 5545, decode.loss_seg: 1.2061, decode.acc_seg: 50.3879, loss: 1.2061
2021-08-14 12:49:33,875 - mmseg - INFO - Iter [29100/160000]	lr: 8.364e-03, eta: 1 day, 23:35:48, time: 1.240, data_time: 0.013, memory: 5545, decode.loss_seg: 1.1683, decode.acc_seg: 50.0197, loss: 1.1683
2021-08-14 12:50:35,918 - mmseg - INFO - Iter [29150/160000]	lr: 8.361e-03, eta: 1 day, 23:34:27, time: 1.242, data_time: 0.014, memory: 5545, decode.loss_seg: 1.1685, decode.acc_seg: 50.7735, loss: 1.1685
2021-08-14 12:51:37,258 - mmseg - INFO - Iter [29200/160000]	lr: 8.358e-03, eta: 1 day, 23:33:04, time: 1.227, data_time: 0.013, memory: 5545, decode.loss_seg: 1.1959, decode.acc_seg: 50.2930, loss: 1.1959
2021-08-14 12:52:37,654 - mmseg - INFO - Iter [29250/160000]	lr: 8.355e-03, eta: 1 day, 23:31:36, time: 1.208, data_time: 0.014, memory: 5545, decode.loss_seg: 1.1666, decode.acc_seg: 50.3408, loss: 1.1666
2021-08-14 12:53:40,428 - mmseg - INFO - Iter [29300/160000]	lr: 8.352e-03, eta: 1 day, 23:30:18, time: 1.255, data_time: 0.014, memory: 5545, decode.loss_seg: 1.1612, decode.acc_seg: 50.6677, loss: 1.1612
2021-08-14 12:54:40,267 - mmseg - INFO - Iter [29350/160000]	lr: 8.350e-03, eta: 1 day, 23:28:48, time: 1.197, data_time: 0.014, memory: 5545, decode.loss_seg: 1.1959, decode.acc_seg: 50.1607, loss: 1.1959
2021-08-14 12:55:40,250 - mmseg - INFO - Iter [29400/160000]	lr: 8.347e-03, eta: 1 day, 23:27:19, time: 1.200, data_time: 0.014, memory: 5545, decode.loss_seg: 1.1959, decode.acc_seg: 50.2861, loss: 1.1959
2021-08-14 12:56:42,617 - mmseg - INFO - Iter [29450/160000]	lr: 8.344e-03, eta: 1 day, 23:26:00, time: 1.247, data_time: 0.013, memory: 5545, decode.loss_seg: 1.2022, decode.acc_seg: 50.0012, loss: 1.2022
2021-08-14 12:57:44,198 - mmseg - INFO - Iter [29500/160000]	lr: 8.341e-03, eta: 1 day, 23:24:37, time: 1.232, data_time: 0.014, memory: 5545, decode.loss_seg: 1.2033, decode.acc_seg: 50.5229, loss: 1.2033
2021-08-14 12:58:44,462 - mmseg - INFO - Iter [29550/160000]	lr: 8.338e-03, eta: 1 day, 23:23:09, time: 1.205, data_time: 0.013, memory: 5545, decode.loss_seg: 1.2057, decode.acc_seg: 50.8189, loss: 1.2057
2021-08-14 12:59:45,805 - mmseg - INFO - Iter [29600/160000]	lr: 8.335e-03, eta: 1 day, 23:21:46, time: 1.226, data_time: 0.013, memory: 5545, decode.loss_seg: 1.1946, decode.acc_seg: 50.1963, loss: 1.1946
2021-08-14 13:00:47,593 - mmseg - INFO - Iter [29650/160000]	lr: 8.332e-03, eta: 1 day, 23:20:25, time: 1.236, data_time: 0.014, memory: 5545, decode.loss_seg: 1.1628, decode.acc_seg: 50.4442, loss: 1.1628
2021-08-14 13:02:23,244 - mmseg - INFO - Iter [29700/160000]	lr: 8.330e-03, eta: 1 day, 23:21:32, time: 1.914, data_time: 0.703, memory: 5545, decode.loss_seg: 1.1398, decode.acc_seg: 50.1046, loss: 1.1398
2021-08-14 13:03:24,742 - mmseg - INFO - Iter [29750/160000]	lr: 8.327e-03, eta: 1 day, 23:20:10, time: 1.230, data_time: 0.014, memory: 5545, decode.loss_seg: 1.1644, decode.acc_seg: 50.8639, loss: 1.1644
2021-08-14 13:04:27,118 - mmseg - INFO - Iter [29800/160000]	lr: 8.324e-03, eta: 1 day, 23:18:51, time: 1.247, data_time: 0.013, memory: 5545, decode.loss_seg: 1.1697, decode.acc_seg: 50.6780, loss: 1.1697
2021-08-14 13:05:28,739 - mmseg - INFO - Iter [29850/160000]	lr: 8.321e-03, eta: 1 day, 23:17:29, time: 1.233, data_time: 0.014, memory: 5545, decode.loss_seg: 1.2328, decode.acc_seg: 50.5043, loss: 1.2328
2021-08-14 13:06:32,980 - mmseg - INFO - Iter [29900/160000]	lr: 8.318e-03, eta: 1 day, 23:16:19, time: 1.285, data_time: 0.014, memory: 5545, decode.loss_seg: 1.1658, decode.acc_seg: 50.6466, loss: 1.1658
2021-08-14 13:07:34,304 - mmseg - INFO - Iter [29950/160000]	lr: 8.315e-03, eta: 1 day, 23:14:55, time: 1.226, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1628, decode.acc_seg: 51.1883, loss: 1.1628
2021-08-14 13:08:36,211 - mmseg - INFO - Exp name: fcn_litehr30-without-head_512x512_160k_ade20k.py
2021-08-14 13:08:36,212 - mmseg - INFO - Iter [30000/160000]	lr: 8.313e-03, eta: 1 day, 23:13:35, time: 1.239, data_time: 0.014, memory: 5545, decode.loss_seg: 1.1826, decode.acc_seg: 50.1107, loss: 1.1826
2021-08-14 13:09:36,354 - mmseg - INFO - Iter [30050/160000]	lr: 8.310e-03, eta: 1 day, 23:12:07, time: 1.203, data_time: 0.013, memory: 5545, decode.loss_seg: 1.1720, decode.acc_seg: 51.0263, loss: 1.1720
2021-08-14 13:10:37,501 - mmseg - INFO - Iter [30100/160000]	lr: 8.307e-03, eta: 1 day, 23:10:43, time: 1.222, data_time: 0.013, memory: 5545, decode.loss_seg: 1.1623, decode.acc_seg: 50.4698, loss: 1.1623
2021-08-14 13:11:40,217 - mmseg - INFO - Iter [30150/160000]	lr: 8.304e-03, eta: 1 day, 23:09:26, time: 1.254, data_time: 0.013, memory: 5545, decode.loss_seg: 1.1904, decode.acc_seg: 51.1270, loss: 1.1904
2021-08-14 13:12:42,605 - mmseg - INFO - Iter [30200/160000]	lr: 8.301e-03, eta: 1 day, 23:08:08, time: 1.248, data_time: 0.013, memory: 5545, decode.loss_seg: 1.1869, decode.acc_seg: 49.8088, loss: 1.1869
2021-08-14 13:13:43,456 - mmseg - INFO - Iter [30250/160000]	lr: 8.298e-03, eta: 1 day, 23:06:43, time: 1.216, data_time: 0.013, memory: 5545, decode.loss_seg: 1.1925, decode.acc_seg: 51.2393, loss: 1.1925
2021-08-14 13:15:20,453 - mmseg - INFO - Iter [30300/160000]	lr: 8.296e-03, eta: 1 day, 23:07:53, time: 1.940, data_time: 0.726, memory: 5545, decode.loss_seg: 1.2275, decode.acc_seg: 48.9276, loss: 1.2275
2021-08-14 13:16:23,588 - mmseg - INFO - Iter [30350/160000]	lr: 8.293e-03, eta: 1 day, 23:06:39, time: 1.263, data_time: 0.013, memory: 5545, decode.loss_seg: 1.1720, decode.acc_seg: 50.2357, loss: 1.1720
2021-08-14 13:17:26,817 - mmseg - INFO - Iter [30400/160000]	lr: 8.290e-03, eta: 1 day, 23:05:24, time: 1.265, data_time: 0.013, memory: 5545, decode.loss_seg: 1.1724, decode.acc_seg: 51.2245, loss: 1.1724
2021-08-14 13:18:29,720 - mmseg - INFO - Iter [30450/160000]	lr: 8.287e-03, eta: 1 day, 23:04:08, time: 1.257, data_time: 0.012, memory: 5545, decode.loss_seg: 1.2094, decode.acc_seg: 50.5430, loss: 1.2094
2021-08-14 13:19:30,639 - mmseg - INFO - Iter [30500/160000]	lr: 8.284e-03, eta: 1 day, 23:02:43, time: 1.219, data_time: 0.013, memory: 5545, decode.loss_seg: 1.1793, decode.acc_seg: 50.3504, loss: 1.1793
2021-08-14 13:20:32,758 - mmseg - INFO - Iter [30550/160000]	lr: 8.281e-03, eta: 1 day, 23:01:24, time: 1.242, data_time: 0.013, memory: 5545, decode.loss_seg: 1.1431, decode.acc_seg: 50.2220, loss: 1.1431
2021-08-14 13:21:35,147 - mmseg - INFO - Iter [30600/160000]	lr: 8.278e-03, eta: 1 day, 23:00:06, time: 1.248, data_time: 0.013, memory: 5545, decode.loss_seg: 1.1561, decode.acc_seg: 50.6424, loss: 1.1561
2021-08-14 13:22:35,585 - mmseg - INFO - Iter [30650/160000]	lr: 8.276e-03, eta: 1 day, 22:58:40, time: 1.209, data_time: 0.013, memory: 5545, decode.loss_seg: 1.1777, decode.acc_seg: 51.0124, loss: 1.1777
2021-08-14 13:23:38,226 - mmseg - INFO - Iter [30700/160000]	lr: 8.273e-03, eta: 1 day, 22:57:23, time: 1.252, data_time: 0.012, memory: 5545, decode.loss_seg: 1.1695, decode.acc_seg: 51.2023, loss: 1.1695
2021-08-14 13:24:42,242 - mmseg - INFO - Iter [30750/160000]	lr: 8.270e-03, eta: 1 day, 22:56:12, time: 1.281, data_time: 0.013, memory: 5545, decode.loss_seg: 1.2286, decode.acc_seg: 49.1279, loss: 1.2286
2021-08-14 13:25:44,753 - mmseg - INFO - Iter [30800/160000]	lr: 8.267e-03, eta: 1 day, 22:54:54, time: 1.250, data_time: 0.013, memory: 5545, decode.loss_seg: 1.1858, decode.acc_seg: 50.3679, loss: 1.1858
2021-08-14 13:26:50,172 - mmseg - INFO - Iter [30850/160000]	lr: 8.264e-03, eta: 1 day, 22:53:49, time: 1.309, data_time: 0.013, memory: 5545, decode.loss_seg: 1.1597, decode.acc_seg: 50.8274, loss: 1.1597
2021-08-14 13:27:55,540 - mmseg - INFO - Iter [30900/160000]	lr: 8.261e-03, eta: 1 day, 22:52:44, time: 1.307, data_time: 0.013, memory: 5545, decode.loss_seg: 1.2083, decode.acc_seg: 50.4674, loss: 1.2083
2021-08-14 13:29:34,060 - mmseg - INFO - Iter [30950/160000]	lr: 8.259e-03, eta: 1 day, 22:53:57, time: 1.971, data_time: 0.715, memory: 5545, decode.loss_seg: 1.1750, decode.acc_seg: 50.8707, loss: 1.1750
2021-08-14 13:30:37,667 - mmseg - INFO - Exp name: fcn_litehr30-without-head_512x512_160k_ade20k.py
2021-08-14 13:30:37,668 - mmseg - INFO - Iter [31000/160000]	lr: 8.256e-03, eta: 1 day, 22:52:44, time: 1.271, data_time: 0.013, memory: 5545, decode.loss_seg: 1.1519, decode.acc_seg: 51.2495, loss: 1.1519
2021-08-14 13:31:40,935 - mmseg - INFO - Iter [31050/160000]	lr: 8.253e-03, eta: 1 day, 22:51:30, time: 1.265, data_time: 0.014, memory: 5545, decode.loss_seg: 1.1613, decode.acc_seg: 50.9347, loss: 1.1613
2021-08-14 13:32:45,296 - mmseg - INFO - Iter [31100/160000]	lr: 8.250e-03, eta: 1 day, 22:50:20, time: 1.287, data_time: 0.013, memory: 5545, decode.loss_seg: 1.1418, decode.acc_seg: 50.8987, loss: 1.1418
2021-08-14 13:33:50,530 - mmseg - INFO - Iter [31150/160000]	lr: 8.247e-03, eta: 1 day, 22:49:14, time: 1.305, data_time: 0.013, memory: 5545, decode.loss_seg: 1.1633, decode.acc_seg: 50.3209, loss: 1.1633
2021-08-14 13:34:54,068 - mmseg - INFO - Iter [31200/160000]	lr: 8.244e-03, eta: 1 day, 22:48:01, time: 1.271, data_time: 0.014, memory: 5545, decode.loss_seg: 1.2126, decode.acc_seg: 49.8055, loss: 1.2126
2021-08-14 13:35:53,993 - mmseg - INFO - Iter [31250/160000]	lr: 8.241e-03, eta: 1 day, 22:46:33, time: 1.198, data_time: 0.013, memory: 5545, decode.loss_seg: 1.1902, decode.acc_seg: 50.6821, loss: 1.1902
2021-08-14 13:36:55,240 - mmseg - INFO - Iter [31300/160000]	lr: 8.239e-03, eta: 1 day, 22:45:10, time: 1.225, data_time: 0.013, memory: 5545, decode.loss_seg: 1.1728, decode.acc_seg: 51.0362, loss: 1.1728
2021-08-14 13:38:01,534 - mmseg - INFO - Iter [31350/160000]	lr: 8.236e-03, eta: 1 day, 22:44:08, time: 1.325, data_time: 0.013, memory: 5545, decode.loss_seg: 1.2087, decode.acc_seg: 50.6998, loss: 1.2087
2021-08-14 13:39:03,986 - mmseg - INFO - Iter [31400/160000]	lr: 8.233e-03, eta: 1 day, 22:42:51, time: 1.249, data_time: 0.014, memory: 5545, decode.loss_seg: 1.2045, decode.acc_seg: 50.8661, loss: 1.2045
2021-08-14 13:40:05,453 - mmseg - INFO - Iter [31450/160000]	lr: 8.230e-03, eta: 1 day, 22:41:30, time: 1.230, data_time: 0.013, memory: 5545, decode.loss_seg: 1.1842, decode.acc_seg: 50.1485, loss: 1.1842
2021-08-14 13:41:06,063 - mmseg - INFO - Iter [31500/160000]	lr: 8.227e-03, eta: 1 day, 22:40:05, time: 1.212, data_time: 0.013, memory: 5545, decode.loss_seg: 1.2099, decode.acc_seg: 49.0572, loss: 1.2099
2021-08-14 13:42:07,203 - mmseg - INFO - Iter [31550/160000]	lr: 8.224e-03, eta: 1 day, 22:38:42, time: 1.223, data_time: 0.013, memory: 5545, decode.loss_seg: 1.1827, decode.acc_seg: 50.6071, loss: 1.1827
2021-08-14 13:43:44,785 - mmseg - INFO - Iter [31600/160000]	lr: 8.222e-03, eta: 1 day, 22:39:48, time: 1.952, data_time: 0.686, memory: 5545, decode.loss_seg: 1.1389, decode.acc_seg: 51.1891, loss: 1.1389
2021-08-14 13:44:46,874 - mmseg - INFO - Iter [31650/160000]	lr: 8.219e-03, eta: 1 day, 22:38:29, time: 1.241, data_time: 0.013, memory: 5545, decode.loss_seg: 1.1441, decode.acc_seg: 52.0736, loss: 1.1441
2021-08-14 13:45:52,021 - mmseg - INFO - Iter [31700/160000]	lr: 8.216e-03, eta: 1 day, 22:37:22, time: 1.303, data_time: 0.013, memory: 5545, decode.loss_seg: 1.1633, decode.acc_seg: 50.9331, loss: 1.1633
2021-08-14 13:46:54,740 - mmseg - INFO - Iter [31750/160000]	lr: 8.213e-03, eta: 1 day, 22:36:06, time: 1.255, data_time: 0.014, memory: 5545, decode.loss_seg: 1.1476, decode.acc_seg: 51.2410, loss: 1.1476
2021-08-14 13:47:59,336 - mmseg - INFO - Iter [31800/160000]	lr: 8.210e-03, eta: 1 day, 22:34:57, time: 1.291, data_time: 0.013, memory: 5545, decode.loss_seg: 1.1658, decode.acc_seg: 50.7828, loss: 1.1658
2021-08-14 13:49:04,507 - mmseg - INFO - Iter [31850/160000]	lr: 8.207e-03, eta: 1 day, 22:33:51, time: 1.304, data_time: 0.014, memory: 5545, decode.loss_seg: 1.1662, decode.acc_seg: 49.6719, loss: 1.1662
2021-08-14 13:50:09,361 - mmseg - INFO - Iter [31900/160000]	lr: 8.204e-03, eta: 1 day, 22:32:43, time: 1.297, data_time: 0.013, memory: 5545, decode.loss_seg: 1.2013, decode.acc_seg: 50.2634, loss: 1.2013
2021-08-14 13:51:10,643 - mmseg - INFO - Iter [31950/160000]	lr: 8.202e-03, eta: 1 day, 22:31:22, time: 1.226, data_time: 0.014, memory: 5545, decode.loss_seg: 1.1656, decode.acc_seg: 50.8174, loss: 1.1656
2021-08-14 13:52:12,636 - mmseg - INFO - Saving checkpoint at 32000 iterations
2021-08-14 13:52:12,960 - mmseg - INFO - Exp name: fcn_litehr30-without-head_512x512_160k_ade20k.py
2021-08-14 13:52:12,963 - mmseg - INFO - Iter [32000/160000]	lr: 8.199e-03, eta: 1 day, 22:30:04, time: 1.247, data_time: 0.013, memory: 5545, decode.loss_seg: 1.1974, decode.acc_seg: 50.6985, loss: 1.1974
2021-08-14 13:54:33,188 - mmseg - INFO - per class results:
2021-08-14 13:54:33,200 - mmseg - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        | 51.93 | 81.67 |
|       building      | 62.59 | 82.04 |
|         sky         |  86.8 | 92.29 |
|        floor        | 53.81 | 78.72 |
|         tree        | 55.82 | 80.35 |
|       ceiling       | 67.43 | 84.47 |
|         road        | 60.12 | 86.35 |
|         bed         | 57.34 | 74.74 |
|      windowpane     | 39.36 | 63.86 |
|        grass        | 48.05 | 57.44 |
|       cabinet       | 31.05 | 70.46 |
|       sidewalk      | 30.34 | 37.79 |
|        person       | 34.84 | 39.05 |
|        earth        | 13.65 |  16.4 |
|         door        | 16.45 | 24.45 |
|        table        | 25.26 |  37.1 |
|       mountain      | 29.28 |  41.3 |
|        plant        | 17.98 | 21.19 |
|       curtain       | 37.51 | 49.94 |
|        chair        | 19.94 | 25.96 |
|         car         | 55.27 | 75.95 |
|        water        | 28.17 | 59.46 |
|       painting      | 43.42 | 51.48 |
|         sofa        | 28.59 |  39.7 |
|        shelf        | 15.11 | 23.75 |
|        house        | 34.12 | 51.81 |
|         sea         | 24.46 | 61.76 |
|        mirror       |  5.76 |  5.95 |
|         rug         | 12.85 | 13.35 |
|        field        | 22.18 | 40.16 |
|       armchair      |  4.68 |  5.1  |
|         seat        | 18.46 |  22.8 |
|        fence        | 12.61 | 19.02 |
|         desk        |  6.44 |  7.91 |
|         rock        |  5.84 |  7.04 |
|       wardrobe      |  1.97 |  1.98 |
|         lamp        | 22.01 | 24.38 |
|       bathtub       |  9.25 |  10.9 |
|       railing       |  9.09 |  9.81 |
|       cushion       |  12.2 | 14.62 |
|         base        |  0.0  |  0.0  |
|         box         |  0.0  |  0.0  |
|        column       |  1.27 |  1.27 |
|      signboard      |  4.55 |  4.76 |
|   chest of drawers  | 15.04 | 18.33 |
|       counter       |  2.19 |  2.27 |
|         sand        |  5.73 |  5.95 |
|         sink        | 19.99 | 24.75 |
|      skyscraper     | 20.96 | 68.81 |
|      fireplace      | 44.35 | 51.89 |
|     refrigerator    | 16.54 | 21.23 |
|      grandstand     |  7.9  | 11.13 |
|         path        |  1.02 |  1.04 |
|        stairs       |  1.38 |  1.41 |
|        runway       |  21.5 | 24.54 |
|         case        |  0.32 |  0.34 |
|      pool table     | 44.34 | 70.17 |
|        pillow       | 16.88 | 19.96 |
|     screen door     |  0.0  |  0.0  |
|       stairway      |  4.57 |  7.55 |
|        river        |  0.0  |  0.0  |
|        bridge       |  0.54 |  0.57 |
|       bookcase      |  9.11 | 10.28 |
|        blind        |  0.0  |  0.0  |
|     coffee table    | 20.25 | 34.01 |
|        toilet       | 23.65 | 24.72 |
|        flower       |  0.85 |  0.88 |
|         book        |  7.41 |  7.66 |
|         hill        |  0.29 |  0.3  |
|        bench        |  6.54 |  6.93 |
|      countertop     |  0.57 |  0.57 |
|        stove        | 19.45 | 30.79 |
|         palm        |  0.0  |  0.0  |
|    kitchen island   |  2.21 |  2.6  |
|       computer      |  7.49 |  7.94 |
|     swivel chair    |  2.07 |  2.08 |
|         boat        |  5.76 |  6.49 |
|         bar         |  0.98 |  1.0  |
|    arcade machine   |  0.07 |  0.07 |
|        hovel        |  0.87 |  0.89 |
|         bus         | 15.68 | 16.46 |
|        towel        |  0.0  |  0.0  |
|        light        |  2.11 |  2.14 |
|        truck        |  0.54 |  0.56 |
|        tower        |  0.0  |  0.0  |
|      chandelier     | 27.22 | 34.82 |
|        awning       |  0.0  |  0.0  |
|     streetlight     |  0.0  |  0.0  |
|        booth        |  0.0  |  0.0  |
| television receiver | 10.77 | 11.97 |
|       airplane      | 12.27 | 15.39 |
|      dirt track     |  0.0  |  0.0  |
|       apparel       |  0.0  |  0.0  |
|         pole        |  0.37 |  0.37 |
|         land        |  0.0  |  0.0  |
|      bannister      |  0.0  |  0.0  |
|      escalator      |  0.0  |  0.0  |
|       ottoman       |  0.0  |  0.0  |
|        bottle       |  0.0  |  0.0  |
|        buffet       |  0.0  |  0.0  |
|        poster       |  0.0  |  0.0  |
|        stage        |  0.0  |  0.0  |
|         van         |  0.0  |  0.0  |
|         ship        |  0.0  |  0.0  |
|       fountain      |  0.0  |  0.0  |
|    conveyer belt    |  0.0  |  0.0  |
|        canopy       |  0.0  |  0.0  |
|        washer       | 32.98 | 36.72 |
|      plaything      |  0.0  |  0.0  |
|    swimming pool    |  2.91 |  4.06 |
|        stool        |  0.0  |  0.0  |
|        barrel       |  0.0  |  0.0  |
|        basket       |  0.0  |  0.0  |
|      waterfall      | 22.35 | 35.73 |
|         tent        | 11.24 | 12.38 |
|         bag         |  0.0  |  0.0  |
|       minibike      |  0.0  |  0.0  |
|        cradle       | 38.87 | 46.93 |
|         oven        |  0.0  |  0.0  |
|         ball        | 12.53 |  17.1 |
|         food        |  1.58 |  1.6  |
|         step        |  0.0  |  0.0  |
|         tank        |  0.0  |  0.0  |
|      trade name     |  0.61 |  0.62 |
|      microwave      |  5.97 |  6.03 |
|         pot         |  0.0  |  0.0  |
|        animal       |  0.0  |  0.0  |
|       bicycle       |  0.0  |  0.0  |
|         lake        |  0.0  |  0.0  |
|      dishwasher     |  2.56 |  2.64 |
|        screen       | 23.25 | 25.05 |
|       blanket       |  0.0  |  0.0  |
|      sculpture      |  0.0  |  0.0  |
|         hood        |  0.59 |  0.6  |
|        sconce       |  0.0  |  0.0  |
|         vase        |  0.0  |  0.0  |
|    traffic light    |  0.0  |  0.0  |
|         tray        |  0.0  |  0.0  |
|        ashcan       |  0.0  |  0.0  |
|         fan         |  0.0  |  0.0  |
|         pier        |  0.0  |  0.0  |
|      crt screen     |  0.0  |  0.0  |
|        plate        |  0.0  |  0.0  |
|       monitor       |  0.0  |  0.0  |
|    bulletin board   |  0.0  |  0.0  |
|        shower       |  0.0  |  0.0  |
|       radiator      |  0.0  |  0.0  |
|        glass        |  0.0  |  0.0  |
|        clock        |  0.0  |  0.0  |
|         flag        |  0.0  |  0.0  |
+---------------------+-------+-------+
2021-08-14 13:54:33,200 - mmseg - INFO - Summary:
2021-08-14 13:54:33,200 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 63.27 | 11.82 | 16.25 |
+-------+-------+-------+
2021-08-14 13:54:33,454 - mmseg - INFO - Exp name: fcn_litehr30-without-head_512x512_160k_ade20k.py
2021-08-14 13:54:33,455 - mmseg - INFO - Iter(val) [250]	aAcc: 0.6327, mIoU: 0.1182, mAcc: 0.1625, IoU.wall: 0.5193, IoU.building: 0.6259, IoU.sky: 0.8680, IoU.floor: 0.5381, IoU.tree: 0.5582, IoU.ceiling: 0.6743, IoU.road: 0.6012, IoU.bed : 0.5734, IoU.windowpane: 0.3936, IoU.grass: 0.4805, IoU.cabinet: 0.3105, IoU.sidewalk: 0.3034, IoU.person: 0.3484, IoU.earth: 0.1365, IoU.door: 0.1645, IoU.table: 0.2526, IoU.mountain: 0.2928, IoU.plant: 0.1798, IoU.curtain: 0.3751, IoU.chair: 0.1994, IoU.car: 0.5527, IoU.water: 0.2817, IoU.painting: 0.4342, IoU.sofa: 0.2859, IoU.shelf: 0.1511, IoU.house: 0.3412, IoU.sea: 0.2446, IoU.mirror: 0.0576, IoU.rug: 0.1285, IoU.field: 0.2218, IoU.armchair: 0.0468, IoU.seat: 0.1846, IoU.fence: 0.1261, IoU.desk: 0.0644, IoU.rock: 0.0584, IoU.wardrobe: 0.0197, IoU.lamp: 0.2201, IoU.bathtub: 0.0925, IoU.railing: 0.0909, IoU.cushion: 0.1220, IoU.base: 0.0000, IoU.box: 0.0000, IoU.column: 0.0127, IoU.signboard: 0.0455, IoU.chest of drawers: 0.1504, IoU.counter: 0.0219, IoU.sand: 0.0573, IoU.sink: 0.1999, IoU.skyscraper: 0.2096, IoU.fireplace: 0.4435, IoU.refrigerator: 0.1654, IoU.grandstand: 0.0790, IoU.path: 0.0102, IoU.stairs: 0.0138, IoU.runway: 0.2150, IoU.case: 0.0032, IoU.pool table: 0.4434, IoU.pillow: 0.1688, IoU.screen door: 0.0000, IoU.stairway: 0.0457, IoU.river: 0.0000, IoU.bridge: 0.0054, IoU.bookcase: 0.0911, IoU.blind: 0.0000, IoU.coffee table: 0.2025, IoU.toilet: 0.2365, IoU.flower: 0.0085, IoU.book: 0.0741, IoU.hill: 0.0029, IoU.bench: 0.0654, IoU.countertop: 0.0057, IoU.stove: 0.1945, IoU.palm: 0.0000, IoU.kitchen island: 0.0221, IoU.computer: 0.0749, IoU.swivel chair: 0.0207, IoU.boat: 0.0576, IoU.bar: 0.0098, IoU.arcade machine: 0.0007, IoU.hovel: 0.0087, IoU.bus: 0.1568, IoU.towel: 0.0000, IoU.light: 0.0211, IoU.truck: 0.0054, IoU.tower: 0.0000, IoU.chandelier: 0.2722, IoU.awning: 0.0000, IoU.streetlight: 0.0000, IoU.booth: 0.0000, IoU.television receiver: 0.1077, IoU.airplane: 0.1227, IoU.dirt track: 0.0000, IoU.apparel: 0.0000, IoU.pole: 0.0037, IoU.land: 0.0000, IoU.bannister: 0.0000, IoU.escalator: 0.0000, IoU.ottoman: 0.0000, IoU.bottle: 0.0000, IoU.buffet: 0.0000, IoU.poster: 0.0000, IoU.stage: 0.0000, IoU.van: 0.0000, IoU.ship: 0.0000, IoU.fountain: 0.0000, IoU.conveyer belt: 0.0000, IoU.canopy: 0.0000, IoU.washer: 0.3298, IoU.plaything: 0.0000, IoU.swimming pool: 0.0291, IoU.stool: 0.0000, IoU.barrel: 0.0000, IoU.basket: 0.0000, IoU.waterfall: 0.2235, IoU.tent: 0.1124, IoU.bag: 0.0000, IoU.minibike: 0.0000, IoU.cradle: 0.3887, IoU.oven: 0.0000, IoU.ball: 0.1253, IoU.food: 0.0158, IoU.step: 0.0000, IoU.tank: 0.0000, IoU.trade name: 0.0061, IoU.microwave: 0.0597, IoU.pot: 0.0000, IoU.animal: 0.0000, IoU.bicycle: 0.0000, IoU.lake: 0.0000, IoU.dishwasher: 0.0256, IoU.screen: 0.2325, IoU.blanket: 0.0000, IoU.sculpture: 0.0000, IoU.hood: 0.0059, IoU.sconce: 0.0000, IoU.vase: 0.0000, IoU.traffic light: 0.0000, IoU.tray: 0.0000, IoU.ashcan: 0.0000, IoU.fan: 0.0000, IoU.pier: 0.0000, IoU.crt screen: 0.0000, IoU.plate: 0.0000, IoU.monitor: 0.0000, IoU.bulletin board: 0.0000, IoU.shower: 0.0000, IoU.radiator: 0.0000, IoU.glass: 0.0000, IoU.clock: 0.0000, IoU.flag: 0.0000, Acc.wall: 0.8167, Acc.building: 0.8204, Acc.sky: 0.9229, Acc.floor: 0.7872, Acc.tree: 0.8035, Acc.ceiling: 0.8447, Acc.road: 0.8635, Acc.bed : 0.7474, Acc.windowpane: 0.6386, Acc.grass: 0.5744, Acc.cabinet: 0.7046, Acc.sidewalk: 0.3779, Acc.person: 0.3905, Acc.earth: 0.1640, Acc.door: 0.2445, Acc.table: 0.3710, Acc.mountain: 0.4130, Acc.plant: 0.2119, Acc.curtain: 0.4994, Acc.chair: 0.2596, Acc.car: 0.7595, Acc.water: 0.5946, Acc.painting: 0.5148, Acc.sofa: 0.3970, Acc.shelf: 0.2375, Acc.house: 0.5181, Acc.sea: 0.6176, Acc.mirror: 0.0595, Acc.rug: 0.1335, Acc.field: 0.4016, Acc.armchair: 0.0510, Acc.seat: 0.2280, Acc.fence: 0.1902, Acc.desk: 0.0791, Acc.rock: 0.0704, Acc.wardrobe: 0.0198, Acc.lamp: 0.2438, Acc.bathtub: 0.1090, Acc.railing: 0.0981, Acc.cushion: 0.1462, Acc.base: 0.0000, Acc.box: 0.0000, Acc.column: 0.0127, Acc.signboard: 0.0476, Acc.chest of drawers: 0.1833, Acc.counter: 0.0227, Acc.sand: 0.0595, Acc.sink: 0.2475, Acc.skyscraper: 0.6881, Acc.fireplace: 0.5189, Acc.refrigerator: 0.2123, Acc.grandstand: 0.1113, Acc.path: 0.0104, Acc.stairs: 0.0141, Acc.runway: 0.2454, Acc.case: 0.0034, Acc.pool table: 0.7017, Acc.pillow: 0.1996, Acc.screen door: 0.0000, Acc.stairway: 0.0755, Acc.river: 0.0000, Acc.bridge: 0.0057, Acc.bookcase: 0.1028, Acc.blind: 0.0000, Acc.coffee table: 0.3401, Acc.toilet: 0.2472, Acc.flower: 0.0088, Acc.book: 0.0766, Acc.hill: 0.0030, Acc.bench: 0.0693, Acc.countertop: 0.0057, Acc.stove: 0.3079, Acc.palm: 0.0000, Acc.kitchen island: 0.0260, Acc.computer: 0.0794, Acc.swivel chair: 0.0208, Acc.boat: 0.0649, Acc.bar: 0.0100, Acc.arcade machine: 0.0007, Acc.hovel: 0.0089, Acc.bus: 0.1646, Acc.towel: 0.0000, Acc.light: 0.0214, Acc.truck: 0.0056, Acc.tower: 0.0000, Acc.chandelier: 0.3482, Acc.awning: 0.0000, Acc.streetlight: 0.0000, Acc.booth: 0.0000, Acc.television receiver: 0.1197, Acc.airplane: 0.1539, Acc.dirt track: 0.0000, Acc.apparel: 0.0000, Acc.pole: 0.0037, Acc.land: 0.0000, Acc.bannister: 0.0000, Acc.escalator: 0.0000, Acc.ottoman: 0.0000, Acc.bottle: 0.0000, Acc.buffet: 0.0000, Acc.poster: 0.0000, Acc.stage: 0.0000, Acc.van: 0.0000, Acc.ship: 0.0000, Acc.fountain: 0.0000, Acc.conveyer belt: 0.0000, Acc.canopy: 0.0000, Acc.washer: 0.3672, Acc.plaything: 0.0000, Acc.swimming pool: 0.0406, Acc.stool: 0.0000, Acc.barrel: 0.0000, Acc.basket: 0.0000, Acc.waterfall: 0.3573, Acc.tent: 0.1238, Acc.bag: 0.0000, Acc.minibike: 0.0000, Acc.cradle: 0.4693, Acc.oven: 0.0000, Acc.ball: 0.1710, Acc.food: 0.0160, Acc.step: 0.0000, Acc.tank: 0.0000, Acc.trade name: 0.0062, Acc.microwave: 0.0603, Acc.pot: 0.0000, Acc.animal: 0.0000, Acc.bicycle: 0.0000, Acc.lake: 0.0000, Acc.dishwasher: 0.0264, Acc.screen: 0.2505, Acc.blanket: 0.0000, Acc.sculpture: 0.0000, Acc.hood: 0.0060, Acc.sconce: 0.0000, Acc.vase: 0.0000, Acc.traffic light: 0.0000, Acc.tray: 0.0000, Acc.ashcan: 0.0000, Acc.fan: 0.0000, Acc.pier: 0.0000, Acc.crt screen: 0.0000, Acc.plate: 0.0000, Acc.monitor: 0.0000, Acc.bulletin board: 0.0000, Acc.shower: 0.0000, Acc.radiator: 0.0000, Acc.glass: 0.0000, Acc.clock: 0.0000, Acc.flag: 0.0000
2021-08-14 13:55:38,311 - mmseg - INFO - Iter [32050/160000]	lr: 8.196e-03, eta: 1 day, 22:38:17, time: 4.106, data_time: 2.823, memory: 5545, decode.loss_seg: 1.1638, decode.acc_seg: 51.2312, loss: 1.1638
2021-08-14 13:56:41,083 - mmseg - INFO - Iter [32100/160000]	lr: 8.193e-03, eta: 1 day, 22:37:00, time: 1.256, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1712, decode.acc_seg: 50.6443, loss: 1.1712
2021-08-14 13:57:42,594 - mmseg - INFO - Iter [32150/160000]	lr: 8.190e-03, eta: 1 day, 22:35:38, time: 1.231, data_time: 0.014, memory: 5545, decode.loss_seg: 1.2067, decode.acc_seg: 50.5478, loss: 1.2067
2021-08-14 13:59:18,788 - mmseg - INFO - Iter [32200/160000]	lr: 8.187e-03, eta: 1 day, 22:36:34, time: 1.924, data_time: 0.729, memory: 5545, decode.loss_seg: 1.1460, decode.acc_seg: 50.3102, loss: 1.1460
2021-08-14 14:00:17,904 - mmseg - INFO - Iter [32250/160000]	lr: 8.185e-03, eta: 1 day, 22:35:03, time: 1.182, data_time: 0.014, memory: 5545, decode.loss_seg: 1.1370, decode.acc_seg: 52.1601, loss: 1.1370
2021-08-14 14:01:17,619 - mmseg - INFO - Iter [32300/160000]	lr: 8.182e-03, eta: 1 day, 22:33:34, time: 1.194, data_time: 0.014, memory: 5545, decode.loss_seg: 1.1999, decode.acc_seg: 51.0384, loss: 1.1999
2021-08-14 14:02:17,523 - mmseg - INFO - Iter [32350/160000]	lr: 8.179e-03, eta: 1 day, 22:32:05, time: 1.198, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1505, decode.acc_seg: 50.4373, loss: 1.1505
2021-08-14 14:03:19,074 - mmseg - INFO - Iter [32400/160000]	lr: 8.176e-03, eta: 1 day, 22:30:44, time: 1.230, data_time: 0.014, memory: 5545, decode.loss_seg: 1.1726, decode.acc_seg: 50.2844, loss: 1.1726
2021-08-14 14:04:21,581 - mmseg - INFO - Iter [32450/160000]	lr: 8.173e-03, eta: 1 day, 22:29:26, time: 1.250, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1313, decode.acc_seg: 51.7793, loss: 1.1313
2021-08-14 14:05:27,426 - mmseg - INFO - Iter [32500/160000]	lr: 8.170e-03, eta: 1 day, 22:28:21, time: 1.317, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1854, decode.acc_seg: 49.6979, loss: 1.1854
2021-08-14 14:06:28,485 - mmseg - INFO - Iter [32550/160000]	lr: 8.167e-03, eta: 1 day, 22:26:58, time: 1.221, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1762, decode.acc_seg: 51.3822, loss: 1.1762
2021-08-14 14:07:30,664 - mmseg - INFO - Iter [32600/160000]	lr: 8.165e-03, eta: 1 day, 22:25:39, time: 1.244, data_time: 0.014, memory: 5545, decode.loss_seg: 1.1509, decode.acc_seg: 50.4958, loss: 1.1509
2021-08-14 14:08:32,680 - mmseg - INFO - Iter [32650/160000]	lr: 8.162e-03, eta: 1 day, 22:24:19, time: 1.240, data_time: 0.014, memory: 5545, decode.loss_seg: 1.1795, decode.acc_seg: 50.4338, loss: 1.1795
2021-08-14 14:09:36,875 - mmseg - INFO - Iter [32700/160000]	lr: 8.159e-03, eta: 1 day, 22:23:08, time: 1.284, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1619, decode.acc_seg: 51.7223, loss: 1.1619
2021-08-14 14:10:38,608 - mmseg - INFO - Iter [32750/160000]	lr: 8.156e-03, eta: 1 day, 22:21:48, time: 1.235, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1441, decode.acc_seg: 50.6674, loss: 1.1441
2021-08-14 14:11:44,225 - mmseg - INFO - Iter [32800/160000]	lr: 8.153e-03, eta: 1 day, 22:20:42, time: 1.312, data_time: 0.014, memory: 5545, decode.loss_seg: 1.1723, decode.acc_seg: 50.8510, loss: 1.1723
2021-08-14 14:13:23,013 - mmseg - INFO - Iter [32850/160000]	lr: 8.150e-03, eta: 1 day, 22:21:45, time: 1.976, data_time: 0.748, memory: 5545, decode.loss_seg: 1.1539, decode.acc_seg: 50.9986, loss: 1.1539
2021-08-14 14:14:26,646 - mmseg - INFO - Iter [32900/160000]	lr: 8.148e-03, eta: 1 day, 22:20:32, time: 1.272, data_time: 0.014, memory: 5545, decode.loss_seg: 1.1510, decode.acc_seg: 50.6166, loss: 1.1510
2021-08-14 14:15:30,271 - mmseg - INFO - Iter [32950/160000]	lr: 8.145e-03, eta: 1 day, 22:19:18, time: 1.273, data_time: 0.014, memory: 5545, decode.loss_seg: 1.1678, decode.acc_seg: 50.2278, loss: 1.1678
2021-08-14 14:16:34,430 - mmseg - INFO - Exp name: fcn_litehr30-without-head_512x512_160k_ade20k.py
2021-08-14 14:16:34,431 - mmseg - INFO - Iter [33000/160000]	lr: 8.142e-03, eta: 1 day, 22:18:07, time: 1.284, data_time: 0.014, memory: 5545, decode.loss_seg: 1.1717, decode.acc_seg: 50.7251, loss: 1.1717
2021-08-14 14:17:38,850 - mmseg - INFO - Iter [33050/160000]	lr: 8.139e-03, eta: 1 day, 22:16:57, time: 1.288, data_time: 0.013, memory: 5545, decode.loss_seg: 1.1568, decode.acc_seg: 49.7004, loss: 1.1568
2021-08-14 14:18:41,549 - mmseg - INFO - Iter [33100/160000]	lr: 8.136e-03, eta: 1 day, 22:15:40, time: 1.254, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1430, decode.acc_seg: 51.6877, loss: 1.1430
2021-08-14 14:19:44,139 - mmseg - INFO - Iter [33150/160000]	lr: 8.133e-03, eta: 1 day, 22:14:23, time: 1.251, data_time: 0.014, memory: 5545, decode.loss_seg: 1.1551, decode.acc_seg: 51.4973, loss: 1.1551
2021-08-14 14:20:49,037 - mmseg - INFO - Iter [33200/160000]	lr: 8.130e-03, eta: 1 day, 22:13:14, time: 1.299, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1460, decode.acc_seg: 51.1048, loss: 1.1460
2021-08-14 14:21:49,800 - mmseg - INFO - Iter [33250/160000]	lr: 8.128e-03, eta: 1 day, 22:11:50, time: 1.216, data_time: 0.014, memory: 5545, decode.loss_seg: 1.1694, decode.acc_seg: 50.6418, loss: 1.1694
2021-08-14 14:22:54,742 - mmseg - INFO - Iter [33300/160000]	lr: 8.125e-03, eta: 1 day, 22:10:42, time: 1.299, data_time: 0.013, memory: 5545, decode.loss_seg: 1.2117, decode.acc_seg: 49.7978, loss: 1.2117
2021-08-14 14:23:59,462 - mmseg - INFO - Iter [33350/160000]	lr: 8.122e-03, eta: 1 day, 22:09:33, time: 1.294, data_time: 0.013, memory: 5545, decode.loss_seg: 1.1907, decode.acc_seg: 50.8894, loss: 1.1907
2021-08-14 14:25:02,532 - mmseg - INFO - Iter [33400/160000]	lr: 8.119e-03, eta: 1 day, 22:08:18, time: 1.261, data_time: 0.014, memory: 5545, decode.loss_seg: 1.1549, decode.acc_seg: 51.3188, loss: 1.1549
2021-08-14 14:26:40,749 - mmseg - INFO - Iter [33450/160000]	lr: 8.116e-03, eta: 1 day, 22:09:16, time: 1.964, data_time: 0.694, memory: 5545, decode.loss_seg: 1.1818, decode.acc_seg: 51.0510, loss: 1.1818
2021-08-14 14:27:42,063 - mmseg - INFO - Iter [33500/160000]	lr: 8.113e-03, eta: 1 day, 22:07:54, time: 1.226, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1265, decode.acc_seg: 50.7847, loss: 1.1265
2021-08-14 14:28:46,647 - mmseg - INFO - Iter [33550/160000]	lr: 8.110e-03, eta: 1 day, 22:06:44, time: 1.291, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1761, decode.acc_seg: 51.1365, loss: 1.1761
2021-08-14 14:29:52,110 - mmseg - INFO - Iter [33600/160000]	lr: 8.108e-03, eta: 1 day, 22:05:38, time: 1.310, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1869, decode.acc_seg: 51.1300, loss: 1.1869
2021-08-14 14:30:54,852 - mmseg - INFO - Iter [33650/160000]	lr: 8.105e-03, eta: 1 day, 22:04:21, time: 1.254, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1621, decode.acc_seg: 51.2633, loss: 1.1621
2021-08-14 14:31:57,002 - mmseg - INFO - Iter [33700/160000]	lr: 8.102e-03, eta: 1 day, 22:03:03, time: 1.244, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1257, decode.acc_seg: 50.9588, loss: 1.1257
2021-08-14 14:33:01,351 - mmseg - INFO - Iter [33750/160000]	lr: 8.099e-03, eta: 1 day, 22:01:52, time: 1.286, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1735, decode.acc_seg: 50.7684, loss: 1.1735
2021-08-14 14:34:07,105 - mmseg - INFO - Iter [33800/160000]	lr: 8.096e-03, eta: 1 day, 22:00:47, time: 1.315, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1308, decode.acc_seg: 52.0851, loss: 1.1308
2021-08-14 14:35:10,372 - mmseg - INFO - Iter [33850/160000]	lr: 8.093e-03, eta: 1 day, 21:59:33, time: 1.265, data_time: 0.014, memory: 5545, decode.loss_seg: 1.1772, decode.acc_seg: 50.4411, loss: 1.1772
2021-08-14 14:36:15,976 - mmseg - INFO - Iter [33900/160000]	lr: 8.090e-03, eta: 1 day, 21:58:27, time: 1.312, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1808, decode.acc_seg: 51.2770, loss: 1.1808
2021-08-14 14:37:18,264 - mmseg - INFO - Iter [33950/160000]	lr: 8.088e-03, eta: 1 day, 21:57:09, time: 1.246, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1884, decode.acc_seg: 51.0877, loss: 1.1884
2021-08-14 14:38:19,102 - mmseg - INFO - Exp name: fcn_litehr30-without-head_512x512_160k_ade20k.py
2021-08-14 14:38:19,102 - mmseg - INFO - Iter [34000/160000]	lr: 8.085e-03, eta: 1 day, 21:55:46, time: 1.218, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1541, decode.acc_seg: 50.5852, loss: 1.1541
2021-08-14 14:39:20,251 - mmseg - INFO - Iter [34050/160000]	lr: 8.082e-03, eta: 1 day, 21:54:23, time: 1.223, data_time: 0.013, memory: 5545, decode.loss_seg: 1.1106, decode.acc_seg: 51.9547, loss: 1.1106
2021-08-14 14:40:59,867 - mmseg - INFO - Iter [34100/160000]	lr: 8.079e-03, eta: 1 day, 21:55:23, time: 1.992, data_time: 0.734, memory: 5545, decode.loss_seg: 1.1655, decode.acc_seg: 50.1936, loss: 1.1655
2021-08-14 14:42:03,672 - mmseg - INFO - Iter [34150/160000]	lr: 8.076e-03, eta: 1 day, 21:54:11, time: 1.276, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1275, decode.acc_seg: 50.3585, loss: 1.1275
2021-08-14 14:43:07,584 - mmseg - INFO - Iter [34200/160000]	lr: 8.073e-03, eta: 1 day, 21:52:59, time: 1.279, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1394, decode.acc_seg: 51.6038, loss: 1.1394
2021-08-14 14:44:10,541 - mmseg - INFO - Iter [34250/160000]	lr: 8.071e-03, eta: 1 day, 21:51:43, time: 1.259, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1610, decode.acc_seg: 50.9162, loss: 1.1610
2021-08-14 14:45:13,710 - mmseg - INFO - Iter [34300/160000]	lr: 8.068e-03, eta: 1 day, 21:50:29, time: 1.263, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1303, decode.acc_seg: 52.0113, loss: 1.1303
2021-08-14 14:46:17,049 - mmseg - INFO - Iter [34350/160000]	lr: 8.065e-03, eta: 1 day, 21:49:15, time: 1.267, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1697, decode.acc_seg: 50.4036, loss: 1.1697
2021-08-14 14:47:19,196 - mmseg - INFO - Iter [34400/160000]	lr: 8.062e-03, eta: 1 day, 21:47:56, time: 1.243, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1480, decode.acc_seg: 51.3069, loss: 1.1480
2021-08-14 14:48:20,818 - mmseg - INFO - Iter [34450/160000]	lr: 8.059e-03, eta: 1 day, 21:46:36, time: 1.233, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1414, decode.acc_seg: 50.8948, loss: 1.1414
2021-08-14 14:49:19,770 - mmseg - INFO - Iter [34500/160000]	lr: 8.056e-03, eta: 1 day, 21:45:06, time: 1.178, data_time: 0.015, memory: 5545, decode.loss_seg: 1.2124, decode.acc_seg: 50.2747, loss: 1.2124
2021-08-14 14:50:22,299 - mmseg - INFO - Iter [34550/160000]	lr: 8.053e-03, eta: 1 day, 21:43:49, time: 1.250, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1837, decode.acc_seg: 50.3540, loss: 1.1837
2021-08-14 14:51:24,777 - mmseg - INFO - Iter [34600/160000]	lr: 8.051e-03, eta: 1 day, 21:42:32, time: 1.250, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1515, decode.acc_seg: 51.4693, loss: 1.1515
2021-08-14 14:52:31,066 - mmseg - INFO - Iter [34650/160000]	lr: 8.048e-03, eta: 1 day, 21:41:29, time: 1.326, data_time: 0.015, memory: 5545, decode.loss_seg: 1.0850, decode.acc_seg: 51.9996, loss: 1.0850
2021-08-14 14:53:36,968 - mmseg - INFO - Iter [34700/160000]	lr: 8.045e-03, eta: 1 day, 21:40:24, time: 1.318, data_time: 0.015, memory: 5545, decode.loss_seg: 1.2045, decode.acc_seg: 49.8759, loss: 1.2045
2021-08-14 14:55:15,567 - mmseg - INFO - Iter [34750/160000]	lr: 8.042e-03, eta: 1 day, 21:41:18, time: 1.972, data_time: 0.736, memory: 5545, decode.loss_seg: 1.1207, decode.acc_seg: 51.0819, loss: 1.1207
2021-08-14 14:56:15,451 - mmseg - INFO - Iter [34800/160000]	lr: 8.039e-03, eta: 1 day, 21:39:51, time: 1.198, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1437, decode.acc_seg: 51.8346, loss: 1.1437
2021-08-14 14:57:16,057 - mmseg - INFO - Iter [34850/160000]	lr: 8.036e-03, eta: 1 day, 21:38:27, time: 1.212, data_time: 0.014, memory: 5545, decode.loss_seg: 1.1341, decode.acc_seg: 50.2615, loss: 1.1341
2021-08-14 14:58:16,474 - mmseg - INFO - Iter [34900/160000]	lr: 8.033e-03, eta: 1 day, 21:37:03, time: 1.208, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1668, decode.acc_seg: 51.7249, loss: 1.1668
2021-08-14 14:59:19,499 - mmseg - INFO - Iter [34950/160000]	lr: 8.031e-03, eta: 1 day, 21:35:48, time: 1.260, data_time: 0.014, memory: 5545, decode.loss_seg: 1.1234, decode.acc_seg: 51.5299, loss: 1.1234
2021-08-14 15:00:20,244 - mmseg - INFO - Exp name: fcn_litehr30-without-head_512x512_160k_ade20k.py
2021-08-14 15:00:20,244 - mmseg - INFO - Iter [35000/160000]	lr: 8.028e-03, eta: 1 day, 21:34:25, time: 1.215, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1575, decode.acc_seg: 51.4772, loss: 1.1575
2021-08-14 15:01:21,857 - mmseg - INFO - Iter [35050/160000]	lr: 8.025e-03, eta: 1 day, 21:33:05, time: 1.233, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1639, decode.acc_seg: 49.8104, loss: 1.1639
2021-08-14 15:02:22,273 - mmseg - INFO - Iter [35100/160000]	lr: 8.022e-03, eta: 1 day, 21:31:41, time: 1.208, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1400, decode.acc_seg: 51.2169, loss: 1.1400
2021-08-14 15:03:25,301 - mmseg - INFO - Iter [35150/160000]	lr: 8.019e-03, eta: 1 day, 21:30:26, time: 1.261, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1829, decode.acc_seg: 51.2034, loss: 1.1829
2021-08-14 15:04:29,576 - mmseg - INFO - Iter [35200/160000]	lr: 8.016e-03, eta: 1 day, 21:29:16, time: 1.286, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1742, decode.acc_seg: 51.5506, loss: 1.1742
2021-08-14 15:05:31,706 - mmseg - INFO - Iter [35250/160000]	lr: 8.013e-03, eta: 1 day, 21:27:58, time: 1.242, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1469, decode.acc_seg: 51.7145, loss: 1.1469
2021-08-14 15:06:35,917 - mmseg - INFO - Iter [35300/160000]	lr: 8.011e-03, eta: 1 day, 21:26:47, time: 1.284, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1570, decode.acc_seg: 50.3406, loss: 1.1570
2021-08-14 15:08:12,377 - mmseg - INFO - Iter [35350/160000]	lr: 8.008e-03, eta: 1 day, 21:27:31, time: 1.929, data_time: 0.687, memory: 5545, decode.loss_seg: 1.1824, decode.acc_seg: 50.4138, loss: 1.1824
2021-08-14 15:09:13,634 - mmseg - INFO - Iter [35400/160000]	lr: 8.005e-03, eta: 1 day, 21:26:10, time: 1.225, data_time: 0.017, memory: 5545, decode.loss_seg: 1.1279, decode.acc_seg: 51.8894, loss: 1.1279
2021-08-14 15:10:15,211 - mmseg - INFO - Iter [35450/160000]	lr: 8.002e-03, eta: 1 day, 21:24:50, time: 1.231, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1678, decode.acc_seg: 50.4203, loss: 1.1678
2021-08-14 15:11:18,258 - mmseg - INFO - Iter [35500/160000]	lr: 7.999e-03, eta: 1 day, 21:23:35, time: 1.262, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1659, decode.acc_seg: 51.1149, loss: 1.1659
2021-08-14 15:12:20,100 - mmseg - INFO - Iter [35550/160000]	lr: 7.996e-03, eta: 1 day, 21:22:16, time: 1.236, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1258, decode.acc_seg: 51.0055, loss: 1.1258
2021-08-14 15:13:22,100 - mmseg - INFO - Iter [35600/160000]	lr: 7.993e-03, eta: 1 day, 21:20:58, time: 1.240, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1798, decode.acc_seg: 49.9912, loss: 1.1798
2021-08-14 15:14:24,083 - mmseg - INFO - Iter [35650/160000]	lr: 7.991e-03, eta: 1 day, 21:19:39, time: 1.239, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1673, decode.acc_seg: 50.5993, loss: 1.1673
2021-08-14 15:15:26,368 - mmseg - INFO - Iter [35700/160000]	lr: 7.988e-03, eta: 1 day, 21:18:22, time: 1.246, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1162, decode.acc_seg: 51.7699, loss: 1.1162
2021-08-14 15:16:25,851 - mmseg - INFO - Iter [35750/160000]	lr: 7.985e-03, eta: 1 day, 21:16:55, time: 1.189, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1469, decode.acc_seg: 50.6581, loss: 1.1469
2021-08-14 15:17:27,684 - mmseg - INFO - Iter [35800/160000]	lr: 7.982e-03, eta: 1 day, 21:15:37, time: 1.237, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1529, decode.acc_seg: 51.2198, loss: 1.1529
2021-08-14 15:18:29,105 - mmseg - INFO - Iter [35850/160000]	lr: 7.979e-03, eta: 1 day, 21:14:16, time: 1.228, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1480, decode.acc_seg: 51.5451, loss: 1.1480
2021-08-14 15:19:31,865 - mmseg - INFO - Iter [35900/160000]	lr: 7.976e-03, eta: 1 day, 21:13:01, time: 1.255, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1418, decode.acc_seg: 51.1176, loss: 1.1418
2021-08-14 15:20:34,346 - mmseg - INFO - Iter [35950/160000]	lr: 7.973e-03, eta: 1 day, 21:11:45, time: 1.250, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1616, decode.acc_seg: 50.6488, loss: 1.1616
2021-08-14 15:22:09,907 - mmseg - INFO - Exp name: fcn_litehr30-without-head_512x512_160k_ade20k.py
2021-08-14 15:22:09,914 - mmseg - INFO - Iter [36000/160000]	lr: 7.971e-03, eta: 1 day, 21:12:22, time: 1.911, data_time: 0.719, memory: 5545, decode.loss_seg: 1.1423, decode.acc_seg: 50.2880, loss: 1.1423
2021-08-14 15:23:13,106 - mmseg - INFO - Iter [36050/160000]	lr: 7.968e-03, eta: 1 day, 21:11:09, time: 1.264, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1975, decode.acc_seg: 50.8892, loss: 1.1975
2021-08-14 15:24:18,661 - mmseg - INFO - Iter [36100/160000]	lr: 7.965e-03, eta: 1 day, 21:10:03, time: 1.311, data_time: 0.014, memory: 5545, decode.loss_seg: 1.1316, decode.acc_seg: 52.1546, loss: 1.1316
2021-08-14 15:25:24,020 - mmseg - INFO - Iter [36150/160000]	lr: 7.962e-03, eta: 1 day, 21:08:56, time: 1.308, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1032, decode.acc_seg: 51.8736, loss: 1.1032
2021-08-14 15:26:22,888 - mmseg - INFO - Iter [36200/160000]	lr: 7.959e-03, eta: 1 day, 21:07:28, time: 1.177, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1103, decode.acc_seg: 51.4014, loss: 1.1103
2021-08-14 15:27:23,302 - mmseg - INFO - Iter [36250/160000]	lr: 7.956e-03, eta: 1 day, 21:06:04, time: 1.208, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1281, decode.acc_seg: 51.5088, loss: 1.1281
2021-08-14 15:28:26,904 - mmseg - INFO - Iter [36300/160000]	lr: 7.953e-03, eta: 1 day, 21:04:52, time: 1.272, data_time: 0.014, memory: 5545, decode.loss_seg: 1.2106, decode.acc_seg: 50.8202, loss: 1.2106
2021-08-14 15:29:28,835 - mmseg - INFO - Iter [36350/160000]	lr: 7.951e-03, eta: 1 day, 21:03:34, time: 1.239, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1621, decode.acc_seg: 51.6140, loss: 1.1621
2021-08-14 15:30:28,990 - mmseg - INFO - Iter [36400/160000]	lr: 7.948e-03, eta: 1 day, 21:02:10, time: 1.203, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1159, decode.acc_seg: 50.9373, loss: 1.1159
2021-08-14 15:31:29,185 - mmseg - INFO - Iter [36450/160000]	lr: 7.945e-03, eta: 1 day, 21:00:46, time: 1.204, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1403, decode.acc_seg: 50.9890, loss: 1.1403
2021-08-14 15:32:28,670 - mmseg - INFO - Iter [36500/160000]	lr: 7.942e-03, eta: 1 day, 20:59:20, time: 1.190, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1516, decode.acc_seg: 51.1029, loss: 1.1516
2021-08-14 15:33:32,415 - mmseg - INFO - Iter [36550/160000]	lr: 7.939e-03, eta: 1 day, 20:58:08, time: 1.274, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1369, decode.acc_seg: 51.3369, loss: 1.1369
2021-08-14 15:35:12,119 - mmseg - INFO - Iter [36600/160000]	lr: 7.936e-03, eta: 1 day, 20:58:57, time: 1.994, data_time: 0.739, memory: 5545, decode.loss_seg: 1.1448, decode.acc_seg: 51.5815, loss: 1.1448
2021-08-14 15:36:14,990 - mmseg - INFO - Iter [36650/160000]	lr: 7.933e-03, eta: 1 day, 20:57:42, time: 1.258, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1184, decode.acc_seg: 51.8329, loss: 1.1184
2021-08-14 15:37:17,695 - mmseg - INFO - Iter [36700/160000]	lr: 7.931e-03, eta: 1 day, 20:56:27, time: 1.255, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1366, decode.acc_seg: 51.7954, loss: 1.1366
2021-08-14 15:38:18,515 - mmseg - INFO - Iter [36750/160000]	lr: 7.928e-03, eta: 1 day, 20:55:06, time: 1.216, data_time: 0.015, memory: 5545, decode.loss_seg: 1.0941, decode.acc_seg: 52.0419, loss: 1.0941
2021-08-14 15:39:19,165 - mmseg - INFO - Iter [36800/160000]	lr: 7.925e-03, eta: 1 day, 20:53:43, time: 1.213, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1958, decode.acc_seg: 50.7834, loss: 1.1958
2021-08-14 15:40:22,813 - mmseg - INFO - Iter [36850/160000]	lr: 7.922e-03, eta: 1 day, 20:52:31, time: 1.273, data_time: 0.017, memory: 5545, decode.loss_seg: 1.1826, decode.acc_seg: 50.1964, loss: 1.1826
2021-08-14 15:41:27,906 - mmseg - INFO - Iter [36900/160000]	lr: 7.919e-03, eta: 1 day, 20:51:24, time: 1.301, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1589, decode.acc_seg: 50.5969, loss: 1.1589
2021-08-14 15:42:28,765 - mmseg - INFO - Iter [36950/160000]	lr: 7.916e-03, eta: 1 day, 20:50:03, time: 1.218, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1464, decode.acc_seg: 51.7914, loss: 1.1464
2021-08-14 15:43:31,749 - mmseg - INFO - Exp name: fcn_litehr30-without-head_512x512_160k_ade20k.py
2021-08-14 15:43:31,750 - mmseg - INFO - Iter [37000/160000]	lr: 7.913e-03, eta: 1 day, 20:48:48, time: 1.260, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1427, decode.acc_seg: 51.0471, loss: 1.1427
2021-08-14 15:44:36,362 - mmseg - INFO - Iter [37050/160000]	lr: 7.911e-03, eta: 1 day, 20:47:40, time: 1.292, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1376, decode.acc_seg: 50.8864, loss: 1.1376
2021-08-14 15:45:38,173 - mmseg - INFO - Iter [37100/160000]	lr: 7.908e-03, eta: 1 day, 20:46:21, time: 1.236, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1440, decode.acc_seg: 51.7007, loss: 1.1440
2021-08-14 15:46:40,126 - mmseg - INFO - Iter [37150/160000]	lr: 7.905e-03, eta: 1 day, 20:45:04, time: 1.240, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1285, decode.acc_seg: 50.2802, loss: 1.1285
2021-08-14 15:47:40,742 - mmseg - INFO - Iter [37200/160000]	lr: 7.902e-03, eta: 1 day, 20:43:42, time: 1.212, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1811, decode.acc_seg: 51.5508, loss: 1.1811
2021-08-14 15:49:16,522 - mmseg - INFO - Iter [37250/160000]	lr: 7.899e-03, eta: 1 day, 20:44:16, time: 1.916, data_time: 0.717, memory: 5545, decode.loss_seg: 1.1259, decode.acc_seg: 51.0680, loss: 1.1259
2021-08-14 15:50:16,540 - mmseg - INFO - Iter [37300/160000]	lr: 7.896e-03, eta: 1 day, 20:42:52, time: 1.200, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1219, decode.acc_seg: 51.2992, loss: 1.1219
2021-08-14 15:51:17,129 - mmseg - INFO - Iter [37350/160000]	lr: 7.893e-03, eta: 1 day, 20:41:30, time: 1.212, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1232, decode.acc_seg: 51.7537, loss: 1.1232
2021-08-14 15:52:18,168 - mmseg - INFO - Iter [37400/160000]	lr: 7.891e-03, eta: 1 day, 20:40:09, time: 1.220, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1553, decode.acc_seg: 52.4881, loss: 1.1553
2021-08-14 15:53:24,191 - mmseg - INFO - Iter [37450/160000]	lr: 7.888e-03, eta: 1 day, 20:39:05, time: 1.321, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1738, decode.acc_seg: 51.4016, loss: 1.1738
2021-08-14 15:54:29,713 - mmseg - INFO - Iter [37500/160000]	lr: 7.885e-03, eta: 1 day, 20:37:59, time: 1.310, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1308, decode.acc_seg: 51.4284, loss: 1.1308
2021-08-14 15:55:32,825 - mmseg - INFO - Iter [37550/160000]	lr: 7.882e-03, eta: 1 day, 20:36:46, time: 1.262, data_time: 0.015, memory: 5545, decode.loss_seg: 1.0984, decode.acc_seg: 52.5707, loss: 1.0984
2021-08-14 15:56:34,637 - mmseg - INFO - Iter [37600/160000]	lr: 7.879e-03, eta: 1 day, 20:35:28, time: 1.237, data_time: 0.017, memory: 5545, decode.loss_seg: 1.1446, decode.acc_seg: 50.9418, loss: 1.1446
2021-08-14 15:57:37,395 - mmseg - INFO - Iter [37650/160000]	lr: 7.876e-03, eta: 1 day, 20:34:13, time: 1.255, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1394, decode.acc_seg: 51.1561, loss: 1.1394
2021-08-14 15:58:37,696 - mmseg - INFO - Iter [37700/160000]	lr: 7.873e-03, eta: 1 day, 20:32:51, time: 1.206, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1314, decode.acc_seg: 51.2626, loss: 1.1314
2021-08-14 15:59:39,922 - mmseg - INFO - Iter [37750/160000]	lr: 7.871e-03, eta: 1 day, 20:31:34, time: 1.244, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1586, decode.acc_seg: 51.2969, loss: 1.1586
2021-08-14 16:00:41,926 - mmseg - INFO - Iter [37800/160000]	lr: 7.868e-03, eta: 1 day, 20:30:17, time: 1.240, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1215, decode.acc_seg: 52.5105, loss: 1.1215
2021-08-14 16:01:44,093 - mmseg - INFO - Iter [37850/160000]	lr: 7.865e-03, eta: 1 day, 20:29:01, time: 1.243, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1555, decode.acc_seg: 50.4250, loss: 1.1555
2021-08-14 16:03:23,452 - mmseg - INFO - Iter [37900/160000]	lr: 7.862e-03, eta: 1 day, 20:29:44, time: 1.988, data_time: 0.741, memory: 5545, decode.loss_seg: 1.0969, decode.acc_seg: 51.4635, loss: 1.0969
2021-08-14 16:04:23,986 - mmseg - INFO - Iter [37950/160000]	lr: 7.859e-03, eta: 1 day, 20:28:22, time: 1.211, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1330, decode.acc_seg: 50.7484, loss: 1.1330
2021-08-14 16:05:24,899 - mmseg - INFO - Exp name: fcn_litehr30-without-head_512x512_160k_ade20k.py
2021-08-14 16:05:24,899 - mmseg - INFO - Iter [38000/160000]	lr: 7.856e-03, eta: 1 day, 20:27:02, time: 1.218, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1436, decode.acc_seg: 51.4885, loss: 1.1436
2021-08-14 16:06:25,112 - mmseg - INFO - Iter [38050/160000]	lr: 7.853e-03, eta: 1 day, 20:25:39, time: 1.204, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1360, decode.acc_seg: 52.3580, loss: 1.1360
2021-08-14 16:07:26,755 - mmseg - INFO - Iter [38100/160000]	lr: 7.851e-03, eta: 1 day, 20:24:21, time: 1.233, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1164, decode.acc_seg: 52.3463, loss: 1.1164
2021-08-14 16:08:27,252 - mmseg - INFO - Iter [38150/160000]	lr: 7.848e-03, eta: 1 day, 20:22:59, time: 1.210, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1167, decode.acc_seg: 52.5137, loss: 1.1167
2021-08-14 16:09:31,358 - mmseg - INFO - Iter [38200/160000]	lr: 7.845e-03, eta: 1 day, 20:21:49, time: 1.282, data_time: 0.017, memory: 5545, decode.loss_seg: 1.1491, decode.acc_seg: 50.9122, loss: 1.1491
2021-08-14 16:10:33,067 - mmseg - INFO - Iter [38250/160000]	lr: 7.842e-03, eta: 1 day, 20:20:31, time: 1.234, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1217, decode.acc_seg: 50.6922, loss: 1.1217
2021-08-14 16:11:36,917 - mmseg - INFO - Iter [38300/160000]	lr: 7.839e-03, eta: 1 day, 20:19:20, time: 1.276, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1108, decode.acc_seg: 52.2273, loss: 1.1108
2021-08-14 16:12:36,476 - mmseg - INFO - Iter [38350/160000]	lr: 7.836e-03, eta: 1 day, 20:17:55, time: 1.192, data_time: 0.017, memory: 5545, decode.loss_seg: 1.1481, decode.acc_seg: 51.8421, loss: 1.1481
2021-08-14 16:13:37,806 - mmseg - INFO - Iter [38400/160000]	lr: 7.833e-03, eta: 1 day, 20:16:36, time: 1.226, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1484, decode.acc_seg: 51.2764, loss: 1.1484
2021-08-14 16:14:38,726 - mmseg - INFO - Iter [38450/160000]	lr: 7.831e-03, eta: 1 day, 20:15:16, time: 1.218, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1365, decode.acc_seg: 52.3242, loss: 1.1365
2021-08-14 16:16:13,435 - mmseg - INFO - Iter [38500/160000]	lr: 7.828e-03, eta: 1 day, 20:15:43, time: 1.894, data_time: 0.725, memory: 5545, decode.loss_seg: 1.1619, decode.acc_seg: 50.1181, loss: 1.1619
2021-08-14 16:17:13,904 - mmseg - INFO - Iter [38550/160000]	lr: 7.825e-03, eta: 1 day, 20:14:21, time: 1.210, data_time: 0.015, memory: 5545, decode.loss_seg: 1.0639, decode.acc_seg: 52.4836, loss: 1.0639
2021-08-14 16:18:13,532 - mmseg - INFO - Iter [38600/160000]	lr: 7.822e-03, eta: 1 day, 20:12:57, time: 1.193, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1171, decode.acc_seg: 51.0675, loss: 1.1171
2021-08-14 16:19:12,432 - mmseg - INFO - Iter [38650/160000]	lr: 7.819e-03, eta: 1 day, 20:11:30, time: 1.178, data_time: 0.016, memory: 5545, decode.loss_seg: 1.0750, decode.acc_seg: 52.1273, loss: 1.0750
2021-08-14 16:20:12,555 - mmseg - INFO - Iter [38700/160000]	lr: 7.816e-03, eta: 1 day, 20:10:08, time: 1.202, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1534, decode.acc_seg: 51.1977, loss: 1.1534
2021-08-14 16:21:12,990 - mmseg - INFO - Iter [38750/160000]	lr: 7.813e-03, eta: 1 day, 20:08:46, time: 1.209, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1303, decode.acc_seg: 51.6668, loss: 1.1303
2021-08-14 16:22:14,643 - mmseg - INFO - Iter [38800/160000]	lr: 7.811e-03, eta: 1 day, 20:07:29, time: 1.233, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1624, decode.acc_seg: 51.5628, loss: 1.1624
2021-08-14 16:23:15,224 - mmseg - INFO - Iter [38850/160000]	lr: 7.808e-03, eta: 1 day, 20:06:08, time: 1.211, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1438, decode.acc_seg: 51.5503, loss: 1.1438
2021-08-14 16:24:18,451 - mmseg - INFO - Iter [38900/160000]	lr: 7.805e-03, eta: 1 day, 20:04:55, time: 1.265, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1623, decode.acc_seg: 50.3776, loss: 1.1623
2021-08-14 16:25:20,275 - mmseg - INFO - Iter [38950/160000]	lr: 7.802e-03, eta: 1 day, 20:03:38, time: 1.237, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1837, decode.acc_seg: 49.9800, loss: 1.1837
2021-08-14 16:26:19,589 - mmseg - INFO - Exp name: fcn_litehr30-without-head_512x512_160k_ade20k.py
2021-08-14 16:26:19,590 - mmseg - INFO - Iter [39000/160000]	lr: 7.799e-03, eta: 1 day, 20:02:13, time: 1.186, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1247, decode.acc_seg: 51.4563, loss: 1.1247
2021-08-14 16:27:19,538 - mmseg - INFO - Iter [39050/160000]	lr: 7.796e-03, eta: 1 day, 20:00:50, time: 1.198, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1158, decode.acc_seg: 50.7460, loss: 1.1158
2021-08-14 16:28:20,016 - mmseg - INFO - Iter [39100/160000]	lr: 7.793e-03, eta: 1 day, 19:59:29, time: 1.210, data_time: 0.017, memory: 5545, decode.loss_seg: 1.1406, decode.acc_seg: 50.7993, loss: 1.1406
2021-08-14 16:29:57,533 - mmseg - INFO - Iter [39150/160000]	lr: 7.790e-03, eta: 1 day, 20:00:03, time: 1.949, data_time: 0.740, memory: 5545, decode.loss_seg: 1.1287, decode.acc_seg: 50.7600, loss: 1.1287
2021-08-14 16:30:59,306 - mmseg - INFO - Iter [39200/160000]	lr: 7.788e-03, eta: 1 day, 19:58:46, time: 1.236, data_time: 0.018, memory: 5545, decode.loss_seg: 1.1621, decode.acc_seg: 51.1453, loss: 1.1621
2021-08-14 16:32:01,935 - mmseg - INFO - Iter [39250/160000]	lr: 7.785e-03, eta: 1 day, 19:57:31, time: 1.252, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1051, decode.acc_seg: 52.2606, loss: 1.1051
2021-08-14 16:33:05,870 - mmseg - INFO - Iter [39300/160000]	lr: 7.782e-03, eta: 1 day, 19:56:21, time: 1.279, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1155, decode.acc_seg: 51.9326, loss: 1.1155
2021-08-14 16:34:08,924 - mmseg - INFO - Iter [39350/160000]	lr: 7.779e-03, eta: 1 day, 19:55:08, time: 1.262, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1258, decode.acc_seg: 51.2595, loss: 1.1258
2021-08-14 16:35:11,364 - mmseg - INFO - Iter [39400/160000]	lr: 7.776e-03, eta: 1 day, 19:53:53, time: 1.248, data_time: 0.014, memory: 5545, decode.loss_seg: 1.1443, decode.acc_seg: 51.9708, loss: 1.1443
2021-08-14 16:36:12,506 - mmseg - INFO - Iter [39450/160000]	lr: 7.773e-03, eta: 1 day, 19:52:34, time: 1.223, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1291, decode.acc_seg: 52.2152, loss: 1.1291
2021-08-14 16:37:14,610 - mmseg - INFO - Iter [39500/160000]	lr: 7.770e-03, eta: 1 day, 19:51:18, time: 1.242, data_time: 0.014, memory: 5545, decode.loss_seg: 1.1538, decode.acc_seg: 50.3858, loss: 1.1538
2021-08-14 16:38:16,880 - mmseg - INFO - Iter [39550/160000]	lr: 7.768e-03, eta: 1 day, 19:50:02, time: 1.246, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1607, decode.acc_seg: 50.5887, loss: 1.1607
2021-08-14 16:39:17,759 - mmseg - INFO - Iter [39600/160000]	lr: 7.765e-03, eta: 1 day, 19:48:43, time: 1.217, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1113, decode.acc_seg: 52.2083, loss: 1.1113
2021-08-14 16:40:22,554 - mmseg - INFO - Iter [39650/160000]	lr: 7.762e-03, eta: 1 day, 19:47:35, time: 1.296, data_time: 0.014, memory: 5545, decode.loss_seg: 1.1390, decode.acc_seg: 51.7591, loss: 1.1390
2021-08-14 16:41:27,647 - mmseg - INFO - Iter [39700/160000]	lr: 7.759e-03, eta: 1 day, 19:46:28, time: 1.302, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1710, decode.acc_seg: 50.8107, loss: 1.1710
2021-08-14 16:42:29,759 - mmseg - INFO - Iter [39750/160000]	lr: 7.756e-03, eta: 1 day, 19:45:13, time: 1.242, data_time: 0.014, memory: 5545, decode.loss_seg: 1.1426, decode.acc_seg: 50.5793, loss: 1.1426
2021-08-14 16:44:09,203 - mmseg - INFO - Iter [39800/160000]	lr: 7.753e-03, eta: 1 day, 19:45:50, time: 1.989, data_time: 0.754, memory: 5545, decode.loss_seg: 1.0903, decode.acc_seg: 52.2476, loss: 1.0903
2021-08-14 16:45:12,966 - mmseg - INFO - Iter [39850/160000]	lr: 7.750e-03, eta: 1 day, 19:44:39, time: 1.275, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1371, decode.acc_seg: 51.0144, loss: 1.1371
2021-08-14 16:46:14,261 - mmseg - INFO - Iter [39900/160000]	lr: 7.747e-03, eta: 1 day, 19:43:21, time: 1.226, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1426, decode.acc_seg: 51.6540, loss: 1.1426
2021-08-14 16:47:15,995 - mmseg - INFO - Iter [39950/160000]	lr: 7.745e-03, eta: 1 day, 19:42:04, time: 1.235, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1439, decode.acc_seg: 51.6476, loss: 1.1439
2021-08-14 16:48:16,638 - mmseg - INFO - Exp name: fcn_litehr30-without-head_512x512_160k_ade20k.py
2021-08-14 16:48:16,638 - mmseg - INFO - Iter [40000/160000]	lr: 7.742e-03, eta: 1 day, 19:40:44, time: 1.213, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1254, decode.acc_seg: 51.9211, loss: 1.1254
2021-08-14 16:49:17,847 - mmseg - INFO - Iter [40050/160000]	lr: 7.739e-03, eta: 1 day, 19:39:25, time: 1.224, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1254, decode.acc_seg: 51.9651, loss: 1.1254
2021-08-14 16:50:17,732 - mmseg - INFO - Iter [40100/160000]	lr: 7.736e-03, eta: 1 day, 19:38:03, time: 1.198, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1331, decode.acc_seg: 51.1856, loss: 1.1331
2021-08-14 16:51:18,208 - mmseg - INFO - Iter [40150/160000]	lr: 7.733e-03, eta: 1 day, 19:36:42, time: 1.209, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1517, decode.acc_seg: 51.4345, loss: 1.1517
2021-08-14 16:52:19,761 - mmseg - INFO - Iter [40200/160000]	lr: 7.730e-03, eta: 1 day, 19:35:25, time: 1.231, data_time: 0.015, memory: 5545, decode.loss_seg: 1.0935, decode.acc_seg: 51.6875, loss: 1.0935
2021-08-14 16:53:21,630 - mmseg - INFO - Iter [40250/160000]	lr: 7.727e-03, eta: 1 day, 19:34:09, time: 1.237, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1387, decode.acc_seg: 51.6370, loss: 1.1387
2021-08-14 16:54:25,935 - mmseg - INFO - Iter [40300/160000]	lr: 7.725e-03, eta: 1 day, 19:33:00, time: 1.287, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1586, decode.acc_seg: 51.1789, loss: 1.1586
2021-08-14 16:55:26,486 - mmseg - INFO - Iter [40350/160000]	lr: 7.722e-03, eta: 1 day, 19:31:40, time: 1.211, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1025, decode.acc_seg: 51.8235, loss: 1.1025
2021-08-14 16:57:05,005 - mmseg - INFO - Iter [40400/160000]	lr: 7.719e-03, eta: 1 day, 19:32:12, time: 1.970, data_time: 0.743, memory: 5545, decode.loss_seg: 1.1221, decode.acc_seg: 50.8633, loss: 1.1221
2021-08-14 16:58:05,542 - mmseg - INFO - Iter [40450/160000]	lr: 7.716e-03, eta: 1 day, 19:30:52, time: 1.210, data_time: 0.017, memory: 5545, decode.loss_seg: 1.1269, decode.acc_seg: 51.7203, loss: 1.1269
2021-08-14 16:59:08,155 - mmseg - INFO - Iter [40500/160000]	lr: 7.713e-03, eta: 1 day, 19:29:37, time: 1.252, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1115, decode.acc_seg: 51.8902, loss: 1.1115
2021-08-14 17:00:08,989 - mmseg - INFO - Iter [40550/160000]	lr: 7.710e-03, eta: 1 day, 19:28:18, time: 1.216, data_time: 0.017, memory: 5545, decode.loss_seg: 1.1385, decode.acc_seg: 51.8519, loss: 1.1385
2021-08-14 17:01:12,072 - mmseg - INFO - Iter [40600/160000]	lr: 7.707e-03, eta: 1 day, 19:27:06, time: 1.262, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1181, decode.acc_seg: 51.0751, loss: 1.1181
2021-08-14 17:02:13,712 - mmseg - INFO - Iter [40650/160000]	lr: 7.705e-03, eta: 1 day, 19:25:49, time: 1.233, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1151, decode.acc_seg: 51.4874, loss: 1.1151
2021-08-14 17:03:14,121 - mmseg - INFO - Iter [40700/160000]	lr: 7.702e-03, eta: 1 day, 19:24:28, time: 1.208, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1151, decode.acc_seg: 51.6634, loss: 1.1151
2021-08-14 17:04:15,590 - mmseg - INFO - Iter [40750/160000]	lr: 7.699e-03, eta: 1 day, 19:23:11, time: 1.230, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1183, decode.acc_seg: 52.3629, loss: 1.1183
2021-08-14 17:05:16,200 - mmseg - INFO - Iter [40800/160000]	lr: 7.696e-03, eta: 1 day, 19:21:51, time: 1.212, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1502, decode.acc_seg: 51.2972, loss: 1.1502
2021-08-14 17:06:17,133 - mmseg - INFO - Iter [40850/160000]	lr: 7.693e-03, eta: 1 day, 19:20:33, time: 1.219, data_time: 0.014, memory: 5545, decode.loss_seg: 1.1399, decode.acc_seg: 51.1189, loss: 1.1399
2021-08-14 17:07:18,696 - mmseg - INFO - Iter [40900/160000]	lr: 7.690e-03, eta: 1 day, 19:19:16, time: 1.231, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1680, decode.acc_seg: 51.6908, loss: 1.1680
2021-08-14 17:08:18,671 - mmseg - INFO - Iter [40950/160000]	lr: 7.687e-03, eta: 1 day, 19:17:54, time: 1.199, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1126, decode.acc_seg: 52.7470, loss: 1.1126
2021-08-14 17:09:18,390 - mmseg - INFO - Exp name: fcn_litehr30-without-head_512x512_160k_ade20k.py
2021-08-14 17:09:18,391 - mmseg - INFO - Iter [41000/160000]	lr: 7.684e-03, eta: 1 day, 19:16:32, time: 1.195, data_time: 0.018, memory: 5545, decode.loss_seg: 1.0950, decode.acc_seg: 51.7810, loss: 1.0950
2021-08-14 17:10:55,598 - mmseg - INFO - Iter [41050/160000]	lr: 7.682e-03, eta: 1 day, 19:16:59, time: 1.944, data_time: 0.731, memory: 5545, decode.loss_seg: 1.1090, decode.acc_seg: 52.8122, loss: 1.1090
2021-08-14 17:11:58,341 - mmseg - INFO - Iter [41100/160000]	lr: 7.679e-03, eta: 1 day, 19:15:45, time: 1.254, data_time: 0.015, memory: 5545, decode.loss_seg: 1.0772, decode.acc_seg: 52.5726, loss: 1.0772
2021-08-14 17:13:02,669 - mmseg - INFO - Iter [41150/160000]	lr: 7.676e-03, eta: 1 day, 19:14:36, time: 1.287, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1408, decode.acc_seg: 51.8529, loss: 1.1408
2021-08-14 17:14:04,523 - mmseg - INFO - Iter [41200/160000]	lr: 7.673e-03, eta: 1 day, 19:13:20, time: 1.237, data_time: 0.017, memory: 5545, decode.loss_seg: 1.1248, decode.acc_seg: 52.4798, loss: 1.1248
2021-08-14 17:15:08,047 - mmseg - INFO - Iter [41250/160000]	lr: 7.670e-03, eta: 1 day, 19:12:09, time: 1.270, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1551, decode.acc_seg: 51.6530, loss: 1.1551
2021-08-14 17:16:10,167 - mmseg - INFO - Iter [41300/160000]	lr: 7.667e-03, eta: 1 day, 19:10:54, time: 1.243, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1042, decode.acc_seg: 51.7201, loss: 1.1042
2021-08-14 17:17:11,958 - mmseg - INFO - Iter [41350/160000]	lr: 7.664e-03, eta: 1 day, 19:09:38, time: 1.235, data_time: 0.017, memory: 5545, decode.loss_seg: 1.1283, decode.acc_seg: 52.0998, loss: 1.1283
2021-08-14 17:18:12,520 - mmseg - INFO - Iter [41400/160000]	lr: 7.661e-03, eta: 1 day, 19:08:18, time: 1.211, data_time: 0.017, memory: 5545, decode.loss_seg: 1.1417, decode.acc_seg: 51.1695, loss: 1.1417
2021-08-14 17:19:13,369 - mmseg - INFO - Iter [41450/160000]	lr: 7.659e-03, eta: 1 day, 19:07:00, time: 1.217, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1360, decode.acc_seg: 50.8179, loss: 1.1360
2021-08-14 17:20:14,814 - mmseg - INFO - Iter [41500/160000]	lr: 7.656e-03, eta: 1 day, 19:05:43, time: 1.228, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1536, decode.acc_seg: 51.1801, loss: 1.1536
2021-08-14 17:21:17,059 - mmseg - INFO - Iter [41550/160000]	lr: 7.653e-03, eta: 1 day, 19:04:28, time: 1.245, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1008, decode.acc_seg: 51.5629, loss: 1.1008
2021-08-14 17:22:17,727 - mmseg - INFO - Iter [41600/160000]	lr: 7.650e-03, eta: 1 day, 19:03:09, time: 1.214, data_time: 0.017, memory: 5545, decode.loss_seg: 1.1363, decode.acc_seg: 52.0754, loss: 1.1363
2021-08-14 17:23:54,170 - mmseg - INFO - Iter [41650/160000]	lr: 7.647e-03, eta: 1 day, 19:03:31, time: 1.929, data_time: 0.713, memory: 5545, decode.loss_seg: 1.1447, decode.acc_seg: 51.5380, loss: 1.1447
2021-08-14 17:24:55,969 - mmseg - INFO - Iter [41700/160000]	lr: 7.644e-03, eta: 1 day, 19:02:16, time: 1.236, data_time: 0.016, memory: 5545, decode.loss_seg: 1.0786, decode.acc_seg: 52.0355, loss: 1.0786
2021-08-14 17:25:56,106 - mmseg - INFO - Iter [41750/160000]	lr: 7.641e-03, eta: 1 day, 19:00:55, time: 1.203, data_time: 0.017, memory: 5545, decode.loss_seg: 1.0911, decode.acc_seg: 53.1826, loss: 1.0911
2021-08-14 17:26:56,438 - mmseg - INFO - Iter [41800/160000]	lr: 7.639e-03, eta: 1 day, 18:59:35, time: 1.207, data_time: 0.016, memory: 5545, decode.loss_seg: 1.0853, decode.acc_seg: 52.3216, loss: 1.0853
2021-08-14 17:27:57,460 - mmseg - INFO - Iter [41850/160000]	lr: 7.636e-03, eta: 1 day, 18:58:17, time: 1.220, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1590, decode.acc_seg: 51.7311, loss: 1.1590
2021-08-14 17:29:00,715 - mmseg - INFO - Iter [41900/160000]	lr: 7.633e-03, eta: 1 day, 18:57:05, time: 1.265, data_time: 0.018, memory: 5545, decode.loss_seg: 1.1403, decode.acc_seg: 50.6662, loss: 1.1403
2021-08-14 17:30:02,897 - mmseg - INFO - Iter [41950/160000]	lr: 7.630e-03, eta: 1 day, 18:55:50, time: 1.243, data_time: 0.014, memory: 5545, decode.loss_seg: 1.1603, decode.acc_seg: 50.8943, loss: 1.1603
2021-08-14 17:31:04,551 - mmseg - INFO - Exp name: fcn_litehr30-without-head_512x512_160k_ade20k.py
2021-08-14 17:31:04,551 - mmseg - INFO - Iter [42000/160000]	lr: 7.627e-03, eta: 1 day, 18:54:34, time: 1.233, data_time: 0.017, memory: 5545, decode.loss_seg: 1.1146, decode.acc_seg: 51.2045, loss: 1.1146
2021-08-14 17:32:05,924 - mmseg - INFO - Iter [42050/160000]	lr: 7.624e-03, eta: 1 day, 18:53:17, time: 1.227, data_time: 0.015, memory: 5545, decode.loss_seg: 1.0858, decode.acc_seg: 51.4483, loss: 1.0858
2021-08-14 17:33:08,422 - mmseg - INFO - Iter [42100/160000]	lr: 7.621e-03, eta: 1 day, 18:52:04, time: 1.250, data_time: 0.017, memory: 5545, decode.loss_seg: 1.1316, decode.acc_seg: 50.7690, loss: 1.1316
2021-08-14 17:34:10,450 - mmseg - INFO - Iter [42150/160000]	lr: 7.618e-03, eta: 1 day, 18:50:49, time: 1.240, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1410, decode.acc_seg: 51.1447, loss: 1.1410
2021-08-14 17:35:15,426 - mmseg - INFO - Iter [42200/160000]	lr: 7.616e-03, eta: 1 day, 18:49:42, time: 1.300, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1314, decode.acc_seg: 50.9875, loss: 1.1314
2021-08-14 17:36:19,574 - mmseg - INFO - Iter [42250/160000]	lr: 7.613e-03, eta: 1 day, 18:48:33, time: 1.282, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1642, decode.acc_seg: 50.7260, loss: 1.1642
2021-08-14 17:37:56,385 - mmseg - INFO - Iter [42300/160000]	lr: 7.610e-03, eta: 1 day, 18:48:55, time: 1.937, data_time: 0.717, memory: 5545, decode.loss_seg: 1.1116, decode.acc_seg: 51.4013, loss: 1.1116
2021-08-14 17:38:56,769 - mmseg - INFO - Iter [42350/160000]	lr: 7.607e-03, eta: 1 day, 18:47:35, time: 1.208, data_time: 0.016, memory: 5545, decode.loss_seg: 1.0785, decode.acc_seg: 52.0079, loss: 1.0785
2021-08-14 17:39:57,321 - mmseg - INFO - Iter [42400/160000]	lr: 7.604e-03, eta: 1 day, 18:46:16, time: 1.211, data_time: 0.016, memory: 5545, decode.loss_seg: 1.0928, decode.acc_seg: 51.7402, loss: 1.0928
2021-08-14 17:40:57,413 - mmseg - INFO - Iter [42450/160000]	lr: 7.601e-03, eta: 1 day, 18:44:56, time: 1.202, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1551, decode.acc_seg: 50.6805, loss: 1.1551
2021-08-14 17:41:58,059 - mmseg - INFO - Iter [42500/160000]	lr: 7.598e-03, eta: 1 day, 18:43:37, time: 1.212, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1130, decode.acc_seg: 52.5896, loss: 1.1130
2021-08-14 17:43:01,697 - mmseg - INFO - Iter [42550/160000]	lr: 7.595e-03, eta: 1 day, 18:42:26, time: 1.273, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1222, decode.acc_seg: 51.7594, loss: 1.1222
2021-08-14 17:44:04,802 - mmseg - INFO - Iter [42600/160000]	lr: 7.593e-03, eta: 1 day, 18:41:14, time: 1.261, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1361, decode.acc_seg: 52.2508, loss: 1.1361
2021-08-14 17:45:10,825 - mmseg - INFO - Iter [42650/160000]	lr: 7.590e-03, eta: 1 day, 18:40:10, time: 1.320, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1351, decode.acc_seg: 51.1855, loss: 1.1351
2021-08-14 17:46:13,202 - mmseg - INFO - Iter [42700/160000]	lr: 7.587e-03, eta: 1 day, 18:38:57, time: 1.248, data_time: 0.017, memory: 5545, decode.loss_seg: 1.1052, decode.acc_seg: 51.6654, loss: 1.1052
2021-08-14 17:47:18,843 - mmseg - INFO - Iter [42750/160000]	lr: 7.584e-03, eta: 1 day, 18:37:52, time: 1.312, data_time: 0.014, memory: 5545, decode.loss_seg: 1.1176, decode.acc_seg: 52.3797, loss: 1.1176
2021-08-14 17:48:23,316 - mmseg - INFO - Iter [42800/160000]	lr: 7.581e-03, eta: 1 day, 18:36:44, time: 1.290, data_time: 0.015, memory: 5545, decode.loss_seg: 1.0684, decode.acc_seg: 54.0259, loss: 1.0684
2021-08-14 17:49:22,948 - mmseg - INFO - Iter [42850/160000]	lr: 7.578e-03, eta: 1 day, 18:35:22, time: 1.192, data_time: 0.014, memory: 5545, decode.loss_seg: 1.1471, decode.acc_seg: 51.5117, loss: 1.1471
2021-08-14 17:50:25,110 - mmseg - INFO - Iter [42900/160000]	lr: 7.575e-03, eta: 1 day, 18:34:08, time: 1.244, data_time: 0.014, memory: 5545, decode.loss_seg: 1.1248, decode.acc_seg: 51.4283, loss: 1.1248
2021-08-14 17:51:59,693 - mmseg - INFO - Iter [42950/160000]	lr: 7.572e-03, eta: 1 day, 18:34:22, time: 1.892, data_time: 0.723, memory: 5545, decode.loss_seg: 1.0774, decode.acc_seg: 51.7833, loss: 1.0774
2021-08-14 17:52:59,907 - mmseg - INFO - Exp name: fcn_litehr30-without-head_512x512_160k_ade20k.py
2021-08-14 17:52:59,908 - mmseg - INFO - Iter [43000/160000]	lr: 7.570e-03, eta: 1 day, 18:33:02, time: 1.204, data_time: 0.015, memory: 5545, decode.loss_seg: 1.0638, decode.acc_seg: 52.6887, loss: 1.0638
2021-08-14 17:54:02,380 - mmseg - INFO - Iter [43050/160000]	lr: 7.567e-03, eta: 1 day, 18:31:49, time: 1.249, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1202, decode.acc_seg: 52.3025, loss: 1.1202
2021-08-14 17:55:03,140 - mmseg - INFO - Iter [43100/160000]	lr: 7.564e-03, eta: 1 day, 18:30:30, time: 1.215, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1395, decode.acc_seg: 50.7114, loss: 1.1395
2021-08-14 17:56:04,843 - mmseg - INFO - Iter [43150/160000]	lr: 7.561e-03, eta: 1 day, 18:29:15, time: 1.234, data_time: 0.014, memory: 5545, decode.loss_seg: 1.0666, decode.acc_seg: 52.6513, loss: 1.0666
2021-08-14 17:57:04,556 - mmseg - INFO - Iter [43200/160000]	lr: 7.558e-03, eta: 1 day, 18:27:54, time: 1.194, data_time: 0.014, memory: 5545, decode.loss_seg: 1.1193, decode.acc_seg: 52.3903, loss: 1.1193
2021-08-14 17:58:04,880 - mmseg - INFO - Iter [43250/160000]	lr: 7.555e-03, eta: 1 day, 18:26:35, time: 1.206, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1701, decode.acc_seg: 50.0966, loss: 1.1701
2021-08-14 17:59:05,290 - mmseg - INFO - Iter [43300/160000]	lr: 7.552e-03, eta: 1 day, 18:25:16, time: 1.208, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1496, decode.acc_seg: 51.5327, loss: 1.1496
2021-08-14 18:00:04,961 - mmseg - INFO - Iter [43350/160000]	lr: 7.549e-03, eta: 1 day, 18:23:54, time: 1.192, data_time: 0.014, memory: 5545, decode.loss_seg: 1.1221, decode.acc_seg: 51.7220, loss: 1.1221
2021-08-14 18:01:07,005 - mmseg - INFO - Iter [43400/160000]	lr: 7.547e-03, eta: 1 day, 18:22:40, time: 1.242, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1503, decode.acc_seg: 51.1362, loss: 1.1503
2021-08-14 18:02:07,004 - mmseg - INFO - Iter [43450/160000]	lr: 7.544e-03, eta: 1 day, 18:21:20, time: 1.199, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1286, decode.acc_seg: 51.7671, loss: 1.1286
2021-08-14 18:03:08,978 - mmseg - INFO - Iter [43500/160000]	lr: 7.541e-03, eta: 1 day, 18:20:05, time: 1.239, data_time: 0.015, memory: 5545, decode.loss_seg: 1.0961, decode.acc_seg: 52.9307, loss: 1.0961
2021-08-14 18:04:52,043 - mmseg - INFO - Iter [43550/160000]	lr: 7.538e-03, eta: 1 day, 18:20:41, time: 2.062, data_time: 0.823, memory: 5545, decode.loss_seg: 1.1056, decode.acc_seg: 52.4323, loss: 1.1056
2021-08-14 18:05:56,807 - mmseg - INFO - Iter [43600/160000]	lr: 7.535e-03, eta: 1 day, 18:19:33, time: 1.295, data_time: 0.016, memory: 5545, decode.loss_seg: 1.0523, decode.acc_seg: 52.8779, loss: 1.0523
2021-08-14 18:07:02,923 - mmseg - INFO - Iter [43650/160000]	lr: 7.532e-03, eta: 1 day, 18:18:30, time: 1.322, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1190, decode.acc_seg: 51.5765, loss: 1.1190
2021-08-14 18:08:07,854 - mmseg - INFO - Iter [43700/160000]	lr: 7.529e-03, eta: 1 day, 18:17:23, time: 1.299, data_time: 0.016, memory: 5545, decode.loss_seg: 1.0827, decode.acc_seg: 52.6828, loss: 1.0827
2021-08-14 18:09:14,388 - mmseg - INFO - Iter [43750/160000]	lr: 7.527e-03, eta: 1 day, 18:16:20, time: 1.331, data_time: 0.014, memory: 5545, decode.loss_seg: 1.0835, decode.acc_seg: 52.9895, loss: 1.0835
2021-08-14 18:10:20,141 - mmseg - INFO - Iter [43800/160000]	lr: 7.524e-03, eta: 1 day, 18:15:16, time: 1.316, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1523, decode.acc_seg: 50.5641, loss: 1.1523
2021-08-14 18:11:22,150 - mmseg - INFO - Iter [43850/160000]	lr: 7.521e-03, eta: 1 day, 18:14:01, time: 1.239, data_time: 0.014, memory: 5545, decode.loss_seg: 1.0753, decode.acc_seg: 53.0009, loss: 1.0753
2021-08-14 18:12:23,369 - mmseg - INFO - Iter [43900/160000]	lr: 7.518e-03, eta: 1 day, 18:12:44, time: 1.225, data_time: 0.015, memory: 5545, decode.loss_seg: 1.0923, decode.acc_seg: 52.4022, loss: 1.0923
2021-08-14 18:13:24,249 - mmseg - INFO - Iter [43950/160000]	lr: 7.515e-03, eta: 1 day, 18:11:27, time: 1.217, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1899, decode.acc_seg: 51.0834, loss: 1.1899
2021-08-14 18:14:26,309 - mmseg - INFO - Exp name: fcn_litehr30-without-head_512x512_160k_ade20k.py
2021-08-14 18:14:26,309 - mmseg - INFO - Iter [44000/160000]	lr: 7.512e-03, eta: 1 day, 18:10:13, time: 1.242, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1003, decode.acc_seg: 51.6400, loss: 1.1003
2021-08-14 18:15:28,365 - mmseg - INFO - Iter [44050/160000]	lr: 7.509e-03, eta: 1 day, 18:08:58, time: 1.241, data_time: 0.014, memory: 5545, decode.loss_seg: 1.1225, decode.acc_seg: 51.4033, loss: 1.1225
2021-08-14 18:16:29,466 - mmseg - INFO - Iter [44100/160000]	lr: 7.506e-03, eta: 1 day, 18:07:41, time: 1.222, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1472, decode.acc_seg: 51.1166, loss: 1.1472
2021-08-14 18:17:32,234 - mmseg - INFO - Iter [44150/160000]	lr: 7.503e-03, eta: 1 day, 18:06:29, time: 1.256, data_time: 0.015, memory: 5545, decode.loss_seg: 1.0860, decode.acc_seg: 52.9986, loss: 1.0860
2021-08-14 18:19:08,843 - mmseg - INFO - Iter [44200/160000]	lr: 7.501e-03, eta: 1 day, 18:06:45, time: 1.932, data_time: 0.727, memory: 5545, decode.loss_seg: 1.0978, decode.acc_seg: 52.8665, loss: 1.0978
2021-08-14 18:20:10,649 - mmseg - INFO - Iter [44250/160000]	lr: 7.498e-03, eta: 1 day, 18:05:30, time: 1.236, data_time: 0.016, memory: 5545, decode.loss_seg: 1.0902, decode.acc_seg: 52.1381, loss: 1.0902
2021-08-14 18:21:11,349 - mmseg - INFO - Iter [44300/160000]	lr: 7.495e-03, eta: 1 day, 18:04:12, time: 1.214, data_time: 0.014, memory: 5545, decode.loss_seg: 1.1633, decode.acc_seg: 52.4192, loss: 1.1633
2021-08-14 18:22:11,790 - mmseg - INFO - Iter [44350/160000]	lr: 7.492e-03, eta: 1 day, 18:02:54, time: 1.209, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1023, decode.acc_seg: 52.1755, loss: 1.1023
2021-08-14 18:23:12,135 - mmseg - INFO - Iter [44400/160000]	lr: 7.489e-03, eta: 1 day, 18:01:35, time: 1.206, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1251, decode.acc_seg: 51.7128, loss: 1.1251
2021-08-14 18:24:13,849 - mmseg - INFO - Iter [44450/160000]	lr: 7.486e-03, eta: 1 day, 18:00:20, time: 1.234, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1055, decode.acc_seg: 51.5333, loss: 1.1055
2021-08-14 18:25:16,222 - mmseg - INFO - Iter [44500/160000]	lr: 7.483e-03, eta: 1 day, 17:59:07, time: 1.247, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1090, decode.acc_seg: 52.3705, loss: 1.1090
2021-08-14 18:26:17,053 - mmseg - INFO - Iter [44550/160000]	lr: 7.480e-03, eta: 1 day, 17:57:49, time: 1.217, data_time: 0.017, memory: 5545, decode.loss_seg: 1.0630, decode.acc_seg: 52.6139, loss: 1.0630
2021-08-14 18:27:17,636 - mmseg - INFO - Iter [44600/160000]	lr: 7.478e-03, eta: 1 day, 17:56:31, time: 1.212, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1230, decode.acc_seg: 51.6028, loss: 1.1230
2021-08-14 18:28:19,335 - mmseg - INFO - Iter [44650/160000]	lr: 7.475e-03, eta: 1 day, 17:55:16, time: 1.234, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1192, decode.acc_seg: 52.0348, loss: 1.1192
2021-08-14 18:29:20,005 - mmseg - INFO - Iter [44700/160000]	lr: 7.472e-03, eta: 1 day, 17:53:59, time: 1.213, data_time: 0.015, memory: 5545, decode.loss_seg: 1.0985, decode.acc_seg: 53.1013, loss: 1.0985
2021-08-14 18:30:22,634 - mmseg - INFO - Iter [44750/160000]	lr: 7.469e-03, eta: 1 day, 17:52:46, time: 1.253, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1423, decode.acc_seg: 51.5280, loss: 1.1423
2021-08-14 18:31:21,567 - mmseg - INFO - Iter [44800/160000]	lr: 7.466e-03, eta: 1 day, 17:51:24, time: 1.179, data_time: 0.015, memory: 5545, decode.loss_seg: 1.0975, decode.acc_seg: 52.2465, loss: 1.0975
2021-08-14 18:32:59,184 - mmseg - INFO - Iter [44850/160000]	lr: 7.463e-03, eta: 1 day, 17:51:41, time: 1.952, data_time: 0.735, memory: 5545, decode.loss_seg: 1.0722, decode.acc_seg: 52.4972, loss: 1.0722
2021-08-14 18:34:00,623 - mmseg - INFO - Iter [44900/160000]	lr: 7.460e-03, eta: 1 day, 17:50:26, time: 1.228, data_time: 0.016, memory: 5545, decode.loss_seg: 1.0980, decode.acc_seg: 52.4727, loss: 1.0980
2021-08-14 18:35:03,426 - mmseg - INFO - Iter [44950/160000]	lr: 7.457e-03, eta: 1 day, 17:49:13, time: 1.256, data_time: 0.015, memory: 5545, decode.loss_seg: 1.0933, decode.acc_seg: 52.6637, loss: 1.0933
2021-08-14 18:36:08,682 - mmseg - INFO - Exp name: fcn_litehr30-without-head_512x512_160k_ade20k.py
2021-08-14 18:36:08,683 - mmseg - INFO - Iter [45000/160000]	lr: 7.455e-03, eta: 1 day, 17:48:08, time: 1.305, data_time: 0.016, memory: 5545, decode.loss_seg: 1.0897, decode.acc_seg: 52.8382, loss: 1.0897
2021-08-14 18:37:10,411 - mmseg - INFO - Iter [45050/160000]	lr: 7.452e-03, eta: 1 day, 17:46:53, time: 1.235, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1034, decode.acc_seg: 51.2050, loss: 1.1034
2021-08-14 18:38:11,613 - mmseg - INFO - Iter [45100/160000]	lr: 7.449e-03, eta: 1 day, 17:45:37, time: 1.224, data_time: 0.017, memory: 5545, decode.loss_seg: 1.0915, decode.acc_seg: 51.9154, loss: 1.0915
2021-08-14 18:39:11,578 - mmseg - INFO - Iter [45150/160000]	lr: 7.446e-03, eta: 1 day, 17:44:17, time: 1.199, data_time: 0.017, memory: 5545, decode.loss_seg: 1.0812, decode.acc_seg: 52.2322, loss: 1.0812
2021-08-14 18:40:12,312 - mmseg - INFO - Iter [45200/160000]	lr: 7.443e-03, eta: 1 day, 17:43:00, time: 1.215, data_time: 0.017, memory: 5545, decode.loss_seg: 1.1028, decode.acc_seg: 51.4153, loss: 1.1028
2021-08-14 18:41:13,272 - mmseg - INFO - Iter [45250/160000]	lr: 7.440e-03, eta: 1 day, 17:41:43, time: 1.219, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1453, decode.acc_seg: 51.1979, loss: 1.1453
2021-08-14 18:42:16,795 - mmseg - INFO - Iter [45300/160000]	lr: 7.437e-03, eta: 1 day, 17:40:33, time: 1.270, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1406, decode.acc_seg: 51.8156, loss: 1.1406
2021-08-14 18:43:16,757 - mmseg - INFO - Iter [45350/160000]	lr: 7.434e-03, eta: 1 day, 17:39:14, time: 1.199, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1335, decode.acc_seg: 51.1125, loss: 1.1335
2021-08-14 18:44:16,888 - mmseg - INFO - Iter [45400/160000]	lr: 7.432e-03, eta: 1 day, 17:37:55, time: 1.203, data_time: 0.017, memory: 5545, decode.loss_seg: 1.1098, decode.acc_seg: 52.4662, loss: 1.1098
2021-08-14 18:45:51,933 - mmseg - INFO - Iter [45450/160000]	lr: 7.429e-03, eta: 1 day, 17:38:05, time: 1.901, data_time: 0.722, memory: 5545, decode.loss_seg: 1.1288, decode.acc_seg: 52.1186, loss: 1.1288
2021-08-14 18:46:53,697 - mmseg - INFO - Iter [45500/160000]	lr: 7.426e-03, eta: 1 day, 17:36:50, time: 1.235, data_time: 0.015, memory: 5545, decode.loss_seg: 1.0563, decode.acc_seg: 52.2643, loss: 1.0563
2021-08-14 18:47:55,993 - mmseg - INFO - Iter [45550/160000]	lr: 7.423e-03, eta: 1 day, 17:35:37, time: 1.246, data_time: 0.016, memory: 5545, decode.loss_seg: 1.0998, decode.acc_seg: 52.7147, loss: 1.0998
2021-08-14 18:48:58,810 - mmseg - INFO - Iter [45600/160000]	lr: 7.420e-03, eta: 1 day, 17:34:25, time: 1.257, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1148, decode.acc_seg: 52.2375, loss: 1.1148
2021-08-14 18:49:59,936 - mmseg - INFO - Iter [45650/160000]	lr: 7.417e-03, eta: 1 day, 17:33:09, time: 1.222, data_time: 0.016, memory: 5545, decode.loss_seg: 1.0990, decode.acc_seg: 51.9824, loss: 1.0990
2021-08-14 18:51:01,507 - mmseg - INFO - Iter [45700/160000]	lr: 7.414e-03, eta: 1 day, 17:31:54, time: 1.231, data_time: 0.017, memory: 5545, decode.loss_seg: 1.1185, decode.acc_seg: 51.8496, loss: 1.1185
2021-08-14 18:52:06,133 - mmseg - INFO - Iter [45750/160000]	lr: 7.411e-03, eta: 1 day, 17:30:46, time: 1.292, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1351, decode.acc_seg: 51.7426, loss: 1.1351
2021-08-14 18:53:10,882 - mmseg - INFO - Iter [45800/160000]	lr: 7.409e-03, eta: 1 day, 17:29:39, time: 1.295, data_time: 0.017, memory: 5545, decode.loss_seg: 1.1073, decode.acc_seg: 52.2616, loss: 1.1073
2021-08-14 18:54:14,412 - mmseg - INFO - Iter [45850/160000]	lr: 7.406e-03, eta: 1 day, 17:28:29, time: 1.271, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1360, decode.acc_seg: 51.7449, loss: 1.1360
2021-08-14 18:55:17,275 - mmseg - INFO - Iter [45900/160000]	lr: 7.403e-03, eta: 1 day, 17:27:17, time: 1.257, data_time: 0.017, memory: 5545, decode.loss_seg: 1.1225, decode.acc_seg: 51.5940, loss: 1.1225
2021-08-14 18:56:19,347 - mmseg - INFO - Iter [45950/160000]	lr: 7.400e-03, eta: 1 day, 17:26:04, time: 1.242, data_time: 0.016, memory: 5545, decode.loss_seg: 1.0736, decode.acc_seg: 52.7616, loss: 1.0736
2021-08-14 18:57:19,513 - mmseg - INFO - Exp name: fcn_litehr30-without-head_512x512_160k_ade20k.py
2021-08-14 18:57:19,514 - mmseg - INFO - Iter [46000/160000]	lr: 7.397e-03, eta: 1 day, 17:24:45, time: 1.204, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1333, decode.acc_seg: 52.3641, loss: 1.1333
2021-08-14 18:58:21,644 - mmseg - INFO - Iter [46050/160000]	lr: 7.394e-03, eta: 1 day, 17:23:32, time: 1.242, data_time: 0.015, memory: 5545, decode.loss_seg: 1.0946, decode.acc_seg: 51.9139, loss: 1.0946
2021-08-14 19:00:00,370 - mmseg - INFO - Iter [46100/160000]	lr: 7.391e-03, eta: 1 day, 17:23:49, time: 1.975, data_time: 0.732, memory: 5545, decode.loss_seg: 1.0846, decode.acc_seg: 52.2103, loss: 1.0846
2021-08-14 19:01:01,266 - mmseg - INFO - Iter [46150/160000]	lr: 7.388e-03, eta: 1 day, 17:22:32, time: 1.218, data_time: 0.016, memory: 5545, decode.loss_seg: 1.0930, decode.acc_seg: 52.6425, loss: 1.0930
2021-08-14 19:02:01,478 - mmseg - INFO - Iter [46200/160000]	lr: 7.385e-03, eta: 1 day, 17:21:14, time: 1.204, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1272, decode.acc_seg: 52.2646, loss: 1.1272
2021-08-14 19:03:03,580 - mmseg - INFO - Iter [46250/160000]	lr: 7.383e-03, eta: 1 day, 17:20:01, time: 1.242, data_time: 0.017, memory: 5545, decode.loss_seg: 1.1190, decode.acc_seg: 51.9821, loss: 1.1190
2021-08-14 19:04:03,901 - mmseg - INFO - Iter [46300/160000]	lr: 7.380e-03, eta: 1 day, 17:18:43, time: 1.206, data_time: 0.015, memory: 5545, decode.loss_seg: 1.0916, decode.acc_seg: 51.6092, loss: 1.0916
2021-08-14 19:05:06,067 - mmseg - INFO - Iter [46350/160000]	lr: 7.377e-03, eta: 1 day, 17:17:29, time: 1.243, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1102, decode.acc_seg: 51.0248, loss: 1.1102
2021-08-14 19:06:08,765 - mmseg - INFO - Iter [46400/160000]	lr: 7.374e-03, eta: 1 day, 17:16:17, time: 1.254, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1269, decode.acc_seg: 51.0785, loss: 1.1269
2021-08-14 19:07:08,908 - mmseg - INFO - Iter [46450/160000]	lr: 7.371e-03, eta: 1 day, 17:14:59, time: 1.202, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1035, decode.acc_seg: 52.6347, loss: 1.1035
2021-08-14 19:08:09,797 - mmseg - INFO - Iter [46500/160000]	lr: 7.368e-03, eta: 1 day, 17:13:43, time: 1.218, data_time: 0.016, memory: 5545, decode.loss_seg: 1.0996, decode.acc_seg: 52.0567, loss: 1.0996
2021-08-14 19:09:11,104 - mmseg - INFO - Iter [46550/160000]	lr: 7.365e-03, eta: 1 day, 17:12:27, time: 1.226, data_time: 0.016, memory: 5545, decode.loss_seg: 1.0779, decode.acc_seg: 52.9771, loss: 1.0779
2021-08-14 19:10:13,432 - mmseg - INFO - Iter [46600/160000]	lr: 7.362e-03, eta: 1 day, 17:11:15, time: 1.246, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1010, decode.acc_seg: 52.5087, loss: 1.1010
2021-08-14 19:11:14,369 - mmseg - INFO - Iter [46650/160000]	lr: 7.360e-03, eta: 1 day, 17:09:58, time: 1.219, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1302, decode.acc_seg: 52.0174, loss: 1.1302
2021-08-14 19:12:52,079 - mmseg - INFO - Iter [46700/160000]	lr: 7.357e-03, eta: 1 day, 17:10:12, time: 1.955, data_time: 0.682, memory: 5545, decode.loss_seg: 1.1154, decode.acc_seg: 52.6457, loss: 1.1154
2021-08-14 19:13:53,441 - mmseg - INFO - Iter [46750/160000]	lr: 7.354e-03, eta: 1 day, 17:08:56, time: 1.227, data_time: 0.016, memory: 5545, decode.loss_seg: 1.0883, decode.acc_seg: 52.5490, loss: 1.0883
2021-08-14 19:14:55,507 - mmseg - INFO - Iter [46800/160000]	lr: 7.351e-03, eta: 1 day, 17:07:43, time: 1.241, data_time: 0.016, memory: 5545, decode.loss_seg: 1.0786, decode.acc_seg: 51.8678, loss: 1.0786
2021-08-14 19:15:57,132 - mmseg - INFO - Iter [46850/160000]	lr: 7.348e-03, eta: 1 day, 17:06:28, time: 1.232, data_time: 0.016, memory: 5545, decode.loss_seg: 1.0602, decode.acc_seg: 52.0593, loss: 1.0602
2021-08-14 19:16:57,562 - mmseg - INFO - Iter [46900/160000]	lr: 7.345e-03, eta: 1 day, 17:05:11, time: 1.209, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1182, decode.acc_seg: 52.3610, loss: 1.1182
2021-08-14 19:17:58,315 - mmseg - INFO - Iter [46950/160000]	lr: 7.342e-03, eta: 1 day, 17:03:54, time: 1.215, data_time: 0.016, memory: 5545, decode.loss_seg: 1.0963, decode.acc_seg: 53.5111, loss: 1.0963
2021-08-14 19:18:59,628 - mmseg - INFO - Exp name: fcn_litehr30-without-head_512x512_160k_ade20k.py
2021-08-14 19:18:59,629 - mmseg - INFO - Iter [47000/160000]	lr: 7.339e-03, eta: 1 day, 17:02:39, time: 1.226, data_time: 0.017, memory: 5545, decode.loss_seg: 1.0791, decode.acc_seg: 53.0769, loss: 1.0791
2021-08-14 19:20:00,212 - mmseg - INFO - Iter [47050/160000]	lr: 7.336e-03, eta: 1 day, 17:01:22, time: 1.212, data_time: 0.017, memory: 5545, decode.loss_seg: 1.1172, decode.acc_seg: 51.5736, loss: 1.1172
2021-08-14 19:21:02,263 - mmseg - INFO - Iter [47100/160000]	lr: 7.334e-03, eta: 1 day, 17:00:09, time: 1.242, data_time: 0.016, memory: 5545, decode.loss_seg: 1.0614, decode.acc_seg: 52.2563, loss: 1.0614
2021-08-14 19:22:05,497 - mmseg - INFO - Iter [47150/160000]	lr: 7.331e-03, eta: 1 day, 16:58:58, time: 1.264, data_time: 0.017, memory: 5545, decode.loss_seg: 1.1011, decode.acc_seg: 52.6374, loss: 1.1011
2021-08-14 19:23:08,219 - mmseg - INFO - Iter [47200/160000]	lr: 7.328e-03, eta: 1 day, 16:57:47, time: 1.254, data_time: 0.017, memory: 5545, decode.loss_seg: 1.1294, decode.acc_seg: 52.0830, loss: 1.1294
2021-08-14 19:24:09,451 - mmseg - INFO - Iter [47250/160000]	lr: 7.325e-03, eta: 1 day, 16:56:32, time: 1.225, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1129, decode.acc_seg: 51.8442, loss: 1.1129
2021-08-14 19:25:10,893 - mmseg - INFO - Iter [47300/160000]	lr: 7.322e-03, eta: 1 day, 16:55:17, time: 1.229, data_time: 0.017, memory: 5545, decode.loss_seg: 1.1443, decode.acc_seg: 51.7780, loss: 1.1443
2021-08-14 19:26:46,283 - mmseg - INFO - Iter [47350/160000]	lr: 7.319e-03, eta: 1 day, 16:55:23, time: 1.908, data_time: 0.736, memory: 5545, decode.loss_seg: 1.0908, decode.acc_seg: 52.1290, loss: 1.0908
2021-08-14 19:27:48,443 - mmseg - INFO - Iter [47400/160000]	lr: 7.316e-03, eta: 1 day, 16:54:10, time: 1.243, data_time: 0.016, memory: 5545, decode.loss_seg: 1.0936, decode.acc_seg: 51.1483, loss: 1.0936
2021-08-14 19:28:49,314 - mmseg - INFO - Iter [47450/160000]	lr: 7.313e-03, eta: 1 day, 16:52:54, time: 1.217, data_time: 0.015, memory: 5545, decode.loss_seg: 1.0977, decode.acc_seg: 52.0766, loss: 1.0977
2021-08-14 19:29:49,733 - mmseg - INFO - Iter [47500/160000]	lr: 7.311e-03, eta: 1 day, 16:51:37, time: 1.208, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1041, decode.acc_seg: 52.3858, loss: 1.1041
2021-08-14 19:30:51,267 - mmseg - INFO - Iter [47550/160000]	lr: 7.308e-03, eta: 1 day, 16:50:22, time: 1.230, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1038, decode.acc_seg: 51.7202, loss: 1.1038
2021-08-14 19:31:52,791 - mmseg - INFO - Iter [47600/160000]	lr: 7.305e-03, eta: 1 day, 16:49:08, time: 1.231, data_time: 0.016, memory: 5545, decode.loss_seg: 1.0703, decode.acc_seg: 52.8351, loss: 1.0703
2021-08-14 19:32:53,501 - mmseg - INFO - Iter [47650/160000]	lr: 7.302e-03, eta: 1 day, 16:47:51, time: 1.214, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1370, decode.acc_seg: 52.5539, loss: 1.1370
2021-08-14 19:33:53,881 - mmseg - INFO - Iter [47700/160000]	lr: 7.299e-03, eta: 1 day, 16:46:34, time: 1.207, data_time: 0.014, memory: 5545, decode.loss_seg: 1.0669, decode.acc_seg: 54.1639, loss: 1.0669
2021-08-14 19:34:57,916 - mmseg - INFO - Iter [47750/160000]	lr: 7.296e-03, eta: 1 day, 16:45:26, time: 1.281, data_time: 0.014, memory: 5545, decode.loss_seg: 1.1136, decode.acc_seg: 51.3928, loss: 1.1136
2021-08-14 19:35:59,620 - mmseg - INFO - Iter [47800/160000]	lr: 7.293e-03, eta: 1 day, 16:44:12, time: 1.234, data_time: 0.014, memory: 5545, decode.loss_seg: 1.0750, decode.acc_seg: 53.0243, loss: 1.0750
2021-08-14 19:37:01,101 - mmseg - INFO - Iter [47850/160000]	lr: 7.290e-03, eta: 1 day, 16:42:57, time: 1.229, data_time: 0.014, memory: 5545, decode.loss_seg: 1.1245, decode.acc_seg: 52.3087, loss: 1.1245
2021-08-14 19:38:01,270 - mmseg - INFO - Iter [47900/160000]	lr: 7.287e-03, eta: 1 day, 16:41:40, time: 1.204, data_time: 0.015, memory: 5545, decode.loss_seg: 1.0834, decode.acc_seg: 52.4225, loss: 1.0834
2021-08-14 19:39:03,077 - mmseg - INFO - Iter [47950/160000]	lr: 7.285e-03, eta: 1 day, 16:40:26, time: 1.236, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1115, decode.acc_seg: 53.0078, loss: 1.1115
2021-08-14 19:40:40,219 - mmseg - INFO - Saving checkpoint at 48000 iterations
2021-08-14 19:40:40,588 - mmseg - INFO - Exp name: fcn_litehr30-without-head_512x512_160k_ade20k.py
2021-08-14 19:40:40,589 - mmseg - INFO - Iter [48000/160000]	lr: 7.282e-03, eta: 1 day, 16:40:36, time: 1.950, data_time: 0.683, memory: 5545, decode.loss_seg: 1.0583, decode.acc_seg: 52.5246, loss: 1.0583
2021-08-14 19:42:46,132 - mmseg - INFO - per class results:
2021-08-14 19:42:46,145 - mmseg - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        | 54.24 | 82.43 |
|       building      | 66.91 | 85.87 |
|         sky         | 88.51 | 95.37 |
|        floor        | 57.71 | 84.79 |
|         tree        |  57.4 | 83.85 |
|       ceiling       | 68.24 | 89.77 |
|         road        | 66.63 | 79.11 |
|         bed         | 61.22 | 79.29 |
|      windowpane     |  38.6 | 67.31 |
|        grass        | 48.65 |  66.1 |
|       cabinet       | 33.47 | 40.33 |
|       sidewalk      | 40.39 | 52.59 |
|        person       | 43.78 | 55.57 |
|        earth        | 19.16 | 27.28 |
|         door        | 11.93 | 15.98 |
|        table        | 26.53 | 35.17 |
|       mountain      | 31.17 | 36.12 |
|        plant        | 25.38 | 33.93 |
|       curtain       | 36.82 |  56.2 |
|        chair        | 25.14 | 36.85 |
|         car         | 58.79 | 74.65 |
|        water        | 23.02 | 34.01 |
|       painting      | 40.87 | 46.07 |
|         sofa        | 33.67 | 46.57 |
|        shelf        | 13.64 | 18.29 |
|        house        | 27.68 | 37.75 |
|         sea         |  35.2 |  86.0 |
|        mirror       | 15.88 |  18.3 |
|         rug         | 21.14 | 23.04 |
|        field        | 18.61 | 58.35 |
|       armchair      |  6.17 |  7.37 |
|         seat        | 19.98 |  29.2 |
|        fence        | 11.82 | 14.79 |
|         desk        |  9.37 | 10.96 |
|         rock        | 13.55 | 17.73 |
|       wardrobe      | 11.14 | 13.89 |
|         lamp        | 24.34 |  30.7 |
|       bathtub       | 16.99 | 21.09 |
|       railing       |  9.66 | 10.11 |
|       cushion       |  15.5 | 19.49 |
|         base        |  0.1  |  0.1  |
|         box         |  0.09 |  0.09 |
|        column       |  6.66 |  7.25 |
|      signboard      |  4.6  |  4.73 |
|   chest of drawers  | 29.04 | 34.21 |
|       counter       |  6.73 |  7.6  |
|         sand        | 16.18 | 25.82 |
|         sink        | 12.95 | 14.16 |
|      skyscraper     | 42.33 | 68.97 |
|      fireplace      | 49.74 | 64.68 |
|     refrigerator    | 20.61 |  24.8 |
|      grandstand     | 17.75 | 27.05 |
|         path        | 15.81 | 23.75 |
|        stairs       |  6.28 |  7.2  |
|        runway       | 36.59 | 40.81 |
|         case        |  3.93 |  5.6  |
|      pool table     |  56.9 | 69.93 |
|        pillow       | 17.44 | 19.88 |
|     screen door     |  0.06 |  0.06 |
|       stairway      |  6.04 |  9.9  |
|        river        |  4.7  |  8.17 |
|        bridge       |  6.5  |  7.85 |
|       bookcase      | 18.02 | 35.05 |
|        blind        |  0.0  |  0.0  |
|     coffee table    | 23.55 | 31.96 |
|        toilet       | 33.88 | 42.05 |
|        flower       |  0.49 |  0.5  |
|         book        | 13.37 | 17.27 |
|         hill        |  0.56 |  0.56 |
|        bench        |  6.16 |  6.79 |
|      countertop     |  4.47 |  4.5  |
|        stove        |  25.2 | 32.21 |
|         palm        |  3.86 |  3.89 |
|    kitchen island   |  3.65 |  3.79 |
|       computer      | 17.91 | 20.37 |
|     swivel chair    |  9.36 | 10.43 |
|         boat        |  6.51 |  7.24 |
|         bar         | 16.48 | 17.22 |
|    arcade machine   |  0.4  |  0.48 |
|        hovel        |  0.77 |  0.81 |
|         bus         |  4.05 |  4.17 |
|        towel        |  1.8  |  1.81 |
|        light        |  9.5  |  9.99 |
|        truck        |  0.2  |  0.21 |
|        tower        |  8.89 |  8.94 |
|      chandelier     | 35.02 | 47.63 |
|        awning       |  0.04 |  0.05 |
|     streetlight     |  0.02 |  0.02 |
|        booth        |  0.0  |  0.0  |
| television receiver | 15.67 | 16.87 |
|       airplane      | 15.19 | 19.18 |
|      dirt track     |  0.0  |  0.0  |
|       apparel       |  0.01 |  0.02 |
|         pole        |  2.2  |  2.27 |
|         land        |  0.0  |  0.0  |
|      bannister      |  0.0  |  0.0  |
|      escalator      |  0.59 |  0.66 |
|       ottoman       |  0.0  |  0.0  |
|        bottle       |  0.0  |  0.0  |
|        buffet       |  0.0  |  0.0  |
|        poster       |  0.0  |  0.0  |
|        stage        |  0.0  |  0.0  |
|         van         |  0.03 |  0.03 |
|         ship        |  0.0  |  0.0  |
|       fountain      |  0.0  |  0.0  |
|    conveyer belt    |  0.0  |  0.0  |
|        canopy       |  0.0  |  0.0  |
|        washer       | 30.63 | 32.22 |
|      plaything      |  0.0  |  0.0  |
|    swimming pool    |  2.32 |  3.06 |
|        stool        |  0.0  |  0.0  |
|        barrel       |  0.0  |  0.0  |
|        basket       |  0.0  |  0.0  |
|      waterfall      | 28.63 | 42.19 |
|         tent        | 32.09 | 48.93 |
|         bag         |  0.0  |  0.0  |
|       minibike      |  0.0  |  0.0  |
|        cradle       | 49.64 | 64.94 |
|         oven        |  0.0  |  0.0  |
|         ball        |  0.0  |  0.0  |
|         food        |  1.59 |  1.6  |
|         step        |  0.0  |  0.0  |
|         tank        |  0.0  |  0.0  |
|      trade name     |  1.42 |  1.42 |
|      microwave      | 12.59 | 13.36 |
|         pot         |  0.0  |  0.0  |
|        animal       |  0.01 |  0.01 |
|       bicycle       |  0.0  |  0.0  |
|         lake        |  0.0  |  0.0  |
|      dishwasher     |  0.82 |  0.83 |
|        screen       | 15.76 | 17.02 |
|       blanket       |  0.0  |  0.0  |
|      sculpture      |  0.0  |  0.0  |
|         hood        | 12.62 | 14.04 |
|        sconce       |  0.0  |  0.0  |
|         vase        |  0.0  |  0.0  |
|    traffic light    |  0.0  |  0.0  |
|         tray        |  0.0  |  0.0  |
|        ashcan       |  0.0  |  0.0  |
|         fan         |  0.0  |  0.0  |
|         pier        |  0.0  |  0.0  |
|      crt screen     |  0.0  |  0.0  |
|        plate        |  0.0  |  0.0  |
|       monitor       |  0.0  |  0.0  |
|    bulletin board   |  0.0  |  0.0  |
|        shower       |  0.0  |  0.0  |
|       radiator      |  0.0  |  0.0  |
|        glass        |  0.0  |  0.0  |
|        clock        |  0.0  |  0.0  |
|         flag        |  0.0  |  0.0  |
+---------------------+-------+-------+
2021-08-14 19:42:46,145 - mmseg - INFO - Summary:
2021-08-14 19:42:46,145 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 65.89 | 14.37 | 19.21 |
+-------+-------+-------+
2021-08-14 19:42:46,310 - mmseg - INFO - Exp name: fcn_litehr30-without-head_512x512_160k_ade20k.py
2021-08-14 19:42:46,310 - mmseg - INFO - Iter(val) [250]	aAcc: 0.6589, mIoU: 0.1437, mAcc: 0.1921, IoU.wall: 0.5424, IoU.building: 0.6691, IoU.sky: 0.8851, IoU.floor: 0.5771, IoU.tree: 0.5740, IoU.ceiling: 0.6824, IoU.road: 0.6663, IoU.bed : 0.6122, IoU.windowpane: 0.3860, IoU.grass: 0.4865, IoU.cabinet: 0.3347, IoU.sidewalk: 0.4039, IoU.person: 0.4378, IoU.earth: 0.1916, IoU.door: 0.1193, IoU.table: 0.2653, IoU.mountain: 0.3117, IoU.plant: 0.2538, IoU.curtain: 0.3682, IoU.chair: 0.2514, IoU.car: 0.5879, IoU.water: 0.2302, IoU.painting: 0.4087, IoU.sofa: 0.3367, IoU.shelf: 0.1364, IoU.house: 0.2768, IoU.sea: 0.3520, IoU.mirror: 0.1588, IoU.rug: 0.2114, IoU.field: 0.1861, IoU.armchair: 0.0617, IoU.seat: 0.1998, IoU.fence: 0.1182, IoU.desk: 0.0937, IoU.rock: 0.1355, IoU.wardrobe: 0.1114, IoU.lamp: 0.2434, IoU.bathtub: 0.1699, IoU.railing: 0.0966, IoU.cushion: 0.1550, IoU.base: 0.0010, IoU.box: 0.0009, IoU.column: 0.0666, IoU.signboard: 0.0460, IoU.chest of drawers: 0.2904, IoU.counter: 0.0673, IoU.sand: 0.1618, IoU.sink: 0.1295, IoU.skyscraper: 0.4233, IoU.fireplace: 0.4974, IoU.refrigerator: 0.2061, IoU.grandstand: 0.1775, IoU.path: 0.1581, IoU.stairs: 0.0628, IoU.runway: 0.3659, IoU.case: 0.0393, IoU.pool table: 0.5690, IoU.pillow: 0.1744, IoU.screen door: 0.0006, IoU.stairway: 0.0604, IoU.river: 0.0470, IoU.bridge: 0.0650, IoU.bookcase: 0.1802, IoU.blind: 0.0000, IoU.coffee table: 0.2355, IoU.toilet: 0.3388, IoU.flower: 0.0049, IoU.book: 0.1337, IoU.hill: 0.0056, IoU.bench: 0.0616, IoU.countertop: 0.0447, IoU.stove: 0.2520, IoU.palm: 0.0386, IoU.kitchen island: 0.0365, IoU.computer: 0.1791, IoU.swivel chair: 0.0936, IoU.boat: 0.0651, IoU.bar: 0.1648, IoU.arcade machine: 0.0040, IoU.hovel: 0.0077, IoU.bus: 0.0405, IoU.towel: 0.0180, IoU.light: 0.0950, IoU.truck: 0.0020, IoU.tower: 0.0889, IoU.chandelier: 0.3502, IoU.awning: 0.0004, IoU.streetlight: 0.0002, IoU.booth: 0.0000, IoU.television receiver: 0.1567, IoU.airplane: 0.1519, IoU.dirt track: 0.0000, IoU.apparel: 0.0001, IoU.pole: 0.0220, IoU.land: 0.0000, IoU.bannister: 0.0000, IoU.escalator: 0.0059, IoU.ottoman: 0.0000, IoU.bottle: 0.0000, IoU.buffet: 0.0000, IoU.poster: 0.0000, IoU.stage: 0.0000, IoU.van: 0.0003, IoU.ship: 0.0000, IoU.fountain: 0.0000, IoU.conveyer belt: 0.0000, IoU.canopy: 0.0000, IoU.washer: 0.3063, IoU.plaything: 0.0000, IoU.swimming pool: 0.0232, IoU.stool: 0.0000, IoU.barrel: 0.0000, IoU.basket: 0.0000, IoU.waterfall: 0.2863, IoU.tent: 0.3209, IoU.bag: 0.0000, IoU.minibike: 0.0000, IoU.cradle: 0.4964, IoU.oven: 0.0000, IoU.ball: 0.0000, IoU.food: 0.0159, IoU.step: 0.0000, IoU.tank: 0.0000, IoU.trade name: 0.0142, IoU.microwave: 0.1259, IoU.pot: 0.0000, IoU.animal: 0.0001, IoU.bicycle: 0.0000, IoU.lake: 0.0000, IoU.dishwasher: 0.0082, IoU.screen: 0.1576, IoU.blanket: 0.0000, IoU.sculpture: 0.0000, IoU.hood: 0.1262, IoU.sconce: 0.0000, IoU.vase: 0.0000, IoU.traffic light: 0.0000, IoU.tray: 0.0000, IoU.ashcan: 0.0000, IoU.fan: 0.0000, IoU.pier: 0.0000, IoU.crt screen: 0.0000, IoU.plate: 0.0000, IoU.monitor: 0.0000, IoU.bulletin board: 0.0000, IoU.shower: 0.0000, IoU.radiator: 0.0000, IoU.glass: 0.0000, IoU.clock: 0.0000, IoU.flag: 0.0000, Acc.wall: 0.8243, Acc.building: 0.8587, Acc.sky: 0.9537, Acc.floor: 0.8479, Acc.tree: 0.8385, Acc.ceiling: 0.8977, Acc.road: 0.7911, Acc.bed : 0.7929, Acc.windowpane: 0.6731, Acc.grass: 0.6610, Acc.cabinet: 0.4033, Acc.sidewalk: 0.5259, Acc.person: 0.5557, Acc.earth: 0.2728, Acc.door: 0.1598, Acc.table: 0.3517, Acc.mountain: 0.3612, Acc.plant: 0.3393, Acc.curtain: 0.5620, Acc.chair: 0.3685, Acc.car: 0.7465, Acc.water: 0.3401, Acc.painting: 0.4607, Acc.sofa: 0.4657, Acc.shelf: 0.1829, Acc.house: 0.3775, Acc.sea: 0.8600, Acc.mirror: 0.1830, Acc.rug: 0.2304, Acc.field: 0.5835, Acc.armchair: 0.0737, Acc.seat: 0.2920, Acc.fence: 0.1479, Acc.desk: 0.1096, Acc.rock: 0.1773, Acc.wardrobe: 0.1389, Acc.lamp: 0.3070, Acc.bathtub: 0.2109, Acc.railing: 0.1011, Acc.cushion: 0.1949, Acc.base: 0.0010, Acc.box: 0.0009, Acc.column: 0.0725, Acc.signboard: 0.0473, Acc.chest of drawers: 0.3421, Acc.counter: 0.0760, Acc.sand: 0.2582, Acc.sink: 0.1416, Acc.skyscraper: 0.6897, Acc.fireplace: 0.6468, Acc.refrigerator: 0.2480, Acc.grandstand: 0.2705, Acc.path: 0.2375, Acc.stairs: 0.0720, Acc.runway: 0.4081, Acc.case: 0.0560, Acc.pool table: 0.6993, Acc.pillow: 0.1988, Acc.screen door: 0.0006, Acc.stairway: 0.0990, Acc.river: 0.0817, Acc.bridge: 0.0785, Acc.bookcase: 0.3505, Acc.blind: 0.0000, Acc.coffee table: 0.3196, Acc.toilet: 0.4205, Acc.flower: 0.0050, Acc.book: 0.1727, Acc.hill: 0.0056, Acc.bench: 0.0679, Acc.countertop: 0.0450, Acc.stove: 0.3221, Acc.palm: 0.0389, Acc.kitchen island: 0.0379, Acc.computer: 0.2037, Acc.swivel chair: 0.1043, Acc.boat: 0.0724, Acc.bar: 0.1722, Acc.arcade machine: 0.0048, Acc.hovel: 0.0081, Acc.bus: 0.0417, Acc.towel: 0.0181, Acc.light: 0.0999, Acc.truck: 0.0021, Acc.tower: 0.0894, Acc.chandelier: 0.4763, Acc.awning: 0.0005, Acc.streetlight: 0.0002, Acc.booth: 0.0000, Acc.television receiver: 0.1687, Acc.airplane: 0.1918, Acc.dirt track: 0.0000, Acc.apparel: 0.0002, Acc.pole: 0.0227, Acc.land: 0.0000, Acc.bannister: 0.0000, Acc.escalator: 0.0066, Acc.ottoman: 0.0000, Acc.bottle: 0.0000, Acc.buffet: 0.0000, Acc.poster: 0.0000, Acc.stage: 0.0000, Acc.van: 0.0003, Acc.ship: 0.0000, Acc.fountain: 0.0000, Acc.conveyer belt: 0.0000, Acc.canopy: 0.0000, Acc.washer: 0.3222, Acc.plaything: 0.0000, Acc.swimming pool: 0.0306, Acc.stool: 0.0000, Acc.barrel: 0.0000, Acc.basket: 0.0000, Acc.waterfall: 0.4219, Acc.tent: 0.4893, Acc.bag: 0.0000, Acc.minibike: 0.0000, Acc.cradle: 0.6494, Acc.oven: 0.0000, Acc.ball: 0.0000, Acc.food: 0.0160, Acc.step: 0.0000, Acc.tank: 0.0000, Acc.trade name: 0.0142, Acc.microwave: 0.1336, Acc.pot: 0.0000, Acc.animal: 0.0001, Acc.bicycle: 0.0000, Acc.lake: 0.0000, Acc.dishwasher: 0.0083, Acc.screen: 0.1702, Acc.blanket: 0.0000, Acc.sculpture: 0.0000, Acc.hood: 0.1404, Acc.sconce: 0.0000, Acc.vase: 0.0000, Acc.traffic light: 0.0000, Acc.tray: 0.0000, Acc.ashcan: 0.0000, Acc.fan: 0.0000, Acc.pier: 0.0000, Acc.crt screen: 0.0000, Acc.plate: 0.0000, Acc.monitor: 0.0000, Acc.bulletin board: 0.0000, Acc.shower: 0.0000, Acc.radiator: 0.0000, Acc.glass: 0.0000, Acc.clock: 0.0000, Acc.flag: 0.0000
2021-08-14 19:43:50,547 - mmseg - INFO - Iter [48050/160000]	lr: 7.279e-03, eta: 1 day, 16:44:21, time: 3.799, data_time: 2.531, memory: 5545, decode.loss_seg: 1.0716, decode.acc_seg: 52.6850, loss: 1.0716
2021-08-14 19:44:51,707 - mmseg - INFO - Iter [48100/160000]	lr: 7.276e-03, eta: 1 day, 16:43:05, time: 1.223, data_time: 0.014, memory: 5545, decode.loss_seg: 1.0774, decode.acc_seg: 53.6833, loss: 1.0774
2021-08-14 19:45:52,396 - mmseg - INFO - Iter [48150/160000]	lr: 7.273e-03, eta: 1 day, 16:41:49, time: 1.213, data_time: 0.014, memory: 5545, decode.loss_seg: 1.0873, decode.acc_seg: 52.4800, loss: 1.0873
2021-08-14 19:46:57,167 - mmseg - INFO - Iter [48200/160000]	lr: 7.270e-03, eta: 1 day, 16:40:41, time: 1.295, data_time: 0.014, memory: 5545, decode.loss_seg: 1.0809, decode.acc_seg: 52.6701, loss: 1.0809
2021-08-14 19:48:01,735 - mmseg - INFO - Iter [48250/160000]	lr: 7.267e-03, eta: 1 day, 16:39:34, time: 1.292, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1157, decode.acc_seg: 51.9941, loss: 1.1157
2021-08-14 19:49:04,825 - mmseg - INFO - Iter [48300/160000]	lr: 7.264e-03, eta: 1 day, 16:38:23, time: 1.262, data_time: 0.016, memory: 5545, decode.loss_seg: 1.0796, decode.acc_seg: 52.4432, loss: 1.0796
2021-08-14 19:50:04,899 - mmseg - INFO - Iter [48350/160000]	lr: 7.261e-03, eta: 1 day, 16:37:05, time: 1.201, data_time: 0.015, memory: 5545, decode.loss_seg: 1.0910, decode.acc_seg: 52.2892, loss: 1.0910
2021-08-14 19:51:04,798 - mmseg - INFO - Iter [48400/160000]	lr: 7.259e-03, eta: 1 day, 16:35:46, time: 1.198, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1387, decode.acc_seg: 51.5730, loss: 1.1387
2021-08-14 19:52:06,749 - mmseg - INFO - Iter [48450/160000]	lr: 7.256e-03, eta: 1 day, 16:34:33, time: 1.239, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1108, decode.acc_seg: 51.9009, loss: 1.1108
2021-08-14 19:53:06,679 - mmseg - INFO - Iter [48500/160000]	lr: 7.253e-03, eta: 1 day, 16:33:15, time: 1.198, data_time: 0.015, memory: 5545, decode.loss_seg: 1.0857, decode.acc_seg: 52.3751, loss: 1.0857
2021-08-14 19:54:07,795 - mmseg - INFO - Iter [48550/160000]	lr: 7.250e-03, eta: 1 day, 16:31:59, time: 1.223, data_time: 0.017, memory: 5545, decode.loss_seg: 1.0885, decode.acc_seg: 52.3282, loss: 1.0885
2021-08-14 19:55:44,766 - mmseg - INFO - Iter [48600/160000]	lr: 7.247e-03, eta: 1 day, 16:32:06, time: 1.939, data_time: 0.720, memory: 5545, decode.loss_seg: 1.1074, decode.acc_seg: 52.1654, loss: 1.1074
2021-08-14 19:56:47,589 - mmseg - INFO - Iter [48650/160000]	lr: 7.244e-03, eta: 1 day, 16:30:54, time: 1.257, data_time: 0.016, memory: 5545, decode.loss_seg: 1.0885, decode.acc_seg: 53.1918, loss: 1.0885
2021-08-14 19:57:49,208 - mmseg - INFO - Iter [48700/160000]	lr: 7.241e-03, eta: 1 day, 16:29:40, time: 1.232, data_time: 0.015, memory: 5545, decode.loss_seg: 1.0994, decode.acc_seg: 51.6699, loss: 1.0994
2021-08-14 19:58:54,047 - mmseg - INFO - Iter [48750/160000]	lr: 7.238e-03, eta: 1 day, 16:28:33, time: 1.297, data_time: 0.015, memory: 5545, decode.loss_seg: 1.0828, decode.acc_seg: 51.7872, loss: 1.0828
2021-08-14 19:59:56,581 - mmseg - INFO - Iter [48800/160000]	lr: 7.236e-03, eta: 1 day, 16:27:21, time: 1.252, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1158, decode.acc_seg: 52.4902, loss: 1.1158
2021-08-14 20:00:57,330 - mmseg - INFO - Iter [48850/160000]	lr: 7.233e-03, eta: 1 day, 16:26:05, time: 1.215, data_time: 0.016, memory: 5545, decode.loss_seg: 1.0858, decode.acc_seg: 52.9527, loss: 1.0858
2021-08-14 20:01:57,519 - mmseg - INFO - Iter [48900/160000]	lr: 7.230e-03, eta: 1 day, 16:24:47, time: 1.204, data_time: 0.015, memory: 5545, decode.loss_seg: 1.0890, decode.acc_seg: 52.1004, loss: 1.0890
2021-08-14 20:02:57,633 - mmseg - INFO - Iter [48950/160000]	lr: 7.227e-03, eta: 1 day, 16:23:29, time: 1.202, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1082, decode.acc_seg: 52.1847, loss: 1.1082
2021-08-14 20:04:01,869 - mmseg - INFO - Exp name: fcn_litehr30-without-head_512x512_160k_ade20k.py
2021-08-14 20:04:01,869 - mmseg - INFO - Iter [49000/160000]	lr: 7.224e-03, eta: 1 day, 16:22:21, time: 1.284, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1469, decode.acc_seg: 51.2260, loss: 1.1469
2021-08-14 20:05:04,532 - mmseg - INFO - Iter [49050/160000]	lr: 7.221e-03, eta: 1 day, 16:21:09, time: 1.254, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1002, decode.acc_seg: 51.2630, loss: 1.1002
2021-08-14 20:06:05,796 - mmseg - INFO - Iter [49100/160000]	lr: 7.218e-03, eta: 1 day, 16:19:54, time: 1.225, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1192, decode.acc_seg: 52.0233, loss: 1.1192
2021-08-14 20:07:05,403 - mmseg - INFO - Iter [49150/160000]	lr: 7.215e-03, eta: 1 day, 16:18:36, time: 1.192, data_time: 0.016, memory: 5545, decode.loss_seg: 1.0995, decode.acc_seg: 52.0302, loss: 1.0995
2021-08-14 20:08:07,664 - mmseg - INFO - Iter [49200/160000]	lr: 7.212e-03, eta: 1 day, 16:17:23, time: 1.245, data_time: 0.015, memory: 5545, decode.loss_seg: 1.0826, decode.acc_seg: 52.6823, loss: 1.0826
2021-08-14 20:09:45,195 - mmseg - INFO - Iter [49250/160000]	lr: 7.210e-03, eta: 1 day, 16:17:30, time: 1.951, data_time: 0.718, memory: 5545, decode.loss_seg: 1.0868, decode.acc_seg: 53.4504, loss: 1.0868
2021-08-14 20:10:47,070 - mmseg - INFO - Iter [49300/160000]	lr: 7.207e-03, eta: 1 day, 16:16:16, time: 1.238, data_time: 0.016, memory: 5545, decode.loss_seg: 1.0608, decode.acc_seg: 51.8720, loss: 1.0608
2021-08-14 20:11:47,108 - mmseg - INFO - Iter [49350/160000]	lr: 7.204e-03, eta: 1 day, 16:14:58, time: 1.201, data_time: 0.016, memory: 5545, decode.loss_seg: 1.0445, decode.acc_seg: 53.6195, loss: 1.0445
2021-08-14 20:12:47,821 - mmseg - INFO - Iter [49400/160000]	lr: 7.201e-03, eta: 1 day, 16:13:42, time: 1.214, data_time: 0.017, memory: 5545, decode.loss_seg: 1.1278, decode.acc_seg: 51.4102, loss: 1.1278
2021-08-14 20:13:49,174 - mmseg - INFO - Iter [49450/160000]	lr: 7.198e-03, eta: 1 day, 16:12:28, time: 1.227, data_time: 0.017, memory: 5545, decode.loss_seg: 1.0850, decode.acc_seg: 52.3608, loss: 1.0850
2021-08-14 20:14:50,537 - mmseg - INFO - Iter [49500/160000]	lr: 7.195e-03, eta: 1 day, 16:11:13, time: 1.227, data_time: 0.015, memory: 5545, decode.loss_seg: 1.0992, decode.acc_seg: 52.7508, loss: 1.0992
2021-08-14 20:15:52,623 - mmseg - INFO - Iter [49550/160000]	lr: 7.192e-03, eta: 1 day, 16:10:00, time: 1.242, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1265, decode.acc_seg: 52.1389, loss: 1.1265
2021-08-14 20:16:55,593 - mmseg - INFO - Iter [49600/160000]	lr: 7.189e-03, eta: 1 day, 16:08:49, time: 1.259, data_time: 0.017, memory: 5545, decode.loss_seg: 1.0798, decode.acc_seg: 51.9248, loss: 1.0798
2021-08-14 20:17:57,762 - mmseg - INFO - Iter [49650/160000]	lr: 7.186e-03, eta: 1 day, 16:07:36, time: 1.243, data_time: 0.016, memory: 5545, decode.loss_seg: 1.0817, decode.acc_seg: 51.3382, loss: 1.0817
2021-08-14 20:19:00,116 - mmseg - INFO - Iter [49700/160000]	lr: 7.184e-03, eta: 1 day, 16:06:24, time: 1.248, data_time: 0.017, memory: 5545, decode.loss_seg: 1.0829, decode.acc_seg: 52.7815, loss: 1.0829
2021-08-14 20:20:03,149 - mmseg - INFO - Iter [49750/160000]	lr: 7.181e-03, eta: 1 day, 16:05:13, time: 1.260, data_time: 0.017, memory: 5545, decode.loss_seg: 1.1081, decode.acc_seg: 51.8825, loss: 1.1081
2021-08-14 20:21:07,512 - mmseg - INFO - Iter [49800/160000]	lr: 7.178e-03, eta: 1 day, 16:04:05, time: 1.288, data_time: 0.015, memory: 5545, decode.loss_seg: 1.0918, decode.acc_seg: 53.0165, loss: 1.0918
2021-08-14 20:22:44,366 - mmseg - INFO - Iter [49850/160000]	lr: 7.175e-03, eta: 1 day, 16:04:09, time: 1.937, data_time: 0.700, memory: 5545, decode.loss_seg: 1.0928, decode.acc_seg: 52.3431, loss: 1.0928
2021-08-14 20:23:44,819 - mmseg - INFO - Iter [49900/160000]	lr: 7.172e-03, eta: 1 day, 16:02:52, time: 1.209, data_time: 0.017, memory: 5545, decode.loss_seg: 1.0803, decode.acc_seg: 51.8563, loss: 1.0803
2021-08-14 20:24:46,999 - mmseg - INFO - Iter [49950/160000]	lr: 7.169e-03, eta: 1 day, 16:01:40, time: 1.244, data_time: 0.015, memory: 5545, decode.loss_seg: 1.0800, decode.acc_seg: 52.1758, loss: 1.0800
2021-08-14 20:25:46,300 - mmseg - INFO - Exp name: fcn_litehr30-without-head_512x512_160k_ade20k.py
2021-08-14 20:25:46,301 - mmseg - INFO - Iter [50000/160000]	lr: 7.166e-03, eta: 1 day, 16:00:21, time: 1.186, data_time: 0.015, memory: 5545, decode.loss_seg: 1.0638, decode.acc_seg: 53.4199, loss: 1.0638
2021-08-14 20:26:46,516 - mmseg - INFO - Iter [50050/160000]	lr: 7.163e-03, eta: 1 day, 15:59:04, time: 1.204, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1184, decode.acc_seg: 51.7060, loss: 1.1184
2021-08-14 20:27:47,347 - mmseg - INFO - Iter [50100/160000]	lr: 7.160e-03, eta: 1 day, 15:57:48, time: 1.217, data_time: 0.017, memory: 5545, decode.loss_seg: 1.0559, decode.acc_seg: 52.4934, loss: 1.0559
2021-08-14 20:28:47,073 - mmseg - INFO - Iter [50150/160000]	lr: 7.157e-03, eta: 1 day, 15:56:30, time: 1.194, data_time: 0.014, memory: 5545, decode.loss_seg: 1.0968, decode.acc_seg: 52.6104, loss: 1.0968
2021-08-14 20:29:49,432 - mmseg - INFO - Iter [50200/160000]	lr: 7.155e-03, eta: 1 day, 15:55:18, time: 1.248, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1077, decode.acc_seg: 52.5066, loss: 1.1077
2021-08-14 20:30:53,149 - mmseg - INFO - Iter [50250/160000]	lr: 7.152e-03, eta: 1 day, 15:54:09, time: 1.273, data_time: 0.014, memory: 5545, decode.loss_seg: 1.0787, decode.acc_seg: 52.4711, loss: 1.0787
2021-08-14 20:31:55,603 - mmseg - INFO - Iter [50300/160000]	lr: 7.149e-03, eta: 1 day, 15:52:57, time: 1.249, data_time: 0.018, memory: 5545, decode.loss_seg: 1.0881, decode.acc_seg: 52.1209, loss: 1.0881
2021-08-14 20:32:59,301 - mmseg - INFO - Iter [50350/160000]	lr: 7.146e-03, eta: 1 day, 15:51:47, time: 1.273, data_time: 0.015, memory: 5545, decode.loss_seg: 1.0789, decode.acc_seg: 51.5848, loss: 1.0789
2021-08-14 20:34:04,827 - mmseg - INFO - Iter [50400/160000]	lr: 7.143e-03, eta: 1 day, 15:50:42, time: 1.311, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1007, decode.acc_seg: 52.3906, loss: 1.1007
2021-08-14 20:35:08,952 - mmseg - INFO - Iter [50450/160000]	lr: 7.140e-03, eta: 1 day, 15:49:34, time: 1.284, data_time: 0.016, memory: 5545, decode.loss_seg: 1.0726, decode.acc_seg: 53.0177, loss: 1.0726
2021-08-14 20:36:46,820 - mmseg - INFO - Iter [50500/160000]	lr: 7.137e-03, eta: 1 day, 15:49:39, time: 1.957, data_time: 0.728, memory: 5545, decode.loss_seg: 1.1158, decode.acc_seg: 52.5916, loss: 1.1158
2021-08-14 20:37:51,192 - mmseg - INFO - Iter [50550/160000]	lr: 7.134e-03, eta: 1 day, 15:48:31, time: 1.288, data_time: 0.016, memory: 5545, decode.loss_seg: 1.0834, decode.acc_seg: 52.3386, loss: 1.0834
2021-08-14 20:38:52,676 - mmseg - INFO - Iter [50600/160000]	lr: 7.131e-03, eta: 1 day, 15:47:17, time: 1.230, data_time: 0.017, memory: 5545, decode.loss_seg: 1.0557, decode.acc_seg: 53.1156, loss: 1.0557
2021-08-14 20:39:56,248 - mmseg - INFO - Iter [50650/160000]	lr: 7.129e-03, eta: 1 day, 15:46:07, time: 1.272, data_time: 0.015, memory: 5545, decode.loss_seg: 1.0767, decode.acc_seg: 53.3329, loss: 1.0767
2021-08-14 20:40:58,222 - mmseg - INFO - Iter [50700/160000]	lr: 7.126e-03, eta: 1 day, 15:44:54, time: 1.239, data_time: 0.017, memory: 5545, decode.loss_seg: 1.1020, decode.acc_seg: 52.6170, loss: 1.1020
2021-08-14 20:42:02,415 - mmseg - INFO - Iter [50750/160000]	lr: 7.123e-03, eta: 1 day, 15:43:46, time: 1.283, data_time: 0.014, memory: 5545, decode.loss_seg: 1.0504, decode.acc_seg: 53.2294, loss: 1.0504
2021-08-14 20:43:08,891 - mmseg - INFO - Iter [50800/160000]	lr: 7.120e-03, eta: 1 day, 15:42:43, time: 1.330, data_time: 0.017, memory: 5545, decode.loss_seg: 1.0839, decode.acc_seg: 53.3011, loss: 1.0839
2021-08-14 20:44:15,317 - mmseg - INFO - Iter [50850/160000]	lr: 7.117e-03, eta: 1 day, 15:41:39, time: 1.328, data_time: 0.014, memory: 5545, decode.loss_seg: 1.1164, decode.acc_seg: 51.7380, loss: 1.1164
2021-08-14 20:45:21,518 - mmseg - INFO - Iter [50900/160000]	lr: 7.114e-03, eta: 1 day, 15:40:36, time: 1.324, data_time: 0.015, memory: 5545, decode.loss_seg: 1.0963, decode.acc_seg: 51.6634, loss: 1.0963
2021-08-14 20:46:24,444 - mmseg - INFO - Iter [50950/160000]	lr: 7.111e-03, eta: 1 day, 15:39:25, time: 1.259, data_time: 0.017, memory: 5545, decode.loss_seg: 1.0795, decode.acc_seg: 52.7628, loss: 1.0795
2021-08-14 20:47:28,026 - mmseg - INFO - Exp name: fcn_litehr30-without-head_512x512_160k_ade20k.py
2021-08-14 20:47:28,027 - mmseg - INFO - Iter [51000/160000]	lr: 7.108e-03, eta: 1 day, 15:38:15, time: 1.271, data_time: 0.015, memory: 5545, decode.loss_seg: 1.0857, decode.acc_seg: 52.9622, loss: 1.0857
2021-08-14 20:48:29,765 - mmseg - INFO - Iter [51050/160000]	lr: 7.105e-03, eta: 1 day, 15:37:02, time: 1.235, data_time: 0.017, memory: 5545, decode.loss_seg: 1.0874, decode.acc_seg: 51.6812, loss: 1.0874
2021-08-14 20:49:34,139 - mmseg - INFO - Iter [51100/160000]	lr: 7.103e-03, eta: 1 day, 15:35:54, time: 1.287, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1179, decode.acc_seg: 52.6608, loss: 1.1179
2021-08-14 20:51:10,096 - mmseg - INFO - Iter [51150/160000]	lr: 7.100e-03, eta: 1 day, 15:35:54, time: 1.919, data_time: 0.724, memory: 5545, decode.loss_seg: 1.0451, decode.acc_seg: 52.8817, loss: 1.0451
2021-08-14 20:52:10,938 - mmseg - INFO - Iter [51200/160000]	lr: 7.097e-03, eta: 1 day, 15:34:38, time: 1.217, data_time: 0.016, memory: 5545, decode.loss_seg: 1.0909, decode.acc_seg: 52.7265, loss: 1.0909
2021-08-14 20:53:11,294 - mmseg - INFO - Iter [51250/160000]	lr: 7.094e-03, eta: 1 day, 15:33:22, time: 1.207, data_time: 0.015, memory: 5545, decode.loss_seg: 1.0474, decode.acc_seg: 53.6743, loss: 1.0474
2021-08-14 20:54:12,508 - mmseg - INFO - Iter [51300/160000]	lr: 7.091e-03, eta: 1 day, 15:32:07, time: 1.224, data_time: 0.016, memory: 5545, decode.loss_seg: 1.0763, decode.acc_seg: 53.6934, loss: 1.0763
2021-08-14 20:55:12,030 - mmseg - INFO - Iter [51350/160000]	lr: 7.088e-03, eta: 1 day, 15:30:49, time: 1.191, data_time: 0.016, memory: 5545, decode.loss_seg: 1.0502, decode.acc_seg: 53.0313, loss: 1.0502
2021-08-14 20:56:14,404 - mmseg - INFO - Iter [51400/160000]	lr: 7.085e-03, eta: 1 day, 15:29:37, time: 1.247, data_time: 0.016, memory: 5545, decode.loss_seg: 1.0613, decode.acc_seg: 52.0823, loss: 1.0613
2021-08-14 20:57:16,593 - mmseg - INFO - Iter [51450/160000]	lr: 7.082e-03, eta: 1 day, 15:28:25, time: 1.243, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1097, decode.acc_seg: 51.6428, loss: 1.1097
2021-08-14 20:58:17,861 - mmseg - INFO - Iter [51500/160000]	lr: 7.079e-03, eta: 1 day, 15:27:11, time: 1.226, data_time: 0.017, memory: 5545, decode.loss_seg: 1.0884, decode.acc_seg: 51.8247, loss: 1.0884
2021-08-14 20:59:19,500 - mmseg - INFO - Iter [51550/160000]	lr: 7.076e-03, eta: 1 day, 15:25:57, time: 1.232, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1082, decode.acc_seg: 52.0051, loss: 1.1082
2021-08-14 21:00:22,584 - mmseg - INFO - Iter [51600/160000]	lr: 7.074e-03, eta: 1 day, 15:24:47, time: 1.262, data_time: 0.016, memory: 5545, decode.loss_seg: 1.0802, decode.acc_seg: 52.8313, loss: 1.0802
2021-08-14 21:01:23,283 - mmseg - INFO - Iter [51650/160000]	lr: 7.071e-03, eta: 1 day, 15:23:31, time: 1.214, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1028, decode.acc_seg: 51.8716, loss: 1.1028
2021-08-14 21:02:23,913 - mmseg - INFO - Iter [51700/160000]	lr: 7.068e-03, eta: 1 day, 15:22:16, time: 1.213, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1105, decode.acc_seg: 52.8860, loss: 1.1105
2021-08-14 21:04:00,407 - mmseg - INFO - Iter [51750/160000]	lr: 7.065e-03, eta: 1 day, 15:22:15, time: 1.929, data_time: 0.698, memory: 5545, decode.loss_seg: 1.1207, decode.acc_seg: 51.8590, loss: 1.1207
2021-08-14 21:05:01,627 - mmseg - INFO - Iter [51800/160000]	lr: 7.062e-03, eta: 1 day, 15:21:01, time: 1.224, data_time: 0.017, memory: 5545, decode.loss_seg: 1.0715, decode.acc_seg: 51.8851, loss: 1.0715
2021-08-14 21:06:02,405 - mmseg - INFO - Iter [51850/160000]	lr: 7.059e-03, eta: 1 day, 15:19:46, time: 1.216, data_time: 0.016, memory: 5545, decode.loss_seg: 1.0683, decode.acc_seg: 51.9847, loss: 1.0683
2021-08-14 21:07:02,190 - mmseg - INFO - Iter [51900/160000]	lr: 7.056e-03, eta: 1 day, 15:18:29, time: 1.196, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1058, decode.acc_seg: 52.0301, loss: 1.1058
2021-08-14 21:08:02,210 - mmseg - INFO - Iter [51950/160000]	lr: 7.053e-03, eta: 1 day, 15:17:12, time: 1.199, data_time: 0.015, memory: 5545, decode.loss_seg: 1.0807, decode.acc_seg: 53.4355, loss: 1.0807
2021-08-14 21:09:02,691 - mmseg - INFO - Exp name: fcn_litehr30-without-head_512x512_160k_ade20k.py
2021-08-14 21:09:02,692 - mmseg - INFO - Iter [52000/160000]	lr: 7.050e-03, eta: 1 day, 15:15:56, time: 1.210, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1028, decode.acc_seg: 53.1588, loss: 1.1028
2021-08-14 21:10:04,592 - mmseg - INFO - Iter [52050/160000]	lr: 7.048e-03, eta: 1 day, 15:14:43, time: 1.238, data_time: 0.015, memory: 5545, decode.loss_seg: 1.0934, decode.acc_seg: 52.4067, loss: 1.0934
2021-08-14 21:11:06,195 - mmseg - INFO - Iter [52100/160000]	lr: 7.045e-03, eta: 1 day, 15:13:30, time: 1.232, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1134, decode.acc_seg: 52.6361, loss: 1.1134
2021-08-14 21:12:09,626 - mmseg - INFO - Iter [52150/160000]	lr: 7.042e-03, eta: 1 day, 15:12:20, time: 1.268, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1040, decode.acc_seg: 52.4546, loss: 1.1040
2021-08-14 21:13:13,438 - mmseg - INFO - Iter [52200/160000]	lr: 7.039e-03, eta: 1 day, 15:11:11, time: 1.276, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1348, decode.acc_seg: 50.8446, loss: 1.1348
2021-08-14 21:14:19,050 - mmseg - INFO - Iter [52250/160000]	lr: 7.036e-03, eta: 1 day, 15:10:06, time: 1.312, data_time: 0.015, memory: 5545, decode.loss_seg: 1.0896, decode.acc_seg: 52.8620, loss: 1.0896
2021-08-14 21:15:24,686 - mmseg - INFO - Iter [52300/160000]	lr: 7.033e-03, eta: 1 day, 15:09:01, time: 1.313, data_time: 0.015, memory: 5545, decode.loss_seg: 1.0947, decode.acc_seg: 52.0284, loss: 1.0947
2021-08-14 21:16:26,212 - mmseg - INFO - Iter [52350/160000]	lr: 7.030e-03, eta: 1 day, 15:07:48, time: 1.231, data_time: 0.015, memory: 5545, decode.loss_seg: 1.0540, decode.acc_seg: 53.7400, loss: 1.0540
2021-08-14 21:18:04,917 - mmseg - INFO - Iter [52400/160000]	lr: 7.027e-03, eta: 1 day, 15:07:51, time: 1.974, data_time: 0.747, memory: 5545, decode.loss_seg: 1.1091, decode.acc_seg: 52.1218, loss: 1.1091
2021-08-14 21:19:05,586 - mmseg - INFO - Iter [52450/160000]	lr: 7.024e-03, eta: 1 day, 15:06:36, time: 1.214, data_time: 0.018, memory: 5545, decode.loss_seg: 1.0647, decode.acc_seg: 52.5539, loss: 1.0647
2021-08-14 21:20:05,961 - mmseg - INFO - Iter [52500/160000]	lr: 7.021e-03, eta: 1 day, 15:05:20, time: 1.207, data_time: 0.016, memory: 5545, decode.loss_seg: 1.0668, decode.acc_seg: 52.7627, loss: 1.0668
2021-08-14 21:21:05,939 - mmseg - INFO - Iter [52550/160000]	lr: 7.019e-03, eta: 1 day, 15:04:03, time: 1.200, data_time: 0.016, memory: 5545, decode.loss_seg: 1.0918, decode.acc_seg: 52.6028, loss: 1.0918
2021-08-14 21:22:06,540 - mmseg - INFO - Iter [52600/160000]	lr: 7.016e-03, eta: 1 day, 15:02:48, time: 1.211, data_time: 0.015, memory: 5545, decode.loss_seg: 1.0579, decode.acc_seg: 52.3662, loss: 1.0579
2021-08-14 21:23:07,551 - mmseg - INFO - Iter [52650/160000]	lr: 7.013e-03, eta: 1 day, 15:01:33, time: 1.220, data_time: 0.016, memory: 5545, decode.loss_seg: 1.0477, decode.acc_seg: 53.1074, loss: 1.0477
2021-08-14 21:24:06,855 - mmseg - INFO - Iter [52700/160000]	lr: 7.010e-03, eta: 1 day, 15:00:15, time: 1.187, data_time: 0.016, memory: 5545, decode.loss_seg: 1.0779, decode.acc_seg: 52.7308, loss: 1.0779
2021-08-14 21:25:06,998 - mmseg - INFO - Iter [52750/160000]	lr: 7.007e-03, eta: 1 day, 14:58:59, time: 1.203, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1297, decode.acc_seg: 50.6300, loss: 1.1297
2021-08-14 21:26:09,668 - mmseg - INFO - Iter [52800/160000]	lr: 7.004e-03, eta: 1 day, 14:57:48, time: 1.253, data_time: 0.014, memory: 5545, decode.loss_seg: 1.1002, decode.acc_seg: 53.0204, loss: 1.1002
2021-08-14 21:27:15,592 - mmseg - INFO - Iter [52850/160000]	lr: 7.001e-03, eta: 1 day, 14:56:44, time: 1.318, data_time: 0.016, memory: 5545, decode.loss_seg: 1.0618, decode.acc_seg: 52.7726, loss: 1.0618
2021-08-14 21:28:20,990 - mmseg - INFO - Iter [52900/160000]	lr: 6.998e-03, eta: 1 day, 14:55:38, time: 1.308, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1058, decode.acc_seg: 52.2720, loss: 1.1058
2021-08-14 21:29:25,222 - mmseg - INFO - Iter [52950/160000]	lr: 6.995e-03, eta: 1 day, 14:54:30, time: 1.286, data_time: 0.015, memory: 5545, decode.loss_seg: 1.0619, decode.acc_seg: 52.7953, loss: 1.0619
2021-08-14 21:30:26,887 - mmseg - INFO - Exp name: fcn_litehr30-without-head_512x512_160k_ade20k.py
2021-08-14 21:30:26,888 - mmseg - INFO - Iter [53000/160000]	lr: 6.992e-03, eta: 1 day, 14:53:17, time: 1.233, data_time: 0.015, memory: 5545, decode.loss_seg: 1.0776, decode.acc_seg: 52.7631, loss: 1.0776
2021-08-14 21:32:03,391 - mmseg - INFO - Iter [53050/160000]	lr: 6.990e-03, eta: 1 day, 14:53:15, time: 1.931, data_time: 0.709, memory: 5545, decode.loss_seg: 1.0688, decode.acc_seg: 52.3370, loss: 1.0688
2021-08-14 21:33:05,479 - mmseg - INFO - Iter [53100/160000]	lr: 6.987e-03, eta: 1 day, 14:52:02, time: 1.241, data_time: 0.016, memory: 5545, decode.loss_seg: 1.0715, decode.acc_seg: 53.6827, loss: 1.0715
2021-08-14 21:34:09,163 - mmseg - INFO - Iter [53150/160000]	lr: 6.984e-03, eta: 1 day, 14:50:53, time: 1.274, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1245, decode.acc_seg: 52.2818, loss: 1.1245
2021-08-14 21:35:11,615 - mmseg - INFO - Iter [53200/160000]	lr: 6.981e-03, eta: 1 day, 14:49:42, time: 1.249, data_time: 0.015, memory: 5545, decode.loss_seg: 1.0804, decode.acc_seg: 52.9769, loss: 1.0804
2021-08-14 21:36:11,633 - mmseg - INFO - Iter [53250/160000]	lr: 6.978e-03, eta: 1 day, 14:48:26, time: 1.200, data_time: 0.015, memory: 5545, decode.loss_seg: 1.0618, decode.acc_seg: 52.1543, loss: 1.0618
2021-08-14 21:37:11,958 - mmseg - INFO - Iter [53300/160000]	lr: 6.975e-03, eta: 1 day, 14:47:10, time: 1.206, data_time: 0.015, memory: 5545, decode.loss_seg: 1.0822, decode.acc_seg: 52.5603, loss: 1.0822
2021-08-14 21:38:14,937 - mmseg - INFO - Iter [53350/160000]	lr: 6.972e-03, eta: 1 day, 14:46:00, time: 1.259, data_time: 0.016, memory: 5545, decode.loss_seg: 1.0774, decode.acc_seg: 53.2880, loss: 1.0774
2021-08-14 21:39:17,214 - mmseg - INFO - Iter [53400/160000]	lr: 6.969e-03, eta: 1 day, 14:44:48, time: 1.246, data_time: 0.016, memory: 5545, decode.loss_seg: 1.0664, decode.acc_seg: 52.9947, loss: 1.0664
2021-08-14 21:40:19,961 - mmseg - INFO - Iter [53450/160000]	lr: 6.966e-03, eta: 1 day, 14:43:37, time: 1.254, data_time: 0.014, memory: 5545, decode.loss_seg: 1.0404, decode.acc_seg: 52.9264, loss: 1.0404
2021-08-14 21:41:24,530 - mmseg - INFO - Iter [53500/160000]	lr: 6.963e-03, eta: 1 day, 14:42:30, time: 1.292, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1111, decode.acc_seg: 52.2135, loss: 1.1111
2021-08-14 21:42:26,015 - mmseg - INFO - Iter [53550/160000]	lr: 6.961e-03, eta: 1 day, 14:41:17, time: 1.229, data_time: 0.016, memory: 5545, decode.loss_seg: 1.0692, decode.acc_seg: 52.2892, loss: 1.0692
2021-08-14 21:43:27,728 - mmseg - INFO - Iter [53600/160000]	lr: 6.958e-03, eta: 1 day, 14:40:04, time: 1.235, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1113, decode.acc_seg: 51.5201, loss: 1.1113
2021-08-14 21:45:02,738 - mmseg - INFO - Iter [53650/160000]	lr: 6.955e-03, eta: 1 day, 14:39:57, time: 1.900, data_time: 0.708, memory: 5545, decode.loss_seg: 1.0935, decode.acc_seg: 51.5889, loss: 1.0935
2021-08-14 21:46:02,422 - mmseg - INFO - Iter [53700/160000]	lr: 6.952e-03, eta: 1 day, 14:38:40, time: 1.193, data_time: 0.016, memory: 5545, decode.loss_seg: 1.0941, decode.acc_seg: 52.6633, loss: 1.0941
2021-08-14 21:47:02,860 - mmseg - INFO - Iter [53750/160000]	lr: 6.949e-03, eta: 1 day, 14:37:25, time: 1.208, data_time: 0.016, memory: 5545, decode.loss_seg: 1.0967, decode.acc_seg: 53.0343, loss: 1.0967
2021-08-14 21:48:03,896 - mmseg - INFO - Iter [53800/160000]	lr: 6.946e-03, eta: 1 day, 14:36:11, time: 1.221, data_time: 0.017, memory: 5545, decode.loss_seg: 1.0721, decode.acc_seg: 52.6382, loss: 1.0721
2021-08-14 21:49:06,331 - mmseg - INFO - Iter [53850/160000]	lr: 6.943e-03, eta: 1 day, 14:35:00, time: 1.248, data_time: 0.016, memory: 5545, decode.loss_seg: 1.0719, decode.acc_seg: 52.7761, loss: 1.0719
2021-08-14 21:50:09,715 - mmseg - INFO - Iter [53900/160000]	lr: 6.940e-03, eta: 1 day, 14:33:50, time: 1.269, data_time: 0.016, memory: 5545, decode.loss_seg: 1.0380, decode.acc_seg: 52.9201, loss: 1.0380
2021-08-14 21:51:11,185 - mmseg - INFO - Iter [53950/160000]	lr: 6.937e-03, eta: 1 day, 14:32:37, time: 1.230, data_time: 0.015, memory: 5545, decode.loss_seg: 1.0194, decode.acc_seg: 53.6430, loss: 1.0194
2021-08-14 21:52:14,312 - mmseg - INFO - Exp name: fcn_litehr30-without-head_512x512_160k_ade20k.py
2021-08-14 21:52:14,313 - mmseg - INFO - Iter [54000/160000]	lr: 6.934e-03, eta: 1 day, 14:31:27, time: 1.263, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1271, decode.acc_seg: 52.6434, loss: 1.1271
2021-08-14 21:53:14,218 - mmseg - INFO - Iter [54050/160000]	lr: 6.932e-03, eta: 1 day, 14:30:11, time: 1.198, data_time: 0.015, memory: 5545, decode.loss_seg: 1.0885, decode.acc_seg: 52.0875, loss: 1.0885
2021-08-14 21:54:15,191 - mmseg - INFO - Iter [54100/160000]	lr: 6.929e-03, eta: 1 day, 14:28:57, time: 1.219, data_time: 0.016, memory: 5545, decode.loss_seg: 1.0905, decode.acc_seg: 52.6859, loss: 1.0905
2021-08-14 21:55:14,504 - mmseg - INFO - Iter [54150/160000]	lr: 6.926e-03, eta: 1 day, 14:27:39, time: 1.186, data_time: 0.015, memory: 5545, decode.loss_seg: 1.0864, decode.acc_seg: 53.3733, loss: 1.0864
2021-08-14 21:56:15,419 - mmseg - INFO - Iter [54200/160000]	lr: 6.923e-03, eta: 1 day, 14:26:25, time: 1.218, data_time: 0.016, memory: 5545, decode.loss_seg: 1.0798, decode.acc_seg: 53.3206, loss: 1.0798
2021-08-14 21:57:17,017 - mmseg - INFO - Iter [54250/160000]	lr: 6.920e-03, eta: 1 day, 14:25:12, time: 1.231, data_time: 0.015, memory: 5545, decode.loss_seg: 1.0736, decode.acc_seg: 53.4553, loss: 1.0736
2021-08-14 21:58:55,742 - mmseg - INFO - Iter [54300/160000]	lr: 6.917e-03, eta: 1 day, 14:25:12, time: 1.975, data_time: 0.738, memory: 5545, decode.loss_seg: 1.0586, decode.acc_seg: 52.8322, loss: 1.0586
2021-08-14 21:59:55,607 - mmseg - INFO - Iter [54350/160000]	lr: 6.914e-03, eta: 1 day, 14:23:56, time: 1.197, data_time: 0.016, memory: 5545, decode.loss_seg: 1.0763, decode.acc_seg: 53.6893, loss: 1.0763
2021-08-14 22:00:56,094 - mmseg - INFO - Iter [54400/160000]	lr: 6.911e-03, eta: 1 day, 14:22:41, time: 1.210, data_time: 0.016, memory: 5545, decode.loss_seg: 1.0830, decode.acc_seg: 52.4910, loss: 1.0830
2021-08-14 22:01:57,416 - mmseg - INFO - Iter [54450/160000]	lr: 6.908e-03, eta: 1 day, 14:21:27, time: 1.226, data_time: 0.016, memory: 5545, decode.loss_seg: 1.0709, decode.acc_seg: 52.5530, loss: 1.0709
2021-08-14 22:02:59,069 - mmseg - INFO - Iter [54500/160000]	lr: 6.905e-03, eta: 1 day, 14:20:15, time: 1.233, data_time: 0.016, memory: 5545, decode.loss_seg: 1.0847, decode.acc_seg: 52.9786, loss: 1.0847
2021-08-14 22:04:01,282 - mmseg - INFO - Iter [54550/160000]	lr: 6.903e-03, eta: 1 day, 14:19:03, time: 1.244, data_time: 0.015, memory: 5545, decode.loss_seg: 1.0988, decode.acc_seg: 53.2114, loss: 1.0988
2021-08-14 22:05:01,851 - mmseg - INFO - Iter [54600/160000]	lr: 6.900e-03, eta: 1 day, 14:17:48, time: 1.212, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1003, decode.acc_seg: 53.0600, loss: 1.1003
2021-08-14 22:06:03,403 - mmseg - INFO - Iter [54650/160000]	lr: 6.897e-03, eta: 1 day, 14:16:35, time: 1.230, data_time: 0.014, memory: 5545, decode.loss_seg: 1.0633, decode.acc_seg: 52.2842, loss: 1.0633
2021-08-14 22:07:08,791 - mmseg - INFO - Iter [54700/160000]	lr: 6.894e-03, eta: 1 day, 14:15:30, time: 1.307, data_time: 0.015, memory: 5545, decode.loss_seg: 1.0788, decode.acc_seg: 51.6549, loss: 1.0788
2021-08-14 22:08:11,409 - mmseg - INFO - Iter [54750/160000]	lr: 6.891e-03, eta: 1 day, 14:14:19, time: 1.253, data_time: 0.015, memory: 5545, decode.loss_seg: 1.0550, decode.acc_seg: 53.2918, loss: 1.0550
2021-08-14 22:09:13,748 - mmseg - INFO - Iter [54800/160000]	lr: 6.888e-03, eta: 1 day, 14:13:08, time: 1.248, data_time: 0.015, memory: 5545, decode.loss_seg: 1.1091, decode.acc_seg: 52.5519, loss: 1.1091
2021-08-14 22:10:15,741 - mmseg - INFO - Iter [54850/160000]	lr: 6.885e-03, eta: 1 day, 14:11:56, time: 1.239, data_time: 0.014, memory: 5545, decode.loss_seg: 1.0728, decode.acc_seg: 52.6677, loss: 1.0728
2021-08-14 22:11:52,498 - mmseg - INFO - Iter [54900/160000]	lr: 6.882e-03, eta: 1 day, 14:11:51, time: 1.935, data_time: 0.705, memory: 5545, decode.loss_seg: 1.0602, decode.acc_seg: 53.3134, loss: 1.0602
2021-08-14 22:12:55,913 - mmseg - INFO - Iter [54950/160000]	lr: 6.879e-03, eta: 1 day, 14:10:41, time: 1.268, data_time: 0.016, memory: 5545, decode.loss_seg: 1.0686, decode.acc_seg: 52.0075, loss: 1.0686
2021-08-14 22:14:01,421 - mmseg - INFO - Exp name: fcn_litehr30-without-head_512x512_160k_ade20k.py
2021-08-14 22:14:01,422 - mmseg - INFO - Iter [55000/160000]	lr: 6.876e-03, eta: 1 day, 14:09:36, time: 1.310, data_time: 0.015, memory: 5545, decode.loss_seg: 1.0368, decode.acc_seg: 53.9622, loss: 1.0368
2021-08-14 22:15:07,491 - mmseg - INFO - Iter [55050/160000]	lr: 6.874e-03, eta: 1 day, 14:08:32, time: 1.321, data_time: 0.016, memory: 5545, decode.loss_seg: 1.0702, decode.acc_seg: 52.4136, loss: 1.0702
2021-08-14 22:16:11,343 - mmseg - INFO - Iter [55100/160000]	lr: 6.871e-03, eta: 1 day, 14:07:24, time: 1.278, data_time: 0.016, memory: 5545, decode.loss_seg: 1.0721, decode.acc_seg: 53.6204, loss: 1.0721
2021-08-14 22:17:11,366 - mmseg - INFO - Iter [55150/160000]	lr: 6.868e-03, eta: 1 day, 14:06:08, time: 1.201, data_time: 0.016, memory: 5545, decode.loss_seg: 1.0965, decode.acc_seg: 53.2555, loss: 1.0965
2021-08-14 22:18:13,435 - mmseg - INFO - Iter [55200/160000]	lr: 6.865e-03, eta: 1 day, 14:04:56, time: 1.241, data_time: 0.015, memory: 5545, decode.loss_seg: 1.0888, decode.acc_seg: 52.6282, loss: 1.0888
2021-08-14 22:19:14,777 - mmseg - INFO - Iter [55250/160000]	lr: 6.862e-03, eta: 1 day, 14:03:43, time: 1.227, data_time: 0.017, memory: 5545, decode.loss_seg: 1.0863, decode.acc_seg: 53.1925, loss: 1.0863
2021-08-14 22:20:14,385 - mmseg - INFO - Iter [55300/160000]	lr: 6.859e-03, eta: 1 day, 14:02:27, time: 1.192, data_time: 0.016, memory: 5545, decode.loss_seg: 1.0683, decode.acc_seg: 53.7128, loss: 1.0683
2021-08-14 22:21:16,139 - mmseg - INFO - Iter [55350/160000]	lr: 6.856e-03, eta: 1 day, 14:01:14, time: 1.235, data_time: 0.016, memory: 5545, decode.loss_seg: 1.0868, decode.acc_seg: 51.4738, loss: 1.0868
2021-08-14 22:22:18,600 - mmseg - INFO - Iter [55400/160000]	lr: 6.853e-03, eta: 1 day, 14:00:04, time: 1.250, data_time: 0.016, memory: 5545, decode.loss_seg: 1.0903, decode.acc_seg: 52.4448, loss: 1.0903
2021-08-14 22:23:20,517 - mmseg - INFO - Iter [55450/160000]	lr: 6.850e-03, eta: 1 day, 13:58:52, time: 1.238, data_time: 0.016, memory: 5545, decode.loss_seg: 1.0575, decode.acc_seg: 53.1984, loss: 1.0575
2021-08-14 22:24:22,910 - mmseg - INFO - Iter [55500/160000]	lr: 6.847e-03, eta: 1 day, 13:57:41, time: 1.248, data_time: 0.015, memory: 5545, decode.loss_seg: 1.0722, decode.acc_seg: 53.1328, loss: 1.0722
2021-08-14 22:26:00,923 - mmseg - INFO - Iter [55550/160000]	lr: 6.844e-03, eta: 1 day, 13:57:37, time: 1.961, data_time: 0.731, memory: 5545, decode.loss_seg: 1.0548, decode.acc_seg: 52.4528, loss: 1.0548
2021-08-14 22:27:01,562 - mmseg - INFO - Iter [55600/160000]	lr: 6.842e-03, eta: 1 day, 13:56:22, time: 1.213, data_time: 0.016, memory: 5545, decode.loss_seg: 1.0606, decode.acc_seg: 52.9915, loss: 1.0606
2021-08-14 22:28:05,043 - mmseg - INFO - Iter [55650/160000]	lr: 6.839e-03, eta: 1 day, 13:55:13, time: 1.269, data_time: 0.015, memory: 5545, decode.loss_seg: 1.0744, decode.acc_seg: 52.6820, loss: 1.0744
2021-08-14 22:29:10,501 - mmseg - INFO - Iter [55700/160000]	lr: 6.836e-03, eta: 1 day, 13:54:08, time: 1.309, data_time: 0.014, memory: 5545, decode.loss_seg: 1.0565, decode.acc_seg: 53.0862, loss: 1.0565
2021-08-14 22:30:16,464 - mmseg - INFO - Iter [55750/160000]	lr: 6.833e-03, eta: 1 day, 13:53:03, time: 1.319, data_time: 0.015, memory: 5545, decode.loss_seg: 1.0579, decode.acc_seg: 53.2948, loss: 1.0579
2021-08-14 22:31:21,139 - mmseg - INFO - Iter [55800/160000]	lr: 6.830e-03, eta: 1 day, 13:51:57, time: 1.295, data_time: 0.016, memory: 5545, decode.loss_seg: 1.1192, decode.acc_seg: 51.7177, loss: 1.1192
2021-08-14 22:32:25,396 - mmseg - INFO - Iter [55850/160000]	lr: 6.827e-03, eta: 1 day, 13:50:49, time: 1.284, data_time: 0.015, memory: 5545, decode.loss_seg: 1.0858, decode.acc_seg: 52.4752, loss: 1.0858
2021-08-14 22:33:29,996 - mmseg - INFO - Iter [55900/160000]	lr: 6.824e-03, eta: 1 day, 13:49:42, time: 1.293, data_time: 0.015, memory: 5545, decode.loss_seg: 1.0804, decode.acc_seg: 52.9615, loss: 1.0804
2021-08-14 22:34:33,771 - mmseg - INFO - Iter [55950/160000]	lr: 6.821e-03, eta: 1 day, 13:48:34, time: 1.275, data_time: 0.015, memory: 5545, decode.loss_seg: 1.0949, decode.acc_seg: 52.6145, loss: 1.0949
2021-08-14 22:35:34,819 - mmseg - INFO - Exp name: fcn_litehr30-without-head_512x512_160k_ade20k.py
2021-08-14 22:35:34,819 - mmseg - INFO - Iter [56000/160000]	lr: 6.818e-03, eta: 1 day, 13:47:20, time: 1.221, data_time: 0.017, memory: 5545, decode.loss_seg: 1.0543, decode.acc_seg: 52.8620, loss: 1.0543
2021-08-14 22:36:36,627 - mmseg - INFO - Iter [56050/160000]	lr: 6.815e-03, eta: 1 day, 13:46:08, time: 1.236, data_time: 0.016, memory: 5545, decode.loss_seg: 1.0734, decode.acc_seg: 53.2184, loss: 1.0734
2021-08-14 22:37:37,012 - mmseg - INFO - Iter [56100/160000]	lr: 6.813e-03, eta: 1 day, 13:44:53, time: 1.207, data_time: 0.015, memory: 5545, decode.loss_seg: 1.0942, decode.acc_seg: 52.8368, loss: 1.0942
2021-08-14 22:38:37,960 - mmseg - INFO - Iter [56150/160000]	lr: 6.810e-03, eta: 1 day, 13:43:40, time: 1.219, data_time: 0.016, memory: 5545, decode.loss_seg: 1.0562, decode.acc_seg: 53.1995, loss: 1.0562
